#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      QMC QUANTUM TESTING FRAMEWORK v2.5.23                           â•‘
â•‘                           QMC Research Lab - 2025                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Framework rÃ©utilisable et EXTENSIBLE pour tests quantiques â•‘
â•‘                                                                                      â•‘
â•‘  CHANGELOG v2.5.23 (2025-01-05) - MEGA UPDATE: 18 NOUVELLES FONCTIONNALITÃ‰S:        â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [NEW] SimulatorComparator: Comparaison automatique Sim â†” QPU avec mÃ©triques        â•‘
â•‘        - compare(): Fidelity, TVD, KL-divergence, Hellinger, XEB                     â•‘
â•‘        - generate_report(): Rapport HTML comparatif                                  â•‘
â•‘  [NEW] XEBCalculator: Cross-Entropy Benchmarking intÃ©grÃ© (preuve avantage quantique)â•‘
â•‘        - compute(): Score XEB avec intervalle de confiance                           â•‘
â•‘        - compute_from_circuits(): XEB automatique depuis circuits                    â•‘
â•‘  [NEW] BudgetAlertManager: Alertes budget QPU multi-seuils                          â•‘
â•‘        - Seuils configurables (50%, 80%, 95%)                                        â•‘
â•‘        - Callbacks personnalisÃ©s, blocage automatique                                â•‘
â•‘  [NEW] DryRunManager: Mode simulation complÃ¨te SANS envoi QPU                       â•‘
â•‘        - Validation circuits, transpilation, estimation coÃ»t                         â•‘
â•‘        - DÃ©tection erreurs avant consommation budget                                 â•‘
â•‘  [NEW] CampaignManager: Campagnes d'expÃ©riences paramÃ©triques                       â•‘
â•‘        - Variations automatiques de paramÃ¨tres                                       â•‘
â•‘        - Rapports comparatifs HTML, export DataFrame                                 â•‘
â•‘  [NEW] ArchiveReplayer: Replay d'expÃ©riences depuis archives JSON                   â•‘
â•‘        - ReproductibilitÃ© garantie                                                   â•‘
â•‘        - Comparaison multi-backend                                                   â•‘
â•‘  [NEW] AnomalyDetector: DÃ©tection automatique d'anomalies                           â•‘
â•‘        - Qubits dÃ©faillants, bruit excessif, dÃ©cohÃ©rence                            â•‘
â•‘        - Recommandations automatiques                                                â•‘
â•‘  [NEW] GitTracker: IntÃ©gration Git pour traÃ§abilitÃ© code â†” rÃ©sultats               â•‘
â•‘        - Commit hash, branch, dirty status dans archives                             â•‘
â•‘        - VÃ©rification reproductibilitÃ©                                               â•‘
â•‘  [NEW] MultiBackendRunner: ExÃ©cution multi-backend simultanÃ©e                       â•‘
â•‘        - Comparaison performances entre backends                                     â•‘
â•‘        - Ranking automatique, analyse consistance                                    â•‘
â•‘  [NEW] StandardBenchmarks: Suite de benchmarks intÃ©grÃ©s                             â•‘
â•‘        - Mirror circuits, Layer fidelity, Quantum Volume                             â•‘
â•‘        - Score global avec interprÃ©tation                                            â•‘
â•‘  [NEW] PublicationExporter: Export LaTeX/PDF/Markdown pour publications             â•‘
â•‘        - Format INPI (N&B) avec prompts JSON pour figures                            â•‘
â•‘        - Compatible arXiv et journaux scientifiques                                  â•‘
â•‘  [NEW] CorrelationAnalyzer: Analyse corrÃ©lations inter-qubits                       â•‘
â•‘        - Matrice de corrÃ©lation, dÃ©tection crosstalk                                 â•‘
â•‘        - Identification qubits problÃ©matiques                                        â•‘
â•‘  [NEW] TranspilationCache: Cache intelligent de transpilation                       â•‘
â•‘        - Ã‰vite re-transpilation circuits identiques                                  â•‘
â•‘        - TTL configurable, statistiques hit/miss                                     â•‘
â•‘  [NEW] WebDashboard: Dashboard web temps rÃ©el (localhost)                           â•‘
â•‘        - Visualisation jobs, historique, statistiques                                â•‘
â•‘        - API REST pour intÃ©grations                                                  â•‘
â•‘  [NEW] NotificationHub: Notifications multi-canal                                   â•‘
â•‘        - Console, fichier, email SMTP, webhooks (Slack/Discord)                      â•‘
â•‘        - Ã‰vÃ©nements configurables                                                    â•‘
â•‘  [NEW] JobScheduler: Planification de jobs diffÃ©rÃ©s                                 â•‘
â•‘        - ExÃ©cution Ã  heure fixe (heures creuses)                                     â•‘
â•‘        - DÃ©clenchement sur file d'attente basse                                      â•‘
â•‘  [NEW] DatabaseExporter: Export vers bases de donnÃ©es                               â•‘
â•‘        - SQLite (local), PostgreSQL                                                  â•‘
â•‘        - RequÃªtes SQL pour analyses                                                  â•‘
â•‘  [NEW] AdversarialCircuitGenerator: Circuits pour stress-test QPU                   â•‘
â•‘        - noise_sensitivity, depth_stress, connectivity_stress                        â•‘
â•‘        - crosstalk_probe, decoherence_test                                           â•‘
â•‘                                                                                      â•‘
â•‘  CHANGELOG v2.5.22 (2025-01-01) - COMPATIBILITÃ‰ Ã‰MULATEUR â†” QPU & AUDIT:            â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [CRITICAL] _normalize_counts_format(): Conversion formats SANS ALTÃ‰RER QPU         â•‘
â•‘             - Si format dÃ©jÃ  correct â†’ retourne counts ORIGINAUX (pas de copie)     â•‘
â•‘             - Conversion auto: QuasiDist (intâ†’str), probas (floatâ†’int), '0b' prefix â•‘
â•‘  [AUDIT] Certification technique: Framework n'altÃ¨re PAS les rÃ©sultats IBM Runtime  â•‘
â•‘  [NEW] ParamÃ¨tre shots dans constructeur: QMCFramework(shots=4096)                  â•‘
â•‘        - DÃ©finit le dÃ©faut pour tous les run_on_qpu() sans shots explicite          â•‘
â•‘        - run_on_qpu(circuits) utilise self.default_shots automatiquement            â•‘
â•‘        - run_on_qpu(circuits, shots=8192) override toujours le dÃ©faut               â•‘
â•‘  [NEW] Support multi-format rÃ©sultats:                                              â•‘
â•‘        - FORMAT 1: SamplerV2 IBM (pub_result.data.c.get_counts())                   â•‘
â•‘        - FORMAT 2: QuasiDistribution ({0: 0.5, 3: 0.5} â†’ {'00': 512, '11': 512})   â•‘
â•‘        - FORMAT 3: Dict bitstrings direct ({'00': 500})                             â•‘
â•‘  [NEW] result_format dans rÃ©sultats: TraÃ§abilitÃ© du format dÃ©tectÃ©                  â•‘
â•‘  [NEW] Mise Ã  jour pÃ©riodique file d'attente (toutes les 45s en mode QUEUED)        â•‘
â•‘  [NEW] Affichage nombre jobs dans animation: "En file d'attente (12 jobs)..."       â•‘
â•‘  [NEW] queue_update_interval paramÃ¨tre dans _monitor_job_with_reconnect()           â•‘
â•‘  [FIX] Warning multi-registres si plusieurs registres classiques dÃ©tectÃ©s           â•‘
â•‘                                                                                      â•‘
â•‘  CHANGELOG v2.5.21 (2025-12-26) - JOB RECOVERY & ROBUST MONITORING:                 â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [NEW] retrieve_job_results(job_id): RÃ©cupÃ¨re les rÃ©sultats d'un job existant        â•‘
â•‘        - Reprise aprÃ¨s dÃ©connexion rÃ©seau/VPN                                        â•‘
â•‘        - CLI: --recover-job JOB_ID, --list-jobs                                      â•‘
â•‘  [NEW] Monitoring robuste ACTIVÃ‰ PAR DÃ‰FAUT (timeout 45s + reconnexion auto)         â•‘
â•‘        - Ã‰vite blocage si VPN/rÃ©seau coupÃ© pendant un job                            â•‘
â•‘        - DÃ©sactiver: QMC_ROBUST_MONITORING=false (non recommandÃ©)                    â•‘
â•‘  [NEW] _safe_get_job_result() avec timeout 120s sur job.result()                     â•‘
â•‘  [NEW] run_on_qpu_batched(): Multi-job pour grandes expÃ©riences (>100 circuits)      â•‘
â•‘  [NEW] check_dependencies(): VÃ©rifie les packages pip au dÃ©marrage (--check-deps)    â•‘
â•‘  [SEC] Archive JSON gÃ©nÃ©rÃ©e EN PREMIER aprÃ¨s run (sÃ©curise donnÃ©es avant rapport)    â•‘
â•‘                                                                                      â•‘
â•‘  CHANGELOG v2.5.20 (2025-12-25) - IBM CARBON DESIGN SYSTEM:                         â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [NEW] QiskitVisualizationWrapper: Wrappers pour plot_state_city, plot_state_qsphere â•‘
â•‘  [NEW] plot_bloch_multivector, plot_state_hinton, plot_state_paulivec intÃ©grÃ©s       â•‘
â•‘  [NEW] plot_gate_map, plot_error_map, plot_circuit_layout, plot_coupling_map         â•‘
â•‘  [NEW] QiskitQuantumInfoWrapper: DÃ©lÃ©gation vers qiskit.quantum_info natif           â•‘
â•‘  [NEW] RuntimeErrorMitigationConfig: Configuration ZNE/PEC/TREX/DD via Runtime       â•‘
â•‘  [ENH] FidelityAnalyzer: Utilise hellinger_fidelity Qiskit natif                     â•‘
â•‘  [ENH] EntropyAnalyzer: Utilise entropy/shannon_entropy Qiskit natif                 â•‘
â•‘  [ENH] CorrelationAnalyzer: Utilise mutual_information Qiskit natif                  â•‘
â•‘  [ENH] AutoReportGenerator: GÃ©nÃ¨re visualisations Qiskit natives dans rapports       â•‘
â•‘  [ENH] Transpilation: Utilise generate_preset_pass_manager Qiskit optimisÃ©           â•‘
â•‘  [NEW] IBM Carbon Design System intÃ©grÃ© - palette couleurs officielle IBM            â•‘
â•‘  [NEW] Police IBM Plex Sans/Mono (Google Fonts) remplace Inter/JetBrains             â•‘
â•‘  [NEW] CSS Variables IBM: --ibm-blue-60 (#0f62fe), --ibm-gray-100 (#161616)          â•‘
â•‘  [NEW] Spacing IBM 2x Grid: --spacing-01 Ã  --spacing-09                              â•‘
â•‘  [NEW] Colormap IBM personnalisÃ© pour heatmaps (blueâ†’yellowâ†’red)                     â•‘
â•‘                                                                                      â•‘
â•‘  CHANGELOG v2.5.18 (2025-12-20) - PROTECTION DES RÃ‰SULTATS QPU:                     â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [CRITICAL] Rapport HTML + Archive JSON TOUJOURS gÃ©nÃ©rÃ©s par dÃ©faut                  â•‘
â•‘  [CRITICAL] ParamÃ¨tres generate_report/generate_archive IGNORÃ‰S dans le code!        â•‘
â•‘  [CRITICAL] Seul le fichier .env peut dÃ©sactiver (protection anti-perte donnÃ©es)     â•‘
â•‘  [NEW] Variables d'environnement: QMC_GENERATE_REPORT, QMC_GENERATE_ARCHIVE          â•‘
â•‘  [NEW] Fonction _load_qmc_env_config() charge config .env au dÃ©marrage               â•‘
â•‘  [NEW] Fonction _get_env_bool() lit boolÃ©ens depuis environnement                    â•‘
â•‘  [ENH] Warning affichÃ© si programmeur tente de dÃ©sactiver via paramÃ¨tres             â•‘
â•‘  [DOC] Guide AI/dÃ©veloppeur avec script dÃ©mo et checklist bonnes pratiques           â•‘
â•‘                                                                                      â•‘
â•‘  CHANGELOG v2.5.16 (2025-12-18) - PRODUCTIVITÃ‰ & OUTILS AVANCÃ‰S:                    â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [NEW] BatchManager: Gestion intelligente de gros jobs en batches avec retry auto    â•‘
â•‘  [NEW] BudgetManager: Gestion du budget QPU mensuel avec alertes et tracking         â•‘
â•‘  [NEW] CircuitProfiler: Analyse dÃ©taillÃ©e des circuits AVANT transpilation           â•‘
â•‘  [NEW] ResultComparator: Comparaison de rÃ©sultats (TVD, fidÃ©litÃ©, JS divergence)     â•‘
â•‘  [NEW] HTMLDashboard: GÃ©nÃ©ration de rapports HTML interactifs avec graphiques        â•‘
â•‘  [ENH] BatchManager: DÃ©coupage automatique, checkpoint, reprise, callback            â•‘
â•‘  [ENH] BudgetManager: Alertes Ã  50/75/90/100%, blocage optionnel, historique         â•‘
â•‘  [ENH] CircuitProfiler: Score complexitÃ©, bottlenecks, prÃ©diction transpilation      â•‘
â•‘  [ENH] ResultComparator: MÃ©triques TVD/fidelity/KL/JS/chiÂ², top diffÃ©rences          â•‘
â•‘  [ENH] HTMLDashboard: Charts Chart.js, thÃ¨me dark, export PDF via navigateur         â•‘
â•‘                                                                                      â•‘
â•‘  CHANGELOG v2.5.15 (2025-12-16) - CIRCUIT BUILDERS + DIAGNOSTIC ERREURS:             â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [NEW] 10 nouveaux CircuitBuilders algorithmiques (Grover, Simon, QPE, etc.)         â•‘
â•‘  [NEW] diagnose_job_error(): Diagnostic dÃ©taillÃ© des jobs IBM en erreur              â•‘
â•‘  [NEW] _get_job_error_details(): Extraction automatique des messages d'erreur IBM    â•‘
â•‘  [ENH] Affichage dÃ©taillÃ© des erreurs lors d'Ã©chec job (causes + recommandations)    â•‘
â•‘  [FIX] initialize(): config.get() sur None + collision clÃ© 'config'                  â•‘
â•‘  [FIX] estimate_cost()/run_on_qpu_with_confirm(): DÃ©placÃ©s vers QMCFramework         â•‘
â•‘                                                                                      â•‘
â•‘  CHANGELOG v2.5.14 (2025-12-15) - CRITICAL FIX + UX + SECURITY:                      â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [CRITICAL] SmartRetryManager: Ajout paramÃ¨tre jitter (manquait = TypeError)         â•‘
â•‘  [UX] Animation d'upload avec barre de progression pendant envoi vers IBM            â•‘
â•‘  [UX] Animation d'attente visible pendant exÃ©cution QPU (QUEUED/RUNNING/DONE)        â•‘
â•‘  [UX] Banner de soumission avec Job ID, circuits, shots                              â•‘
â•‘  [UX] RÃ©sumÃ© final avec durÃ©e par phase (QUEUED, RUNNING)                            â•‘
â•‘  [SECURITY] private=True: Tags IBM appliquÃ©s (QMC_PRIVATE, CONFIDENTIAL)             â•‘
â•‘  [SECURITY] auto_delete_job=True: Suppression job aprÃ¨s rÃ©cupÃ©ration rÃ©sultats       â•‘
â•‘  [SECURITY] redact_logs=True: Logs rÃ©duits au niveau WARNING uniquement              â•‘
â•‘  [SECURITY] production_mode=True: Active le triptyque sÃ©curitÃ© complet               â•‘
â•‘  [SECURITY] _apply_private_tags(): 3 mÃ©thodes fallback pour tags IBM                 â•‘
â•‘  [SECURITY] _secure_delete_job(): Suppression sÃ©curisÃ©e avec 3 mÃ©thodes fallback     â•‘
â•‘  [SECURITY] Banner sÃ©curitÃ© affichÃ© si mode cryptographique activÃ©                   â•‘
â•‘  [SECURITY] get_job_info(): with_inputs=False par dÃ©faut + forcÃ© en production_mode  â•‘
â•‘  [SECURITY] download_all_accounts_jobs(): with_logs interdit en production_mode      â•‘
â•‘  [SECURITY] JobQueueManager: Auto-delete intÃ©grÃ© dans _update_statuses()             â•‘
â•‘  [SECURITY] QMCSecurityError: Nouvelle exception pour violations de sÃ©curitÃ©         â•‘
â•‘  [CRITICAL] Confirmation OBLIGATOIRE avant envoi QPU (auto_confirm=False par dÃ©faut) â•‘
â•‘  [CRITICAL] _confirm_qpu_submission(): Affiche rÃ©sumÃ© + stats transpilation + GO/WARNâ•‘
â•‘  [CRITICAL] Score transpilation: 0-100 avec recommandation GO/WARN/NO-GO             â•‘
â•‘  [CRITICAL] layout_strategy='auto': Compare avec/sans prÃ©-layout, garde le meilleur  â•‘
â•‘  [CRITICAL] _transpile_smart_comparison(): Ã‰vite les catastrophes de routing         â•‘
â•‘  [UX] Auto-wrapping: run_on_qpu/transpile acceptent circuit unique OU liste          â•‘
â•‘  [CLI] --private, --auto-delete-job, --redact-logs, --production-mode, --auto-confirmâ•‘
â•‘                                                                                      â•‘
â•‘  CHANGELOG v2.5.13 (2025-12-15) - Checkpoints #10/#11 TestabilitÃ©:                   â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [FIX] MitigationConfig: Warnings ZNE/PEC/readout NOT_IMPLEMENTED si activÃ©s         â•‘
â•‘  [FIX] configure_sampler_options: shots_per_randomization + dÃ©tection dynamic circ.  â•‘
â•‘  [FIX] QAEE: Protection division par zÃ©ro si total=0                                 â•‘
â•‘  [TEST] run_on_qpu: Injection sampler_factory pour tests sans IBM                    â•‘
â•‘  [TEST] JobMonitor: Injection clock/sleep pour tests temporels                       â•‘
â•‘  [TEST] FakeJob + FakeSamplerV2: Classes de mock complÃ¨tes pour tests offline        â•‘
â•‘                                                                                      â•‘
â•‘  CHANGELOG v2.5.12 (2025-12-15) - Checkpoints #6/#7/#8 Fixes:                        â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [CRITICAL] XEBCrossValidationAnalyzer: Bootstrap sampling multinomial (mÃ©moire)     â•‘
â•‘  [CRITICAL] QuantumAdvantageAnalyzer: Heavy Output test utilise ideal_dist ou N/A    â•‘
â•‘  [FIX] HoneypotAnalyzer: Utilise expected_signature + flag authorized                â•‘
â•‘  [FIX] ResultCache: Hash stable json.dumps(sort_keys=True) + QPY fallback            â•‘
â•‘  [FIX] run_on_qpu: Retry unifiÃ© SmartRetryManager, Checkpoint enrichi                â•‘
â•‘  [FIX] JobQueueManager: Support backend par item + switch automatique                â•‘
â•‘  [FIX] ReportExporter: ConsolidÃ© HTML/LaTeX, EnhancedReportExporter dÃ©prÃ©ciÃ©         â•‘
â•‘  [FIX] Auto-registration: Lazy si QMC_LAZY_REGISTER=1                                â•‘
â•‘                                                                                      â•‘
â•‘  ARCHITECTURE v2.0:                                                                  â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  â”‚  PLUGIN SYSTEM          â”‚  CIRCUIT BUILDERS        â”‚  EXPERIMENT ENGINE         â”‚ â•‘
â•‘  â”‚  - Module Registry      â”‚  - GHZ, IQP, Cluster     â”‚  - Parameter Sweeps        â”‚ â•‘
â•‘  â”‚  - Auto-discovery       â”‚  - Bell, Random          â”‚  - Multi-config runs       â”‚ â•‘
â•‘  â”‚  - Hot-reload           â”‚  - Custom templates      â”‚  - Batch orchestration     â”‚ â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â•‘
â•‘  â”‚  CRYPTO VALIDATION      â”‚  PROTOCOL TESTER         â”‚  SECURITY OPTIONS          â”‚ â•‘
â•‘  â”‚  - NIST randomness      â”‚  - E2E encryption        â”‚  - private (tags IBM)      â”‚ â•‘
â•‘  â”‚  - Entropy analysis     â”‚  - Authentication        â”‚  - auto_delete_job         â”‚ â•‘
â•‘  â”‚  - Key derivation       â”‚  - Signature verify      â”‚  - redact_logs             â”‚ â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â•‘
â•‘  â”‚  DATA PIPELINE          â”‚  BENCHMARK SUITE         â”‚  TESTING SUPPORT           â”‚ â•‘
â•‘  â”‚  - Transformations      â”‚  - Standard tests        â”‚  - FakeJob / FakeSampler   â”‚ â•‘
â•‘  â”‚  - Aggregations         â”‚  - Baseline compare      â”‚  - Clock injection         â”‚ â•‘
â•‘  â”‚  - Stream processing    â”‚  - Performance scoring   â”‚  - Offline validation      â”‚ â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”„ v2.5.22 - MIGRATION DEPUIS v2.5.21 (COMPATIBILITÃ‰ Ã‰MULATEUR â†” QPU)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚ âš ï¸ AUCUNE MODIFICATION REQUISE DANS VOS SCRIPTS!                                        â”‚
â”‚                                                                                         â”‚
â”‚ La v2.5.22 est 100% rÃ©trocompatible avec v2.5.21. Vos scripts existants fonctionnent   â”‚
â”‚ sans aucune modification. Les rÃ©sultats QPU sont retournÃ©s IDENTIQUES.                  â”‚
â”‚                                                                                         â”‚
â”‚ CE QUI A CHANGÃ‰ (transparentement):                                                     â”‚
â”‚   âœ“ Support automatique des formats Ã©mulateur (QuasiDistribution, probas float)        â”‚
â”‚   âœ“ Conversion automatique si nÃ©cessaire: {0: 0.5} â†’ {'00': 512}                        â”‚
â”‚   âœ“ Si format dÃ©jÃ  correct (QPU) â†’ retourne counts ORIGINAUX (mÃªme rÃ©fÃ©rence!)         â”‚
â”‚   âœ“ Nouveau champ 'result_format' dans les rÃ©sultats (traÃ§abilitÃ©)                      â”‚
â”‚   âœ“ Mise Ã  jour pÃ©riodique file d'attente (toutes les 45s)                              â”‚
â”‚                                                                                         â”‚
â”‚ GARANTIES DE NON-ALTÃ‰RATION:                                                            â”‚
â”‚   âœ“ Counts QPU retournÃ©s par RÃ‰FÃ‰RENCE (pas de copie, pas de modification)              â”‚
â”‚   âœ“ sum(counts.values()) == shots (toujours)                                            â”‚
â”‚   âœ“ ProbabilitÃ©s = counts / shots (calcul exact)                                        â”‚
â”‚   âœ“ Archive JSON identique en structure                                                 â”‚
â”‚   âœ“ Rapport HTML identique en format                                                    â”‚
â”‚                                                                                         â”‚
â”‚ NOUVEAU COMPORTEMENT (automatique):                                                     â”‚
â”‚   # MÃªme script fonctionne avec QPU ET simulateur:                                      â”‚
â”‚   results = fw.run_on_qpu(circuits)  # â† QPU: counts intacts                            â”‚
â”‚   results = simulate_local(circuits)  # â† Simulateur: conversion auto                   â”‚
â”‚                                                                                         â”‚
â”‚   # Le format de sortie est TOUJOURS le mÃªme:                                           â”‚
â”‚   for r in results:                                                                     â”‚
â”‚       counts = r['counts']  # Dict[str, int] garanti                                    â”‚
â”‚       for bitstring, count in counts.items():                                           â”‚
â”‚           print(f"{bitstring}: {count}")  # Fonctionne QPU et simulateur                â”‚
â”‚                                                                                         â”‚
â”‚ SI VOUS UTILISEZ UN SIMULATEUR EXTERNE:                                                 â”‚
â”‚   # Avant v2.5.22 - peut Ã©chouer si format diffÃ©rent:                                   â”‚
â”‚   counts = external_simulator_result  # {0: 500, 3: 500} â† clÃ©s entiÃ¨res!              â”‚
â”‚                                                                                         â”‚
â”‚   # Avec v2.5.22 - fonctionne automatiquement:                                          â”‚
â”‚   counts = external_simulator_result  # Converti en {'00': 500, '11': 500}              â”‚
â”‚                                                                                         â”‚
â”‚ NOUVELLE OPTION (optionnelle):                                                          â”‚
â”‚   results = fw.run_on_qpu(circuits)                                                     â”‚
â”‚   print(results[0]['result_format'])  # 'BitArray', 'QuasiDistribution', etc.           â”‚
â”‚                                                                                         â”‚
â”‚ TEST DE VÃ‰RIFICATION:                                                                   â”‚
â”‚   # VÃ©rifier que counts QPU ne sont pas modifiÃ©s:                                       â”‚
â”‚   original_counts = {'00': 2048, '11': 2048}                                            â”‚
â”‚   result = fw._normalize_counts_format(original_counts)                                 â”‚
â”‚   assert result is original_counts  # MÃªme rÃ©fÃ©rence = pas de modification              â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ†• v2.5.16 - OUTILS DE PRODUCTIVITÃ‰ (5 nouvelles classes)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚ ğŸ“¦ BATCH MANAGER - Gestion intelligente des gros jobs:                                  â”‚
â”‚   # Via propriÃ©tÃ© (lazy init)                                                           â”‚
â”‚   results = fw.batch_manager.submit_all(circuits, shots=4096)                           â”‚
â”‚                                                                                         â”‚
â”‚   # Configuration manuelle                                                              â”‚
â”‚   bm = BatchManager(framework=fw, max_circuits_per_batch=30)                            â”‚
â”‚   batches = bm.split_into_batches(circuits, shots=4096)                                 â”‚
â”‚   results = bm.submit_all(circuits, shots=4096,                                         â”‚
â”‚       on_batch_complete=lambda i, r: print(f"Batch {i} done"),                          â”‚
â”‚       on_batch_error=lambda i, e: print(f"Error: {e}"))                                 â”‚
â”‚                                                                                         â”‚
â”‚   # FonctionnalitÃ©s:                                                                    â”‚
â”‚   - DÃ©coupage automatique selon circuits/shots/complexitÃ©                               â”‚
â”‚   - Retry automatique des batches en erreur                                             â”‚
â”‚   - Checkpoints intermÃ©diaires pour reprise                                             â”‚
â”‚   - Callbacks de progression                                                            â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ’° BUDGET MANAGER - ContrÃ´le du budget QPU mensuel:                                     â”‚
â”‚   # Configuration rapide                                                                â”‚
â”‚   fw.set_budget(monthly_minutes=100, alert_at=80, block_on_exceed=True)                 â”‚
â”‚                                                                                         â”‚
â”‚   # Utilisation                                                                         â”‚
â”‚   if fw.budget.can_execute(estimated_minutes=2.5):                                      â”‚
â”‚       results = fw.run_on_qpu(circuits)                                                 â”‚
â”‚       fw.budget.record_usage(results)  # Enregistre automatiquement                     â”‚
â”‚                                                                                         â”‚
â”‚   # MÃ©thodes disponibles                                                                â”‚
â”‚   fw.budget.get_current_month_usage()  # Minutes utilisÃ©es ce mois                      â”‚
â”‚   fw.budget.get_remaining_budget()     # Minutes restantes                              â”‚
â”‚   fw.budget.get_usage_percent()        # Pourcentage utilisÃ©                            â”‚
â”‚   fw.budget.display_status()           # Affiche barre de progression                   â”‚
â”‚                                                                                         â”‚
â”‚   # FonctionnalitÃ©s:                                                                    â”‚
â”‚   - Alertes automatiques Ã  50%, 75%, 90%, 100%                                          â”‚
â”‚   - Blocage optionnel si budget dÃ©passÃ©                                                 â”‚
â”‚   - Historique persistant (~/.qmc_budget_history.json)                                  â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ”¬ CIRCUIT PROFILER - Analyse AVANT transpilation:                                      â”‚
â”‚   # Profiler et afficher                                                                â”‚
â”‚   profile = fw.profile_circuit(circuit, display=True)                                   â”‚
â”‚                                                                                         â”‚
â”‚   # AccÃ¨s aux mÃ©triques                                                                 â”‚
â”‚   profile['basic_metrics']      # qubits, depth, size                                   â”‚
â”‚   profile['gate_analysis']      # 1Q/2Q gates, mesures                                  â”‚
â”‚   profile['complexity_score']   # Score 0-100 (SIMPLE/MODÃ‰RÃ‰/COMPLEXE)                  â”‚
â”‚   profile['bottlenecks']        # Liste des goulots (depth, 2Q gates, coherence)        â”‚
â”‚   profile['suggestions']        # Optimisations suggÃ©rÃ©es                               â”‚
â”‚   profile['transpile_prediction']  # Profondeur estimÃ©e aprÃ¨s transpilation             â”‚
â”‚   profile['estimated_time']     # Temps circuit (ns, Âµs, ms, par 4096 shots)            â”‚
â”‚                                                                                         â”‚
â”‚   # Batch profiling                                                                     â”‚
â”‚   profiles = fw.profiler.profile_batch(circuits)                                        â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ“Š RESULT COMPARATOR - Comparaison de rÃ©sultats:                                        â”‚
â”‚   # Comparer deux distributions                                                         â”‚
â”‚   comparison = fw.compare_results(counts_sim, counts_qpu, "Sim", "QPU", display=True)   â”‚
â”‚                                                                                         â”‚
â”‚   # MÃ©triques de divergence                                                             â”‚
â”‚   comparison['divergence']['tvd']          # Total Variation Distance (0-1)             â”‚
â”‚   comparison['divergence']['fidelity']     # FidÃ©litÃ© classique (0-1)                   â”‚
â”‚   comparison['divergence']['kl_divergence'] # KL Divergence                             â”‚
â”‚   comparison['divergence']['js_divergence'] # Jensen-Shannon Divergence                 â”‚
â”‚   comparison['divergence']['chi_squared']   # Chi-squared statistic                     â”‚
â”‚                                                                                         â”‚
â”‚   # QualitÃ© globale                                                                     â”‚
â”‚   comparison['summary']['quality']  # EXCELLENT/BON/ACCEPTABLE/MÃ‰DIOCRE/MAUVAIS         â”‚
â”‚   comparison['top_differences']     # Top 10 bitstrings avec plus grande divergence     â”‚
â”‚                                                                                         â”‚
â”‚   # Comparer des listes de rÃ©sultats                                                    â”‚
â”‚   comp = fw.comparator.compare_results(results_a, results_b, "A", "B")                  â”‚
â”‚   comp['aggregate']['mean_tvd']     # TVD moyenne sur tous les circuits                 â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ“ˆ HTML DASHBOARD - Rapports interactifs:                                               â”‚
â”‚   # GÃ©nÃ©rer et ouvrir dans navigateur                                                   â”‚
â”‚   filepath = fw.generate_dashboard(results, title="Mon Rapport", open_browser=True)     â”‚
â”‚                                                                                         â”‚
â”‚   # GÃ©nÃ©rer sans ouvrir                                                                 â”‚
â”‚   filepath = fw.dashboard.generate(results, title="Rapport", include_charts=True)       â”‚
â”‚                                                                                         â”‚
â”‚   # FonctionnalitÃ©s:                                                                    â”‚
â”‚   - ThÃ¨me dark moderne                                                                  â”‚
â”‚   - Graphiques Chart.js interactifs                                                     â”‚
â”‚   - Tableaux de donnÃ©es                                                                 â”‚
â”‚   - Export PDF via navigateur (Ctrl+P)                                                  â”‚
â”‚   - Responsive design                                                                   â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ†• v2.5.17 - RAPPORT HTML AUTOMATIQUE (ULTRA-COMPLET)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚ âš¡ GÃ‰NÃ‰RATION AUTOMATIQUE APRÃˆS CHAQUE run_on_qpu():                                    â”‚
â”‚   results = fw.run_on_qpu(circuits, shots=4096)  # Rapport gÃ©nÃ©rÃ© automatiquement!      â”‚
â”‚   # â†’ Fichier HTML crÃ©Ã© dans le rÃ©pertoire de sortie                                    â”‚
â”‚   # â†’ GÃ©nÃ©rÃ© mÃªme en cas d'ERREUR pour diagnostic                                       â”‚
â”‚                                                                                         â”‚
â”‚ ğŸš« DÃ‰SACTIVER LA GÃ‰NÃ‰RATION:                                                            â”‚
â”‚   results = fw.run_on_qpu(circuits, shots=4096, generate_report=False)                  â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ“Š CONTENU DU RAPPORT:                                                                  â”‚
â”‚   - RÃ©sumÃ© exÃ©cutif (SUCCESS/ERROR, circuits, shots, temps)                             â”‚
â”‚   - Timeline d'exÃ©cution (soumission â†’ queue â†’ QPU â†’ terminÃ©)                           â”‚
â”‚   - Configuration complÃ¨te (backend, options, job_id)                                   â”‚
â”‚   - Calibration du backend (T1, T2, erreurs readout, qubits faulty)                     â”‚
â”‚   - Statistiques avancÃ©es (entropie, uniformitÃ©, top bitstrings)                        â”‚
â”‚   - Graphiques interactifs Chart.js (distributions)                                     â”‚
â”‚   - DÃ©tails par circuit (tableau)                                                       â”‚
â”‚   - Section erreur avec traceback si ERROR                                              â”‚
â”‚   - Export JSON des donnÃ©es brutes                                                      â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ”§ ACCÃˆS AU GÃ‰NÃ‰RATEUR:                                                                 â”‚
â”‚   fw.report_generator              # Instance AutoReportGenerator                       â”‚
â”‚   fw.last_report_path              # Chemin du dernier rapport                          â”‚
â”‚   fw.open_last_report()            # Ouvrir dans le navigateur                          â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ“ GÃ‰NÃ‰RATION MANUELLE:                                                                 â”‚
â”‚   from qmc_quantum_framework_v2_5_16 import AutoReportGenerator                         â”‚
â”‚   gen = AutoReportGenerator(framework=fw)                                               â”‚
â”‚   path = gen.generate(results=results, run_context=ctx, error=None)                     â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“¦ v2.5.17 - ARCHIVE JSON COMPLÃˆTE (MEGA-FICHIER POUR ANALYSE)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚ âš¡ GÃ‰NÃ‰RATION AUTOMATIQUE APRÃˆS CHAQUE run_on_qpu():                                    â”‚
â”‚   results = fw.run_on_qpu(circuits, shots=4096)  # Archive JSON gÃ©nÃ©rÃ©e auto!           â”‚
â”‚   # â†’ Fichier JSON COMPLET crÃ©Ã© avec TOUT le contexte d'exÃ©cution                       â”‚
â”‚   # â†’ Parfait pour envoyer Ã  un serveur d'analyse externe                               â”‚
â”‚                                                                                         â”‚
â”‚ ğŸš« DÃ‰SACTIVER LA GÃ‰NÃ‰RATION:                                                            â”‚
â”‚   results = fw.run_on_qpu(circuits, shots=4096, generate_archive=False)                 â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ“¦ CONTENU DE L'ARCHIVE JSON:                                                           â”‚
â”‚   â”œâ”€â”€ metadata          # Timestamp, version, projet, hostname                          â”‚
â”‚   â”œâ”€â”€ backend           # Nom, version, num_qubits, basis_gates, max_shots              â”‚
â”‚   â”œâ”€â”€ calibration       # Ã‰tat COMPLET QPU (156 qubits, T1/T2, erreurs, gates)          â”‚
â”‚   â”‚   â”œâ”€â”€ qubits[]      # T1, T2, frÃ©quence, readout_error par qubit                    â”‚
â”‚   â”‚   â”œâ”€â”€ gates_1q[]    # Erreur et durÃ©e par gate 1-qubit                              â”‚
â”‚   â”‚   â”œâ”€â”€ gates_2q[]    # Erreur et durÃ©e par connexion CX/ECR                          â”‚
â”‚   â”‚   â””â”€â”€ coupling_map  # Topologie complÃ¨te                                            â”‚
â”‚   â”œâ”€â”€ circuits          # Circuits ORIGINAUX (QASM, depth, gates, qubits)               â”‚
â”‚   â”œâ”€â”€ transpiled_circuits  # Circuits TRANSPILÃ‰S (aprÃ¨s optimisation)                   â”‚
â”‚   â”œâ”€â”€ transpilation     # Config: optimization_level, layout_strategy                   â”‚
â”‚   â”œâ”€â”€ mitigation        # Config: twirling, DD, ZNE                                     â”‚
â”‚   â”œâ”€â”€ execution         # Job ID, timing dÃ©taillÃ©, queue, QPU time                      â”‚
â”‚   â”œâ”€â”€ results           # Counts COMPLETS + probabilitÃ©s + top bitstrings               â”‚
â”‚   â”œâ”€â”€ statistics        # Entropie, uniformitÃ©, moments statistiques                    â”‚
â”‚   â”œâ”€â”€ error             # Traceback complet si erreur                                   â”‚
â”‚   â””â”€â”€ integrity         # SHA256 checksums pour validation                              â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ”§ ACCÃˆS AU GÃ‰NÃ‰RATEUR:                                                                 â”‚
â”‚   fw.archive_generator          # Instance ExecutionArchive                             â”‚
â”‚   fw.last_archive_path          # Chemin de la derniÃ¨re archive                         â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ“¤ USAGE POUR SERVEUR D'ANALYSE:                                                        â”‚
â”‚   import json, requests                                                                 â”‚
â”‚   with open(fw.last_archive_path) as f:                                                 â”‚
â”‚       data = json.load(f)                                                               â”‚
â”‚   requests.post('https://analysis.server/upload', json=data)                            â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ“ GÃ‰NÃ‰RATION MANUELLE:                                                                 â”‚
â”‚   from qmc_quantum_framework_v2_5_16 import ExecutionArchive                            â”‚
â”‚   archive = ExecutionArchive(framework=fw, compress=True)  # .json.gz                   â”‚
â”‚   path = archive.generate(results=results, circuits=circ, run_context=ctx)              â”‚
â”‚                                                                                         â”‚
â”‚ ğŸ“Š TAILLE TYPIQUE:                                                                      â”‚
â”‚   - 10 circuits IQP 50q: ~5-10 MB                                                       â”‚
â”‚   - 100 circuits: ~50-100 MB                                                            â”‚
â”‚   - Avec compress=True: ~80% plus petit                                                 â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” v2.5.15 - DIAGNOSTIC D'ERREURS IBM                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚ DIAGNOSTIC D'UN JOB EN ERREUR:                                                          â”‚
â”‚   diagnosis = fw.diagnose_job_error(job_id, verbose=True)                               â”‚
â”‚   # Affiche: message d'erreur, causes possibles, recommandations                        â”‚
â”‚                                                                                         â”‚
â”‚ EXTRACTION AUTOMATIQUE D'ERREURS:                                                       â”‚
â”‚   details = fw._get_job_error_details(job)  # DÃ©tails complets                          â”‚
â”‚   details = fw._extract_ibm_error_details(exception)  # Depuis exception                â”‚
â”‚                                                                                         â”‚
â”‚ GESTION AUTOMATIQUE:                                                                    â”‚
â”‚   - Erreurs de transpilation: diagnostic + suggestions                                  â”‚
â”‚   - Erreurs de soumission: banner avec causes possibles                                 â”‚
â”‚   - Erreurs de job: analyse automatique (timeout, calibration, etc.)                    â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                                         â•‘
â•‘       ğŸš¨ğŸš¨ğŸš¨  ATTENTION CRITIQUE POUR LES DÃ‰VELOPPEURS  ğŸš¨ğŸš¨ğŸš¨                  â•‘
â•‘                                                                                         â•‘
â•‘       âš ï¸  TOUJOURS UTILISER auto_confirm=False (dÃ©faut) POUR Ã‰VITER LES               â•‘
â•‘           ENVOIS ACCIDENTELS SUR QPU QUI CONSOMMENT DU TEMPS COÃ›TEUX !                  â•‘
â•‘                                                                                         â•‘
â•‘       âš ï¸  SI VOUS METTEZ auto_confirm=True, IL N'Y AURA PAS DE CONFIRMATION            â•‘
â•‘           AVANT L'ENVOI DU JOB â†’ RISQUE DE GASPILLAGE DE BUDGET QPU !                   â•‘
â•‘                                                                                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš ï¸ v2.5.18 - PROTECTION DES RÃ‰SULTATS QPU                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚ ATTENTION: Les paramÃ¨tres generate_report=False et generate_archive=False sont IGNORÃ‰S! â”‚
â”‚                                                                                         â”‚
â”‚ Pourquoi? Pour Ã©viter les pertes accidentelles de rÃ©sultats QPU prÃ©cieux.               â”‚
â”‚ Le programmeur ne peut PAS dÃ©sactiver la gÃ©nÃ©ration via le code.                        â”‚
â”‚                                                                                         â”‚
â”‚ SEUL L'UTILISATEUR peut dÃ©sactiver via un fichier .env:                                 â”‚
â”‚                                                                                         â”‚
â”‚   # CrÃ©er un fichier .env dans le rÃ©pertoire de travail                                 â”‚
â”‚   QMC_GENERATE_REPORT=false                                                             â”‚
â”‚   QMC_GENERATE_ARCHIVE=false                                                            â”‚
â”‚   QMC_AUTO_CONFIRM=true      # âš ï¸ DANGEREUX: Skip confirmation avant envoi QPU!        â”‚
â”‚                                                                                         â”‚
â”‚ Si le programmeur tente de modifier via paramÃ¨tres, un WARNING s'affiche:               â”‚
â”‚   "âš ï¸ ParamÃ¨tre xxx=... IGNORÃ‰! Pour modifier: .env"                                   â”‚
â”‚                                                                                         â”‚
â”‚ Cette protection garantit que:                                                          â”‚
â”‚   âœ“ Chaque exÃ©cution QPU gÃ©nÃ¨re des traces exploitables                                 â”‚
â”‚   âœ“ Les rÃ©sultats ne sont jamais perdus par erreur de code                              â”‚
â”‚   âœ“ La confirmation avant envoi QPU est obligatoire (protection budget)                 â”‚
â”‚   âœ“ L'utilisateur garde le contrÃ´le total via .env                                      â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ†• v2.5.21 - QISKIT NATIVE INTEGRATION (Don't reinvent the wheel, extend it)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚ Cette version intÃ¨gre les fonctionnalitÃ©s Qiskit natives pour Ã©viter les               â”‚
â”‚ rÃ©implÃ©mentations inutiles. Le framework dÃ©lÃ¨gue Ã  Qiskit ce qu'il fait mieux.         â”‚
â”‚                                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚ ğŸ“Š NOUVELLE CLASSE: QiskitVisualizationWrapper                                          â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                                         â”‚
â”‚ Wrapper pour les visualisations Qiskit avec style IBM Carbon automatique.               â”‚
â”‚                                                                                         â”‚
â”‚   from qmc_quantum_framework_v2_5_21 import QiskitVisualizationWrapper                  â”‚
â”‚                                                                                         â”‚
â”‚   viz = QiskitVisualizationWrapper(output_dir="./figures")                              â”‚
â”‚                                                                                         â”‚
â”‚   # Histogrammes                                                                        â”‚
â”‚   viz.plot_histogram(counts, title="Results", filename="hist.png")                      â”‚
â”‚                                                                                         â”‚
â”‚   # Visualisations d'Ã©tat quantique (Statevector/DensityMatrix)                         â”‚
â”‚   viz.plot_state_city(statevector, filename="city.png")                                 â”‚
â”‚   viz.plot_state_qsphere(statevector, filename="qsphere.png")                           â”‚
â”‚   viz.plot_bloch_multivector(statevector, filename="bloch.png")                         â”‚
â”‚   viz.plot_state_hinton(statevector, filename="hinton.png")                             â”‚
â”‚   viz.plot_state_paulivec(statevector, filename="pauli.png")                            â”‚
â”‚                                                                                         â”‚
â”‚   # Visualisations backend                                                              â”‚
â”‚   viz.plot_gate_map(backend, filename="gatemap.png")                                    â”‚
â”‚   viz.plot_error_map(backend, filename="errors.png")                                    â”‚
â”‚   viz.plot_coupling_map(backend, filename="coupling.png")                               â”‚
â”‚   viz.plot_circuit_layout(circuit, backend, filename="layout.png")                      â”‚
â”‚                                                                                         â”‚
â”‚   # GÃ©nÃ©rer TOUTES les visualisations d'un Ã©tat                                         â”‚
â”‚   files = viz.generate_all_state_visualizations(statevector, prefix="bell")             â”‚
â”‚   # â†’ {'city': 'bell_city.png', 'qsphere': 'bell_qsphere.png', ...}                     â”‚
â”‚                                                                                         â”‚
â”‚ Couleurs IBM Carbon intÃ©grÃ©es:                                                          â”‚
â”‚   viz.IBM_BLUE_60   = '#0f62fe'                                                         â”‚
â”‚   viz.IBM_TEAL_50   = '#009d9a'                                                         â”‚
â”‚   viz.IBM_PURPLE_60 = '#8a3ffc'                                                         â”‚
â”‚   viz.IBM_GREEN_60  = '#198038'                                                         â”‚
â”‚   viz.IBM_RED_60    = '#da1e28'                                                         â”‚
â”‚                                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚ ğŸ”¬ NOUVELLE CLASSE: QiskitQuantumInfoWrapper                                            â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                                         â”‚
â”‚ Wrapper pour qiskit.quantum_info - mÃ©triques quantiques natives (optimisÃ©es C/Rust).    â”‚
â”‚                                                                                         â”‚
â”‚   from qmc_quantum_framework_v2_5_21 import QiskitQuantumInfoWrapper as QI              â”‚
â”‚                                                                                         â”‚
â”‚   # FidÃ©litÃ©s                                                                           â”‚
â”‚   QI.state_fidelity(state1, state2)              # FidÃ©litÃ© d'Ã©tat                      â”‚
â”‚   QI.hellinger_fidelity(counts1, counts2)        # FidÃ©litÃ© Hellinger (counts)          â”‚
â”‚   QI.process_fidelity(channel, target)           # FidÃ©litÃ© de processus                â”‚
â”‚   QI.average_gate_fidelity(channel, target)      # FidÃ©litÃ© moyenne de porte            â”‚
â”‚                                                                                         â”‚
â”‚   # Entropies                                                                           â”‚
â”‚   QI.entropy(state, base=2)                      # Entropie von-Neumann                 â”‚
â”‚   QI.shannon_entropy(probs, base=2)              # Entropie de Shannon                  â”‚
â”‚                                                                                         â”‚
â”‚   # Autres mÃ©triques                                                                    â”‚
â”‚   QI.purity(state)                               # PuretÃ© (0 Ã  1)                       â”‚
â”‚   QI.concurrence(state_2q)                       # Concurrence (intrication 2q)         â”‚
â”‚   QI.mutual_information(state, base=2)           # Information mutuelle                 â”‚
â”‚   QI.partial_trace(state, [0])                   # Trace partielle                      â”‚
â”‚                                                                                         â”‚
â”‚   # Analyse complÃ¨te de counts                                                          â”‚
â”‚   analysis = QI.analyze_counts(counts, ideal_counts)                                    â”‚
â”‚   # â†’ {'total_counts': 4096, 'unique_outcomes': 4, 'hellinger_fidelity': 0.98, ...}     â”‚
â”‚                                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚ ğŸ›¡ï¸ NOUVELLE CLASSE: RuntimeErrorMitigationConfig                                       â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                                         â”‚
â”‚ Configuration pour l'error mitigation via Qiskit Runtime (cÃ´tÃ© serveur IBM).           â”‚
â”‚                                                                                         â”‚
â”‚   from qmc_quantum_framework_v2_5_21 import RuntimeErrorMitigationConfig                â”‚
â”‚                                                                                         â”‚
â”‚   # Niveaux prÃ©dÃ©finis                                                                  â”‚
â”‚   config0 = RuntimeErrorMitigationConfig.no_mitigation()   # Level 0: Aucune            â”‚
â”‚   config1 = RuntimeErrorMitigationConfig.standard()        # Level 1: DD + TREX         â”‚
â”‚   config2 = RuntimeErrorMitigationConfig.full()            # Level 2: + ZNE + Twirling  â”‚
â”‚                                                                                         â”‚
â”‚   # Application Ã  EstimatorV2 / SamplerV2                                               â”‚
â”‚   config2.apply_to_estimator(estimator)                                                 â”‚
â”‚   config1.apply_to_sampler(sampler)                                                     â”‚
â”‚                                                                                         â”‚
â”‚   # Export configuration                                                                â”‚
â”‚   config_dict = config2.to_dict()                                                       â”‚
â”‚                                                                                         â”‚
â”‚ Tableau des techniques par niveau:                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚   â”‚ Technique               â”‚ Level 0 â”‚ Level 1 â”‚ Level 2 â”‚                             â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                             â”‚
â”‚   â”‚ Dynamical Decoupling    â”‚    âŒ   â”‚    âœ…   â”‚    âœ…   â”‚                             â”‚
â”‚   â”‚ TREX (Measure Mitig.)   â”‚    âŒ   â”‚    âœ…   â”‚    âœ…   â”‚                             â”‚
â”‚   â”‚ ZNE (Zero Noise Extrap.)â”‚    âŒ   â”‚    âŒ   â”‚    âœ…   â”‚                             â”‚
â”‚   â”‚ Gate Twirling           â”‚    âŒ   â”‚    âŒ   â”‚    âœ…   â”‚                             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚ âš¡ NOUVELLE CLASSE: QiskitTranspilerWrapper                                             â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                                         â”‚
â”‚ Wrapper pour le transpiler Qiskit optimisÃ© (83x plus rapide que manuel).                â”‚
â”‚                                                                                         â”‚
â”‚   from qmc_quantum_framework_v2_5_21 import QiskitTranspilerWrapper                     â”‚
â”‚                                                                                         â”‚
â”‚   # Transpilation avec PassManager optimisÃ©                                             â”‚
â”‚   transpiled = QiskitTranspilerWrapper.transpile(                                       â”‚
â”‚       circuits, backend, optimization_level=2, seed_transpiler=42                       â”‚
â”‚   )                                                                                     â”‚
â”‚                                                                                         â”‚
â”‚   # Obtenir le PassManager pour rÃ©utilisation                                           â”‚
â”‚   pm = QiskitTranspilerWrapper.get_pass_manager(backend, optimization_level=2)          â”‚
â”‚                                                                                         â”‚
â”‚   # Analyser la transpilation (avant vs aprÃ¨s)                                          â”‚
â”‚   analysis = QiskitTranspilerWrapper.analyze_transpilation(original, transpiled)        â”‚
â”‚   # â†’ {'original_depth': 10, 'transpiled_depth': 8, 'depth_reduction': 2,               â”‚
â”‚   #    'original_2q_gates': 5, 'transpiled_2q_gates': 4, ...}                           â”‚
â”‚                                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚ ğŸ”„ INTÃ‰GRATIONS DANS CLASSES EXISTANTES                                                 â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ ResultVisualizer - Nouvelles mÃ©thodes:                                                â”‚
â”‚   rv = ResultVisualizer(output_dir="./plots")                                           â”‚
â”‚   rv.plot_histogram(counts, use_qiskit=True)      # Utilise Qiskit histogram            â”‚
â”‚   rv.plot_state_visualization(state, "city")      # Visualisation d'Ã©tat                â”‚
â”‚   rv.plot_all_state_visualizations(state)         # Toutes les visualisations           â”‚
â”‚   rv.plot_backend_topology(backend)               # Gate map du backend                 â”‚
â”‚   rv.plot_error_map(backend)                      # Error map du backend                â”‚
â”‚   rv.plot_circuit_layout(circuit, backend)        # Layout aprÃ¨s transpilation          â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ CalibrationVisualizer - Nouvelles mÃ©thodes:                                           â”‚
â”‚   cv = CalibrationVisualizer(topology)                                                  â”‚
â”‚   cv.export_gate_map(backend, output_dir)         # PNG gate map                        â”‚
â”‚   cv.export_error_map(backend, output_dir)        # PNG error map                       â”‚
â”‚   cv.export_calibration_heatmap(output_dir)       # PNG quality heatmap                 â”‚
â”‚   cv.export_all_visualizations(backend, dir)      # Tout en une fois                    â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ ErrorMitigationManager - Nouvelles mÃ©thodes:                                          â”‚
â”‚   em = ErrorMitigationManager()                                                         â”‚
â”‚   em.set_runtime_level(2)                         # Configure Runtime level 0-2         â”‚
â”‚   em.configure_estimator(estimator)               # Applique config Ã  EstimatorV2       â”‚
â”‚   em.configure_sampler(sampler)                   # Applique config Ã  SamplerV2         â”‚
â”‚   summary = em.get_summary()                      # Inclut runtime_config               â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ ResultComparator - AmÃ©liorations:                                                     â”‚
â”‚   rc = ResultComparator()                                                               â”‚
â”‚   comparison = rc.compare(counts1, counts2)                                             â”‚
â”‚   # â†’ divergence.hellinger_fidelity (Qiskit natif)                                      â”‚
â”‚   # â†’ divergence.qiskit_native = True (marker)                                          â”‚
â”‚   analysis = rc.analyze_with_qiskit(counts1, counts2)  # Nouvelle mÃ©thode               â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ AutoReportGenerator - Nouvelles mÃ©thodes:                                             â”‚
â”‚   arg = AutoReportGenerator(framework=fw)                                               â”‚
â”‚   viz_files = arg.generate_qiskit_visualizations(results, backend)                      â”‚
â”‚   path = arg.generate(results, include_qiskit_viz=True)  # Nouveau paramÃ¨tre            â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ FidelityAnalyzer - AmÃ©liorations:                                                     â”‚
â”‚   fa = FidelityAnalyzer()                                                               â”‚
â”‚   result = fa.analyze(counts, ideal_counts=ideal)                                       â”‚
â”‚   # â†’ 'hellinger_fidelity' prÃ©sent si ideal_counts fourni                               â”‚
â”‚   comparison = fa.compare_distributions(counts1, counts2)  # Nouvelle mÃ©thode           â”‚
â”‚   # â†’ {'hellinger_fidelity': 0.98, 'tvd': 0.02, 'similarity': 0.98}                     â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ EntropyAnalyzer - AmÃ©liorations:                                                      â”‚
â”‚   ea = EntropyAnalyzer()                                                                â”‚
â”‚   result = ea.analyze(counts)                                                           â”‚
â”‚   # â†’ 'collision_entropy' (RÃ©nyi H2) prÃ©sent                                            â”‚
â”‚   # â†’ 'qiskit_native': True (marker)                                                    â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ CorrelationAnalyzer - AmÃ©liorations:                                                  â”‚
â”‚   ca = CorrelationAnalyzer()                                                            â”‚
â”‚   result = ca.analyze(counts)                                                           â”‚
â”‚   # â†’ 'std', 'min', 'max' des corrÃ©lations prÃ©sents                                     â”‚
â”‚                                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚ âŒ NE PLUS RÃ‰IMPLÃ‰MENTER (utiliser Qiskit):                                             â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                                         â”‚
â”‚   âŒ Transpilation        â†’ generate_preset_pass_manager (83x plus rapide)              â”‚
â”‚   âŒ State Fidelity       â†’ qiskit.quantum_info.state_fidelity                          â”‚
â”‚   âŒ Hellinger Fidelity   â†’ qiskit.quantum_info.hellinger_fidelity                      â”‚
â”‚   âŒ Shannon Entropy      â†’ qiskit.quantum_info.shannon_entropy                         â”‚
â”‚   âŒ Von-Neumann Entropy  â†’ qiskit.quantum_info.entropy                                 â”‚
â”‚   âŒ Visualisations d'Ã©tat â†’ qiskit.visualization.plot_state_*                          â”‚
â”‚   âŒ Error Mitigation     â†’ Runtime resilience_level 0-2                                â”‚
â”‚                                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚ âœ… GARDER NOS IMPLÃ‰MENTATIONS (valeur unique QMC):                                      â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                                         â”‚
â”‚   âœ… IQPBuilder             â†’ Circuits #P-hard pour cryptographie (brevet)              â”‚
â”‚   âœ… DynamicTopology        â†’ SÃ©lection qubits basÃ©e sur calibration live               â”‚
â”‚   âœ… AutoReportGenerator    â†’ Rapports HTML IBM Carbon complets                         â”‚
â”‚   âœ… ExecutionArchive       â†’ Archive JSON complÃ¨te pour reproductibilitÃ©               â”‚
â”‚   âœ… â†’ Authentification QPU par bruit 8D (brevet)                â”‚
â”‚   âœ… BatchManager           â†’ Gestion multi-comptes avec rotation                       â”‚
â”‚   âœ… BudgetManager          â†’ Suivi budget QPU mensuel                                  â”‚
â”‚   âœ… Modules brevets        â†’ QMC Core, Shield, Biometric, QGP, QAEE                    â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ†• NOUVELLES FONCTIONNALITÃ‰S v2.5.23 - 18 HELPERS AVANCÃ‰S (LECTURE SEULE)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚ âš ï¸  IMPORTANT: Ces outils sont des HELPERS qui LISENT les rÃ©sultats sans les modifier. â”‚
â”‚     Ils encapsulent Qiskit et ajoutent des fonctionnalitÃ©s qui n'existent pas.         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚ ğŸ“Š ANALYSE & VALIDATION                                                                 â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ SimulatorComparator - Comparaison automatique Sim â†” QPU                              â”‚
â”‚   comparator = SimulatorComparator(fw)                                                  â”‚
â”‚   comparison = comparator.compare(circuits, qpu_results,                                â”‚
â”‚                                   metrics=['fidelity', 'tvd', 'xeb'])                   â”‚
â”‚   comparator.generate_report(comparison, "report.html")                                 â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ XEBCalculator - Cross-Entropy Benchmarking (preuve avantage quantique)               â”‚
â”‚   xeb = XEBCalculator(method='linear')  # ou 'log'                                      â”‚
â”‚   result = xeb.compute(qpu_counts, ideal_probs, n_qubits=50)                            â”‚
â”‚   # â†’ {'xeb_score': 0.85, 'confidence_interval_95': (0.82, 0.88)}                       â”‚
â”‚   batch_result = xeb.compute_from_circuits(circuits, qpu_results)                       â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ AnomalyDetector - DÃ©tection automatique d'anomalies                                  â”‚
â”‚   detector = AnomalyDetector(bias_threshold=0.7, noise_threshold=0.3)                   â”‚
â”‚   analysis = detector.analyze(results, expected_states=['00', '11'])                    â”‚
â”‚   # â†’ {'suspicious_qubits': [23, 45], 'recommendations': [...]}                         â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ InterQubitCorrelationAnalyzer - Analyse corrÃ©lations inter-qubits                    â”‚
â”‚   analyzer = InterQubitCorrelationAnalyzer()                                            â”‚
â”‚   correlations = analyzer.analyze(results)                                              â”‚
â”‚   # â†’ {'correlation_matrix': [...], 'strong_correlations': [...]}                       â”‚
â”‚   analyzer.visualize_matrix(correlations['correlation_matrix'], "matrix.txt")           â”‚
â”‚                                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚ ğŸ§ª EXPÃ‰RIMENTATION                                                                      â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ DryRunManager - Mode simulation SANS envoi QPU                                       â”‚
â”‚   dry_run = DryRunManager(fw)                                                           â”‚
â”‚   result = dry_run.run(circuits, shots=4096,                                            â”‚
â”‚                        include_transpilation=True, include_cost=True)                   â”‚
â”‚   print(dry_run.display(result))  # Affichage ASCII du rÃ©sultat                         â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ CampaignManager - Campagnes d'expÃ©riences paramÃ©triques                              â”‚
â”‚   campaign.add_variation("n_qubits", [50, 75, 100])                                     â”‚
â”‚   campaign.add_variation("depth", [5, 10, 15])                                          â”‚
â”‚   campaign.set_circuit_builder(my_builder_func)                                         â”‚
â”‚   results = campaign.run(shots=4096, mode='qpu')                                        â”‚
â”‚   campaign.generate_report("campaign.html")                                             â”‚
â”‚   df = campaign.to_dataframe()  # Export pandas                                         â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ ArchiveReplayer - Replay d'expÃ©riences depuis archives                               â”‚
â”‚   replayer = ArchiveReplayer(fw)                                                        â”‚
â”‚   replayer.load("archive_20260102.json")                                                â”‚
â”‚   print(replayer.get_summary())                                                         â”‚
â”‚   new_results = replayer.replay(backend="ibm_torino", shots=8192)                       â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ MultiBackendRunner - ExÃ©cution multi-backend simultanÃ©e                              â”‚
â”‚   runner = MultiBackendRunner(fw)                                                       â”‚
â”‚   results = runner.run(circuits,                                                        â”‚
â”‚                        backends=["ibm_fez", "ibm_torino"],                              â”‚
â”‚                        shots=4096)                                                      â”‚
â”‚   # â†’ {'comparison': {'best_backend': 'ibm_fez', 'consistency': {...}}}                 â”‚
â”‚   runner.generate_report(results, "multi_backend.html")                                 â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ StandardBenchmarks - Suite de benchmarks intÃ©grÃ©s                                    â”‚
â”‚   bench = StandardBenchmarks(fw)                                                        â”‚
â”‚   results = bench.run_all(n_qubits=50, shots=4096)                                      â”‚
â”‚   # Ou individuellement:                                                                â”‚
â”‚   mirror = bench.mirror_circuits(n_qubits=50)                                           â”‚
â”‚   qv = bench.quantum_volume(n_qubits=5)                                                 â”‚
â”‚   layer_fid = bench.layer_fidelity(n_qubits=50)                                         â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ AdversarialCircuitGenerator - Circuits stress-test QPU                               â”‚
â”‚   gen = AdversarialCircuitGenerator(seed=42)                                            â”‚
â”‚   circuits = gen.generate('noise_sensitivity', n_qubits=50)                             â”‚
â”‚   # Types: noise_sensitivity, depth_stress, connectivity_stress,                        â”‚
â”‚   #        crosstalk_probe, decoherence_test                                            â”‚
â”‚   analysis = gen.analyze_vulnerability(results, 'noise_sensitivity')                    â”‚
â”‚                                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚ ğŸ’° GESTION BUDGET & PLANIFICATION                                                       â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ BudgetAlertManager - Alertes budget QPU                                              â”‚
â”‚   alert_mgr = BudgetAlertManager(monthly_limit_minutes=50,                              â”‚
â”‚                                   alert_thresholds=[0.5, 0.8, 0.95],                    â”‚
â”‚                                   callback=my_alert_function)                           â”‚
â”‚   status = alert_mgr.check(current_usage_minutes=35)                                    â”‚
â”‚   print(alert_mgr.get_status_display(35))  # Affichage ASCII budget                     â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ JobScheduler - Planification de jobs diffÃ©rÃ©s                                        â”‚
â”‚   scheduler = JobScheduler(fw)                                                          â”‚
â”‚   job_id = scheduler.schedule(circuits, shots=4096,                                     â”‚
â”‚                               run_at="2026-01-06 02:00")  # Heure creuse                â”‚
â”‚   job_id = scheduler.schedule_when_queue_low(circuits, max_queue=5)                     â”‚
â”‚   scheduler.list_scheduled()                                                            â”‚
â”‚   scheduler.cancel(job_id)                                                              â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ TranspilationCache - Cache intelligent de transpilation                              â”‚
â”‚   cache = TranspilationCache(max_age_hours=24, max_entries=1000)                        â”‚
â”‚   transpiled = cache.get_or_transpile(circuit, backend)                                 â”‚
â”‚   print(cache.stats())  # {'hit_rate': '85.3%', 'entries': 150}                         â”‚
â”‚                                                                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚ ğŸ“¤ EXPORT & NOTIFICATIONS                                                               â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ PublicationExporter - Export pour publications scientifiques                         â”‚
â”‚   exporter = PublicationExporter()                                                      â”‚
â”‚   exporter.export_latex(results, "results.tex", language='en')                          â”‚
â”‚   exporter.export_markdown(results, "results.md")                                       â”‚
â”‚   exporter.export_inpi_figures_prompts(results, "figures.json")  # N&B INPI            â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ NotificationHub - Notifications multi-canal                                          â”‚
â”‚   notif = NotificationHub()                                                             â”‚
â”‚   notif.add_channel('console')                                                          â”‚
â”‚   notif.add_channel('webhook', url='https://hooks.slack.com/...')                       â”‚
â”‚   notif.add_channel('email', smtp_server='smtp.gmail.com', ...)                         â”‚
â”‚   notif.notify('job_complete', {'job_id': 'xxx', 'status': 'OK'})                       â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ WebDashboard - Dashboard web temps rÃ©el                                              â”‚
â”‚   dashboard = WebDashboard(fw, data_dir="qmc_runs")                                     â”‚
â”‚   dashboard.start(port=8080, open_browser=True)                                         â”‚
â”‚   # â†’ http://localhost:8080                                                             â”‚
â”‚   dashboard.stop()                                                                      â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ DatabaseExporter - Export vers bases de donnÃ©es                                      â”‚
â”‚   db = DatabaseExporter()                                                               â”‚
â”‚   db.connect_sqlite("qmc_results.db")                                                   â”‚
â”‚   # Ou: db.connect_postgres("postgresql://user:pass@host/db")                           â”‚
â”‚   experiment_id = db.save(archive_data)                                                 â”‚
â”‚   experiments = db.get_experiments(limit=100)                                           â”‚
â”‚                                                                                         â”‚
â”‚ â–¶ GitTracker - IntÃ©gration Git pour traÃ§abilitÃ©                                        â”‚
â”‚   tracker = GitTracker()                                                                â”‚
â”‚   git_state = tracker.get_current_state()                                               â”‚
â”‚   # â†’ {'commit_hash': 'abc123', 'branch': 'main', 'dirty': False}                       â”‚
â”‚   archive = tracker.embed_in_archive(archive_data)                                      â”‚
â”‚   repro = tracker.verify_reproducibility("archive.json")                                â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              FIN DE LA DOCUMENTATION 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import json
import os
import sys
import time
import signal
import atexit
import hashlib
import argparse
import traceback
import csv
import importlib
import inspect
import yaml
import secrets
import struct
import math
from abc import ABC, abstractmethod
from datetime import datetime, timedelta
from pathlib import Path
from typing import (
    List, Dict, Optional, Set, Tuple, Any, Callable, Union, 
    Type, TypeVar, Generic, Iterator, Sequence, Protocol
)
from dataclasses import dataclass, field, asdict
from enum import Enum, auto
from contextlib import contextmanager
import contextlib
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeout
from functools import wraps, lru_cache
from collections import defaultdict, deque
import threading
import copy
import re
import random
import functools
import numpy as np
import warnings
warnings.filterwarnings('ignore')


# =============================================================================
# DEPENDENCY CHECKER - VÃ©rification des dÃ©pendances au dÃ©marrage
# =============================================================================

REQUIRED_PACKAGES = {
    # Package: (import_name, pip_name, required, description)
    "qiskit": ("qiskit", "qiskit", True, "Quantum SDK core"),
    "qiskit_ibm_runtime": ("qiskit_ibm_runtime", "qiskit-ibm-runtime", True, "IBM Quantum Runtime"),
    "numpy": ("numpy", "numpy", True, "Numerical computing"),
    "matplotlib": ("matplotlib", "matplotlib", True, "Plotting & visualization"),
    "python-dotenv": ("dotenv", "python-dotenv", True, "Environment variables"),
    "pyyaml": ("yaml", "pyyaml", True, "YAML parsing"),
    "pylatexenc": ("pylatexenc", "pylatexenc", True, "Circuit diagrams in reports"),
    "scipy": ("scipy", "scipy", True, "Scientific computing & statistics"),
    "networkx": ("networkx", "networkx", True, "Graph/topology analysis"),
}

def check_dependencies(auto_install: bool = False, verbose: bool = True) -> dict:
    """
    VÃ©rifie que toutes les dÃ©pendances requises sont installÃ©es.
    
    Args:
        auto_install: Si True, propose d'installer les packages manquants
        verbose: Affiche les dÃ©tails de la vÃ©rification
        
    Returns:
        Dict avec status de chaque package
    """
    results = {"installed": [], "missing": []}
    
    if verbose:
        print("\nğŸ” VÃ©rification des dÃ©pendances...")
        print("â”€" * 50)
    
    for pkg_name, (import_name, pip_name, required, desc) in REQUIRED_PACKAGES.items():
        try:
            __import__(import_name)
            results["installed"].append(pkg_name)
            if verbose:
                print(f"  âœ… {pkg_name}: OK")
        except ImportError:
            results["missing"].append((pip_name, desc))
            if verbose:
                print(f"  âŒ {pkg_name}: MANQUANT")
    
    if verbose:
        print("â”€" * 50)
    
    # Packages manquants
    if results["missing"]:
        missing_list = [p[0] for p in results["missing"]]
        pip_cmd = f"pip install {' '.join(missing_list)}"
        
        print(f"\nâŒ ERREUR: {len(missing_list)} package(s) manquant(s)!")
        print(f"\n   Pour installer:")
        print(f"   {pip_cmd}")
        print()
        
        if auto_install:
            response = input("   Installer automatiquement? [y/N]: ").strip().lower()
            if response in ('y', 'yes', 'o', 'oui'):
                import subprocess
                print(f"\n   ğŸ“¦ Installation en cours...")
                try:
                    subprocess.check_call([sys.executable, "-m", "pip", "install"] + missing_list)
                    print(f"   âœ… Installation rÃ©ussie!")
                    return check_dependencies(auto_install=False, verbose=False)
                except subprocess.CalledProcessError as e:
                    print(f"   âŒ Erreur d'installation: {e}")
                    sys.exit(1)
    
    if not results["missing"] and verbose:
        print(f"\nâœ… Toutes les dÃ©pendances sont installÃ©es!")
    
    return results


def ensure_dependencies():
    """
    VÃ©rifie les dÃ©pendances critiques au chargement du module.
    Ne bloque pas mais affiche un avertissement si des packages manquent.
    """
    critical_missing = []
    
    # Check seulement les critiques sans output
    for pkg_name, (import_name, pip_name, required, desc) in REQUIRED_PACKAGES.items():
        if required:
            try:
                __import__(import_name)
            except ImportError:
                critical_missing.append(pip_name)
    
    if critical_missing:
        print()
        print("â•”" + "â•" * 68 + "â•—")
        print("â•‘  âš ï¸  QMC FRAMEWORK - DÃ‰PENDANCES MANQUANTES" + " " * 25 + "â•‘")
        print("â• " + "â•" * 68 + "â•£")
        print(f"â•‘  Packages requis manquants: {', '.join(critical_missing):<39}â•‘")
        print("â•‘" + " " * 68 + "â•‘")
        pip_cmd = f"pip install {' '.join(critical_missing)}"
        # Tronquer si trop long
        if len(pip_cmd) > 64:
            print(f"â•‘  Installation: pip install \\{' ' * 30}â•‘")
            print(f"â•‘    {' '.join(critical_missing):<64}â•‘")
        else:
            print(f"â•‘  {pip_cmd:<66}â•‘")
        print("â•š" + "â•" * 68 + "â•")
        print()
        
        # VÃ©rifier si on peut proposer l'installation interactive
        # Ne pas proposer si QMC_SKIP_DEP_CHECK=true ou si pas de TTY
        skip_check = os.environ.get("QMC_SKIP_DEP_CHECK", "").lower() in ("true", "1", "yes")
        auto_install = os.environ.get("QMC_AUTO_INSTALL_DEPS", "").lower() in ("true", "1", "yes")
        
        if not skip_check:
            if auto_install:
                # Installation automatique si demandÃ© via env
                print("ğŸ“¦ Installation automatique (QMC_AUTO_INSTALL_DEPS=true)...")
                try:
                    import subprocess
                    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q"] + critical_missing)
                    print("âœ… Installation rÃ©ussie!")
                except Exception as e:
                    print(f"âŒ Erreur: {e}")
                    print("   Installez manuellement et relancez.")
            elif sys.stdin.isatty():
                # Mode interactif - proposer l'installation
                try:
                    response = input("   Installer automatiquement? [y/N]: ").strip().lower()
                    if response in ('y', 'yes', 'o', 'oui'):
                        print("\nğŸ“¦ Installation en cours...")
                        try:
                            import subprocess
                            subprocess.check_call([sys.executable, "-m", "pip", "install"] + critical_missing)
                            print("âœ… Installation rÃ©ussie! Relancez votre script.")
                        except Exception as e:
                            print(f"âŒ Erreur d'installation: {e}")
                except (EOFError, KeyboardInterrupt):
                    pass  # Non-interactif ou interruption


# VÃ©rification au chargement du module
ensure_dependencies()


# =============================================================================
# VERSION & METADATA
# =============================================================================

__version__ = "2.5.23"
__author__ = "QMC Research Lab"
__license__ = "Proprietary"
__date__ = "2025-12-20"

FRAMEWORK_BANNER = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            QMC QUANTUM TESTING FRAMEWORK v{version}                         â•‘
â•‘                      QMC Research Lab 2025                                â•‘
â•‘                                                                           â•‘
â•‘  ğŸ”Œ PLUGIN SYSTEM    ğŸ”§ CIRCUIT BUILDERS    ğŸ§ª EXPERIMENT ENGINE           â•‘
â•‘  [K] CRYPTO VALID.    [#] BENCHMARK SUITE     [A] ADVANCED ANALYSIS           â•‘
â•‘  ğŸ“Š v2.5.18: Rapport+Archive AUTO (protection via .env)                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""".format(version=__version__)


# =============================================================================
# CONFIGURATION ENVIRONNEMENT - RAPPORT & ARCHIVE (v2.5.18)
# =============================================================================
# 
# âš ï¸ PROTECTION DES RÃ‰SULTATS QPU ET DU BUDGET:
# Les paramÃ¨tres suivants sont contrÃ´lÃ©s par .env pour Ã©viter les erreurs:
#
#   QMC_GENERATE_REPORT=false   # DÃ©sactive rapport HTML (dÃ©conseillÃ©)
#   QMC_GENERATE_ARCHIVE=false  # DÃ©sactive archive JSON (dÃ©conseillÃ©)
#   QMC_AUTO_CONFIRM=true       # DÃ©sactive confirmation QPU (DANGEREUX!)
#
# ğŸ“¦ GESTION DES DÃ‰PENDANCES (v2.5.21):
#
#   QMC_AUTO_INSTALL_DEPS=true  # Installe automatiquement les packages manquants
#   QMC_SKIP_DEP_CHECK=true     # DÃ©sactive la vÃ©rification au chargement
#
# ğŸ”’ MONITORING ROBUSTE (v2.5.21) - ACTIVÃ‰ PAR DÃ‰FAUT:
#
#   QMC_ROBUST_MONITORING=false # DÃ©sactive le monitoring robuste (non recommandÃ©)
#                               # Par dÃ©faut: ACTIVÃ‰ (true)
#                               # - Timeout 45s par vÃ©rification de statut
#                               # - Reconnexion auto aprÃ¨s 5 Ã©checs
#                               # - Message clair si dÃ©connexion
#
# Par dÃ©faut: rapport=ON, archive=ON, confirmation=OBLIGATOIRE, dep_check=ON
# Le code ne peut PAS modifier ces paramÃ¨tres (ils sont ignorÃ©s).
# =============================================================================

def _get_env_bool(name: str, default: bool = True) -> bool:
    """
    Lit une variable d'environnement boolÃ©enne.
    
    Args:
        name: Nom de la variable (ex: QMC_GENERATE_REPORT)
        default: Valeur par dÃ©faut si non dÃ©finie
        
    Returns:
        True si 'true', '1', 'yes', 'on' (insensible Ã  la casse)
        False si 'false', '0', 'no', 'off'
        default sinon
    """
    value = os.environ.get(name, '').lower().strip()
    if value in ('true', '1', 'yes', 'on'):
        return True
    elif value in ('false', '0', 'no', 'off'):
        return False
    return default


def _load_qmc_env_config():
    """
    Charge la configuration QMC depuis .env et variables d'environnement.
    
    Variables supportÃ©es:
        QMC_GENERATE_REPORT: true/false (dÃ©faut: true)
        QMC_GENERATE_ARCHIVE: true/false (dÃ©faut: true)
        QMC_AUTO_CONFIRM: true/false (dÃ©faut: false = confirmation obligatoire)
        QMC_LAZY_REGISTER: 0/1 (dÃ©faut: 0)
    """
    # Charger .env si prÃ©sent
    env_file = Path('.env')
    if env_file.exists():
        try:
            with open(env_file) as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip().strip('"\'')
                        if key.startswith('QMC_'):
                            os.environ.setdefault(key, value)
        except Exception:
            pass  # Silently ignore .env errors


# Charger la config au dÃ©marrage du module
_load_qmc_env_config()

# Configuration globale (lue depuis .env)
QMC_GENERATE_REPORT = _get_env_bool('QMC_GENERATE_REPORT', default=True)
QMC_GENERATE_ARCHIVE = _get_env_bool('QMC_GENERATE_ARCHIVE', default=True)
QMC_AUTO_CONFIRM = _get_env_bool('QMC_AUTO_CONFIRM', default=False)  # False = confirmation obligatoire


# =============================================================================
# TYPE DEFINITIONS
# =============================================================================

T = TypeVar('T')
CircuitType = Any  # Qiskit QuantumCircuit
BackendType = Any  # IBM Backend
CountsType = Dict[str, int]
PathType = Union[str, Path]


# =============================================================================
# v2.5.21 - QISKIT NATIVE INTEGRATION WRAPPERS
# =============================================================================
# 
# Ces classes encapsulent les fonctionnalitÃ©s Qiskit natives pour:
# 1. Ã‰viter la rÃ©implÃ©mentation ("Don't reinvent the wheel")
# 2. Appliquer le style IBM Carbon Ã  toutes les visualisations
# 3. Fournir une interface unifiÃ©e pour le framework QMC
# =============================================================================

class QiskitVisualizationWrapper:
    """
    Wrapper pour les visualisations Qiskit natives avec style IBM Carbon.
    
    Utilise les fonctions qiskit.visualization en appliquant automatiquement
    le thÃ¨me IBM Carbon (couleurs, polices, fond blanc).
    
    Fonctions wrappÃ©es:
        - plot_histogram: Histogramme de counts
        - plot_state_city: Matrice densitÃ© 3D "cityscape"
        - plot_state_qsphere: Q-sphere Qiskit unique
        - plot_state_hinton: Diagramme Hinton
        - plot_state_paulivec: Base Pauli
        - plot_bloch_multivector: Multi-qubit Bloch spheres
        - plot_gate_map: Topologie du backend
        - plot_error_map: Carte d'erreurs du backend
        - plot_circuit_layout: Layout aprÃ¨s transpilation
        - plot_coupling_map: Connexions qubits
    """
    
    # IBM Carbon Colors
    IBM_BLUE_60 = '#0f62fe'
    IBM_BLUE_50 = '#4589ff'
    IBM_TEAL_50 = '#009d9a'
    IBM_PURPLE_60 = '#8a3ffc'
    IBM_GREEN_60 = '#198038'
    IBM_RED_60 = '#da1e28'
    IBM_GRAY_100 = '#161616'
    IBM_GRAY_70 = '#525252'
    IBM_GRAY_30 = '#c6c6c6'
    
    def __init__(self, output_dir: PathType = None, dpi: int = 120):
        """
        Args:
            output_dir: RÃ©pertoire de sortie pour les figures
            dpi: RÃ©solution des images (dÃ©faut: 120)
        """
        self.output_dir = Path(output_dir) if output_dir else Path('.')
        self.dpi = dpi
        self._setup_matplotlib_style()
    
    def _setup_matplotlib_style(self):
        """Configure matplotlib avec le style IBM Carbon"""
        try:
            import matplotlib.pyplot as plt
            plt.style.use('default')
            plt.rcParams.update({
                'figure.facecolor': 'white',
                'axes.facecolor': 'white',
                'axes.edgecolor': self.IBM_GRAY_30,
                'axes.labelcolor': self.IBM_GRAY_100,
                'xtick.color': self.IBM_GRAY_70,
                'ytick.color': self.IBM_GRAY_70,
                'text.color': self.IBM_GRAY_100,
                'grid.color': '#e0e0e0',
                'font.family': 'sans-serif',
                'font.size': 10,
            })
        except ImportError:
            pass
    
    def plot_histogram(self, counts: Union[Dict, List[Dict]], 
                       title: str = None, 
                       legend: List[str] = None,
                       figsize: Tuple[int, int] = (12, 5),
                       filename: str = None,
                       max_bars: int = 25,
                       sort_by_value: bool = True,
                       show_others: bool = True,
                       **kwargs) -> Optional[Any]:
        """
        Wrapper pour qiskit.visualization.plot_histogram avec style IBM.
        
        [v2.5.21] AmÃ©lioration: Filtrage automatique pour grands ensembles
        
        Args:
            counts: Dict ou liste de Dict de counts
            title: Titre du graphique
            legend: LÃ©gendes pour multi-counts
            figsize: Taille de la figure
            filename: Nom du fichier de sortie
            max_bars: Nombre max de barres Ã  afficher (dÃ©faut: 25)
            sort_by_value: Trier par valeur dÃ©croissante (dÃ©faut: True)
            show_others: Grouper les petites valeurs dans "Others" (dÃ©faut: True)
            **kwargs: Arguments additionnels pour plot_histogram
            
        Returns:
            matplotlib.Figure ou None si erreur
        """
        try:
            from qiskit.visualization import plot_histogram
            
            # [v2.5.21] Filtrer les counts pour lisibilitÃ©
            def filter_counts(c: Dict, max_items: int) -> Dict:
                if len(c) <= max_items:
                    return c
                
                # Trier par valeur dÃ©croissante
                sorted_items = sorted(c.items(), key=lambda x: x[1], reverse=True)
                
                # Prendre les top N
                top_items = dict(sorted_items[:max_items - 1] if show_others else sorted_items[:max_items])
                
                # Grouper le reste dans "Others"
                if show_others and len(sorted_items) > max_items - 1:
                    others_sum = sum(v for k, v in sorted_items[max_items - 1:])
                    if others_sum > 0:
                        top_items['(others)'] = others_sum
                
                return top_items
            
            # Filtrer selon le type de counts
            if isinstance(counts, dict):
                filtered_counts = filter_counts(counts, max_bars)
            elif isinstance(counts, list):
                filtered_counts = [filter_counts(c, max_bars) for c in counts]
            else:
                filtered_counts = counts
            
            # Couleurs IBM Carbon
            colors = kwargs.pop('color', [self.IBM_BLUE_60, self.IBM_TEAL_50, 
                                          self.IBM_PURPLE_60, self.IBM_GREEN_60])
            
            # Ajuster la rotation des labels si beaucoup de barres
            n_bars = len(filtered_counts) if isinstance(filtered_counts, dict) else max(len(c) for c in filtered_counts)
            
            fig = plot_histogram(filtered_counts, 
                                title=title,
                                legend=legend,
                                figsize=figsize,
                                color=colors,
                                bar_labels=n_bars <= 15,  # Labels seulement si peu de barres
                                **kwargs)
            
            # Appliquer style IBM Carbon
            if fig:
                fig.patch.set_facecolor('white')
                for ax in fig.axes:
                    ax.set_facecolor('white')
                    ax.tick_params(colors=self.IBM_GRAY_70, labelsize=9)
                    
                    # Rotation des labels x si nÃ©cessaire
                    if n_bars > 10:
                        ax.tick_params(axis='x', rotation=45)
                        for label in ax.get_xticklabels():
                            label.set_ha('right')
                
                if filename:
                    filepath = self.output_dir / filename
                    fig.savefig(filepath, dpi=self.dpi, facecolor='white', 
                               bbox_inches='tight')
            
            return fig
            
        except ImportError as e:
            print(f"[WARN] qiskit.visualization non disponible: {e}")
            return None
        except Exception as e:
            print(f"[ERROR] plot_histogram: {e}")
            return None
    
    def plot_state_city(self, state, 
                        title: str = "State City",
                        figsize: Tuple[int, int] = (10, 8),
                        filename: str = None,
                        **kwargs) -> Optional[Any]:
        """
        Wrapper pour plot_state_city - visualisation 3D de la matrice densitÃ©.
        
        Args:
            state: Statevector, DensityMatrix, ou array
            title: Titre
            figsize: Taille
            filename: Fichier de sortie
            
        Returns:
            matplotlib.Figure
        """
        try:
            from qiskit.visualization import plot_state_city
            
            # Couleurs IBM pour real/imag
            color = kwargs.pop('color', [self.IBM_BLUE_60, self.IBM_RED_60])
            
            fig = plot_state_city(state, title=title, figsize=figsize, 
                                  color=color, **kwargs)
            
            if fig and filename:
                filepath = self.output_dir / filename
                fig.savefig(filepath, dpi=self.dpi, facecolor='white',
                           bbox_inches='tight')
            
            return fig
            
        except ImportError:
            return None
        except Exception as e:
            print(f"[ERROR] plot_state_city: {e}")
            return None
    
    def plot_state_qsphere(self, state,
                           figsize: Tuple[int, int] = (8, 8),
                           filename: str = None,
                           **kwargs) -> Optional[Any]:
        """
        Wrapper pour plot_state_qsphere - Q-sphere unique Qiskit.
        
        La Q-sphere reprÃ©sente l'amplitude par l'Ã©paisseur des flÃ¨ches
        et la phase par la couleur.
        """
        try:
            from qiskit.visualization import plot_state_qsphere
            
            fig = plot_state_qsphere(state, figsize=figsize, **kwargs)
            
            if fig and filename:
                filepath = self.output_dir / filename
                fig.savefig(filepath, dpi=self.dpi, facecolor='white',
                           bbox_inches='tight')
            
            return fig
            
        except ImportError:
            return None
        except Exception as e:
            print(f"[ERROR] plot_state_qsphere: {e}")
            return None
    
    def plot_bloch_multivector(self, state,
                               title: str = "",
                               figsize: Tuple[int, int] = None,
                               filename: str = None,
                               reverse_bits: bool = False,
                               **kwargs) -> Optional[Any]:
        """
        Wrapper pour plot_bloch_multivector - sphÃ¨res de Bloch multi-qubit.
        
        Projette l'Ã©tat quantique sur l'espace single-qubit et affiche
        une sphÃ¨re de Bloch par qubit.
        """
        try:
            from qiskit.visualization import plot_bloch_multivector
            
            fig = plot_bloch_multivector(state, title=title, figsize=figsize,
                                         reverse_bits=reverse_bits, **kwargs)
            
            if fig and filename:
                filepath = self.output_dir / filename
                fig.savefig(filepath, dpi=self.dpi, facecolor='white',
                           bbox_inches='tight')
            
            return fig
            
        except ImportError:
            return None
        except Exception as e:
            print(f"[ERROR] plot_bloch_multivector: {e}")
            return None
    
    def plot_state_hinton(self, state,
                          title: str = "Hinton Diagram",
                          figsize: Tuple[int, int] = (8, 8),
                          filename: str = None,
                          **kwargs) -> Optional[Any]:
        """
        Wrapper pour plot_state_hinton - diagramme de Hinton.
        
        La taille des carrÃ©s reprÃ©sente l'amplitude des Ã©lÃ©ments
        de la matrice densitÃ©.
        """
        try:
            from qiskit.visualization import plot_state_hinton
            
            fig = plot_state_hinton(state, title=title, figsize=figsize, **kwargs)
            
            if fig and filename:
                filepath = self.output_dir / filename
                fig.savefig(filepath, dpi=self.dpi, facecolor='white',
                           bbox_inches='tight')
            
            return fig
            
        except ImportError:
            return None
        except Exception as e:
            print(f"[ERROR] plot_state_hinton: {e}")
            return None
    
    def plot_state_paulivec(self, state,
                            title: str = "Pauli Vector",
                            figsize: Tuple[int, int] = (10, 6),
                            filename: str = None,
                            **kwargs) -> Optional[Any]:
        """
        Wrapper pour plot_state_paulivec - reprÃ©sentation base Pauli.
        
        ReprÃ©sente la matrice densitÃ© dans la base des opÃ©rateurs de Pauli.
        """
        try:
            from qiskit.visualization import plot_state_paulivec
            
            color = kwargs.pop('color', self.IBM_BLUE_60)
            
            fig = plot_state_paulivec(state, title=title, figsize=figsize,
                                      color=color, **kwargs)
            
            if fig and filename:
                filepath = self.output_dir / filename
                fig.savefig(filepath, dpi=self.dpi, facecolor='white',
                           bbox_inches='tight')
            
            return fig
            
        except ImportError:
            return None
        except Exception as e:
            print(f"[ERROR] plot_state_paulivec: {e}")
            return None
    
    def plot_gate_map(self, backend,
                      figsize: Tuple[int, int] = (12, 9),
                      filename: str = None,
                      **kwargs) -> Optional[Any]:
        """
        Wrapper pour plot_gate_map - topologie du backend.
        """
        try:
            from qiskit.visualization import plot_gate_map
            
            qubit_color = kwargs.pop('qubit_color', [self.IBM_BLUE_60])
            line_color = kwargs.pop('line_color', [self.IBM_GRAY_30])
            
            fig = plot_gate_map(backend, figsize=figsize,
                               qubit_color=qubit_color,
                               line_color=line_color,
                               **kwargs)
            
            if fig and filename:
                filepath = self.output_dir / filename
                fig.savefig(filepath, dpi=self.dpi, facecolor='white',
                           bbox_inches='tight')
            
            return fig
            
        except ImportError:
            return None
        except Exception as e:
            print(f"[ERROR] plot_gate_map: {e}")
            return None
    
    def plot_error_map(self, backend,
                       figsize: Tuple[int, int] = (12, 9),
                       filename: str = None,
                       **kwargs) -> Optional[Any]:
        """
        Wrapper pour plot_error_map - carte d'erreurs du backend.
        """
        try:
            from qiskit.visualization import plot_error_map
            
            fig = plot_error_map(backend, figsize=figsize, **kwargs)
            
            if fig and filename:
                filepath = self.output_dir / filename
                fig.savefig(filepath, dpi=self.dpi, facecolor='white',
                           bbox_inches='tight')
            
            return fig
            
        except ImportError:
            return None
        except Exception as e:
            print(f"[ERROR] plot_error_map: {e}")
            return None
    
    def plot_circuit_layout(self, circuit, backend,
                            figsize: Tuple[int, int] = (12, 9),
                            filename: str = None,
                            **kwargs) -> Optional[Any]:
        """
        Wrapper pour plot_circuit_layout - layout aprÃ¨s transpilation.
        """
        try:
            from qiskit.visualization import plot_circuit_layout
            
            qubit_color = kwargs.pop('qubit_color', [self.IBM_BLUE_60])
            
            fig = plot_circuit_layout(circuit, backend, figsize=figsize,
                                      qubit_color=qubit_color, **kwargs)
            
            if fig and filename:
                filepath = self.output_dir / filename
                fig.savefig(filepath, dpi=self.dpi, facecolor='white',
                           bbox_inches='tight')
            
            return fig
            
        except ImportError:
            return None
        except Exception as e:
            print(f"[ERROR] plot_circuit_layout: {e}")
            return None
    
    def plot_coupling_map(self, backend_or_coupling_map,
                          figsize: Tuple[int, int] = (12, 9),
                          filename: str = None,
                          **kwargs) -> Optional[Any]:
        """
        Wrapper pour plot_coupling_map - visualisation des connexions qubits.
        
        Args:
            backend_or_coupling_map: Backend IBM ou CouplingMap directement
            figsize: Taille de la figure
            filename: Nom du fichier de sortie
            **kwargs: Arguments additionnels pour plot_coupling_map
            
        Returns:
            Figure matplotlib ou None
        """
        try:
            from qiskit.visualization import plot_coupling_map
            
            # Extraire le coupling_map si backend fourni
            if hasattr(backend_or_coupling_map, 'coupling_map'):
                coupling_map = backend_or_coupling_map.coupling_map
            else:
                coupling_map = backend_or_coupling_map
            
            # Style IBM Carbon
            self._configure_matplotlib()
            
            fig = plot_coupling_map(coupling_map, figsize=figsize, **kwargs)
            
            if fig and filename:
                filepath = self.output_dir / filename
                fig.savefig(filepath, dpi=self.dpi, facecolor='white',
                           bbox_inches='tight')
            
            return fig
            
        except ImportError:
            print("[WARN] qiskit.visualization non disponible")
            return None
        except Exception as e:
            print(f"[ERROR] plot_coupling_map: {e}")
            return None
    
    def generate_all_state_visualizations(self, state, 
                                          prefix: str = "state",
                                          output_dir: PathType = None) -> Dict[str, str]:
        """
        GÃ©nÃ¨re toutes les visualisations d'Ã©tat disponibles.
        
        Args:
            state: Statevector ou DensityMatrix
            prefix: PrÃ©fixe pour les noms de fichiers
            output_dir: RÃ©pertoire de sortie (optionnel)
            
        Returns:
            Dict avec les chemins des fichiers gÃ©nÃ©rÃ©s
        """
        out_dir = Path(output_dir) if output_dir else self.output_dir
        generated = {}
        
        visualizations = [
            ('city', self.plot_state_city),
            ('qsphere', self.plot_state_qsphere),
            ('hinton', self.plot_state_hinton),
            ('paulivec', self.plot_state_paulivec),
            ('bloch', self.plot_bloch_multivector),
        ]
        
        for name, func in visualizations:
            try:
                filename = f"{prefix}_{name}.png"
                fig = func(state, filename=filename)
                if fig:
                    generated[name] = str(out_dir / filename)
                    try:
                        import matplotlib.pyplot as plt
                        plt.close(fig)
                    except:
                        pass
            except Exception as e:
                print(f"[WARN] Visualization {name} failed: {e}")
        
        return generated


class QiskitQuantumInfoWrapper:
    """
    Wrapper pour qiskit.quantum_info - mÃ©triques quantiques natives.
    
    Utilise les implÃ©mentations Qiskit optimisÃ©es au lieu de rÃ©implÃ©menter.
    
    MÃ©triques disponibles:
        - state_fidelity: FidÃ©litÃ© entre deux Ã©tats
        - hellinger_fidelity: FidÃ©litÃ© Hellinger (pour counts)
        - process_fidelity: FidÃ©litÃ© de processus quantique
        - average_gate_fidelity: FidÃ©litÃ© moyenne de porte
        - entropy: Entropie de von-Neumann
        - shannon_entropy: Entropie de Shannon
        - purity: PuretÃ© d'un Ã©tat
        - concurrence: Mesure d'intrication
        - mutual_information: Information mutuelle
        - partial_trace: Trace partielle
    """
    
    @staticmethod
    def state_fidelity(state1, state2, validate: bool = True) -> float:
        """
        Calcule la fidÃ©litÃ© entre deux Ã©tats quantiques.
        
        F(Ï1, Ï2) = Tr[âˆš(âˆšÏ1 Ï2 âˆšÏ1)]Â²
        
        Args:
            state1: Premier Ã©tat (Statevector ou DensityMatrix)
            state2: Second Ã©tat
            validate: Valider les entrÃ©es
            
        Returns:
            FidÃ©litÃ© entre 0 et 1
        """
        try:
            from qiskit.quantum_info import state_fidelity
            return float(state_fidelity(state1, state2, validate=validate))
        except ImportError:
            return -1.0
        except Exception as e:
            print(f"[ERROR] state_fidelity: {e}")
            return -1.0
    
    @staticmethod
    def hellinger_fidelity(counts1: Dict[str, int], 
                           counts2: Dict[str, int]) -> float:
        """
        Calcule la fidÃ©litÃ© de Hellinger entre deux distributions de counts.
        
        F_H = (Î£ âˆš(p_i Ã— q_i))Â²
        
        Args:
            counts1: Premiers counts
            counts2: Seconds counts
            
        Returns:
            FidÃ©litÃ© Hellinger entre 0 et 1
        """
        try:
            from qiskit.quantum_info.analysis import hellinger_fidelity
            return float(hellinger_fidelity(counts1, counts2))
        except ImportError:
            # Fallback implementation
            total1 = sum(counts1.values())
            total2 = sum(counts2.values())
            all_keys = set(counts1.keys()) | set(counts2.keys())
            
            fidelity = 0.0
            for key in all_keys:
                p = counts1.get(key, 0) / total1
                q = counts2.get(key, 0) / total2
                fidelity += (p * q) ** 0.5
            
            return fidelity ** 2
        except Exception as e:
            print(f"[ERROR] hellinger_fidelity: {e}")
            return -1.0
    
    @staticmethod
    def entropy(state, base: int = 2) -> float:
        """
        Calcule l'entropie de von-Neumann d'un Ã©tat quantique.
        
        S(Ï) = -Tr(Ï log Ï)
        
        Args:
            state: Ã‰tat quantique (DensityMatrix ou Statevector)
            base: Base du logarithme (dÃ©faut: 2)
            
        Returns:
            Entropie de von-Neumann
        """
        try:
            from qiskit.quantum_info import entropy
            return float(entropy(state, base=base))
        except ImportError:
            return -1.0
        except Exception as e:
            print(f"[ERROR] entropy: {e}")
            return -1.0
    
    @staticmethod
    def shannon_entropy(probabilities, base: int = 2) -> float:
        """
        Calcule l'entropie de Shannon d'une distribution de probabilitÃ©s.
        
        H = -Î£ p_i log(p_i)
        
        Args:
            probabilities: Liste ou array de probabilitÃ©s
            base: Base du logarithme
            
        Returns:
            Entropie de Shannon
        """
        try:
            from qiskit.quantum_info.states.utils import shannon_entropy
            return float(shannon_entropy(probabilities, base=base))
        except ImportError:
            # Fallback
            import numpy as np
            probs = np.array(probabilities)
            probs = probs[probs > 0]  # Ã‰viter log(0)
            return float(-np.sum(probs * np.log(probs) / np.log(base)))
        except Exception as e:
            print(f"[ERROR] shannon_entropy: {e}")
            return -1.0
    
    @staticmethod
    def purity(state) -> float:
        """
        Calcule la puretÃ© d'un Ã©tat quantique.
        
        Î³ = Tr(ÏÂ²)
        
        Î³ = 1 pour Ã©tats purs, Î³ < 1 pour Ã©tats mixtes.
        
        Args:
            state: Ã‰tat quantique
            
        Returns:
            PuretÃ© entre 1/d et 1
        """
        try:
            from qiskit.quantum_info import purity
            return float(purity(state))
        except ImportError:
            return -1.0
        except Exception as e:
            print(f"[ERROR] purity: {e}")
            return -1.0
    
    @staticmethod
    def concurrence(state) -> float:
        """
        Calcule la concurrence d'un Ã©tat 2-qubit.
        
        Mesure l'intrication pour les Ã©tats Ã  2 qubits.
        C = 0 pour Ã©tats sÃ©parables, C = 1 pour Ã©tats maximalement intriquÃ©s.
        
        Args:
            state: Ã‰tat 2-qubit
            
        Returns:
            Concurrence entre 0 et 1
        """
        try:
            from qiskit.quantum_info import concurrence
            return float(concurrence(state))
        except ImportError:
            return -1.0
        except Exception as e:
            print(f"[ERROR] concurrence: {e}")
            return -1.0
    
    @staticmethod
    def mutual_information(state, base: int = 2) -> float:
        """
        Calcule l'information mutuelle d'un Ã©tat bipartite.
        
        I(A:B) = S(A) + S(B) - S(AB)
        
        Args:
            state: Ã‰tat bipartite
            base: Base du logarithme
            
        Returns:
            Information mutuelle
        """
        try:
            from qiskit.quantum_info import mutual_information
            return float(mutual_information(state, base=base))
        except ImportError:
            return -1.0
        except Exception as e:
            print(f"[ERROR] mutual_information: {e}")
            return -1.0
    
    @staticmethod
    def partial_trace(state, qargs: List[int]):
        """
        Calcule la trace partielle d'un Ã©tat quantique.
        
        Args:
            state: Ã‰tat quantique
            qargs: Indices des qubits Ã  tracer
            
        Returns:
            Ã‰tat rÃ©duit (DensityMatrix)
        """
        try:
            from qiskit.quantum_info import partial_trace
            return partial_trace(state, qargs)
        except ImportError:
            return None
        except Exception as e:
            print(f"[ERROR] partial_trace: {e}")
            return None
    
    @staticmethod
    def process_fidelity(channel, target=None) -> float:
        """
        Calcule la fidÃ©litÃ© de processus d'un canal quantique.
        
        Args:
            channel: Canal quantique
            target: Canal cible (dÃ©faut: identitÃ©)
            
        Returns:
            FidÃ©litÃ© de processus
        """
        try:
            from qiskit.quantum_info import process_fidelity
            return float(process_fidelity(channel, target=target))
        except ImportError:
            return -1.0
        except Exception as e:
            print(f"[ERROR] process_fidelity: {e}")
            return -1.0
    
    @staticmethod
    def average_gate_fidelity(channel, target=None) -> float:
        """
        Calcule la fidÃ©litÃ© moyenne de porte.
        
        Args:
            channel: Canal quantique
            target: Unitaire cible
            
        Returns:
            FidÃ©litÃ© moyenne de porte
        """
        try:
            from qiskit.quantum_info import average_gate_fidelity
            return float(average_gate_fidelity(channel, target=target))
        except ImportError:
            return -1.0
        except Exception as e:
            print(f"[ERROR] average_gate_fidelity: {e}")
            return -1.0
    
    @classmethod
    def analyze_counts(cls, counts: Dict[str, int], 
                       ideal_counts: Dict[str, int] = None) -> Dict[str, float]:
        """
        Analyse complÃ¨te d'une distribution de counts.
        
        Args:
            counts: Counts mesurÃ©s
            ideal_counts: Counts idÃ©aux pour comparaison
            
        Returns:
            Dict avec toutes les mÃ©triques
        """
        import numpy as np
        
        total = sum(counts.values())
        probs = [c / total for c in counts.values()]
        
        result = {
            'total_counts': total,
            'n_outcomes': len(counts),
            'shannon_entropy': cls.shannon_entropy(probs),
            'max_probability': max(probs),
            'min_probability': min(probs),
            'uniformity': 1.0 - (max(probs) - min(probs)),
        }
        
        if ideal_counts:
            result['hellinger_fidelity'] = cls.hellinger_fidelity(counts, ideal_counts)
        
        return result


class RuntimeErrorMitigationConfig:
    """
    Configuration pour l'error mitigation via Qiskit Runtime.
    
    Niveaux de rÃ©silience:
        0: Aucune mitigation
        1: TREX (mesure) - dÃ©faut
        2: TREX + ZNE + Gate Twirling
        
    Techniques disponibles:
        - Dynamical Decoupling (DD): Suppression d'erreurs sur qubits idle
        - TREX: Twirled Readout Error Extinction
        - ZNE: Zero Noise Extrapolation
        - PEC: Probabilistic Error Cancellation
        - Gate Twirling: Randomisation des portes
    """
    
    def __init__(self, resilience_level: int = 1):
        """
        Args:
            resilience_level: Niveau de rÃ©silience 0-2
        """
        self.resilience_level = min(max(resilience_level, 0), 2)
        
        # Options par dÃ©faut selon le niveau
        self.dynamical_decoupling = resilience_level >= 1
        self.dd_sequence = "XpXm"  # XX, XpXm, XY4
        
        self.measure_mitigation = resilience_level >= 1  # TREX
        self.measure_num_randomizations = 32
        self.measure_shots_per_randomization = 100
        
        self.zne_mitigation = resilience_level >= 2
        self.zne_noise_factors = [1, 3, 5]
        self.zne_extrapolator = "exponential"
        
        self.gate_twirling = resilience_level >= 2
        self.twirling_num_randomizations = "auto"
    
    def apply_to_estimator(self, estimator) -> None:
        """
        Applique la configuration Ã  un EstimatorV2.
        
        Args:
            estimator: Instance de EstimatorV2
        """
        try:
            # Niveau de rÃ©silience
            estimator.options.resilience_level = self.resilience_level
            
            # Dynamical Decoupling
            estimator.options.dynamical_decoupling.enable = self.dynamical_decoupling
            if self.dynamical_decoupling:
                estimator.options.dynamical_decoupling.sequence_type = self.dd_sequence
            
            # TREX (measure mitigation)
            if hasattr(estimator.options, 'resilience'):
                estimator.options.resilience.measure_mitigation = self.measure_mitigation
                if self.measure_mitigation:
                    estimator.options.resilience.measure_noise_learning.num_randomizations = \
                        self.measure_num_randomizations
                    estimator.options.resilience.measure_noise_learning.shots_per_randomization = \
                        self.measure_shots_per_randomization
                
                # ZNE
                estimator.options.resilience.zne_mitigation = self.zne_mitigation
                if self.zne_mitigation:
                    estimator.options.resilience.zne.noise_factors = self.zne_noise_factors
                    estimator.options.resilience.zne.extrapolator = self.zne_extrapolator
            
            # Gate Twirling
            if hasattr(estimator.options, 'twirling'):
                estimator.options.twirling.enable_gates = self.gate_twirling
                if self.gate_twirling:
                    estimator.options.twirling.num_randomizations = self.twirling_num_randomizations
                    
        except Exception as e:
            print(f"[WARN] Could not apply error mitigation config: {e}")
    
    def apply_to_sampler(self, sampler) -> None:
        """
        Applique la configuration Ã  un SamplerV2.
        
        Note: Sampler supporte DD et twirling mais pas ZNE/PEC.
        """
        try:
            # Dynamical Decoupling
            sampler.options.dynamical_decoupling.enable = self.dynamical_decoupling
            if self.dynamical_decoupling:
                sampler.options.dynamical_decoupling.sequence_type = self.dd_sequence
            
            # Twirling (measurement uniquement pour Sampler)
            if hasattr(sampler.options, 'twirling'):
                sampler.options.twirling.enable_measure = True
                
        except Exception as e:
            print(f"[WARN] Could not apply sampler config: {e}")
    
    def to_dict(self) -> Dict[str, Any]:
        """Retourne la configuration comme dictionnaire."""
        return {
            'resilience_level': self.resilience_level,
            'dynamical_decoupling': {
                'enable': self.dynamical_decoupling,
                'sequence': self.dd_sequence,
            },
            'measure_mitigation': {
                'enable': self.measure_mitigation,
                'num_randomizations': self.measure_num_randomizations,
                'shots_per_randomization': self.measure_shots_per_randomization,
            },
            'zne': {
                'enable': self.zne_mitigation,
                'noise_factors': self.zne_noise_factors,
                'extrapolator': self.zne_extrapolator,
            },
            'gate_twirling': {
                'enable': self.gate_twirling,
                'num_randomizations': self.twirling_num_randomizations,
            },
        }
    
    @classmethod
    def from_level(cls, level: int) -> 'RuntimeErrorMitigationConfig':
        """CrÃ©e une configuration depuis un niveau de rÃ©silience."""
        return cls(resilience_level=level)
    
    @classmethod
    def no_mitigation(cls) -> 'RuntimeErrorMitigationConfig':
        """Configuration sans mitigation."""
        return cls(resilience_level=0)
    
    @classmethod
    def standard(cls) -> 'RuntimeErrorMitigationConfig':
        """Configuration standard (niveau 1)."""
        return cls(resilience_level=1)
    
    @classmethod
    def full(cls) -> 'RuntimeErrorMitigationConfig':
        """Configuration complÃ¨te (niveau 2)."""
        return cls(resilience_level=2)


class QiskitTranspilerWrapper:
    """
    Wrapper pour le transpiler Qiskit optimisÃ©.
    
    Utilise generate_preset_pass_manager au lieu de rÃ©implÃ©menter.
    Le transpiler Qiskit est 83x plus rapide et produit des circuits
    avec 29% moins de portes 2-qubit.
    """
    
    @staticmethod
    def transpile(circuits, backend, 
                  optimization_level: int = 2,
                  seed_transpiler: int = None,
                  **kwargs):
        """
        Transpile des circuits pour un backend.
        
        Args:
            circuits: Circuit ou liste de circuits
            backend: Backend cible
            optimization_level: Niveau d'optimisation 0-3
            seed_transpiler: Seed pour reproductibilitÃ©
            **kwargs: Arguments additionnels
            
        Returns:
            Circuit(s) transpilÃ©(s)
        """
        try:
            from qiskit.transpiler import generate_preset_pass_manager
            
            pm = generate_preset_pass_manager(
                optimization_level=optimization_level,
                backend=backend,
                seed_transpiler=seed_transpiler,
                **kwargs
            )
            
            return pm.run(circuits)
            
        except ImportError:
            # Fallback vers transpile()
            from qiskit import transpile
            return transpile(circuits, backend=backend, 
                           optimization_level=optimization_level,
                           seed_transpiler=seed_transpiler)
    
    @staticmethod
    def get_pass_manager(backend, 
                         optimization_level: int = 2,
                         **kwargs):
        """
        Obtient un PassManager configurÃ©.
        
        Args:
            backend: Backend cible
            optimization_level: Niveau 0-3
            
        Returns:
            StagedPassManager
        """
        try:
            from qiskit.transpiler import generate_preset_pass_manager
            return generate_preset_pass_manager(
                optimization_level=optimization_level,
                backend=backend,
                **kwargs
            )
        except ImportError:
            return None
    
    @staticmethod
    def analyze_transpilation(original_circuit, transpiled_circuit) -> Dict[str, Any]:
        """
        Analyse les diffÃ©rences avant/aprÃ¨s transpilation.
        
        Args:
            original_circuit: Circuit original
            transpiled_circuit: Circuit transpilÃ©
            
        Returns:
            Dict avec les mÃ©triques de transpilation
        """
        def count_gates(circuit):
            """Compte les portes par type."""
            ops = {}
            for inst in circuit.data:
                name = inst.operation.name
                ops[name] = ops.get(name, 0) + 1
            return ops
        
        original_ops = count_gates(original_circuit)
        transpiled_ops = count_gates(transpiled_circuit)
        
        # Compter les portes 2-qubit
        two_qubit_gates = ['cx', 'cz', 'ecr', 'rzx', 'swap', 'iswap', 'cp', 'crz', 'cry', 'crx']
        original_2q = sum(original_ops.get(g, 0) for g in two_qubit_gates)
        transpiled_2q = sum(transpiled_ops.get(g, 0) for g in two_qubit_gates)
        
        return {
            'original_depth': original_circuit.depth(),
            'transpiled_depth': transpiled_circuit.depth(),
            'depth_reduction': original_circuit.depth() - transpiled_circuit.depth(),
            'original_gates': sum(original_ops.values()),
            'transpiled_gates': sum(transpiled_ops.values()),
            'original_2q_gates': original_2q,
            'transpiled_2q_gates': transpiled_2q,
            '2q_reduction': original_2q - transpiled_2q,
            'original_ops': original_ops,
            'transpiled_ops': transpiled_ops,
        }


# =============================================================================
# QMC EXCEPTION HIERARCHY v1.0
# =============================================================================
# SystÃ¨me centralisÃ© de gestion d'erreurs avec retry logic
# IntÃ©grÃ© dans toutes les fonctions critiques du framework
# =============================================================================

class QMCException(Exception):
    """
    Exception de base pour toutes les erreurs QMC Framework.
    
    Attributes:
        message: Message d'erreur
        code: Code d'erreur unique (ex: QMC-001)
        details: DÃ©tails additionnels (dict)
        recoverable: Si l'erreur peut Ãªtre rÃ©cupÃ©rÃ©e par retry
        suggestion: Suggestion de rÃ©solution
    """
    def __init__(self, message: str, code: str = "QMC-000", 
                 details: Dict = None, recoverable: bool = False,
                 suggestion: str = None):
        self.message = message
        self.code = code
        self.details = details or {}
        self.recoverable = recoverable
        self.suggestion = suggestion
        self.timestamp = datetime.now().isoformat()
        super().__init__(self.format_message())
    
    def format_message(self) -> str:
        msg = f"[{self.code}] {self.message}"
        if self.suggestion:
            msg += f" â†’ {self.suggestion}"
        return msg
    
    def to_dict(self) -> Dict:
        return {
            'code': self.code,
            'message': self.message,
            'details': self.details,
            'recoverable': self.recoverable,
            'suggestion': self.suggestion,
            'timestamp': self.timestamp,
            'type': self.__class__.__name__
        }


class QMCConnectionError(QMCException):
    """Erreur de connexion au backend IBM."""
    def __init__(self, message: str, backend: str = None, **kwargs):
        super().__init__(
            message=message,
            code="QMC-100",
            details={'backend': backend, **kwargs.get('details', {})},
            recoverable=True,
            suggestion=kwargs.get('suggestion', "VÃ©rifiez votre connexion et les credentials IBM")
        )


class QMCCredentialsError(QMCException):
    """Erreur d'authentification IBM."""
    def __init__(self, message: str = "Credentials IBM invalides ou manquants", **kwargs):
        super().__init__(
            message=message,
            code="QMC-101",
            recoverable=False,
            suggestion="VÃ©rifiez IBM_API_KEY_ACTIVE_* dans .env"
        )


class QMCBackendError(QMCException):
    """Erreur liÃ©e au backend QPU."""
    def __init__(self, message: str, backend: str = None, **kwargs):
        super().__init__(
            message=message,
            code="QMC-102",
            details={'backend': backend},
            recoverable=kwargs.get('recoverable', True),
            suggestion=kwargs.get('suggestion', "Le backend peut Ãªtre en maintenance, essayez plus tard")
        )


class QMCTranspilationError(QMCException):
    """Erreur lors de la transpilation."""
    def __init__(self, message: str, circuit_name: str = None, **kwargs):
        super().__init__(
            message=message,
            code="QMC-200",
            details={'circuit': circuit_name},
            recoverable=False,
            suggestion="VÃ©rifiez que le circuit est compatible avec le backend"
        )


class QMCExecutionError(QMCException):
    """Erreur lors de l'exÃ©cution QPU."""
    def __init__(self, message: str, job_id: str = None, **kwargs):
        super().__init__(
            message=message,
            code="QMC-300",
            details={'job_id': job_id, **kwargs.get('details', {})},
            recoverable=kwargs.get('recoverable', True),
            suggestion=kwargs.get('suggestion', "RÃ©essayez ou vÃ©rifiez le statut du job")
        )


class QMCTimeoutError(QMCException):
    """Timeout lors de l'attente d'un job."""
    def __init__(self, message: str, job_id: str = None, timeout_s: float = None, **kwargs):
        super().__init__(
            message=message,
            code="QMC-301",
            details={'job_id': job_id, 'timeout_s': timeout_s},
            recoverable=True,
            suggestion="Augmentez le timeout ou vÃ©rifiez la queue IBM"
        )


class QMCJobCancelledError(QMCException):
    """Job annulÃ© par IBM ou l'utilisateur."""
    def __init__(self, message: str, job_id: str = None, reason: str = None, **kwargs):
        super().__init__(
            message=message,
            code="QMC-302",
            details={'job_id': job_id, 'reason': reason},
            recoverable=True,
            suggestion="Resoumettez le job"
        )


class QMCCircuitError(QMCException):
    """Erreur dans la construction du circuit."""
    def __init__(self, message: str, **kwargs):
        super().__init__(
            message=message,
            code="QMC-400",
            recoverable=False,
            suggestion="VÃ©rifiez les paramÃ¨tres du circuit"
        )


class QMCCalibrationError(QMCException):
    """Erreur lors de l'analyse de calibration."""
    def __init__(self, message: str, backend: str = None, **kwargs):
        super().__init__(
            message=message,
            code="QMC-500",
            details={'backend': backend},
            recoverable=True,
            suggestion=kwargs.get('suggestion', "Le backend peut avoir des donnÃ©es de calibration obsolÃ¨tes")
        )


class QMCValidationError(QMCException):
    """Erreur de validation des paramÃ¨tres."""
    def __init__(self, message: str, parameter: str = None, **kwargs):
        super().__init__(
            message=message,
            code="QMC-700",
            details={'parameter': parameter},
            recoverable=False,
            suggestion="VÃ©rifiez les paramÃ¨tres d'entrÃ©e"
        )


class QMCSecurityError(QMCException):
    """
    [v2.5.14] Erreur de sÃ©curitÃ© cryptographique.
    
    LevÃ©e quand une opÃ©ration violerait les contraintes de sÃ©curitÃ©
    en mode production (tentative d'accÃ¨s aux logs, circuits, etc.)
    """
    def __init__(self, message: str, operation: str = None, **kwargs):
        super().__init__(
            message=message,
            code="QMC-SEC",
            details={'operation': operation, 'security_violation': True},
            recoverable=False,
            suggestion="DÃ©sactivez production_mode ou modifiez les paramÃ¨tres de sÃ©curitÃ©"
        )


# Alias pour compatibilitÃ©
SecurityError = QMCSecurityError


# =============================================================================
# RETRY DECORATOR WITH EXPONENTIAL BACKOFF
# =============================================================================

@dataclass
class RetryConfig:
    """Configuration du retry."""
    max_attempts: int = 3
    initial_delay_s: float = 1.0
    max_delay_s: float = 60.0
    exponential_base: float = 2.0
    jitter: bool = True
    retry_on: Tuple[type, ...] = (QMCConnectionError, QMCTimeoutError, QMCExecutionError)


def with_retry(config: RetryConfig = None, logger = None):
    """
    DÃ©corateur pour retry automatique avec backoff exponentiel.
    
    Usage:
        @with_retry(RetryConfig(max_attempts=3))
        def connect_to_backend():
            ...
    
    Args:
        config: Configuration du retry
        logger: Logger optionnel pour les messages
    """
    if config is None:
        config = RetryConfig()
    
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(1, config.max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                    
                except config.retry_on as e:
                    last_exception = e
                    
                    # Check if recoverable
                    if isinstance(e, QMCException) and not e.recoverable:
                        raise
                    
                    if attempt == config.max_attempts:
                        break
                    
                    # Calculate delay with exponential backoff
                    delay = min(
                        config.initial_delay_s * (config.exponential_base ** (attempt - 1)),
                        config.max_delay_s
                    )
                    
                    # Add jitter to prevent thundering herd
                    if config.jitter:
                        delay *= (0.5 + random.random())
                    
                    # Log retry attempt
                    if logger:
                        logger.warn(
                            f"[RETRY] Attempt {attempt}/{config.max_attempts} failed: {e}. "
                            f"Retrying in {delay:.1f}s..."
                        )
                    
                    time.sleep(delay)
                    
                except Exception as e:
                    # Non-retryable exception
                    raise
            
            # All attempts failed
            if last_exception:
                if logger:
                    logger.error(f"[RETRY] All {config.max_attempts} attempts failed")
                raise last_exception
        
        return wrapper
    return decorator


# =============================================================================
# ERROR HANDLER - CENTRALIZED ERROR TRACKING
# =============================================================================

class QMCErrorHandler:
    """
    Gestionnaire centralisÃ© des erreurs QMC.
    
    FonctionnalitÃ©s:
    - Tracking de toutes les erreurs
    - Statistiques d'erreurs
    - Export pour diagnostic
    - Suggestions automatiques
    """
    
    def __init__(self, logger = None, max_history: int = 100):
        self.logger = logger
        self.max_history = max_history
        self._errors: List[Dict] = []
        self._stats: Dict[str, int] = {}
    
    def handle(self, exception: Exception, context: str = None, 
               raise_exception: bool = True) -> Optional[Dict]:
        """
        GÃ¨re une exception de maniÃ¨re centralisÃ©e.
        
        Args:
            exception: L'exception Ã  gÃ©rer
            context: Contexte additionnel (ex: "run_on_qpu")
            raise_exception: Si True, relÃ¨ve l'exception aprÃ¨s logging
            
        Returns:
            Dict avec les dÃ©tails de l'erreur si raise_exception=False
        """
        # Convertir en QMCException si nÃ©cessaire
        if isinstance(exception, QMCException):
            error_info = exception.to_dict()
        else:
            error_info = {
                'code': 'QMC-999',
                'message': str(exception),
                'type': type(exception).__name__,
                'recoverable': False,
                'timestamp': datetime.now().isoformat()
            }
        
        # Ajouter le contexte
        error_info['context'] = context
        
        # Tracker l'erreur
        self._errors.append(error_info)
        if len(self._errors) > self.max_history:
            self._errors.pop(0)
        
        # Mettre Ã  jour les stats
        error_code = error_info.get('code', 'UNKNOWN')
        self._stats[error_code] = self._stats.get(error_code, 0) + 1
        
        # Logger l'erreur
        if self.logger:
            self._log_error(error_info)
        
        if raise_exception:
            raise exception
        
        return error_info
    
    def _log_error(self, error_info: Dict):
        """Log formatÃ© de l'erreur."""
        code = error_info.get('code', 'UNKNOWN')
        message = error_info.get('message', 'Unknown error')
        context = error_info.get('context', '')
        suggestion = error_info.get('suggestion', '')
        
        # Couleurs ANSI
        R = "\033[31m"
        Y = "\033[33m"
        DIM = "\033[2m"
        X = "\033[0m"
        
        self.logger.error(f"{R}â•”â•â• QMC ERROR â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—{X}")
        self.logger.error(f"{R}â•‘{X} Code: {code:<62}{R}â•‘{X}")
        self.logger.error(f"{R}â•‘{X} {message:<68}{R}â•‘{X}")
        if context:
            self.logger.error(f"{R}â•‘{X} Context: {context:<59}{R}â•‘{X}")
        if suggestion:
            self.logger.error(f"{R}â•‘{X} {Y}â†’ {suggestion}{X:<57}{R}â•‘{X}")
        self.logger.error(f"{R}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{X}")
    
    def get_stats(self) -> Dict[str, int]:
        """Retourne les statistiques d'erreurs."""
        return dict(self._stats)
    
    def get_recent_errors(self, n: int = 10) -> List[Dict]:
        """Retourne les N derniÃ¨res erreurs."""
        return self._errors[-n:]
    
    def get_summary(self) -> Dict:
        """Retourne un rÃ©sumÃ© des erreurs."""
        return {
            'total_errors': len(self._errors),
            'error_types': dict(self._stats),
            'most_common': max(self._stats.items(), key=lambda x: x[1]) if self._stats else None,
            'last_error': self._errors[-1] if self._errors else None
        }
    
    def export_errors(self, filepath: str):
        """Exporte les erreurs en JSON."""
        with open(filepath, 'w') as f:
            json.dump({
                'errors': self._errors,
                'stats': self._stats,
                'exported_at': datetime.now().isoformat()
            }, f, indent=2)
    
    def clear(self):
        """Efface l'historique des erreurs."""
        self._errors.clear()
        self._stats.clear()


# =============================================================================
# SAFE EXECUTION CONTEXT MANAGER
# =============================================================================

@contextlib.contextmanager
def safe_qmc_execution(error_handler: QMCErrorHandler = None, 
                       context: str = None,
                       default_return = None,
                       suppress: bool = False):
    """
    Context manager pour exÃ©cution sÃ©curisÃ©e.
    
    Usage:
        with safe_qmc_execution(handler, context="transpilation") as ctx:
            result = transpile_circuit(...)
            ctx.result = result
    
    Args:
        error_handler: Handler pour les erreurs
        context: Contexte de l'opÃ©ration
        default_return: Valeur par dÃ©faut si erreur
        suppress: Si True, supprime l'exception et retourne default_return
    """
    class ExecutionContext:
        def __init__(self):
            self.result = default_return
            self.error = None
            self.success = True
    
    ctx = ExecutionContext()
    
    try:
        yield ctx
    except Exception as e:
        ctx.error = e
        ctx.success = False
        
        if error_handler:
            error_handler.handle(e, context=context, raise_exception=not suppress)
        elif not suppress:
            raise


# =============================================================================
# ENUMS & CONSTANTS
# =============================================================================

class RunMode(Enum):
    """Modes d'exÃ©cution"""
    VALIDATE = "validate"
    SIMULATE = "simulate"
    QPU = "qpu"
    CALIBRATION = "calibration"
    BENCHMARK = "benchmark"
    EXPERIMENT = "experiment"


class LogLevel(Enum):
    """Niveaux de log"""
    DEBUG = 0
    INFO = 1
    WARN = 2
    ERROR = 3
    CRITICAL = 4


class ProjectType(Enum):
    """Types de projets"""
    CUSTOM = "custom"


class MitigationTechnique(Enum):
    """Techniques de mitigation d'erreurs"""
    TWIRLING = "twirling"
    DYNAMICAL_DECOUPLING = "dd"
    ZERO_NOISE_EXTRAPOLATION = "zne"
    PROBABILISTIC_ERROR_CANCELLATION = "pec"
    READOUT_MITIGATION = "readout"
    MEASUREMENT_ERROR_MITIGATION = "mem"


class CircuitFamily(Enum):
    """Familles de circuits"""
    GHZ = "ghz"
    IQP = "iqp"
    CLUSTER = "cluster"
    BELL = "bell"
    RANDOM = "random"
    QFT = "qft"
    GROVER = "grover"
    VQE = "vqe"
    QAOA = "qaoa"
    CUSTOM = "custom"


class AnalysisType(Enum):
    """Types d'analyses"""
    FIDELITY = "fidelity"
    ENTROPY = "entropy"
    CORRELATION = "correlation"
    XEB = "xeb"
    BELL_VIOLATION = "bell_violation"
    RANDOMNESS = "randomness"
    COMPRESSION = "compression"
    QUANTUM_VOLUME = "qv"


class ExperimentStatus(Enum):
    """Status d'expÃ©rience"""
    PENDING = auto()
    RUNNING = auto()
    COMPLETED = auto()
    FAILED = auto()
    CANCELLED = auto()
    PAUSED = auto()


# Backends supportÃ©s avec caractÃ©ristiques dÃ©taillÃ©es
SUPPORTED_BACKENDS = {
    'ibm_fez': {
        'qubits': 156, 
        'type': 'heron2', 
        'gate': 'cz',
        't1_typical_us': 300,
        't2_typical_us': 200,
        'gate_time_ns': 68,
        'readout_time_us': 1.2,
    },
    'ibm_torino': {
        'qubits': 133, 
        'type': 'heron', 
        'gate': 'cz',
        't1_typical_us': 250,
        't2_typical_us': 150,
        'gate_time_ns': 72,
        'readout_time_us': 1.5,
    },
    'ibm_brisbane': {
        'qubits': 127, 
        'type': 'eagle', 
        'gate': 'ecr',
        't1_typical_us': 200,
        't2_typical_us': 100,
        'gate_time_ns': 660,
        'readout_time_us': 1.8,
    },
    'ibm_kyoto': {'qubits': 127, 'type': 'eagle', 'gate': 'ecr'},
    'ibm_osaka': {'qubits': 127, 'type': 'eagle', 'gate': 'ecr'},
    'ibm_sherbrooke': {'qubits': 127, 'type': 'eagle', 'gate': 'ecr'},
}

# Erreurs retriables
RETRIABLE_ERRORS = [
    'IBMJobTimeoutError',
    'IBMRuntimeError', 
    'ConnectionError',
    'TimeoutError',
    'RuntimeJobFailureError',
    'QueueFullError',
    'ServiceUnavailableError',
]


# =============================================================================
# CONFIGURATION CLASSES
# =============================================================================

@dataclass
class QualityThresholds:
    """Seuils configurables pour l'analyse de calibration"""
    qubit_readout_warning: float = 0.03
    qubit_readout_error: float = 0.05
    qubit_readout_critical: float = 0.15
    qubit_sx_warning: float = 0.003
    qubit_sx_error: float = 0.005
    qubit_sx_critical: float = 0.02
    qubit_t1_min_us: float = 10.0
    qubit_t2_min_us: float = 5.0
    gate_2q_good: float = 0.01
    gate_2q_warning: float = 0.02
    gate_2q_weak: float = 0.03
    gate_2q_critical: float = 0.05
    gate_2q_broken: float = 0.10
    
    def to_dict(self) -> Dict:
        return asdict(self)
    
    @classmethod
    def strict(cls) -> 'QualityThresholds':
        return cls(qubit_readout_error=0.03, gate_2q_weak=0.02, gate_2q_critical=0.03)
    
    @classmethod
    def relaxed(cls) -> 'QualityThresholds':
        return cls(qubit_readout_error=0.10, gate_2q_weak=0.05, gate_2q_critical=0.08)
    
    @classmethod
    def ultra_strict(cls) -> 'QualityThresholds':
        """Pour applications cryptographiques critiques"""
        return cls(
            qubit_readout_error=0.02,
            qubit_sx_error=0.002,
            gate_2q_good=0.005,
            gate_2q_warning=0.01,
            gate_2q_weak=0.015,
            gate_2q_critical=0.02)


@dataclass
class MitigationConfig:
    """Configuration des techniques de mitigation"""
    enable_twirling: bool = True
    enable_dd: bool = True
    enable_zne: bool = False
    enable_pec: bool = False
    enable_readout_mitigation: bool = True
    enable_measurement_error_mitigation: bool = False
    
    twirling_num_randomizations: int = 32
    twirling_shots_per_randomization: int = None
    dd_sequence: str = 'XY4'
    zne_noise_factors: List[float] = field(default_factory=lambda: [1, 1.5, 2])
    zne_extrapolator: str = 'linear'
    
    def to_dict(self) -> Dict:
        return asdict(self)
    
    @classmethod
    def none(cls) -> 'MitigationConfig':
        """Pas de mitigation"""
        return cls(
            enable_twirling=False,
            enable_dd=False,
            enable_readout_mitigation=False)
    
    @classmethod
    def full(cls) -> 'MitigationConfig':
        """Toutes les mitigations"""
        return cls(
            enable_twirling=True,
            enable_dd=True,
            enable_zne=True,
            enable_readout_mitigation=True,
            enable_measurement_error_mitigation=True,
            twirling_num_randomizations=64)


@dataclass
class ExperimentConfig:
    """Configuration complÃ¨te d'une expÃ©rience"""
    name: str = "experiment"
    description: str = ""
    
    # ParamÃ¨tres de base
    backend_name: str = "ibm_fez"
    scales: List[int] = field(default_factory=lambda: [50, 75, 100])
    shots: int = 8192
    
    # Circuit
    circuit_family: CircuitFamily = CircuitFamily.GHZ
    circuit_params: Dict = field(default_factory=dict)
    
    # Mitigation
    mitigation: MitigationConfig = field(default_factory=MitigationConfig)
    
    # Thresholds
    thresholds: QualityThresholds = field(default_factory=QualityThresholds)
    
    # Analyses Ã  effectuer
    analyses: List[AnalysisType] = field(default_factory=lambda: [
        AnalysisType.FIDELITY, 
        AnalysisType.ENTROPY,
        AnalysisType.CORRELATION,
    ])
    
    # Options avancÃ©es
    timeout_per_job: float = 3600.0
    max_retries: int = 3
    save_raw_counts: bool = True
    generate_visualizations: bool = True
    export_formats: List[str] = field(default_factory=lambda: ['json', 'csv', 'html'])
    
    # [v2.5.14] Options de sÃ©curitÃ©/confidentialitÃ© pour jobs cryptographiques
    private: bool = False  # Rendre le job privÃ© (tags IBM)
    auto_delete_job: bool = False  # Supprimer le job aprÃ¨s rÃ©cupÃ©ration des rÃ©sultats
    redact_logs: bool = False  # Masquer les donnÃ©es sensibles dans les logs
    production_mode: bool = False  # Active le triptyque: private + auto_delete + redact_logs
    
    # Tags et mÃ©tadonnÃ©es
    tags: List[str] = field(default_factory=list)
    metadata: Dict = field(default_factory=dict)
    
    def to_dict(self) -> Dict:
        d = asdict(self)
        d['circuit_family'] = self.circuit_family.value
        d['analyses'] = [a.value for a in self.analyses]
        return d
    
    @classmethod
    def from_yaml(cls, path: PathType) -> 'ExperimentConfig':
        """Charge depuis un fichier YAML"""
        with open(path) as f:
            data = yaml.safe_load(f)
        
        if 'circuit_family' in data:
            data['circuit_family'] = CircuitFamily(data['circuit_family'])
        if 'analyses' in data:
            data['analyses'] = [AnalysisType(a) for a in data['analyses']]
        if 'mitigation' in data:
            data['mitigation'] = MitigationConfig(**data['mitigation'])
        if 'thresholds' in data:
            data['thresholds'] = QualityThresholds(**data['thresholds'])
        
        return cls(**data)
    
    def to_yaml(self, path: PathType):
        """Sauvegarde en YAML"""
        with open(path, 'w') as f:
            yaml.dump(self.to_dict(), f, default_flow_style=False)


# =============================================================================
# UTILITIES
# =============================================================================

def ensure_list(x: Any) -> List:
    """Convertit en liste si nÃ©cessaire"""
    if x is None:
        return []
    if isinstance(x, (list, tuple)):
        return list(x)
    return [x]


def deep_merge(base: Dict, override: Dict) -> Dict:
    """Fusionne deux dicts rÃ©cursivement"""
    result = copy.deepcopy(base)
    for key, value in override.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = deep_merge(result[key], value)
        else:
            result[key] = copy.deepcopy(value)
    return result


def generate_id(prefix: str = "", length: int = 8) -> str:
    """GÃ©nÃ¨re un ID unique"""
    random_hex = secrets.token_hex(length // 2)
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    if prefix:
        return f"{prefix}_{timestamp}_{random_hex}"
    return f"{timestamp}_{random_hex}"


def timing(func):
    """DÃ©corateur pour mesurer le temps d'exÃ©cution"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        elapsed = time.time() - start
        return result, elapsed
    return wrapper


class Singleton(type):
    """MÃ©taclasse pour pattern Singleton"""
    _instances = {}
    
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super().__call__(*args, **kwargs)
        return cls._instances[cls]


# =============================================================================
# LOGGING SYSTEM (Enhanced)
# =============================================================================

class Logger:
    """SystÃ¨me de logging avancÃ© avec contexte et mÃ©triques"""
    
    COLORS = {
        LogLevel.DEBUG: '\033[90m',
        LogLevel.INFO: '\033[0m',
        LogLevel.WARN: '\033[93m',
        LogLevel.ERROR: '\033[91m',
        LogLevel.CRITICAL: '\033[91;1m',
    }
    RESET = '\033[0m'
    
    ICONS = {
        LogLevel.DEBUG: 'ğŸ”',
        LogLevel.INFO: '[=]',
        LogLevel.WARN: '[!!]',
        LogLevel.ERROR: '[XX]',
        LogLevel.CRITICAL: 'ğŸš¨',
    }
    
    def __init__(self, 
                 log_file: Path = None,
                 min_level: LogLevel = LogLevel.INFO,
                 buffer_size: int = 20,
                 use_colors: bool = True):
        
        self.log_file = log_file
        self.min_level = min_level
        self.buffer_size = buffer_size
        self.use_colors = use_colors
        
        self._buffer = []
        self._start_time = time.time()
        self._lock = threading.Lock()
        self._context_stack = []
        self._counts = {level: 0 for level in LogLevel}
        self._timings = {}
    
    def _format_time(self) -> str:
        return datetime.now().strftime('%H:%M:%S.%f')[:-3]
    
    def _format_duration(self) -> str:
        elapsed = time.time() - self._start_time
        return f"{elapsed:8.2f}s"
    
    def _get_context(self) -> str:
        if self._context_stack:
            return " > ".join(self._context_stack)
        return ""
    
    @contextmanager
    def context(self, name: str):
        """Context manager pour logging contextuel"""
        self._context_stack.append(name)
        start = time.time()
        try:
            yield
        finally:
            elapsed = time.time() - start
            self._timings[name] = elapsed
            self._context_stack.pop()
    
    def log(self, msg: str, level: LogLevel = LogLevel.INFO, 
            section: str = None, data: Dict = None):
        
        if level.value < self.min_level.value:
            return
        
        with self._lock:
            self._counts[level] += 1
            
            timestamp = self._format_time()
            duration = self._format_duration()
            icon = self.ICONS.get(level, '')
            context = self._get_context()
            
            prefix = f"[{timestamp}] [{duration}]"
            if context:
                prefix += f" [{context}]"
            if section:
                prefix += f" [{section}]"
            
            full_msg = f"{prefix} {icon} {msg}"
            
            if data:
                full_msg += f" | {json.dumps(data, default=str)}"
            
            if self.use_colors:
                color = self.COLORS.get(level, '')
                print(f"{color}{full_msg}{self.RESET}")
            else:
                print(full_msg)
            
            if self.log_file:
                self._buffer.append(full_msg)
                if len(self._buffer) >= self.buffer_size:
                    self._flush_buffer()
    
    def debug(self, msg: str, **kwargs): self.log(msg, LogLevel.DEBUG, **kwargs)
    def info(self, msg: str, **kwargs): self.log(msg, LogLevel.INFO, **kwargs)
    def warn(self, msg: str, **kwargs): self.log(msg, LogLevel.WARN, **kwargs)
    def error(self, msg: str, **kwargs): self.log(msg, LogLevel.ERROR, **kwargs)
    def critical(self, msg: str, **kwargs): self.log(msg, LogLevel.CRITICAL, **kwargs)
    
    def section(self, title: str, char: str = '=', width: int = 70):
        line = char * width
        self.log(line, LogLevel.INFO)
        self.log(f" {title} ".center(width, char), LogLevel.INFO)
        self.log(line, LogLevel.INFO)
    
    def subsection(self, title: str):
        self.log(f"--- {title} ---", LogLevel.INFO)
    
    def progress(self, current: int, total: int, prefix: str = ""):
        pct = 100 * current / total if total > 0 else 0
        bar_len = 30
        filled = int(bar_len * current / total) if total > 0 else 0
        bar = 'â–ˆ' * filled + 'â–‘' * (bar_len - filled)
        self.log(f"{prefix} [{bar}] {pct:.1f}% ({current}/{total})", LogLevel.INFO)
    
    def table(self, headers: List[str], rows: List[List], title: str = None):
        """Affiche un tableau formatÃ©"""
        if title:
            self.subsection(title)
        
        widths = [max(len(str(h)), max(len(str(r[i])) for r in rows)) 
                  for i, h in enumerate(headers)]
        
        header_line = " | ".join(h.ljust(widths[i]) for i, h in enumerate(headers))
        sep_line = "-+-".join("-" * w for w in widths)
        
        self.log(header_line, LogLevel.INFO)
        self.log(sep_line, LogLevel.INFO)
        
        for row in rows:
            row_line = " | ".join(str(row[i]).ljust(widths[i]) for i in range(len(headers)))
            self.log(row_line, LogLevel.INFO)
    
    def _flush_buffer(self):
        if self._buffer and self.log_file:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                for line in self._buffer:
                    clean_line = line
                    for color in self.COLORS.values():
                        clean_line = clean_line.replace(color, '')
                    clean_line = clean_line.replace(self.RESET, '')
                    f.write(clean_line + '\n')
            self._buffer = []
    
    def flush(self):
        with self._lock:
            self._flush_buffer()
    
    def get_stats(self) -> Dict:
        return {
            'counts': {level.name: count for level, count in self._counts.items()},
            'duration_s': time.time() - self._start_time,
            'errors': self._counts[LogLevel.ERROR] + self._counts[LogLevel.CRITICAL],
            'timings': self._timings.copy(),
        }


# =============================================================================
# PLUGIN SYSTEM - CORE
# =============================================================================

class PluginMeta(type):
    """MÃ©taclasse pour auto-enregistrement des plugins"""
    
    def __new__(mcs, name, bases, namespace):
        cls = super().__new__(mcs, name, bases, namespace)
        
        # Ne pas enregistrer les classes de base abstraites
        if not namespace.get('_abstract', False) and name not in ['QMCModule', 'CircuitBuilder', 'Analyzer']:
            registry = PluginRegistry.instance()
            registry.register(cls)
        
        return cls


class PluginRegistry:
    """
    Registre central des plugins - avec auto-registration
    
    Les plugins built-in sont automatiquement enregistrÃ©s au premier accÃ¨s.
    """
    
    _instance = None
    _builtins_registered = False
    
    @classmethod
    def instance(cls) -> 'PluginRegistry':
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    def __init__(self):
        self._modules: Dict[str, Type['QMCModule']] = {}
        self._circuit_builders: Dict[str, Type['CircuitBuilder']] = {}
        self._analyzers: Dict[str, Type['Analyzer']] = {}
        self._hooks: Dict[str, List[Callable]] = defaultdict(list)
        self._logger: Optional[Logger] = None
    
    def _ensure_builtins_registered(self):
        """S'assure que les plugins built-in sont enregistrÃ©s"""
        if PluginRegistry._builtins_registered:
            return
        
        # Circuit Builders - v2.3.1
        self._circuit_builders['ghz'] = GHZBuilder
        self._circuit_builders['iqp'] = IQPBuilder
        self._circuit_builders['bell'] = BellBuilder
        self._circuit_builders['cluster'] = ClusterBuilder
        self._circuit_builders['random'] = RandomCircuitBuilder
        self._circuit_builders['qft'] = QFTBuilder
        self._circuit_builders['parametrized'] = ParameterizedCircuitBuilder
        
        # Analyzers - v2.3.1
        self._analyzers['fidelity'] = FidelityAnalyzer
        self._analyzers['entropy'] = EntropyAnalyzer
        self._analyzers['correlation'] = CorrelationAnalyzer
        self._analyzers['xeb'] = XEBAnalyzer
        self._analyzers['bell'] = BellAnalyzer
        self._analyzers['randomness'] = RandomnessAnalyzer
        self._analyzers['compression'] = CompressionAnalyzer
        
        # QMC Modules - v2.3.1
                                                
        PluginRegistry._builtins_registered = True
        
        # Enregistrer les plugins v2.4.0 (appelÃ© aprÃ¨s pour les classes dÃ©finies plus tard)
        self._register_v24_plugins()
    
    def set_logger(self, logger: Logger):
        self._logger = logger
    
    def _register_v24_plugins(self):
        """Enregistre les plugins v2.4.0 (appelÃ© dynamiquement)"""
        # Cette mÃ©thode est appelÃ©e aprÃ¨s _ensure_builtins_registered
        # Les classes v2.4.0 sont dÃ©finies plus tard dans le fichier
        # On les enregistre via globals() pour les trouver dynamiquement
        try:
            g = globals()
            
            # Circuit Builders v2.4.0
            v24_builders = [
                ('quantum_signature', 'QuantumSignatureBuilder'),
                ('zkp', 'ZKPBuilder'),
                ('timelock', 'TimeLockBuilder'),
                ('oblivious_transfer', 'ObliviousTransferBuilder'),
            ]
            for name, cls_name in v24_builders:
                if cls_name in g:
                    self._circuit_builders[name] = g[cls_name]
            
            # Analyzers v2.4.0
            v24_analyzers = [
                ('xeb_cross', 'XEBCrossValidationAnalyzer'),
                ('honeypot', 'HoneypotAnalyzer'),
                ('quantum_advantage', 'QuantumAdvantageAnalyzer'),
            ]
            for name, cls_name in v24_analyzers:
                if cls_name in g:
                    self._analyzers[name] = g[cls_name]
            
            # Modules v2.4.0
            v24_modules = [
                ('threshold_crypto', 'ThresholdCryptoModule'),
                ('quantum_signature', 'QuantumSignatureModule'),
                ('zkp', 'ZKPModule'),
            ]
            for name, cls_name in v24_modules:
                if cls_name in g:
                    self._modules[name] = g[cls_name]
        except Exception:
            pass  # Silencieux si les classes ne sont pas encore dÃ©finies
    
    def _log(self, msg: str, level: LogLevel = LogLevel.DEBUG):
        if self._logger:
            self._logger.log(msg, level, section='REGISTRY')
    
    def register(self, cls: Type):
        """Enregistre automatiquement un plugin selon son type"""
        from abc import ABC
        
        # Identifier le type de plugin
        for base in inspect.getmro(cls):
            if base.__name__ == 'QMCModule' and cls.__name__ != 'QMCModule':
                self._modules[cls.get_name()] = cls
                self._log(f"Module registered: {cls.get_name()}")
                return
            elif base.__name__ == 'CircuitBuilder' and cls.__name__ != 'CircuitBuilder':
                name = getattr(cls, 'name', cls.__name__.lower().replace('builder', ''))
                self._circuit_builders[name] = cls
                self._log(f"CircuitBuilder registered: {name}")
                return
            elif base.__name__ == 'Analyzer' and cls.__name__ != 'Analyzer':
                name = getattr(cls, 'name', cls.__name__.lower().replace('analyzer', ''))
                self._analyzers[name] = cls
                self._log(f"Analyzer registered: {name}")
                return
    
    def get_module(self, name: str) -> Optional[Type['QMCModule']]:
        self._ensure_builtins_registered()
        return self._modules.get(name)
    
    def get_circuit_builder(self, name: str) -> Optional[Type['CircuitBuilder']]:
        self._ensure_builtins_registered()
        return self._circuit_builders.get(name.lower())
    
    def get_analyzer(self, name: str) -> Optional[Type['Analyzer']]:
        self._ensure_builtins_registered()
        return self._analyzers.get(name.lower())
    
    def list_modules(self) -> List[str]:
        self._ensure_builtins_registered()
        return list(self._modules.keys())
    
    def list_circuit_builders(self) -> List[str]:
        self._ensure_builtins_registered()
        return list(self._circuit_builders.keys())
    
    def list_analyzers(self) -> List[str]:
        self._ensure_builtins_registered()
        return list(self._analyzers.keys())
    
    def register_hook(self, event: str, callback: Callable):
        """Enregistre un hook pour un Ã©vÃ©nement"""
        self._hooks[event].append(callback)
    
    def trigger_hook(self, event: str, *args, **kwargs):
        """DÃ©clenche tous les hooks pour un Ã©vÃ©nement"""
        for callback in self._hooks.get(event, []):
            try:
                callback(*args, **kwargs)
            except Exception as e:
                self._log(f"Hook error ({event}): {e}", LogLevel.WARN)
    
    def discover_plugins(self, path: PathType):
        """DÃ©couvre et charge les plugins depuis un rÃ©pertoire"""
        plugin_path = Path(path)
        if not plugin_path.exists():
            return
        
        sys.path.insert(0, str(plugin_path))
        
        for py_file in plugin_path.glob("*.py"):
            if py_file.stem.startswith("_"):
                continue
            
            try:
                module_name = py_file.stem
                importlib.import_module(module_name)
                self._log(f"Loaded plugin: {module_name}")
            except Exception as e:
                self._log(f"Failed to load {py_file}: {e}", LogLevel.WARN)


# =============================================================================
# BASE CLASSES FOR PLUGINS
# =============================================================================

class QMCModule(ABC):
    """
    Classe de base pour les modules QMC (Core, Shield, Biometric, etc.)
    
    Chaque module reprÃ©sente un brevet/fonctionnalitÃ© complÃ¨te.
    """
    
    _abstract = True
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.logger = framework.logger if framework else None
        self._initialized = False
        self._results = {}
    
    @classmethod
    @abstractmethod
    def get_name(cls) -> str:
        """Nom unique du module"""
        pass
    
    @classmethod
    def get_version(cls) -> str:
        """Version du module"""
        return "1.0.0"
    
    @classmethod
    def get_description(cls) -> str:
        """Description du module"""
        return ""
    
    @classmethod
    def get_patent_ref(cls) -> str:
        """RÃ©fÃ©rence du brevet associÃ©"""
        return ""
    
    @classmethod
    def get_dependencies(cls) -> List[str]:
        """Modules requis"""
        return []
    
    def initialize(self, config: Dict = None):
        """Initialise le module"""
        self._config = config or {}
        self._initialized = True
        self._log(f"Module {self.get_name()} initialized")
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section=self.get_name().upper())
    
    @abstractmethod
    def run(self, **kwargs) -> Dict:
        """ExÃ©cute la fonctionnalitÃ© principale du module"""
        pass
    
    def validate(self) -> Tuple[bool, str]:
        """Valide que le module est correctement configurÃ©"""
        if not self._initialized:
            return False, "Module not initialized"
        return True, "OK"
    
    def get_results(self) -> Dict:
        """Retourne les derniers rÃ©sultats"""
        return self._results
    
    def export_results(self, path: PathType, format: str = 'json'):
        """Exporte les rÃ©sultats"""
        path = Path(path)
        
        if format == 'json':
            with open(path, 'w') as f:
                json.dump(self._results, f, indent=2, default=str)
        elif format == 'yaml':
            with open(path, 'w') as f:
                yaml.dump(self._results, f, default_flow_style=False)


class CircuitBuilder(ABC):
    """
    Classe de base pour les constructeurs de circuits.
    
    Permet de crÃ©er des circuits de diffÃ©rentes familles de maniÃ¨re standardisÃ©e.
    """
    
    _abstract = True
    name: str = "base"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: Logger = None):
        self.topology = topology
        self.logger = logger
        self._circuits = []
        self._metadata = {}
    
    def _log(self, msg: str, level: LogLevel = LogLevel.DEBUG):
        if self.logger:
            self.logger.log(msg, level, section=f'BUILDER:{self.name.upper()}')
    
    @abstractmethod
    def build(self, n_qubits: int, **params) -> CircuitType:
        """Construit un circuit pour n qubits"""
        pass
    
    def build_batch(self, scales: List[int], **params) -> List[CircuitType]:
        """Construit plusieurs circuits pour diffÃ©rentes Ã©chelles"""
        circuits = []
        for n in scales:
            try:
                qc = self.build(n, **params)
                circuits.append(qc)
                self._circuits.append(qc)
            except Exception as e:
                self._log(f"Failed to build circuit for n={n}: {e}", LogLevel.WARN)
        return circuits
    
    def get_optimal_path(self, n_qubits: int) -> List[int]:
        """Obtient le chemin optimal depuis la topologie"""
        if self.topology:
            return self.topology.get_best_path(n_qubits)
        return list(range(n_qubits))
    
    def add_measurements(self, qc: CircuitType, qubits: List[int], 
                         basis: str = 'Z') -> CircuitType:
        """Ajoute les mesures dans une base donnÃ©e"""
        from qiskit import ClassicalRegister
        
        if not hasattr(qc, 'cregs') or not qc.cregs:
            cr = ClassicalRegister(len(qubits), 'c')
            qc.add_register(cr)
        
        if basis == 'X':
            for q in qubits:
                qc.h(q)
        elif basis == 'Y':
            for q in qubits:
                qc.sdg(q)
                qc.h(q)
        
        for i, q in enumerate(qubits):
            qc.measure(q, i)
        
        return qc
    
    def get_metadata(self) -> Dict[str, Any]:
        """
        Retourne les mÃ©tadonnÃ©es du dernier circuit construit.
        
        Returns:
            Dict contenant les informations sur le circuit
        """
        return self._metadata.copy()
    
    def get_info(self) -> Dict:
        """Retourne les informations sur les circuits construits"""
        return {
            'builder': self.name,
            'circuits_count': len(self._circuits),
            'metadata': self._metadata,
        }


class Analyzer(ABC):
    """
    Classe de base pour les analyseurs de rÃ©sultats.
    
    [v2.5.9] Ajout de la normalisation automatique des bitstrings.
    """
    
    _abstract = True
    name: str = "base"
    
    def __init__(self, logger: Logger = None):
        self.logger = logger
        self._results = {}
    
    def _log(self, msg: str, level: LogLevel = LogLevel.DEBUG):
        if self.logger:
            self.logger.log(msg, level, section=f'ANALYZER:{self.name.upper()}')
    
    def _normalize_counts(self, counts: Dict[str, int]) -> Dict[str, int]:
        """
        [v2.5.9] Normalise les bitstrings des counts.
        
        - Supprime les espaces (multi-register Qiskit: "00 11" â†’ "0011")
        - Garde uniquement les caractÃ¨res 0/1
        
        Args:
            counts: Dict {bitstring: count}
            
        Returns:
            Dict avec bitstrings nettoyÃ©s
        """
        if not counts:
            return counts
        
        normalized = {}
        for bitstring, count in counts.items():
            # Supprimer espaces et garder uniquement 0/1
            clean = ''.join(c for c in bitstring if c in '01')
            if clean:
                normalized[clean] = normalized.get(clean, 0) + count
        
        return normalized
    
    @abstractmethod
    def analyze(self, counts: CountsType, **params) -> Dict:
        """Analyse les rÃ©sultats"""
        pass
    
    def analyze_batch(self, results: List[Dict], **params) -> List[Dict]:
        """
        Analyse plusieurs rÃ©sultats.
        
        [v2.5.9] Les counts sont automatiquement normalisÃ©s.
        """
        analyses = []
        for res in results:
            counts = res.get('counts', {})
            
            # [v2.5.9] Normaliser les bitstrings
            counts = self._normalize_counts(counts)
            
            n_qubits = res.get('n_qubits', len(next(iter(counts.keys()), '')))
            
            analysis = self.analyze(counts, n_qubits=n_qubits, **params)
            analysis['circuit_index'] = res.get('circuit_index', len(analyses))
            analyses.append(analysis)
        
        self._results = analyses
        return analyses
    
    def get_summary(self) -> Dict:
        """GÃ©nÃ¨re un rÃ©sumÃ© des analyses"""
        if not self._results:
            return {}
        
        return {
            'analyzer': self.name,
            'count': len(self._results),
            'results': self._results,
        }


# =============================================================================
# CIRCUIT BUILDERS - IMPLEMENTATIONS
# =============================================================================

class GHZBuilder(CircuitBuilder):
    """Constructeur de circuits GHZ"""
    
    name = "ghz"
    
    def build(self, n_qubits: int, add_barriers: bool = False, 
              add_measurements: bool = True) -> CircuitType:
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"GHZ_{n_qubits}Q")
        else:
            qc = QuantumCircuit(qr, name=f"GHZ_{n_qubits}Q")
        
        # Hadamard sur le premier qubit
        qc.h(path[0])
        
        if add_barriers:
            qc.barrier()
        
        # ChaÃ®ne de CNOT
        for i in range(n_qubits - 1):
            qc.cx(path[i], path[i + 1])
        
        if add_barriers:
            qc.barrier()
        
        # Mesures
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['path'] = path
        self._log(f"Built GHZ circuit: {n_qubits}Q, path={path[:5]}...")
        
        return qc


class IQPBuilder(CircuitBuilder):
    """Constructeur de circuits IQP (Instantaneous Quantum Polynomial)
    
    [v2.5.9] Ajout du paramÃ¨tre seed pour reproductibilitÃ©.
    """
    
    name = "iqp"
    
    def build(self, n_qubits: int, depth: int = 10, 
              use_random_angles: bool = True,
              seed: int = None,
              add_measurements: bool = True) -> CircuitType:
        """
        Construit un circuit IQP.
        
        Args:
            n_qubits: Nombre de qubits
            depth: Profondeur du circuit (nombre de couches)
            use_random_angles: Utiliser des angles alÃ©atoires (sinon dÃ©terministe)
            seed: Seed pour reproductibilitÃ© (None = non reproductible)
            add_measurements: Ajouter les mesures
            
        Returns:
            QuantumCircuit IQP
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        # RNG local pour reproductibilitÃ© (v2.5.9)
        rng = np.random.default_rng(seed)
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"IQP_{n_qubits}Q_d{depth}")
        else:
            qc = QuantumCircuit(qr, name=f"IQP_{n_qubits}Q_d{depth}")
        
        # Couche de Hadamard initiale
        for q in path:
            qc.h(q)
        
        # Couches IQP
        for layer in range(depth):
            # Portes CZ entre qubits ADJACENTS (CRITIQUE!)
            for i in range(n_qubits - 1):
                qc.cz(path[i], path[i + 1])
            
            # Rotations RZ
            for i, q in enumerate(path):
                if use_random_angles:
                    angle = rng.uniform(0, 2 * np.pi)
                else:
                    angle = np.pi / 4 * (layer + 1) * (i + 1) / n_qubits
                qc.rz(angle, q)
        
        # Couche de Hadamard finale
        for q in path:
            qc.h(q)
        
        # Mesures
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['depth'] = depth
        self._metadata['path'] = path
        self._metadata['seed'] = seed
        self._log(f"Built IQP circuit: {n_qubits}Q, depth={depth}, seed={seed}")
        
        return qc


class ClusterBuilder(CircuitBuilder):
    """Constructeur de circuits Cluster State 1D"""
    
    name = "cluster"
    
    def build(self, n_qubits: int, add_measurements: bool = True,
              measurement_basis: str = 'Z') -> CircuitType:
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"Cluster1D_{n_qubits}Q")
        else:
            qc = QuantumCircuit(qr, name=f"Cluster1D_{n_qubits}Q")
        
        # Tous les qubits en |+âŸ©
        for q in path:
            qc.h(q)
        
        # Portes CZ entre adjacents
        for i in range(n_qubits - 1):
            qc.cz(path[i], path[i + 1])
        
        # Changement de base si nÃ©cessaire
        if measurement_basis == 'X':
            for q in path:
                qc.h(q)
        elif measurement_basis == 'Y':
            for q in path:
                qc.sdg(q)
                qc.h(q)
        
        # Mesures
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['path'] = path
        self._metadata['basis'] = measurement_basis
        self._log(f"Built Cluster circuit: {n_qubits}Q, basis={measurement_basis}")
        
        return qc


class BellBuilder(CircuitBuilder):
    """
    Constructeur de circuits Bell/CHSH
    
    [v2.5.9] Ajout du warning si n_qubits impair.
    
    Angles CHSH optimaux pour violation maximale (S = 2âˆš2 â‰ˆ 2.83):
    - Alice: a0 = 0, a1 = Ï€/4
    - Bob: b0 = Ï€/8, b1 = 3Ï€/8
    """
    
    name = "bell"
    
    # Angles CHSH optimaux (en radians)
    CHSH_ANGLES = {
        0: (0, np.pi/8),           # A0, B0
        1: (0, 3*np.pi/8),         # A0, B1
        2: (np.pi/4, np.pi/8),     # A1, B0
        3: (np.pi/4, 3*np.pi/8),   # A1, B1
    }
    
    def build(self, n_qubits: int = 2, n_pairs: int = None,
              chsh_setting: int = 0, add_measurements: bool = True) -> CircuitType:
        """
        Construit un circuit Bell ou CHSH.
        
        Args:
            n_qubits: Nombre de qubits (doit Ãªtre pair)
            n_pairs: Nombre de paires Bell (dÃ©faut: n_qubits/2)
            chsh_setting: 0-3 pour les 4 settings CHSH
            add_measurements: Ajouter les mesures
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        # [v2.5.9] Warning explicite si qubits impairs
        if n_qubits % 2 != 0:
            self._log(
                f"âš ï¸ BellBuilder: n_qubits={n_qubits} est impair, rÃ©duit Ã  {n_qubits-1} "
                f"(les circuits Bell nÃ©cessitent des paires)",
                LogLevel.WARN
            )
            n_qubits = n_qubits - 1
        
        n_pairs = n_pairs or n_qubits // 2
        n_qubits = n_pairs * 2
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"Bell_{n_pairs}pairs_s{chsh_setting}")
        else:
            qc = QuantumCircuit(qr, name=f"Bell_{n_pairs}pairs_s{chsh_setting}")
        
        # Angles pour ce setting CHSH
        alice_angle, bob_angle = self.CHSH_ANGLES.get(chsh_setting, (0, np.pi/8))
        
        # CrÃ©er les paires Bell et appliquer les rotations
        for i in range(n_pairs):
            q_alice, q_bob = path[2*i], path[2*i + 1]
            
            # CrÃ©er paire Bell |Î¦+âŸ© = (|00âŸ© + |11âŸ©)/âˆš2
            qc.h(q_alice)
            qc.cx(q_alice, q_bob)
            
            # Rotations de mesure (RY(-2Î¸) pour mesurer dans la base Î¸)
            if alice_angle != 0:
                qc.ry(-2 * alice_angle, q_alice)
            if bob_angle != 0:
                qc.ry(-2 * bob_angle, q_bob)
        
        # Mesures
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['n_pairs'] = n_pairs
        self._metadata['chsh_setting'] = chsh_setting
        self._metadata['alice_angle'] = alice_angle
        self._metadata['bob_angle'] = bob_angle
        self._log(f"Built Bell circuit: {n_pairs} pairs, setting={chsh_setting}")
        
        return qc
    
    def build_chsh_suite(self, n_pairs: int = 1) -> List[CircuitType]:
        """Construit les 4 circuits CHSH"""
        return [self.build(n_pairs * 2, n_pairs, setting) for setting in range(4)]


class RandomCircuitBuilder(CircuitBuilder):
    """Constructeur de circuits alÃ©atoires (Random Circuit Sampling)
    
    [v2.5.9] Utilise RNG local au lieu de np.random.seed global.
    """
    
    name = "random"
    
    def build(self, n_qubits: int, depth: int = 20, 
              seed: int = None, add_measurements: bool = True) -> CircuitType:
        """
        Construit un circuit alÃ©atoire.
        
        Args:
            n_qubits: Nombre de qubits
            depth: Profondeur du circuit
            seed: Seed pour reproductibilitÃ© (RNG local, pas d'effet de bord)
            add_measurements: Ajouter les mesures
            
        Returns:
            QuantumCircuit alÃ©atoire
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        from qiskit.circuit.library import UGate
        
        # RNG local pour Ã©viter les effets de bord (v2.5.9)
        rng = np.random.default_rng(seed)
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"Random_{n_qubits}Q_d{depth}")
        else:
            qc = QuantumCircuit(qr, name=f"Random_{n_qubits}Q_d{depth}")
        
        # Couches alternÃ©es
        for layer in range(depth):
            # Portes single-qubit alÃ©atoires
            for q in path:
                theta = rng.uniform(0, np.pi)
                phi = rng.uniform(0, 2 * np.pi)
                lam = rng.uniform(0, 2 * np.pi)
                qc.append(UGate(theta, phi, lam), [q])
            
            # Portes CZ (pattern alternÃ©)
            start = layer % 2
            for i in range(start, n_qubits - 1, 2):
                qc.cz(path[i], path[i + 1])
        
        # Couche finale de portes alÃ©atoires
        for q in path:
            theta = rng.uniform(0, np.pi)
            phi = rng.uniform(0, 2 * np.pi)
            lam = rng.uniform(0, 2 * np.pi)
            qc.append(UGate(theta, phi, lam), [q])
        
        # Mesures
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['depth'] = depth
        self._metadata['seed'] = seed
        self._log(f"Built Random circuit: {n_qubits}Q, depth={depth}, seed={seed}")
        
        return qc


class QFTBuilder(CircuitBuilder):
    """Constructeur de circuits Quantum Fourier Transform"""
    
    name = "qft"
    
    def build(self, n_qubits: int, inverse: bool = False,
              add_measurements: bool = True) -> CircuitType:
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        suffix = "inv" if inverse else ""
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"QFT{suffix}_{n_qubits}Q")
        else:
            qc = QuantumCircuit(qr, name=f"QFT{suffix}_{n_qubits}Q")
        
        # PrÃ©parer un Ã©tat non-trivial
        for i, q in enumerate(path):
            if i % 2 == 0:
                qc.x(q)
        
        qc.barrier()
        
        # QFT
        def qft_rotations(circuit, qubits, n):
            if n == 0:
                return circuit
            n -= 1
            circuit.h(qubits[n])
            for qubit in range(n):
                k = n - qubit
                circuit.cp(np.pi / (2 ** k), qubits[qubit], qubits[n])
            return qft_rotations(circuit, qubits, n)
        
        def swap_qubits(circuit, qubits, n):
            for i in range(n // 2):
                circuit.swap(qubits[i], qubits[n - i - 1])
            return circuit
        
        if inverse:
            swap_qubits(qc, path, n_qubits)
            for i in range(n_qubits):
                for j in range(i):
                    k = i - j
                    qc.cp(-np.pi / (2 ** k), path[j], path[i])
                qc.h(path[i])
        else:
            qft_rotations(qc, path, n_qubits)
            swap_qubits(qc, path, n_qubits)
        
        qc.barrier()
        
        # Mesures
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['inverse'] = inverse
        self._log(f"Built QFT circuit: {n_qubits}Q, inverse={inverse}")
        
        return qc


class ParameterizedCircuitBuilder(CircuitBuilder):
    """Constructeur de circuits paramÃ©trÃ©s (VQE-like)"""
    
    name = "parametrized"
    
    def build(self, n_qubits: int, n_layers: int = 2,
              entanglement: str = 'linear', parameter_values: List[float] = None,
              add_measurements: bool = True) -> CircuitType:
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        from qiskit.circuit import Parameter
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"VQE_{n_qubits}Q_L{n_layers}")
        else:
            qc = QuantumCircuit(qr, name=f"VQE_{n_qubits}Q_L{n_layers}")
        
        params = []
        param_idx = 0
        
        for layer in range(n_layers):
            # Couche de rotations RY
            for i, q in enumerate(path):
                if parameter_values is not None and param_idx < len(parameter_values):
                    angle = parameter_values[param_idx]
                else:
                    p = Parameter(f'Î¸_{layer}_{i}')
                    params.append(p)
                    angle = p
                param_idx += 1
                qc.ry(angle if isinstance(angle, (int, float)) else angle, q)
            
            # Couche d'intrication
            if entanglement == 'linear':
                for i in range(n_qubits - 1):
                    qc.cx(path[i], path[i + 1])
            elif entanglement == 'circular':
                for i in range(n_qubits - 1):
                    qc.cx(path[i], path[i + 1])
                if n_qubits > 2:
                    qc.cx(path[-1], path[0])
            elif entanglement == 'full':
                for i in range(n_qubits):
                    for j in range(i + 1, n_qubits):
                        qc.cx(path[i], path[j])
        
        # Mesures
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['n_layers'] = n_layers
        self._metadata['entanglement'] = entanglement
        self._metadata['n_parameters'] = len(params)
        self._log(f"Built Parametrized circuit: {n_qubits}Q, {n_layers} layers, {len(params)} params")
        
        return qc


# =============================================================================
# ANALYZERS - IMPLEMENTATIONS
# =============================================================================

class FidelityAnalyzer(Analyzer):
    """
    Analyse de fidÃ©litÃ© avec intÃ©gration Qiskit native (v2.5.21).
    
    Utilise qiskit.quantum_info.analysis.hellinger_fidelity pour la comparaison
    de distributions de counts, et notre calcul pour la fidÃ©litÃ© cible.
    """
    
    name = "fidelity"
    
    def analyze(self, counts: CountsType, n_qubits: int = None,
                target_states: List[str] = None, 
                ideal_counts: Dict[str, int] = None,
                **params) -> Dict:
        """
        Analyse la fidÃ©litÃ© d'une distribution de counts.
        
        Args:
            counts: Counts mesurÃ©s
            n_qubits: Nombre de qubits (auto-dÃ©tectÃ© si None)
            target_states: Ã‰tats cibles (dÃ©faut: GHZ |00...0âŸ©, |11...1âŸ©)
            ideal_counts: Counts idÃ©aux pour comparaison Hellinger
            
        Returns:
            Dict avec fidÃ©litÃ©, erreur, et mÃ©triques
        """
        if not counts:
            return {'fidelity': 0, 'error': 'No counts'}
        
        total = sum(counts.values())
        
        # DÃ©terminer n_qubits depuis les counts
        if n_qubits is None:
            n_qubits = len(next(iter(counts.keys())))
        
        # Ã‰tats cibles par dÃ©faut: |00...0âŸ© et |11...1âŸ© (GHZ)
        if target_states is None:
            target_states = ['0' * n_qubits, '1' * n_qubits]
        
        target_count = sum(counts.get(s, 0) for s in target_states)
        fidelity = target_count / total
        
        # Incertitude binomiale
        std_err = np.sqrt(fidelity * (1 - fidelity) / total)
        
        result = {
            'fidelity': round(fidelity, 6),
            'std_error': round(std_err, 6),
            'ci_95': (round(max(0, fidelity - 1.96*std_err), 6), 
                      round(min(1, fidelity + 1.96*std_err), 6)),
            'target_states': target_states,
            'target_count': target_count,
            'total_shots': total,
            'n_qubits': n_qubits,
        }
        
        # v2.5.21: Ajouter fidÃ©litÃ© Hellinger si counts idÃ©aux fournis
        if ideal_counts:
            hellinger = QiskitQuantumInfoWrapper.hellinger_fidelity(counts, ideal_counts)
            if hellinger >= 0:
                result['hellinger_fidelity'] = round(hellinger, 6)
        
        return result
    
    def compare_distributions(self, counts1: CountsType, 
                              counts2: CountsType) -> Dict[str, float]:
        """
        Compare deux distributions de counts (v2.5.21).
        
        Utilise qiskit.quantum_info.analysis.hellinger_fidelity.
        
        Args:
            counts1: PremiÃ¨re distribution
            counts2: Seconde distribution
            
        Returns:
            Dict avec hellinger_fidelity et TVD
        """
        hellinger = QiskitQuantumInfoWrapper.hellinger_fidelity(counts1, counts2)
        
        # TVD (Total Variation Distance) manuel
        total1 = sum(counts1.values())
        total2 = sum(counts2.values())
        all_keys = set(counts1.keys()) | set(counts2.keys())
        tvd = 0.5 * sum(
            abs(counts1.get(k, 0)/total1 - counts2.get(k, 0)/total2)
            for k in all_keys
        )
        
        return {
            'hellinger_fidelity': round(hellinger, 6) if hellinger >= 0 else None,
            'tvd': round(tvd, 6),
            'similarity': round(1 - tvd, 6),
        }


class EntropyAnalyzer(Analyzer):
    """
    Analyse d'entropie avec intÃ©gration Qiskit native (v2.5.21).
    
    Utilise qiskit.quantum_info.states.utils.shannon_entropy quand disponible.
    """
    
    name = "entropy"
    
    def analyze(self, counts: CountsType, n_qubits: int = None, **params) -> Dict:
        """
        Analyse l'entropie d'une distribution de counts.
        
        Args:
            counts: Counts mesurÃ©s
            n_qubits: Nombre de qubits
            
        Returns:
            Dict avec entropies Shannon, min-entropy, et mÃ©triques
        """
        if not counts:
            return {'entropy': 0, 'error': 'No counts'}
        
        total = sum(counts.values())
        unique = len(counts)
        
        if n_qubits is None:
            n_qubits = len(next(iter(counts.keys())))
        
        probs = np.array(list(counts.values())) / total
        
        # v2.5.21: Utiliser Qiskit shannon_entropy si disponible
        entropy = QiskitQuantumInfoWrapper.shannon_entropy(probs, base=2)
        if entropy < 0:
            # Fallback si Qiskit non disponible
            entropy = -np.sum(probs * np.log2(probs + 1e-12))
        
        max_entropy = n_qubits
        
        # UniformitÃ© (KL divergence)
        uniform_prob = 1 / (2 ** n_qubits)
        kl_divergence = np.sum(probs * np.log2(probs / uniform_prob + 1e-12))
        
        # Min-entropy (pour crypto)
        p_max = max(probs)
        min_entropy = -np.log2(p_max)
        
        # v2.5.21: Collision entropy (RÃ©nyi H2)
        collision_entropy = -np.log2(np.sum(probs ** 2))
        
        return {
            'entropy': round(float(entropy), 4),
            'max_entropy': n_qubits,
            'entropy_ratio': round(float(entropy / max_entropy), 4),
            'min_entropy': round(float(min_entropy), 4),
            'collision_entropy': round(float(collision_entropy), 4),  # v2.5.21
            'unique_states': unique,
            'possible_states': 2 ** n_qubits,
            'coverage': round(unique / (2 ** n_qubits), 6),
            'kl_divergence': round(float(kl_divergence), 4),
            'n_qubits': n_qubits,
            'qiskit_native': True,  # v2.5.21 marker
        }


class CorrelationAnalyzer(Analyzer):
    """
    Analyse des corrÃ©lations ZZ pour Ã©tats GHZ (v2.5.21).
    
    Calcule les corrÃ©lations qubit-qubit et peut utiliser
    qiskit.quantum_info.mutual_information pour les Ã©tats.
    """
    
    name = "correlation"
    
    def analyze(self, counts: CountsType, n_qubits: int = None, **params) -> Dict:
        """
        Analyse les corrÃ©lations ZZ d'une distribution.
        
        Args:
            counts: Counts mesurÃ©s
            n_qubits: Nombre de qubits
            
        Returns:
            Dict avec corrÃ©lations, sigma, et mÃ©triques
        """
        if not counts:
            return {'sigma': 0, 'error': 'No counts'}
        
        total = sum(counts.values())
        
        if n_qubits is None:
            n_qubits = len(next(iter(counts.keys())))
        
        correlations = []
        
        for j in range(n_qubits - 1):
            same = 0
            diff = 0
            
            for bitstring, count in counts.items():
                if len(bitstring) >= n_qubits:
                    # Bits depuis la droite (LSB)
                    b1 = bitstring[-(j+1)]
                    b2 = bitstring[-(j+2)]
                    
                    if b1 == b2:
                        same += count
                    else:
                        diff += count
            
            corr = (same - diff) / total if total > 0 else 0
            correlations.append(corr)
        
        zz_array = np.array(correlations)
        zz_sum = float(np.sum(zz_array))
        zz_mean = float(np.mean(zz_array))
        zz_std = float(np.std(zz_array)) if len(zz_array) > 1 else 0.0
        
        # Calcul du sigma (significance)
        std_err = np.sqrt(n_qubits - 1) / np.sqrt(total)
        sigma = zz_sum / std_err if std_err > 0 else 0
        
        # v2.5.21: CorrÃ©lation minimum et maximum
        min_corr = float(np.min(zz_array)) if len(zz_array) > 0 else 0
        max_corr = float(np.max(zz_array)) if len(zz_array) > 0 else 0
        
        return {
            'correlations': correlations,
            'mean': round(zz_mean, 6),
            'std': round(zz_std, 6),  # v2.5.21
            'min': round(min_corr, 6),  # v2.5.21
            'max': round(max_corr, 6),  # v2.5.21
            'sum': round(zz_sum, 4),
            'sigma': round(sigma, 2),
            'std_error': round(std_err, 6),
            'n_pairs': n_qubits - 1,
            'success': sigma > 5,  # Seuil standard
            'n_qubits': n_qubits,
        }


class XEBAnalyzer(Analyzer):
    """Cross-Entropy Benchmarking Analyzer
    
    [v2.5.9] CorrigÃ©: Warning explicite si ideal_probs=None
    XEB REQUIERT les probabilitÃ©s idÃ©ales pour Ãªtre significatif.
    Sans ideal_probs, le score XEB est toujours ~0.
    """
    
    name = "xeb"
    
    def analyze(self, counts: CountsType, ideal_probs: Dict[str, float] = None,
                n_qubits: int = None, warn_no_ideal: bool = True, **params) -> Dict:
        """
        Calcule le score XEB (Cross-Entropy Benchmarking).
        
        IMPORTANT: XEB requiert ideal_probs pour Ãªtre significatif!
        Sans ideal_probs, le rÃ©sultat n'est pas interprÃ©table.
        
        Args:
            counts: RÃ©sultats de mesure {bitstring: count}
            ideal_probs: ProbabilitÃ©s idÃ©ales {bitstring: prob} - REQUIS pour XEB valide
            n_qubits: Nombre de qubits (auto-dÃ©tectÃ© si None)
            warn_no_ideal: Afficher un warning si ideal_probs manque (dÃ©faut: True)
            
        Returns:
            Dict avec xeb_score, quantum_signature, etc.
        """
        if not counts:
            return {'xeb_score': 0, 'error': 'No counts'}
        
        total = sum(counts.values())
        
        if n_qubits is None:
            n_qubits = len(next(iter(counts.keys())))
        
        n_states = 2 ** n_qubits
        
        # [v2.5.9] Warning explicite si pas de probs idÃ©ales
        if ideal_probs is None:
            if warn_no_ideal:
                self._log(
                    f"âš ï¸ XEB sans ideal_probs: rÃ©sultat NON INTERPRÃ‰TABLE! "
                    f"XEB avec distribution uniforme â‰ˆ 0 par dÃ©finition. "
                    f"Fournissez ideal_probs via simulation ou utilisez Heavy Output Generation.",
                    LogLevel.WARN
                )
            
            # Retourner un rÃ©sultat marquÃ© comme invalide
            return {
                'xeb_score': None,
                'xeb_normalized': None,
                'quantum_signature': None,
                'valid': False,
                'warning': 'ideal_probs required for meaningful XEB score',
                'n_qubits': n_qubits,
                'n_states': n_states,
                'suggestion': 'Provide ideal_probs from simulation or use Heavy Output Generation'
            }
        
        # XEB = D * <P_ideal> - 1
        # oÃ¹ D = 2^n et <P_ideal> est pondÃ©rÃ© par les observations
        weighted_prob = 0.0
        for bitstring, count in counts.items():
            # Normaliser le bitstring (v2.5.9)
            clean_bs = bitstring.replace(' ', '')
            p_ideal = ideal_probs.get(clean_bs, 1/n_states)
            weighted_prob += (count / total) * p_ideal
        
        xeb = n_states * weighted_prob - 1
        
        # Normaliser entre 0 et 1
        # XEB = 0 pour distribution uniforme, XEB = D-1 pour parfait
        xeb_normalized = xeb / (n_states - 1) if n_states > 1 else xeb
        
        return {
            'xeb_score': round(float(xeb), 4),
            'xeb_normalized': round(float(xeb_normalized), 4),
            'quantum_signature': xeb > 0,
            'valid': True,
            'n_qubits': n_qubits,
            'n_states': n_states,
            'weighted_prob': round(float(weighted_prob), 6),
        }


class BellAnalyzer(Analyzer):
    """Analyse de violation Bell/CHSH"""
    
    name = "bell"
    
    def analyze(self, counts: CountsType, n_pairs: int = 1, **params) -> Dict:
        """Analyse un seul setting CHSH"""
        
        if not counts:
            return {'correlation': 0, 'error': 'No counts'}
        
        total = sum(counts.values())
        
        # Calculer la corrÃ©lation E(a,b) = P(++|ab) + P(--|ab) - P(+-|ab) - P(-+|ab)
        correlation = 0
        
        for bitstring, count in counts.items():
            # Pour chaque paire
            for i in range(n_pairs):
                if len(bitstring) >= 2 * (i + 1):
                    b1 = int(bitstring[-(2*i + 1)])
                    b2 = int(bitstring[-(2*i + 2)])
                    
                    # (+1 si mÃªme, -1 si diffÃ©rent)
                    if b1 == b2:
                        correlation += count
                    else:
                        correlation -= count
        
        correlation = correlation / (total * n_pairs)
        
        return {
            'correlation': round(float(correlation), 4),
            'n_pairs': n_pairs,
            'total_shots': total,
        }
    
    def compute_chsh(self, correlations: List[float]) -> Dict:
        """
        Calcule S de CHSH Ã  partir des 4 corrÃ©lations.
        
        S = E(a0,b0) - E(a0,b1) + E(a1,b0) + E(a1,b1)
        
        Borne classique: |S| â‰¤ 2
        Borne quantique: |S| â‰¤ 2âˆš2 â‰ˆ 2.828
        """
        if len(correlations) != 4:
            return {'error': 'Need exactly 4 correlations'}
        
        E00, E01, E10, E11 = correlations
        # Formule CHSH correcte pour violation maximale
        S = E00 - E01 + E10 + E11
        
        classical_bound = 2.0
        quantum_bound = 2 * np.sqrt(2)
        
        violation = abs(S) > classical_bound
        violation_sigma = (abs(S) - classical_bound) / 0.1  # Approximation
        
        return {
            'S': round(float(S), 4),
            'correlations': correlations,
            'classical_bound': classical_bound,
            'quantum_bound': round(quantum_bound, 4),
            'violation': violation,
            'violation_sigma': round(violation_sigma, 2) if violation else 0,
            'tsirelson_ratio': round(abs(S) / quantum_bound, 4),
        }


class RandomnessAnalyzer(Analyzer):
    """
    Analyse de la qualitÃ© d'alÃ©a pour applications cryptographiques.
    ImplÃ©mente des tests simplifiÃ©s inspirÃ©s des tests NIST SP 800-22.
    """
    
    name = "randomness"
    
    def analyze(self, counts: CountsType, n_qubits: int = None, **params) -> Dict:
        
        if not counts:
            return {'quality': 0, 'error': 'No counts'}
        
        # Convertir les counts en sÃ©quence de bits
        bits = self._counts_to_bits(counts)
        
        if len(bits) < 100:
            return {'quality': 0, 'error': 'Not enough data'}
        
        results = {}
        
        # Test 1: Frequency (monobit)
        results['frequency'] = self._frequency_test(bits)
        
        # Test 2: Runs
        results['runs'] = self._runs_test(bits)
        
        # Test 3: Block frequency
        results['block_frequency'] = self._block_frequency_test(bits)
        
        # Test 4: Serial
        results['serial'] = self._serial_test(bits)
        
        # Score global
        passed = sum(1 for r in results.values() if r.get('passed', False))
        total_tests = len(results)
        
        quality_score = passed / total_tests
        
        return {
            'quality_score': round(quality_score, 2),
            'tests_passed': passed,
            'tests_total': total_tests,
            'tests': results,
            'bit_count': len(bits),
            'crypto_suitable': quality_score >= 0.75,
        }
    
    def _counts_to_bits(self, counts: CountsType) -> np.ndarray:
        """Convertit les counts en sÃ©quence de bits (avec nettoyage des espaces)"""
        bits = []
        for bitstring, count in counts.items():
            # Nettoyer le bitstring des espaces et autres caractÃ¨res non-binaires
            clean_bitstring = ''.join(c for c in bitstring if c in '01')
            for _ in range(count):
                bits.extend([int(b) for b in clean_bitstring])
        return np.array(bits)
    
    def _frequency_test(self, bits: np.ndarray) -> Dict:
        """Test de frÃ©quence monobit"""
        n = len(bits)
        s = np.sum(2 * bits - 1)  # Convertir 0,1 en -1,+1
        s_obs = abs(s) / np.sqrt(n)
        
        # P-value approximÃ©e
        try:
            from scipy.special import erfc
            p_value = erfc(s_obs / np.sqrt(2))
        except ImportError:
            p_value = 2 * (1 - 0.5 * (1 + math.erf(s_obs / np.sqrt(2))))
        
        return {
            'statistic': round(float(s_obs), 4),
            'p_value': round(float(p_value), 4),
            'passed': p_value >= 0.01,
        }
    
    def _runs_test(self, bits: np.ndarray) -> Dict:
        """Test des runs"""
        n = len(bits)
        pi = np.sum(bits) / n
        
        if abs(pi - 0.5) > 2 / np.sqrt(n):
            return {'passed': False, 'reason': 'Frequency precondition failed'}
        
        # Compter les runs
        runs = 1
        for i in range(1, n):
            if bits[i] != bits[i-1]:
                runs += 1
        
        expected_runs = 2 * n * pi * (1 - pi) + 1
        std_runs = 2 * np.sqrt(2 * n) * pi * (1 - pi)
        
        if std_runs == 0:
            return {'passed': False, 'reason': 'Zero variance'}
        
        z = (runs - expected_runs) / std_runs
        
        try:
            from scipy.special import erfc
            p_value = erfc(abs(z) / np.sqrt(2))
        except ImportError:
            p_value = 2 * (1 - 0.5 * (1 + math.erf(abs(z) / np.sqrt(2))))
        
        return {
            'runs': runs,
            'expected': round(expected_runs, 2),
            'z_score': round(float(z), 4),
            'p_value': round(float(p_value), 4),
            'passed': p_value >= 0.01,
        }
    
    def _block_frequency_test(self, bits: np.ndarray, block_size: int = 100) -> Dict:
        """Test de frÃ©quence par blocs"""
        n = len(bits)
        n_blocks = n // block_size
        
        if n_blocks < 10:
            return {'passed': True, 'reason': 'Not enough blocks, skipped'}
        
        chi_sq = 0
        for i in range(n_blocks):
            block = bits[i * block_size:(i + 1) * block_size]
            pi_i = np.sum(block) / block_size
            chi_sq += (pi_i - 0.5) ** 2
        
        chi_sq *= 4 * block_size
        
        try:
            from scipy.stats import chi2
            p_value = 1 - chi2.cdf(chi_sq, n_blocks)
        except ImportError:
            p_value = 0.5  # Approximation
        
        return {
            'chi_squared': round(float(chi_sq), 4),
            'n_blocks': n_blocks,
            'p_value': round(float(p_value), 4),
            'passed': p_value >= 0.01,
        }
    
    def _serial_test(self, bits: np.ndarray, m: int = 2) -> Dict:
        """Test sÃ©riel (paires de bits)"""
        n = len(bits)
        
        # Compter les paires
        counts = defaultdict(int)
        for i in range(n - m + 1):
            pattern = tuple(bits[i:i+m])
            counts[pattern] += 1
        
        # Chi-carrÃ©
        expected = (n - m + 1) / (2 ** m)
        chi_sq = sum((c - expected) ** 2 / expected for c in counts.values())
        
        try:
            from scipy.stats import chi2
            df = 2 ** m - 1
            p_value = 1 - chi2.cdf(chi_sq, df)
        except ImportError:
            p_value = 0.5
        
        return {
            'chi_squared': round(float(chi_sq), 4),
            'p_value': round(float(p_value), 4),
            'passed': p_value >= 0.01,
        }


class CompressionAnalyzer(Analyzer):
    """Analyse du ratio de compression"""
    
    name = "compression"
    
    def analyze(self, counts: CountsType, n_qubits: int = None, **params) -> Dict:
        
        if not counts:
            return {'compression': 0, 'error': 'No counts'}
        
        total = sum(counts.values())
        unique = len(counts)
        
        if n_qubits is None:
            n_qubits = len(next(iter(counts.keys())))
        
        possible_states = 2 ** n_qubits
        compression_ratio = unique / total
        
        # Ratio par rapport au maximum possible
        coverage = unique / possible_states
        
        # Pour GHZ: compression_ratio devrait Ãªtre ~2/total (2 Ã©tats dominants)
        # Pour IQP/Random: devrait Ãªtre ~1 (tous les shots uniques)
        
        return {
            'unique_states': unique,
            'total_shots': total,
            'possible_states': possible_states,
            'compression_ratio': round(compression_ratio, 6),
            'coverage': round(coverage, 6),
            'n_qubits': n_qubits,
            'signature': 'structured' if compression_ratio < 0.5 else 'random',
        }


# =============================================================================
# EXPERIMENT ENGINE
# =============================================================================

@dataclass
class ParameterSweep:
    """DÃ©finition d'un sweep de paramÃ¨tres"""
    name: str
    values: List[Any]
    param_type: str = "linear"  # linear, log, random
    
    @classmethod
    def linear(cls, name: str, start: float, end: float, steps: int) -> 'ParameterSweep':
        values = list(np.linspace(start, end, steps))
        return cls(name=name, values=values, param_type="linear")
    
    @classmethod
    def logarithmic(cls, name: str, start: float, end: float, steps: int) -> 'ParameterSweep':
        values = list(np.logspace(np.log10(start), np.log10(end), steps))
        return cls(name=name, values=values, param_type="log")
    
    @classmethod
    def discrete(cls, name: str, values: List[Any]) -> 'ParameterSweep':
        return cls(name=name, values=values, param_type="discrete")


class ExperimentEngine:
    """
    Moteur d'expÃ©rimentation pour orchestrer des expÃ©riences complexes.
    
    FonctionnalitÃ©s:
    - Parameter sweeps (exploration de l'espace des paramÃ¨tres)
    - Multi-configuration runs
    - Batch orchestration
    - Progress tracking
    - Resume capability
    """
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.logger = framework.logger if framework else None
        
        self._experiments: Dict[str, Dict] = {}
        self._current_experiment: Optional[str] = None
        self._results: Dict[str, List[Dict]] = defaultdict(list)
        self._status: Dict[str, ExperimentStatus] = {}
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='EXPERIMENT')
    
    def create_experiment(self, name: str, config: ExperimentConfig,
                         sweeps: List[ParameterSweep] = None) -> str:
        """
        CrÃ©e une nouvelle expÃ©rience.
        
        Args:
            name: Nom de l'expÃ©rience
            config: Configuration de base
            sweeps: ParamÃ¨tres Ã  balayer
        
        Returns:
            ID de l'expÃ©rience
        """
        exp_id = generate_id("EXP")
        
        # GÃ©nÃ©rer toutes les configurations
        configurations = self._generate_configurations(config, sweeps or [])
        
        self._experiments[exp_id] = {
            'name': name,
            'id': exp_id,
            'base_config': config,
            'sweeps': [asdict(s) for s in (sweeps or [])],
            'configurations': configurations,
            'n_configs': len(configurations),
            'created_at': datetime.now().isoformat(),
        }
        
        self._status[exp_id] = ExperimentStatus.PENDING
        
        self._log(f"Created experiment '{name}' with {len(configurations)} configurations")
        
        return exp_id
    
    def _generate_configurations(self, base_config: ExperimentConfig,
                                  sweeps: List[ParameterSweep]) -> List[Dict]:
        """GÃ©nÃ¨re toutes les combinaisons de configurations"""
        if not sweeps:
            return [base_config.to_dict()]
        
        configs = []
        
        # Produit cartÃ©sien de tous les sweeps
        from itertools import product
        
        sweep_values = [s.values for s in sweeps]
        sweep_names = [s.name for s in sweeps]
        
        for combination in product(*sweep_values):
            config_dict = base_config.to_dict()
            
            for name, value in zip(sweep_names, combination):
                # Naviguer dans la config (supporte les chemins comme "mitigation.enable_twirling")
                parts = name.split('.')
                target = config_dict
                for part in parts[:-1]:
                    target = target[part]
                target[parts[-1]] = value
            
            config_dict['_sweep_values'] = dict(zip(sweep_names, combination))
            configs.append(config_dict)
        
        return configs
    
    def run_experiment(self, exp_id: str, 
                       resume: bool = False,
                       parallel: bool = False,
                       max_workers: int = 2) -> Dict:
        """
        ExÃ©cute une expÃ©rience.
        
        [v2.5.10] Fix: Logger guard + warning explicite pour parallel (non implÃ©mentÃ©)
        
        Args:
            exp_id: ID de l'expÃ©rience
            resume: Reprendre depuis le dernier checkpoint (mÃ©moire uniquement)
            parallel: NON IMPLÃ‰MENTÃ‰ - exÃ©cution toujours sÃ©quentielle
            max_workers: NON IMPLÃ‰MENTÃ‰ - ignorÃ©
        
        Returns:
            RÃ©sultats agrÃ©gÃ©s
        """
        if exp_id not in self._experiments:
            raise ValueError(f"Experiment {exp_id} not found")
        
        # [v2.5.10] Warning explicite pour parallel non implÃ©mentÃ©
        if parallel:
            self._log(
                "âš ï¸ parallel=True ignorÃ©: exÃ©cution parallÃ¨le non implÃ©mentÃ©e "
                "(risque de dÃ©passement quota IBM). ExÃ©cution sÃ©quentielle.",
                LogLevel.WARN
            )
        
        exp = self._experiments[exp_id]
        self._current_experiment = exp_id
        self._status[exp_id] = ExperimentStatus.RUNNING
        
        self._log(f"Starting experiment: {exp['name']}")
        
        # [v2.5.10] Guard pour Ã©viter crash si logger=None
        if self.logger:
            self.logger.section(f"EXPERIMENT: {exp['name']}")
        
        start_time = time.time()
        configs = exp['configurations']
        
        # DÃ©terminer oÃ¹ reprendre
        start_idx = 0
        if resume:
            start_idx = len(self._results.get(exp_id, []))
            self._log(f"Resuming from configuration {start_idx + 1}")
        
        # ExÃ©cuter les configurations
        for i, config_dict in enumerate(configs[start_idx:], start_idx):
            self._log(f"\n--- Configuration {i + 1}/{len(configs)} ---")
            
            sweep_info = config_dict.get('_sweep_values', {})
            if sweep_info:
                self._log(f"Parameters: {sweep_info}")
            
            try:
                result = self._run_single_config(config_dict)
                result['config_index'] = i
                result['sweep_values'] = sweep_info
                self._results[exp_id].append(result)
                
            except Exception as e:
                self._log(f"Configuration {i + 1} failed: {e}", LogLevel.ERROR)
                self._results[exp_id].append({
                    'config_index': i,
                    'error': str(e),
                    'sweep_values': sweep_info,
                })
        
        # Finaliser
        elapsed = time.time() - start_time
        self._status[exp_id] = ExperimentStatus.COMPLETED
        
        summary = self._generate_experiment_summary(exp_id, elapsed)
        
        self._log(f"\nExperiment completed in {elapsed:.1f}s")
        
        return summary
    
    def _run_single_config(self, config_dict: Dict) -> Dict:
        """ExÃ©cute une seule configuration"""
        # CrÃ©er la config
        circuit_family = CircuitFamily(config_dict.get('circuit_family', 'ghz'))
        
        # Obtenir le builder appropriÃ©
        registry = PluginRegistry.instance()
        builder_cls = registry.get_circuit_builder(circuit_family.value)
        
        if builder_cls is None:
            raise ValueError(f"No builder for circuit family: {circuit_family}")
        
        builder = builder_cls(self.framework.topology, self.logger)
        
        # CrÃ©er les circuits
        scales = config_dict.get('scales', [50])
        circuits = builder.build_batch(scales, **config_dict.get('circuit_params', {}))
        
        if not circuits:
            return {'error': 'No circuits built'}
        
        # Transpiler
        transpiled = self.framework.transpile_circuits(circuits)
        
        # ExÃ©cuter
        shots = config_dict.get('shots', 4096)
        results = self.framework.run_on_qpu(transpiled, shots)
        
        if not results:
            return {'error': 'Execution failed'}
        
        # Analyser
        analyses = config_dict.get('analyses', ['fidelity', 'entropy'])
        analysis_results = {}
        
        for analysis_name in analyses:
            if isinstance(analysis_name, AnalysisType):
                analysis_name = analysis_name.value
            
            analyzer_cls = registry.get_analyzer(analysis_name)
            if analyzer_cls:
                analyzer = analyzer_cls(self.logger)
                analysis_results[analysis_name] = analyzer.analyze_batch(results)
        
        return {
            'scales': scales,
            'shots': shots,
            'raw_results': results,
            'analyses': analysis_results,
        }
    
    def _generate_experiment_summary(self, exp_id: str, elapsed: float) -> Dict:
        """GÃ©nÃ¨re le rÃ©sumÃ© de l'expÃ©rience"""
        exp = self._experiments[exp_id]
        results = self._results.get(exp_id, [])
        
        successful = [r for r in results if 'error' not in r]
        failed = [r for r in results if 'error' in r]
        
        summary = {
            'experiment_id': exp_id,
            'name': exp['name'],
            'status': self._status[exp_id].name,
            'total_configurations': len(exp['configurations']),
            'successful': len(successful),
            'failed': len(failed),
            'elapsed_s': round(elapsed, 1),
            'results': results,
        }
        
        # AgrÃ©ger les mÃ©triques
        if successful:
            all_sigmas = []
            all_fidelities = []
            
            for r in successful:
                if 'analyses' in r:
                    if 'correlation' in r['analyses']:
                        for c in r['analyses']['correlation']:
                            if 'sigma' in c:
                                all_sigmas.append(c['sigma'])
                    if 'fidelity' in r['analyses']:
                        for f in r['analyses']['fidelity']:
                            if 'fidelity' in f:
                                all_fidelities.append(f['fidelity'])
            
            if all_sigmas:
                summary['sigma_mean'] = round(np.mean(all_sigmas), 2)
                summary['sigma_max'] = round(max(all_sigmas), 2)
            
            if all_fidelities:
                summary['fidelity_mean'] = round(np.mean(all_fidelities), 6)
        
        return summary
    
    def get_results(self, exp_id: str) -> List[Dict]:
        """RÃ©cupÃ¨re les rÃ©sultats d'une expÃ©rience"""
        return self._results.get(exp_id, [])
    
    def export_experiment(self, exp_id: str, path: PathType, format: str = 'json'):
        """Exporte les rÃ©sultats d'une expÃ©rience"""
        results = {
            'experiment': self._experiments.get(exp_id, {}),
            'results': self._results.get(exp_id, []),
            'status': self._status.get(exp_id, ExperimentStatus.PENDING).name,
        }
        
        path = Path(path)
        
        if format == 'json':
            with open(path, 'w') as f:
                json.dump(results, f, indent=2, default=str)
        elif format == 'csv':
            # Flatten results for CSV
            rows = []
            for r in results['results']:
                row = {'config_index': r.get('config_index')}
                row.update(r.get('sweep_values', {}))
                
                # Add analysis summaries
                for name, analyses in r.get('analyses', {}).items():
                    if analyses and len(analyses) > 0:
                        for key, value in analyses[0].items():
                            if isinstance(value, (int, float)):
                                row[f'{name}_{key}'] = value
                
                rows.append(row)
            
            if rows:
                with open(path, 'w', newline='') as f:
                    writer = csv.DictWriter(f, fieldnames=rows[0].keys())
                    writer.writeheader()
                    writer.writerows(rows)


# =============================================================================
# PROTOCOL TESTER - Tests de protocoles cryptographiques complets
# =============================================================================

class ProtocolTester:
    """
    Testeur de protocoles cryptographiques complets.
    
    Permet de valider:
    - Cycle encryption/decryption
    - Authentification
    - Signatures quantiques
    - Key agreement
    """
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.logger = framework.logger if framework else None
        self._results = {}
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='PROTOCOL')
    
    def test_qmc_core_encryption(self, 
                                  plaintext: bytes,
                                  n_qubits: int = 50,
                                  iqp_depth: int = 10,
                                  shots: int = 8192) -> Dict:
        """
        Test du protocole QMC Core (encryption IQP).
        
        [v2.5.11] IMPORTANT: Ceci est un TEST DE PIPELINE, pas un chiffrement sÃ©curisÃ©.
        Le XOR utilisÃ© est une dÃ©monstration du flux de donnÃ©es, pas une primitive
        cryptographique. Pour la sÃ©curitÃ© rÃ©elle, utiliser AES-GCM avec la clÃ© dÃ©rivÃ©e.
        
        Args:
            plaintext: DonnÃ©es Ã  chiffrer
            n_qubits: Nombre de qubits
            iqp_depth: Profondeur du circuit IQP
            shots: Nombre de shots
        
        Returns:
            RÃ©sultats du test incluant succÃ¨s encryption/decryption
        """
        self._log(f"Testing QMC Core encryption: {len(plaintext)} bytes, {n_qubits}Q")
        
        results = {
            'protocol': 'qmc_core_encryption_demo',  # [v2.5.11] RenommÃ© pour clartÃ©
            'security_level': 'TOY_PIPELINE_TEST',   # [v2.5.11] Disclaimer explicite
            'note': 'XOR demo only - use AES-GCM for production',  # [v2.5.11]
            'plaintext_size': len(plaintext),
            'n_qubits': n_qubits,
            'iqp_depth': iqp_depth,
            'steps': [],
        }
        
        # Step 1: Generate IQP circuit
        self._log("Step 1: Generating IQP circuit")
        builder = IQPBuilder(self.framework.topology, self.logger)
        circuit = builder.build(n_qubits, depth=iqp_depth, add_measurements=True)
        
        results['steps'].append({
            'name': 'circuit_generation',
            'status': 'success',
            'circuit_depth': circuit.depth(),
        })
        
        # Step 2: Execute on QPU
        self._log("Step 2: Executing on QPU")
        transpiled = self.framework.transpile_circuits([circuit])
        qpu_results = self.framework.run_on_qpu(transpiled, shots)
        
        if not qpu_results:
            results['steps'].append({'name': 'qpu_execution', 'status': 'failed'})
            results['success'] = False
            return results
        
        counts = qpu_results[0].get('counts', {})
        results['steps'].append({
            'name': 'qpu_execution',
            'status': 'success',
            'unique_states': len(counts),
            'total_shots': sum(counts.values()),
        })
        
        # Step 3: Generate encryption key from quantum output
        self._log("Step 3: Deriving encryption key")
        key = self._derive_key_from_counts(counts, 256)
        
        results['steps'].append({
            'name': 'key_derivation',
            'status': 'success',
            'key_bits': 256,
            'key_entropy': self._estimate_entropy(key),
        })
        
        # Step 4: Encrypt (TOY XOR - for demo only)
        self._log("Step 4: Encrypting data (XOR demo)")
        ciphertext = self._xor_encrypt(plaintext, key)
        
        results['steps'].append({
            'name': 'encryption',
            'status': 'success',
            'ciphertext_size': len(ciphertext),
            'method': 'XOR_DEMO',  # [v2.5.11] ClartÃ©
        })
        
        # [v2.5.11] Stocker le ciphertext hash pour chaining potentiel
        results['ciphertext_hash'] = hashlib.sha256(ciphertext).hexdigest()[:32]
        
        # Step 5: Decrypt
        self._log("Step 5: Decrypting data")
        decrypted = self._xor_encrypt(ciphertext, key)
        
        decryption_success = decrypted == plaintext
        results['steps'].append({
            'name': 'decryption',
            'status': 'success' if decryption_success else 'failed',
            'match': decryption_success,
        })
        
        # Final result
        results['success'] = decryption_success
        results['quantum_entropy_bits'] = results['steps'][2]['key_entropy']
        
        self._log(f"Protocol test {'PASSED' if decryption_success else 'FAILED'}")
        
        self._results['qmc_core_encryption'] = results
        return results
    
    def test_qmc_authentication(self,
                                identity_data: bytes,
                                n_qubits: int = 50,
                                threshold: float = 0.8) -> Dict:
        """
        Test du protocole d'authentification QMC.
        
        Simule l'enregistrement et la vÃ©rification d'identitÃ©.
        """
        self._log(f"Testing QMC authentication: {len(identity_data)} bytes identity")
        
        results = {
            'protocol': 'qmc_authentication',
            'identity_size': len(identity_data),
            'n_qubits': n_qubits,
            'threshold': threshold,
            'steps': [],
        }
        
        # Step 1: Registration (create quantum template)
        self._log("Step 1: Registration - creating quantum template")
        
        # Hash identity to get seed
        seed = int.from_bytes(hashlib.sha256(identity_data).digest()[:4], 'big')
        
        # Generate IQP circuit deterministically (v2.5.9: utilise le paramÃ¨tre seed)
        builder = IQPBuilder(self.framework.topology, self.logger)
        circuit = builder.build(n_qubits, depth=5, use_random_angles=True, seed=seed, add_measurements=True)
        
        # Execute to get template
        transpiled = self.framework.transpile_circuits([circuit])
        template_results = self.framework.run_on_qpu(transpiled, shots=4096)
        
        if not template_results:
            results['success'] = False
            results['error'] = 'Template generation failed'
            return results
        
        template_counts = template_results[0].get('counts', {})
        template_dist = self._normalize_counts(template_counts)
        
        results['steps'].append({
            'name': 'registration',
            'status': 'success',
            'template_states': len(template_dist),
        })
        
        # Step 2: Verification (same identity)
        self._log("Step 2: Verification - same identity")
        
        # Same seed = same circuit (v2.5.9: paramÃ¨tre seed explicite)
        verify_circuit = builder.build(n_qubits, depth=5, use_random_angles=True, seed=seed, add_measurements=True)
        
        verify_transpiled = self.framework.transpile_circuits([verify_circuit])
        verify_results = self.framework.run_on_qpu(verify_transpiled, shots=4096)
        
        if not verify_results:
            results['success'] = False
            results['error'] = 'Verification execution failed'
            return results
        
        verify_counts = verify_results[0].get('counts', {})
        verify_dist = self._normalize_counts(verify_counts)
        
        # Compute similarity (fidelity)
        similarity = self._compute_distribution_similarity(template_dist, verify_dist)
        
        auth_success = similarity >= threshold
        
        results['steps'].append({
            'name': 'verification_same',
            'status': 'success' if auth_success else 'failed',
            'similarity': round(similarity, 4),
            'threshold': threshold,
            'authenticated': auth_success,
        })
        
        # Step 3: Rejection test (different identity)
        self._log("Step 3: Rejection test - different identity")
        
        # [v2.5.11] Fix: Initialiser rejection_success AVANT le bloc conditionnel
        rejection_success = None
        
        fake_identity = secrets.token_bytes(len(identity_data))
        fake_seed = int.from_bytes(hashlib.sha256(fake_identity).digest()[:4], 'big')
        
        # Different seed = different circuit (v2.5.9: paramÃ¨tre seed explicite)
        fake_circuit = builder.build(n_qubits, depth=5, use_random_angles=True, seed=fake_seed, add_measurements=True)
        
        fake_transpiled = self.framework.transpile_circuits([fake_circuit])
        fake_results = self.framework.run_on_qpu(fake_transpiled, shots=4096)
        
        if fake_results:
            fake_counts = fake_results[0].get('counts', {})
            fake_dist = self._normalize_counts(fake_counts)
            fake_similarity = self._compute_distribution_similarity(template_dist, fake_dist)
            rejection_success = fake_similarity < threshold
            
            results['steps'].append({
                'name': 'verification_fake',
                'status': 'success' if rejection_success else 'failed',
                'similarity': round(fake_similarity, 4),
                'rejected': rejection_success,
            })
        else:
            # [v2.5.11] Si le test de rejet n'a pas pu s'exÃ©cuter, on le note
            results['steps'].append({
                'name': 'verification_fake',
                'status': 'skipped',
                'reason': 'QPU execution failed for rejection test',
            })
        
        # [v2.5.11] Fix: Logique stricte - le test de rejet DOIT rÃ©ussir
        # Si rejection_success est None (test pas exÃ©cutÃ©), on considÃ¨re l'auth incomplÃ¨te
        results['success'] = auth_success and (rejection_success == True)
        results['rejection_tested'] = rejection_success is not None
        
        self._log(f"Authentication test {'PASSED' if results['success'] else 'FAILED'}")
        
        self._results['qmc_authentication'] = results
        return results
    
    def test_bell_key_agreement(self, n_pairs: int = 10, shots: int = 8192) -> Dict:
        """
        Test de protocole d'accord de clÃ© basÃ© sur les Ã©tats Bell.
        
        [v2.5.11] OptimisÃ©: calcul pondÃ©rÃ© sans explosion mÃ©moire
        """
        self._log(f"Testing Bell key agreement: {n_pairs} pairs")
        
        results = {
            'protocol': 'bell_key_agreement',
            'n_pairs': n_pairs,
            'steps': [],
        }
        
        # Generate Bell pairs
        builder = BellBuilder(self.framework.topology, self.logger)
        circuit = builder.build(n_pairs * 2, n_pairs, add_measurements=True)
        
        transpiled = self.framework.transpile_circuits([circuit])
        qpu_results = self.framework.run_on_qpu(transpiled, shots)
        
        if not qpu_results:
            results['success'] = False
            return results
        
        counts = qpu_results[0].get('counts', {})
        
        # [v2.5.11] Calcul pondÃ©rÃ© - Ã©vite l'explosion mÃ©moire
        # Au lieu de dÃ©rouler count fois, on calcule directement avec les poids
        weighted_matches = 0
        weighted_total = 0
        
        for bitstring, count in counts.items():
            # Nettoyer le bitstring (espaces possibles avec multi-registres)
            clean_bs = bitstring.replace(' ', '')
            
            for i in range(n_pairs):
                if len(clean_bs) >= 2 * (i + 1):
                    # Alice prend les bits impairs, Bob les bits pairs (depuis la fin)
                    alice_bit = int(clean_bs[-(2*i + 1)])
                    bob_bit = int(clean_bs[-(2*i + 2)])
                    
                    if alice_bit == bob_bit:
                        weighted_matches += count
                    weighted_total += count
        
        # CorrÃ©lation pondÃ©rÃ©e
        correlation = weighted_matches / weighted_total if weighted_total > 0 else 0
        
        # Nombre effectif de bits de clÃ© = shots Ã— n_pairs
        effective_key_bits = weighted_total
        
        results['steps'].append({
            'name': 'key_generation',
            'status': 'success',
            'raw_key_bits': effective_key_bits,
            'correlation': round(correlation, 4),
            'optimization': 'weighted_calculation',  # [v2.5.11]
        })
        
        # Key agreement success if correlation > 0.9
        results['success'] = correlation > 0.9
        results['shared_key_bits'] = effective_key_bits
        results['correlation'] = round(correlation, 4)
        
        self._results['bell_key_agreement'] = results
        return results
    
    def _derive_key_from_counts(self, counts: CountsType, n_bits: int) -> bytes:
        """DÃ©rive une clÃ© depuis les counts quantiques"""
        # Concatenate all bitstrings weighted by frequency
        bit_sequence = []
        for bitstring, count in sorted(counts.items(), key=lambda x: -x[1]):
            bit_sequence.extend([int(b) for b in bitstring] * count)
        
        # Hash to get uniform key
        bit_bytes = bytes([
            sum(bit_sequence[i*8:(i+1)*8][j] << (7-j) 
                for j in range(min(8, len(bit_sequence) - i*8)))
            for i in range((len(bit_sequence) + 7) // 8)
        ])
        
        # Use SHA-256 to derive key
        key = hashlib.sha256(bit_bytes).digest()
        return key[:n_bits // 8]
    
    def _estimate_entropy(self, data: bytes) -> float:
        """Estime l'entropie d'une sÃ©quence de bytes"""
        if not data:
            return 0
        
        counts = defaultdict(int)
        for byte in data:
            counts[byte] += 1
        
        total = len(data)
        entropy = 0
        for count in counts.values():
            p = count / total
            if p > 0:
                entropy -= p * np.log2(p)
        
        return round(entropy * len(data), 2)
    
    def _xor_encrypt(self, data: bytes, key: bytes) -> bytes:
        """XOR encryption simple"""
        return bytes(d ^ key[i % len(key)] for i, d in enumerate(data))
    
    def _normalize_counts(self, counts: CountsType) -> Dict[str, float]:
        """Normalise les counts en distribution de probabilitÃ©"""
        total = sum(counts.values())
        return {k: v / total for k, v in counts.items()}
    
    def _compute_distribution_similarity(self, dist1: Dict, dist2: Dict) -> float:
        """Calcule la similaritÃ© entre deux distributions (fidelity classique)"""
        all_keys = set(dist1.keys()) | set(dist2.keys())
        
        # Fidelity classique: sum(sqrt(p*q))
        fidelity = sum(
            np.sqrt(dist1.get(k, 0) * dist2.get(k, 0))
            for k in all_keys
        )
        
        return fidelity


# =============================================================================
# DATA PIPELINE
# =============================================================================

class DataTransformer(ABC):
    """Classe de base pour les transformations de donnÃ©es"""
    
    @abstractmethod
    def transform(self, data: Any) -> Any:
        pass


class FilterByThreshold(DataTransformer):
    """Filtre les rÃ©sultats par un seuil"""
    
    def __init__(self, field: str, threshold: float, operator: str = 'gte'):
        self.field = field
        self.threshold = threshold
        self.operator = operator
    
    def transform(self, data: List[Dict]) -> List[Dict]:
        ops = {
            'gt': lambda x: x > self.threshold,
            'gte': lambda x: x >= self.threshold,
            'lt': lambda x: x < self.threshold,
            'lte': lambda x: x <= self.threshold,
            'eq': lambda x: x == self.threshold,
        }
        
        op = ops.get(self.operator, ops['gte'])
        
        return [d for d in data if op(self._get_nested(d, self.field))]
    
    def _get_nested(self, d: Dict, path: str) -> Any:
        parts = path.split('.')
        value = d
        for part in parts:
            value = value.get(part, 0) if isinstance(value, dict) else 0
        return value


class AggregateByField(DataTransformer):
    """AgrÃ¨ge les rÃ©sultats par un champ"""
    
    def __init__(self, group_by: str, aggregate_field: str, 
                 operation: str = 'mean'):
        self.group_by = group_by
        self.aggregate_field = aggregate_field
        self.operation = operation
    
    def transform(self, data: List[Dict]) -> Dict[Any, float]:
        groups = defaultdict(list)
        
        for d in data:
            key = self._get_nested(d, self.group_by)
            value = self._get_nested(d, self.aggregate_field)
            if isinstance(value, (int, float)):
                groups[key].append(value)
        
        ops = {
            'mean': np.mean,
            'sum': np.sum,
            'min': np.min,
            'max': np.max,
            'std': np.std,
            'count': len,
        }
        
        op = ops.get(self.operation, np.mean)
        
        return {k: round(float(op(v)), 4) for k, v in groups.items() if v}
    
    def _get_nested(self, d: Dict, path: str) -> Any:
        parts = path.split('.')
        value = d
        for part in parts:
            value = value.get(part) if isinstance(value, dict) else None
        return value


class DataPipeline:
    """
    Pipeline de traitement de donnÃ©es.
    
    Permet de chaÃ®ner des transformations sur les rÃ©sultats.
    """
    
    def __init__(self, logger: Logger = None):
        self.logger = logger
        self._transformers: List[DataTransformer] = []
        self._cache: Dict[str, Any] = {}
    
    def add(self, transformer: DataTransformer) -> 'DataPipeline':
        """Ajoute un transformateur au pipeline"""
        self._transformers.append(transformer)
        return self
    
    def filter(self, field: str, threshold: float, operator: str = 'gte') -> 'DataPipeline':
        """Raccourci pour ajouter un filtre"""
        return self.add(FilterByThreshold(field, threshold, operator))
    
    def aggregate(self, group_by: str, field: str, operation: str = 'mean') -> 'DataPipeline':
        """Raccourci pour ajouter une agrÃ©gation"""
        return self.add(AggregateByField(group_by, field, operation))
    
    def run(self, data: Any) -> Any:
        """ExÃ©cute le pipeline"""
        result = data
        
        for transformer in self._transformers:
            result = transformer.transform(result)
        
        return result
    
    def clear(self) -> 'DataPipeline':
        """Vide le pipeline"""
        self._transformers = []
        return self


# =============================================================================
# BENCHMARK SUITE
# =============================================================================

class BenchmarkSuite:
    """
    Suite de benchmarks standardisÃ©s pour valider les performances quantiques.
    """
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.logger = framework.logger if framework else None
        self._results = {}
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='BENCHMARK')
    
    def run_ghz_benchmark(self, scales: List[int] = None, shots: int = 8192) -> Dict:
        """
        Benchmark GHZ standard.
        
        Mesure:
        - Maximum de qubits avec Ïƒ > 5
        - Scaling du sigma
        - FidÃ©litÃ© Ã  chaque Ã©chelle
        """
        scales = scales or [20, 40, 60, 80, 100, 120]
        
        self._log(f"Running GHZ benchmark: scales={scales}")
        
        builder = GHZBuilder(self.framework.topology, self.logger)
        circuits = builder.build_batch(scales)
        
        transpiled = self.framework.transpile_circuits(circuits)
        results = self.framework.run_on_qpu(transpiled, shots)
        
        if not results:
            return {'error': 'Execution failed'}
        
        # Analyze
        correlation_analyzer = CorrelationAnalyzer(self.logger)
        fidelity_analyzer = FidelityAnalyzer(self.logger)
        
        benchmark_results = {
            'benchmark': 'ghz',
            'scales': scales,
            'shots': shots,
            'results': [],
        }
        
        max_successful_scale = 0
        
        for i, res in enumerate(results):
            n = scales[i]
            counts = res.get('counts', {})
            
            corr = correlation_analyzer.analyze(counts, n)
            fid = fidelity_analyzer.analyze(counts, n)
            
            result = {
                'n_qubits': n,
                'sigma': corr.get('sigma', 0),
                'fidelity': fid.get('fidelity', 0),
                'success': corr.get('success', False),
            }
            
            benchmark_results['results'].append(result)
            
            if result['success']:
                max_successful_scale = n
        
        benchmark_results['max_successful_qubits'] = max_successful_scale
        benchmark_results['summary'] = {
            'sigma_mean': round(np.mean([r['sigma'] for r in benchmark_results['results']]), 2),
            'fidelity_mean': round(np.mean([r['fidelity'] for r in benchmark_results['results']]), 6),
        }
        
        self._results['ghz'] = benchmark_results
        return benchmark_results
    
    def run_iqp_benchmark(self, n_qubits: int = 50, depths: List[int] = None,
                          shots: int = 8192) -> Dict:
        """
        Benchmark IQP.
        
        [v2.5.10] OptimisÃ©: batch tous les circuits depths en 1 seul job QPU
        
        Mesure:
        - Score XEB Ã  diffÃ©rentes profondeurs
        - Entropie de sortie
        - Couverture de l'espace des Ã©tats
        """
        depths = depths or [5, 10, 15, 20, 30]
        
        self._log(f"Running IQP benchmark: n={n_qubits}, depths={depths}")
        
        builder = IQPBuilder(self.framework.topology, self.logger)
        
        # [v2.5.10] Batch tous les circuits en une seule soumission
        circuits = []
        for depth in depths:
            circuit = builder.build(n_qubits, depth=depth)
            circuits.append(circuit)
        
        # Transpiler et exÃ©cuter en batch (1 seul job au lieu de len(depths)!)
        transpiled = self.framework.transpile_circuits(circuits)
        results = self.framework.run_on_qpu(transpiled, shots)
        
        benchmark_results = {
            'benchmark': 'iqp',
            'n_qubits': n_qubits,
            'depths': depths,
            'shots': shots,
            'results': [],
            'optimization': 'batched_all_depths_1_job',  # [v2.5.10]
        }
        
        if not results:
            self._log("IQP benchmark: execution failed", LogLevel.WARN)
            self._results['iqp'] = benchmark_results
            return benchmark_results
        
        # Analyser chaque depth
        entropy_analyzer = EntropyAnalyzer(self.logger)
        compression_analyzer = CompressionAnalyzer(self.logger)
        
        for i, depth in enumerate(depths):
            if i >= len(results):
                break
                
            counts = results[i].get('counts', {})
            
            entropy = entropy_analyzer.analyze(counts, n_qubits)
            compression = compression_analyzer.analyze(counts, n_qubits)
            
            result = {
                'depth': depth,
                'entropy_ratio': entropy.get('entropy_ratio', 0),
                'coverage': compression.get('coverage', 0),
                'unique_states': compression.get('unique_states', 0),
            }
            
            benchmark_results['results'].append(result)
        
        self._results['iqp'] = benchmark_results
        return benchmark_results
    
    def run_bell_benchmark(self, n_pairs: int = 10, shots: int = 8192) -> Dict:
        """
        Benchmark CHSH/Bell.
        
        [v2.5.10] OptimisÃ©: batch les 4 settings CHSH en 1 seul job QPU
        
        Mesure:
        - ParamÃ¨tre S de CHSH
        - Violation de l'inÃ©galitÃ© de Bell
        """
        self._log(f"Running Bell/CHSH benchmark: {n_pairs} pairs")
        
        builder = BellBuilder(self.framework.topology, self.logger)
        analyzer = BellAnalyzer(self.logger)
        
        # [v2.5.10] Batch tous les 4 circuits CHSH en une seule soumission
        circuits = []
        for setting in range(4):
            circuit = builder.build(n_pairs * 2, n_pairs, chsh_setting=setting)
            circuits.append(circuit)
        
        # Transpiler et exÃ©cuter en batch (1 seul job au lieu de 4!)
        transpiled = self.framework.transpile_circuits(circuits)
        results = self.framework.run_on_qpu(transpiled, shots)
        
        # Analyser chaque setting
        correlations = []
        if results and len(results) >= 4:
            for i in range(4):
                counts = results[i].get('counts', {})
                analysis = analyzer.analyze(counts, n_pairs)
                correlations.append(analysis.get('correlation', 0))
        else:
            correlations = [0, 0, 0, 0]
            self._log("Bell benchmark: some settings failed", LogLevel.WARN)
        
        # Compute CHSH S parameter
        chsh_result = analyzer.compute_chsh(correlations)
        
        benchmark_results = {
            'benchmark': 'bell_chsh',
            'n_pairs': n_pairs,
            'shots': shots,
            'correlations': correlations,
            'chsh': chsh_result,
            'violation': chsh_result.get('violation', False),
            'optimization': 'batched_4_circuits_1_job',  # [v2.5.10]
        }
        
        self._results['bell'] = benchmark_results
        return benchmark_results
    
    def run_full_benchmark(self) -> Dict:
        """
        ExÃ©cute la suite complÃ¨te de benchmarks.
        
        [v2.5.10] Fix: Logger guard + stockage dans _results['full']
        """
        self._log("Running full benchmark suite")
        
        # [v2.5.10] Guard pour Ã©viter crash si logger=None
        if self.logger:
            self.logger.section("FULL BENCHMARK SUITE")
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'backend': self.framework.backend_name,
            'benchmarks': {},
        }
        
        # GHZ
        self._log("=== GHZ Benchmark ===")
        results['benchmarks']['ghz'] = self.run_ghz_benchmark()
        
        # IQP
        self._log("=== IQP Benchmark ===")
        results['benchmarks']['iqp'] = self.run_iqp_benchmark()
        
        # Bell
        self._log("=== Bell Benchmark ===")
        results['benchmarks']['bell'] = self.run_bell_benchmark()
        
        # Summary
        results['summary'] = {
            'ghz_max_qubits': results['benchmarks']['ghz'].get('max_successful_qubits', 0),
            'bell_violation': results['benchmarks']['bell'].get('violation', False),
            'iqp_entropy_avg': np.mean([
                r.get('entropy_ratio', 0) 
                for r in results['benchmarks']['iqp'].get('results', [])
            ]),
        }
        
        # [v2.5.10] Stocker dans _results pour cohÃ©rence
        self._results['full'] = results
        
        return results
    
    def get_results(self) -> Dict:
        return self._results


# =============================================================================
# NOISE ANALYZER
# =============================================================================

class NoiseAnalyzer:
    """
    Analyse du bruit et des erreurs quantiques.
    
    Fournit:
    - Estimation du bruit par type
    - Tracking de la dÃ©cohÃ©rence
    - Recommandations d'optimisation
    """
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.logger = framework.logger if framework else None
        self._calibration_data = {}
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='NOISE')
    
    def analyze_calibration(self) -> Dict:
        """Analyse les donnÃ©es de calibration du backend"""
        if not self.framework._connected:
            return {'error': 'Not connected'}
        
        backend = self.framework.backend
        
        try:
            props = backend.properties()
            if props is None:
                return {'error': 'No properties available'}
            
            analysis = {
                'timestamp': datetime.now().isoformat(),
                'backend': backend.name,
                'qubits': {},
                'gates': {},
                'summary': {},
            }
            
            # Analyze qubits
            readout_errors = []
            t1_values = []
            t2_values = []
            
            for i in range(backend.num_qubits):
                qubit_data = {
                    'readout_error': props.readout_error(i),
                    't1': props.t1(i),
                    't2': props.t2(i),
                }
                analysis['qubits'][i] = qubit_data
                
                if qubit_data['readout_error']:
                    readout_errors.append(qubit_data['readout_error'])
                if qubit_data['t1']:
                    t1_values.append(qubit_data['t1'] * 1e6)  # Convert to Âµs
                if qubit_data['t2']:
                    t2_values.append(qubit_data['t2'] * 1e6)
            
            # Summary statistics
            analysis['summary'] = {
                'readout_error': {
                    'mean': round(np.mean(readout_errors), 4) if readout_errors else None,
                    'std': round(np.std(readout_errors), 4) if readout_errors else None,
                    'max': round(max(readout_errors), 4) if readout_errors else None,
                },
                't1_us': {
                    'mean': round(np.mean(t1_values), 1) if t1_values else None,
                    'min': round(min(t1_values), 1) if t1_values else None,
                },
                't2_us': {
                    'mean': round(np.mean(t2_values), 1) if t2_values else None,
                    'min': round(min(t2_values), 1) if t2_values else None,
                },
            }
            
            self._calibration_data = analysis
            return analysis
            
        except Exception as e:
            return {'error': str(e)}
    
    def estimate_circuit_fidelity(self, circuit: CircuitType, 
                                  include_readout: bool = True) -> Dict:
        """
        Estime la fidÃ©litÃ© d'un circuit basÃ© sur les erreurs de calibration.
        """
        if not self._calibration_data:
            self.analyze_calibration()
        
        try:
            ops = dict(circuit.count_ops())
            depth = circuit.depth()
            
            # Simple error model
            # F_total â‰ˆ F_1q^N_1q * F_2q^N_2q * F_readout^N_measure
            
            n_1q = sum(v for k, v in ops.items() if k in ['x', 'y', 'z', 'h', 'rx', 'ry', 'rz', 's', 't', 'sx'])
            n_2q = sum(v for k, v in ops.items() if k in ['cx', 'cz', 'ecr', 'swap'])
            n_measure = ops.get('measure', 0)
            
            # Average error rates
            avg_1q_error = 0.001  # Typical
            avg_2q_error = 0.01   # Typical
            avg_readout_error = self._calibration_data.get('summary', {}).get('readout_error', {}).get('mean', 0.02)
            
            # Estimate fidelity
            f_1q = (1 - avg_1q_error) ** n_1q
            f_2q = (1 - avg_2q_error) ** n_2q
            f_readout = (1 - avg_readout_error) ** n_measure if include_readout else 1
            
            total_fidelity = f_1q * f_2q * f_readout
            
            return {
                'estimated_fidelity': round(total_fidelity, 4),
                'gates_1q': n_1q,
                'gates_2q': n_2q,
                'measurements': n_measure,
                'depth': depth,
                'fidelity_breakdown': {
                    '1q_contribution': round(f_1q, 4),
                    '2q_contribution': round(f_2q, 4),
                    'readout_contribution': round(f_readout, 4),
                },
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def get_optimization_recommendations(self, circuit: CircuitType = None) -> List[Dict]:
        """GÃ©nÃ¨re des recommandations d'optimisation"""
        recommendations = []
        
        if self._calibration_data:
            summary = self._calibration_data.get('summary', {})
            
            # Check readout errors
            readout = summary.get('readout_error', {})
            if readout.get('max', 0) > 0.1:
                recommendations.append({
                    'type': 'hardware',
                    'priority': 'high',
                    'issue': 'High readout errors detected',
                    'suggestion': 'Enable readout error mitigation',
                })
            
            # Check T1/T2
            t2 = summary.get('t2_us', {})
            if t2.get('min', 100) < 50:
                recommendations.append({
                    'type': 'hardware',
                    'priority': 'medium',
                    'issue': 'Low T2 times on some qubits',
                    'suggestion': 'Enable dynamical decoupling (DD)',
                })
        
        if circuit:
            ops = dict(circuit.count_ops())
            n_2q = sum(v for k, v in ops.items() if k in ['cx', 'cz', 'ecr'])
            
            if n_2q > 100:
                recommendations.append({
                    'type': 'circuit',
                    'priority': 'high',
                    'issue': f'High 2-qubit gate count ({n_2q})',
                    'suggestion': 'Consider reducing circuit depth or using error mitigation',
                })
            
            depth = circuit.depth()
            if depth > 200:
                recommendations.append({
                    'type': 'circuit',
                    'priority': 'medium',
                    'issue': f'Deep circuit (depth={depth})',
                    'suggestion': 'Enable twirling for coherent error suppression',
                })
        
        # Always recommend
        recommendations.append({
            'type': 'general',
            'priority': 'low',
            'issue': 'Standard optimization',
            'suggestion': 'Use optimization_level=3 for transpilation',
        })
        
        return recommendations


# =============================================================================
# CREDENTIALS MANAGER
# =============================================================================

class CredentialsManager:
    """Gestionnaire de credentials IBM Quantum"""
    
    ENV_VARS = {
        'api_key': ['IBM_API_KEY', 'IBM_QUANTUM_TOKEN', 'IBMQ_TOKEN'],
        'instance': ['IBM_CRN', 'IBM_INSTANCE', 'IBMQ_INSTANCE'],
        'channel': ['IBM_CHANNEL'],
    }
    
    def __init__(self):
        self._credentials = None
    
    def load(self) -> Optional[Dict]:
        """Charge les credentials"""
        self._load_from_dotenv()
        creds = self._get_from_env()
        
        if creds.get('api_key'):
            self._credentials = creds
            return self._format_credentials(creds)
        return None
    
    def _load_from_dotenv(self):
        """Charge depuis .env"""
        try:
            from dotenv import load_dotenv
            load_dotenv()
        except ImportError:
            # Manual .env parsing
            env_file = Path('.env')
            if env_file.exists():
                with open(env_file) as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#') and '=' in line:
                            key, value = line.split('=', 1)
                            os.environ[key.strip()] = value.strip().strip('"\'')
    
    def _get_from_env(self) -> Dict:
        """RÃ©cupÃ¨re les credentials depuis l'environnement"""
        creds = {}
        for key, env_names in self.ENV_VARS.items():
            for env_name in env_names:
                value = os.getenv(env_name)
                if value:
                    creds[key] = value
                    break
        return creds
    
    def _format_credentials(self, creds: Dict) -> Dict:
        """Formate les credentials pour QiskitRuntimeService"""
        # Auto-dÃ©tection du channel basÃ©e sur la prÃ©sence d'un CRN
        instance = creds.get('instance', '')
        
        if creds.get('channel'):
            channel = creds['channel']
        elif instance and 'crn:' in instance:
            # CRN prÃ©sent = IBM Cloud
            channel = 'ibm_cloud'
        else:
            # Par dÃ©faut = IBM Quantum Platform (gratuit)
            channel = 'ibm_quantum_platform'
        
        formatted = {
            'channel': channel,
            'token': creds['api_key'],
        }
        
        # Instance requise uniquement pour ibm_cloud
        if instance and channel == 'ibm_cloud':
            formatted['instance'] = instance
        
        return formatted
    
    def get_masked_info(self) -> Dict:
        """Retourne les infos masquÃ©es pour les logs"""
        if not self._credentials:
            return {'status': 'not_loaded'}
        
        api_key = self._credentials.get('api_key', '')
        return {
            'status': 'loaded',
            'api_key_prefix': api_key[:8] + '...' if len(api_key) > 8 else '***',
            'instance': self._credentials.get('instance', 'default'),
        }


# =============================================================================
# DIRECTORY MANAGER
# =============================================================================

class DirectoryManager:
    """Gestion des rÃ©pertoires d'exÃ©cution"""
    
    def __init__(self, base_dir: str = "qmc_runs"):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(exist_ok=True)
        self.run_dir: Optional[Path] = None
    
    def create_run_directory(self, mode: str, project: str, 
                              scales: List[int], shots: int) -> Path:
        """CrÃ©e un rÃ©pertoire pour cette exÃ©cution"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        scale_str = "-".join(str(s) for s in scales[:3])
        if len(scales) > 3:
            scale_str += f"-etc{len(scales)}"
        
        dir_name = f"{mode}_{timestamp}_{project}_{scale_str}q_shots{shots}"
        self.run_dir = self.base_dir / dir_name
        self.run_dir.mkdir(exist_ok=True)
        
        # Sous-rÃ©pertoires
        (self.run_dir / 'checkpoints').mkdir(exist_ok=True)
        (self.run_dir / 'plots').mkdir(exist_ok=True)
        (self.run_dir / 'exports').mkdir(exist_ok=True)
        
        return self.run_dir
    
    def get_file(self, name: str) -> Path:
        """Retourne le chemin d'un fichier"""
        if not self.run_dir:
            raise RuntimeError("Run directory not created")
        
        if name in ['checkpoints', 'plots', 'exports']:
            return self.run_dir / name
        
        return self.run_dir / name
    
    def save_json(self, name: str, data: Dict):
        """Sauvegarde des donnÃ©es JSON"""
        path = self.get_file(f"{name}.json")
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, default=str)


# =============================================================================
# REPORT MANAGER
# =============================================================================

class ReportManager:
    """Gestionnaire de rapports"""
    
    def __init__(self, report_path: Path = None, auto_save_interval: int = 30):
        self.report_path = report_path
        self.auto_save_interval = auto_save_interval
        
        self._data = {
            'metadata': {
                'framework_version': __version__,
                'created_at': datetime.now().isoformat(),
            },
            'config': {},
            'execution': {},
            'results': {},
        }
        
        self._last_save = time.time()
        self._lock = threading.Lock()
    
    def set(self, key: str, value: Any, section: str = None):
        """DÃ©finit une valeur dans le rapport"""
        with self._lock:
            if section:
                if section not in self._data:
                    self._data[section] = {}
                self._data[section][key] = value
            else:
                self._data[key] = value
            
            self._auto_save()
    
    def get(self, key: str, section: str = None) -> Any:
        """RÃ©cupÃ¨re une valeur"""
        if section:
            return self._data.get(section, {}).get(key)
        return self._data.get(key)
    
    def _auto_save(self):
        """Sauvegarde automatique pÃ©riodique"""
        if self.report_path and (time.time() - self._last_save) > self.auto_save_interval:
            self.save()
    
    def save(self):
        """Sauvegarde le rapport"""
        if self.report_path:
            self._data['metadata']['updated_at'] = datetime.now().isoformat()
            with open(self.report_path, 'w', encoding='utf-8') as f:
                json.dump(self._data, f, indent=2, default=str)
            self._last_save = time.time()
    
    def to_dict(self) -> Dict:
        """Retourne le rapport complet"""
        return copy.deepcopy(self._data)


# =============================================================================
# CIRCUIT OPTIMIZER ENGINE v1.0
# =============================================================================
# Moteur d'optimisation intelligent utilisant TOUTES les mÃ©triques de calibration
# pour trouver le placement optimal d'un circuit sur le QPU
# =============================================================================

@dataclass
class QubitCalibration:
    """
    DonnÃ©es de calibration complÃ¨tes pour un qubit.
    Utilise TOUTES les mÃ©triques disponibles du CSV IBM.
    """
    qubit_id: int
    t1_us: float = 100.0            # Temps de relaxation (Âµs)
    t2_us: float = 100.0            # Temps de dÃ©phasage (Âµs)
    readout_error: float = 0.01     # Erreur de lecture moyenne
    prob_meas0_prep1: float = 0.01  # P(mesure 0 | prÃ©parÃ© 1)
    prob_meas1_prep0: float = 0.01  # P(mesure 1 | prÃ©parÃ© 0)
    readout_length_ns: float = 1560 # DurÃ©e de lecture (ns)
    id_error: float = 0.001         # Erreur porte identitÃ©
    gate_length_ns: float = 24      # DurÃ©e gate 1Q (ns)
    rx_error: float = 0.001         # Erreur RX
    rz_error: float = 0.0           # Erreur RZ (toujours 0, virtuelle)
    sx_error: float = 0.001         # Erreur âˆšX
    x_error: float = 0.001          # Erreur X (Pauli-X)
    operational: bool = True        # Qubit opÃ©rationnel
    
    @property
    def readout_asymmetry(self) -> float:
        """AsymÃ©trie de lecture (dÃ©tecte biais)"""
        return abs(self.prob_meas0_prep1 - self.prob_meas1_prep0)
    
    @property
    def is_biased(self) -> bool:
        """True si le qubit a un biais de lecture > 10%"""
        return self.readout_asymmetry > 0.1
    
    @property
    def coherence_ratio(self) -> float:
        """Ratio T2/T1 (idÃ©al â‰ˆ 2.0)"""
        return self.t2_us / self.t1_us if self.t1_us > 0 else 0
    
    def quality_score(self, weights: Dict[str, float] = None) -> float:
        """
        Calcule un score de qualitÃ© global [0-1].
        Plus le score est haut, meilleur est le qubit.
        
        Weights par dÃ©faut optimisÃ©s empiriquement:
        - readout: 30% (critique pour la mesure finale)
        - t1: 20% (important pour circuits profonds)
        - t2: 15% (dÃ©phasage)
        - gate_error: 15% (erreur gates 1Q)
        - asymmetry: 10% (biais de lecture)
        - coherence_ratio: 10% (santÃ© globale)
        """
        if not self.operational:
            return 0.0
        
        w = weights or {
            'readout': 0.30,
            't1': 0.20,
            't2': 0.15,
            'gate_error': 0.15,
            'asymmetry': 0.10,
            'coherence_ratio': 0.10,
        }
        
        # Normaliser les mÃ©triques sur [0, 1]
        readout_score = 1.0 - min(self.readout_error, 1.0)
        t1_score = min(self.t1_us / 300.0, 1.0)  # 300Âµs = excellent
        t2_score = min(self.t2_us / 300.0, 1.0)
        gate_score = 1.0 - min(self.sx_error * 100, 1.0)  # Normaliser
        asymmetry_score = 1.0 - min(self.readout_asymmetry * 5, 1.0)
        ratio_score = min(self.coherence_ratio / 2.0, 1.0)  # 2.0 = idÃ©al
        
        score = (
            w['readout'] * readout_score +
            w['t1'] * t1_score +
            w['t2'] * t2_score +
            w['gate_error'] * gate_score +
            w['asymmetry'] * asymmetry_score +
            w['coherence_ratio'] * ratio_score
        )
        
        return max(0.0, min(1.0, score))


@dataclass
class ConnectionCalibration:
    """
    DonnÃ©es de calibration pour une connexion entre deux qubits.
    
    [v2.5.3 FIX] Ajout de gate_type pour Ã©viter le min(cz,ecr) faussÃ©.
    La property error() utilise maintenant le bon type de gate.
    """
    qubit1: int
    qubit2: int
    gate_type: str = "unknown"  # "cz", "ecr", "rzz", ou "unknown"
    cz_error: float = None      # Erreur CZ (Heron) - None = pas mesurÃ©
    ecr_error: float = None     # Erreur ECR (Eagle) - None = pas mesurÃ©
    rzz_error: float = None     # Erreur RZZ
    gate_length_ns: float = 68  # DurÃ©e gate 2Q (ns)
    
    @property
    def error(self) -> float:
        """
        Erreur 2Q principale basÃ©e sur le type de gate rÃ©ellement utilisÃ©.
        
        [FIX] Ne plus utiliser min() qui faussait les scores quand une
        des valeurs Ã©tait Ã  la valeur par dÃ©faut.
        """
        # Utiliser le type de gate spÃ©cifiÃ©
        if self.gate_type == "cz" and self.cz_error is not None:
            return self.cz_error
        if self.gate_type == "ecr" and self.ecr_error is not None:
            return self.ecr_error
        if self.gate_type == "rzz" and self.rzz_error is not None:
            return self.rzz_error
        
        # Fallback: utiliser la premiÃ¨re valeur disponible (pas le min!)
        if self.cz_error is not None:
            return self.cz_error
        if self.ecr_error is not None:
            return self.ecr_error
        if self.rzz_error is not None:
            return self.rzz_error
        
        # Valeur conservative par dÃ©faut si rien n'est disponible
        return 0.02  # 2% - valeur pessimiste
    
    def quality_score(self) -> float:
        """Score de qualitÃ© [0-1], plus haut = mieux"""
        # Erreur typique: 0.5% = excellent, 2% = mauvais
        return max(0.0, 1.0 - self.error * 50)


class CircuitOptimizer:
    """
    Moteur d'optimisation de circuits utilisant les donnÃ©es de calibration complÃ¨tes.
    
    FonctionnalitÃ©s:
    - Charge et analyse toutes les mÃ©triques du CSV de calibration IBM
    - Calcule des scores de qualitÃ© pour chaque qubit et connexion
    - Trouve le placement optimal pour un circuit donnÃ©
    - GÃ©nÃ¨re un initial_layout pour le transpiler Qiskit
    
    Usage:
        optimizer = CircuitOptimizer.from_csv('calibration.csv')
        layout = optimizer.find_optimal_layout(circuit, n_qubits=20)
        transpiled = transpile(circuit, backend, initial_layout=layout)
    """
    
    def __init__(self, logger: 'Logger' = None):
        self.logger = logger
        self.qubits: Dict[int, QubitCalibration] = {}
        self.connections: Dict[Tuple[int, int], ConnectionCalibration] = {}
        self.backend_name: str = ""
        self.calibration_time: str = ""
        self._adjacency: Dict[int, Set[int]] = defaultdict(set)
    
    def _log(self, msg: str, level: 'LogLevel' = None):
        if self.logger:
            level = level or LogLevel.INFO
            self.logger.log(msg, level, section='OPTIMIZER')
    
    @classmethod
    def from_csv(cls, csv_path: str, logger: 'Logger' = None) -> 'CircuitOptimizer':
        """
        CrÃ©e un optimiseur depuis un fichier CSV de calibration IBM.
        
        [v2.5.3 FIX] DÃ©tection automatique du type de gate 2Q depuis les colonnes.
        
        TÃ©lÃ©chargeable depuis: IBM Quantum Dashboard â†’ Backend â†’ Download calibration
        """
        optimizer = cls(logger)
        
        with open(csv_path, 'r') as f:
            reader = csv.DictReader(f)
            rows = list(reader)
        
        if not rows:
            return optimizer
        
        # === DÃ‰TECTION DU TYPE DE GATE 2Q DEPUIS LES COLONNES ===
        first_row = rows[0]
        columns = set(first_row.keys())
        
        detected_gate_type = "unknown"
        if 'CZ error' in columns:
            detected_gate_type = "cz"
        elif 'ECR error' in columns:
            detected_gate_type = "ecr"
        elif 'CNOT error' in columns or 'CX error' in columns:
            detected_gate_type = "cx"
        
        optimizer._detected_gate_type = detected_gate_type
        optimizer._log(f"Detected 2Q gate type from CSV: {detected_gate_type}")
        
        for row in rows:
            q = int(row['Qubit'])
            
            # Fonction helper pour parser les floats avec valeur par dÃ©faut
            def safe_float(val, default=None):
                try:
                    return float(val) if val else default
                except (ValueError, TypeError):
                    return default
            
            # Extraire toutes les mÃ©triques
            cal = QubitCalibration(
                qubit_id=q,
                t1_us=safe_float(row.get('T1 (us)'), 100),
                t2_us=safe_float(row.get('T2 (us)'), 100),
                readout_error=safe_float(row.get('Readout assignment error'), 0.01),
                prob_meas0_prep1=safe_float(row.get('Prob meas0 prep1'), 0.01),
                prob_meas1_prep0=safe_float(row.get('Prob meas1 prep0'), 0.01),
                readout_length_ns=safe_float(row.get('Readout length (ns)'), 1560),
                id_error=safe_float(row.get('ID error'), 0.001),
                gate_length_ns=safe_float(row.get('Single-qubit gate length (ns)'), 24),
                rx_error=safe_float(row.get('RX error'), 0.001),
                rz_error=safe_float(row.get('Z-axis rotation (rz) error'), 0),
                sx_error=safe_float(row.get('âˆšx (sx) error'), 0.001),
                x_error=safe_float(row.get('Pauli-X error'), 0.001),
                operational=row.get('Operational', 'Yes') == 'Yes')
            optimizer.qubits[q] = cal
            
            # === EXTRAIRE LES CONNEXIONS AVEC LE BON TYPE DE GATE ===
            # CZ error (Heron)
            cz_data = row.get('CZ error', '')
            if cz_data:
                for part in cz_data.split(';'):
                    if ':' in part:
                        neighbor, error_str = part.split(':')
                        neighbor = int(neighbor)
                        error = float(error_str)
                        
                        conn_key = (min(q, neighbor), max(q, neighbor))
                        if conn_key not in optimizer.connections:
                            optimizer.connections[conn_key] = ConnectionCalibration(
                                qubit1=conn_key[0],
                                qubit2=conn_key[1],
                                gate_type="cz",
                                cz_error=error)
                        
                        optimizer._adjacency[q].add(neighbor)
                        optimizer._adjacency[neighbor].add(q)
            
            # ECR error (Eagle)
            ecr_data = row.get('ECR error', '')
            if ecr_data:
                for part in ecr_data.split(';'):
                    if ':' in part:
                        neighbor, error_str = part.split(':')
                        neighbor = int(neighbor)
                        error = float(error_str)
                        
                        conn_key = (min(q, neighbor), max(q, neighbor))
                        if conn_key not in optimizer.connections:
                            optimizer.connections[conn_key] = ConnectionCalibration(
                                qubit1=conn_key[0],
                                qubit2=conn_key[1],
                                gate_type="ecr",
                                ecr_error=error)
                        
                        optimizer._adjacency[q].add(neighbor)
                        optimizer._adjacency[neighbor].add(q)
        
        optimizer._log(f"Loaded calibration: {len(optimizer.qubits)} qubits, "
                      f"{len(optimizer.connections)} connections ({detected_gate_type})")
        
        return optimizer
    
    @classmethod
    def from_backend(cls, backend, logger: 'Logger' = None) -> 'CircuitOptimizer':
        """
        CrÃ©e un optimiseur depuis un backend IBM Quantum.
        
        [v2.5.3 FIX] DÃ©tection automatique du type de gate 2Q depuis le backend
        au lieu de deviner depuis le nom.
        
        Note: Cette mÃ©thode extrait moins de mÃ©triques que from_csv().
        Pour une optimisation complÃ¨te, utiliser from_csv().
        """
        optimizer = cls(logger)
        optimizer.backend_name = backend.name
        
        # === DÃ‰TECTION AUTOMATIQUE DU TYPE DE GATE 2Q ===
        # [FIX] Ne plus deviner depuis le nom du backend!
        gate_2q = None
        
        # MÃ©thode 1: Depuis backend.target (Qiskit 1.0+)
        try:
            if hasattr(backend, 'target') and backend.target:
                ops = backend.target.operation_names
                if 'cz' in ops:
                    gate_2q = 'cz'
                elif 'ecr' in ops:
                    gate_2q = 'ecr'
                elif 'cx' in ops:
                    gate_2q = 'cx'
                elif 'rzz' in ops:
                    gate_2q = 'rzz'
        except:
            pass
        
        # MÃ©thode 2: Depuis backend.operation_names
        if gate_2q is None:
            try:
                if hasattr(backend, 'operation_names'):
                    ops = backend.operation_names
                    if 'cz' in ops:
                        gate_2q = 'cz'
                    elif 'ecr' in ops:
                        gate_2q = 'ecr'
                    elif 'cx' in ops:
                        gate_2q = 'cx'
            except:
                pass
        
        # MÃ©thode 3 (fallback): Depuis le nom du backend
        if gate_2q is None:
            name_lower = backend.name.lower()
            if 'heron' in name_lower:
                gate_2q = 'cz'
            elif 'eagle' in name_lower or 'osprey' in name_lower:
                gate_2q = 'ecr'
            else:
                gate_2q = 'ecr'  # Default pour anciens backends
        
        optimizer._detected_gate_type = gate_2q
        optimizer._log(f"Detected 2Q gate type: {gate_2q}")
        
        try:
            props = backend.properties()
            n_qubits = backend.num_qubits
            
            for q in range(n_qubits):
                cal = QubitCalibration(qubit_id=q)
                try:
                    cal.t1_us = (props.t1(q) or 0) * 1e6
                    cal.t2_us = (props.t2(q) or 0) * 1e6
                    cal.readout_error = props.readout_error(q) or 0.01
                    
                    try:
                        cal.sx_error = props.gate_error('sx', q) or 0.001
                        cal.x_error = cal.sx_error
                    except:
                        pass
                except:
                    pass
                
                optimizer.qubits[q] = cal
            
            # Connexions - utiliser le type de gate dÃ©tectÃ©
            for q1, q2 in backend.coupling_map.get_edges():
                try:
                    error = props.gate_error(gate_2q, [q1, q2]) or 0.02
                    conn_key = (min(q1, q2), max(q1, q2))
                    
                    # CrÃ©er la connexion avec le bon type de gate
                    conn = ConnectionCalibration(
                        qubit1=conn_key[0],
                        qubit2=conn_key[1],
                        gate_type=gate_2q,  # Type dÃ©tectÃ© automatiquement
                    )
                    
                    # Assigner l'erreur au bon champ
                    if gate_2q == 'cz':
                        conn.cz_error = error
                    elif gate_2q == 'ecr' or gate_2q == 'cx':
                        conn.ecr_error = error
                    elif gate_2q == 'rzz':
                        conn.rzz_error = error
                    
                    optimizer.connections[conn_key] = conn
                    optimizer._adjacency[q1].add(q2)
                    optimizer._adjacency[q2].add(q1)
                except:
                    pass
        
        except Exception as e:
            optimizer._log(f"Warning: Could not load properties: {e}", LogLevel.WARN)
        
        return optimizer
    
    def get_qubit_ranking(self, weights: Dict[str, float] = None) -> List[Tuple[int, float]]:
        """
        Retourne tous les qubits triÃ©s par score de qualitÃ© dÃ©croissant.
        
        Returns:
            Liste de (qubit_id, score)
        """
        scores = [
            (q, cal.quality_score(weights))
            for q, cal in self.qubits.items()
            if cal.operational
        ]
        scores.sort(key=lambda x: -x[1])
        return scores
    
    def get_connection_ranking(self) -> List[Tuple[Tuple[int, int], float]]:
        """
        Retourne toutes les connexions triÃ©es par score de qualitÃ© dÃ©croissant.
        """
        scores = [
            (conn_key, conn.quality_score())
            for conn_key, conn in self.connections.items()
        ]
        scores.sort(key=lambda x: -x[1])
        return scores
    
    def get_faulty_qubits(self, threshold: float = 0.3) -> Set[int]:
        """
        Identifie les qubits Ã  Ã©viter (score < threshold).
        
        CritÃ¨res additionnels:
        - Non opÃ©rationnel
        - AsymÃ©trie de lecture > 30%
        - T1 < 20Âµs
        - Readout error > 10%
        """
        faulty = set()
        
        for q, cal in self.qubits.items():
            if not cal.operational:
                faulty.add(q)
            elif cal.quality_score() < threshold:
                faulty.add(q)
            elif cal.readout_asymmetry > 0.3:
                faulty.add(q)
            elif cal.t1_us < 20:
                faulty.add(q)
            elif cal.readout_error > 0.1:
                faulty.add(q)
        
        return faulty
    
    def find_best_contiguous_path(self, 
                                   n_qubits: int,
                                   avoid_qubits: Set[int] = None,
                                   max_iterations: int = 500000) -> List[int]:
        """
        Trouve le meilleur chemin contigu de n_qubits en utilisant
        les scores de qualitÃ© pour guider la recherche.
        
        [v2.5.3 FIX] Maximise maintenant le score moyen, pas juste la longueur.
        Si plusieurs chemins atteignent n_qubits, on garde celui avec
        la meilleure qualitÃ© moyenne (qubits + arÃªtes).
        
        Utilise DFS + backtracking avec heuristique basÃ©e sur la qualitÃ©.
        """
        avoid = avoid_qubits or self.get_faulty_qubits()
        
        # Construire adjacency sans les faulty
        adj = defaultdict(set)
        for q, neighbors in self._adjacency.items():
            if q not in avoid:
                for n in neighbors:
                    if n not in avoid:
                        adj[q].add(n)
        
        if not adj:
            return list(range(min(n_qubits, len(self.qubits))))
        
        def calculate_path_score(path: List[int]) -> float:
            """
            Calcule le score global d'un chemin.
            Score = 0.6 * moyenne_scores_qubits + 0.4 * moyenne_scores_arÃªtes
            """
            if not path:
                return 0.0
            
            # Score des qubits
            qubit_scores = []
            for q in path:
                if q in self.qubits:
                    qubit_scores.append(self.qubits[q].quality_score())
            
            avg_qubit = sum(qubit_scores) / len(qubit_scores) if qubit_scores else 0.5
            
            # Score des arÃªtes
            edge_scores = []
            for i in range(len(path) - 1):
                q1, q2 = path[i], path[i+1]
                conn_key = (min(q1, q2), max(q1, q2))
                if conn_key in self.connections:
                    edge_scores.append(self.connections[conn_key].quality_score())
            
            avg_edge = sum(edge_scores) / len(edge_scores) if edge_scores else 0.5
            
            return 0.6 * avg_qubit + 0.4 * avg_edge
        
        # DFS avec score de qualitÃ©
        global_best = []
        global_best_score = 0.0
        total_iterations = 0
        
        # Trier les starts par score de qualitÃ©
        starts = sorted(
            adj.keys(),
            key=lambda q: -self.qubits[q].quality_score() if q in self.qubits else 0
        )
        
        for start in starts[:50]:  # Test les 50 meilleurs
            if total_iterations >= max_iterations:
                break
            
            best_from_start = []
            best_from_start_score = 0.0
            stack = [(start, frozenset([start]), [start])]
            local_iter = 0
            
            while stack and local_iter < max_iterations // 50:
                local_iter += 1
                total_iterations += 1
                
                current, visited, path = stack.pop()
                
                # [FIX] Comparer d'abord la longueur, puis le score si Ã©galitÃ©
                path_score = calculate_path_score(path)
                
                if len(path) > len(best_from_start):
                    best_from_start = path[:]
                    best_from_start_score = path_score
                elif len(path) == len(best_from_start) and path_score > best_from_start_score:
                    # MÃªme longueur mais meilleur score â†’ garder
                    best_from_start = path[:]
                    best_from_start_score = path_score
                
                if len(best_from_start) >= n_qubits:
                    # On a atteint la taille requise, mais on continue un peu
                    # pour voir si on trouve un chemin de mÃªme taille mais meilleur score
                    if local_iter > 5000:  # Limite pour ne pas boucler indÃ©finiment
                        break
                
                # Pruning
                if len(path) + len(adj) - len(visited) <= len(best_from_start):
                    continue
                
                # Trier voisins par qualitÃ© de connexion + qubit
                neighbors = [n for n in adj[current] if n not in visited]
                
                def neighbor_priority(n):
                    conn_key = (min(current, n), max(current, n))
                    conn_score = self.connections.get(conn_key, ConnectionCalibration(current, n, "unknown")).quality_score()
                    qubit_score = self.qubits.get(n, QubitCalibration(n)).quality_score()
                    return -(conn_score * 0.4 + qubit_score * 0.6)
                
                neighbors.sort(key=neighbor_priority, reverse=True)
                
                for neighbor in neighbors:
                    new_visited = frozenset(visited | {neighbor})
                    new_path = path + [neighbor]
                    stack.append((neighbor, new_visited, new_path))
            
            # [FIX] Comparer les chemins par longueur puis par score
            if len(best_from_start) > len(global_best):
                global_best = best_from_start
                global_best_score = best_from_start_score
            elif len(best_from_start) == len(global_best) and best_from_start_score > global_best_score:
                global_best = best_from_start
                global_best_score = best_from_start_score
            
            if len(global_best) >= n_qubits and global_best_score > 0.7:
                # On a un bon chemin, on peut s'arrÃªter
                break
        
        self._log(f"Found path: {len(global_best)} qubits, score={global_best_score:.1%} "
                 f"(requested {n_qubits}, {total_iterations:,} iterations)")
        
        return global_best
    
    def find_optimal_layout(self, 
                            circuit_qubits: int,
                            circuit_connections: List[Tuple[int, int]] = None,
                            strategy: str = 'contiguous') -> Dict[int, int]:
        """
        Trouve le meilleur mapping logique â†’ physique pour un circuit.
        
        Args:
            circuit_qubits: Nombre de qubits du circuit
            circuit_connections: Connexions requises [(q1, q2), ...]
            strategy: 'contiguous' (chemin), 'best_qubits' (meilleurs isolÃ©s), 
                     'topology_aware' (respecte les connexions), 'auto' (choisit le meilleur)
        
        Returns:
            Dict {qubit_logique: qubit_physique}
        """
        if strategy == 'contiguous' or strategy == 'auto':
            path = self.find_best_contiguous_path(circuit_qubits)
            
            # Si le chemin est assez long, l'utiliser
            if len(path) >= circuit_qubits:
                return {i: path[i] for i in range(circuit_qubits)}
            
            # Sinon, fallback vers best_qubits
            if strategy == 'auto':
                self._log(f"[OPTIMIZER] Contiguous path too short ({len(path)}/{circuit_qubits}), using best_qubits")
            
            # Utiliser les meilleurs qubits disponibles
            ranking = self.get_qubit_ranking()
            best = [q for q, _ in ranking[:circuit_qubits]]
            return {i: best[i] for i in range(len(best))}
        
        elif strategy == 'best_qubits':
            ranking = self.get_qubit_ranking()
            best = [q for q, _ in ranking[:circuit_qubits]]
            return {i: best[i] for i in range(len(best))}
        
        elif strategy == 'topology_aware' and circuit_connections:
            # Pour circuits avec structure spÃ©cifique
            # Utilise un algorithme glouton amÃ©liorÃ©
            return self._topology_aware_layout(circuit_qubits, circuit_connections)
        
        else:
            return self.find_optimal_layout(circuit_qubits, strategy='auto')
    
    def _topology_aware_layout(self, 
                               n_qubits: int,
                               connections: List[Tuple[int, int]]) -> Dict[int, int]:
        """
        Placement respectant la topologie du circuit.
        """
        avoid = self.get_faulty_qubits()
        
        # Construire graphe du circuit
        circuit_adj = defaultdict(set)
        for q1, q2 in connections:
            circuit_adj[q1].add(q2)
            circuit_adj[q2].add(q1)
        
        # Trier qubits logiques par degrÃ© (placer les plus connectÃ©s en premier)
        logical_order = sorted(range(n_qubits), key=lambda q: -len(circuit_adj.get(q, [])))
        
        layout = {}
        used_physical = set()
        
        for logical_q in logical_order:
            required_neighbors = circuit_adj.get(logical_q, set())
            mapped_neighbors = [layout[n] for n in required_neighbors if n in layout]
            
            # Trouver le meilleur qubit physique
            best_physical = None
            best_score = -1
            
            for phys_q, cal in self.qubits.items():
                if phys_q in used_physical or phys_q in avoid:
                    continue
                
                # Score de base: qualitÃ© du qubit
                score = cal.quality_score()
                
                # Bonus si connectÃ© aux qubits dÃ©jÃ  mappÃ©s
                for mapped in mapped_neighbors:
                    if mapped in self._adjacency[phys_q]:
                        conn_key = (min(phys_q, mapped), max(phys_q, mapped))
                        conn = self.connections.get(conn_key)
                        if conn:
                            score += conn.quality_score() * 0.5
                
                if score > best_score:
                    best_score = score
                    best_physical = phys_q
            
            if best_physical is not None:
                layout[logical_q] = best_physical
                used_physical.add(best_physical)
        
        return layout
    
    def generate_transpiler_layout(self, 
                                   circuit: 'QuantumCircuit',
                                   strategy: str = 'contiguous') -> 'Layout':
        """
        GÃ©nÃ¨re un objet Layout Qiskit pour le transpiler.
        
        Usage:
            layout = optimizer.generate_transpiler_layout(circuit)
            transpiled = transpile(circuit, backend, initial_layout=layout)
        """
        from qiskit.transpiler import Layout
        
        n_qubits = circuit.num_qubits
        
        # Extraire les connexions du circuit
        connections = []
        for instr, qargs, _ in circuit.data:
            if len(qargs) == 2:
                connections.append((qargs[0]._index, qargs[1]._index))
        
        mapping = self.find_optimal_layout(n_qubits, connections, strategy)
        
        # CrÃ©er le Layout Qiskit
        return Layout.from_intlist(
            [mapping[i] for i in range(n_qubits)],
            *circuit.qregs
        )
    
    def display_summary(self, show_path: bool = True, path_length: int = 50) -> str:
        """
        Affiche un rÃ©sumÃ© visuel complet de l'analyse de calibration.
        
        [v2.5.3] Affichage avec emojis, sans bordures droites pour compatibilitÃ© Windows.
        
        Args:
            show_path: Afficher le chemin optimal (dÃ©faut: True)
            path_length: Longueur du chemin Ã  calculer (dÃ©faut: 50)
        
        Returns:
            RÃ©sumÃ© formatÃ©
        """
        lines = []
        W = 78  # Largeur
        
        # === HEADER ===
        lines.append("")
        lines.append("â•”" + "â•" * W + "â•—")
        lines.append("â•‘" + "ğŸ”¬ CIRCUIT OPTIMIZER v2.5.3 ğŸ”¬".center(W) + "â•‘")
        lines.append("â•‘" + "QPU Calibration Analysis Engine".center(W) + "â•‘")
        lines.append("â• " + "â•" * W + "â•£")
        
        # === STATS GLOBALES ===
        operational = sum(1 for c in self.qubits.values() if c.operational)
        faulty = self.get_faulty_qubits()
        biased = [q for q, c in self.qubits.items() if c.is_biased]
        scores = [c.quality_score() for c in self.qubits.values() if c.operational]
        avg_score = np.mean(scores) if scores else 0
        min_score = min(scores) if scores else 0
        max_score = max(scores) if scores else 0
        
        # Barre de score moyen
        bar_len = 30
        filled = int(avg_score * bar_len)
        bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
        
        lines.append("â•‘  ğŸ“Š GLOBAL STATISTICS")
        lines.append("â•Ÿ" + "â”€" * W + "â•¢")
        lines.append(f"â•‘  Backend: {self.backend_name or 'N/A':<20} Calibration: {self.calibration_time or 'Live'}")
        lines.append(f"â•‘  Qubits: {operational}/{len(self.qubits)} operational       Connections: {len(self.connections)}")
        lines.append(f"â•‘  Faulty: {len(faulty):<3}  Biased: {len(biased)}")
        lines.append("â•‘")
        lines.append(f"â•‘  Quality Score: [{bar}]  {avg_score:.1%}")
        lines.append(f"â•‘                 Min: {min_score:.1%}  Max: {max_score:.1%}  Avg: {avg_score:.1%}")
        
        # === DISTRIBUTION DES SCORES ===
        lines.append("â•Ÿ" + "â”€" * W + "â•¢")
        lines.append("â•‘  ğŸ“ˆ SCORE DISTRIBUTION")
        lines.append("â•‘")
        
        # Histogramme ASCII
        bins = [0, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
        labels = ["ğŸ’€<30%", "âš ï¸30-50%", "ğŸ˜50-60%", "ğŸ™‚60-70%", "ğŸ˜Š70-80%", "ğŸŒŸ80-90%", "ğŸ†90%+"]
        hist = [0] * (len(bins) - 1)
        for s in scores:
            for i in range(len(bins) - 1):
                if bins[i] <= s < bins[i+1]:
                    hist[i] += 1
                    break
            else:
                if s >= bins[-1]:
                    hist[-1] += 1
        
        max_hist = max(hist) if hist else 1
        for label, count in zip(labels, hist):
            bar_width = int(count / max_hist * 25) if max_hist > 0 else 0
            bar = "â–“" * bar_width
            lines.append(f"â•‘      {label:>10}: {bar:<25} {count:>3} qubits")
        
        # === TOP 10 MEILLEURS QUBITS ===
        lines.append("â•Ÿ" + "â”€" * W + "â•¢")
        lines.append("â•‘  ğŸ† TOP 10 BEST QUBITS")
        lines.append("â•‘")
        
        ranking = self.get_qubit_ranking()[:10]
        for i, (q, score) in enumerate(ranking):
            cal = self.qubits[q]
            medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i] if i < 3 else "  "
            bar_len = 15
            filled = int(score * bar_len)
            bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
            lines.append(f"â•‘  {medal} Q{q:>3}: [{bar}] {score:>5.1%}  T1={cal.t1_us:>3.0f}Âµs T2={cal.t2_us:>3.0f}Âµs RE={cal.readout_error:>5.2%}")
        
        # === QUBITS Ã€ Ã‰VITER ===
        lines.append("â•Ÿ" + "â”€" * W + "â•¢")
        lines.append("â•‘  ğŸ’€ QUBITS TO AVOID")
        lines.append("â•‘")
        
        if faulty:
            faulty_list = sorted(faulty)
            chunk_str = ", ".join([f"Q{q}" for q in faulty_list])
            lines.append(f"â•‘    {chunk_str}")
        else:
            lines.append("â•‘    âœ… No faulty qubits detected!")
        
        # === QUBITS BIAISÃ‰S ===
        if biased:
            lines.append("â•‘")
            lines.append("â•‘  âš ï¸  BIASED QUBITS (readout asymmetry > 10%)")
            for q in biased[:5]:
                cal = self.qubits[q]
                asym = cal.readout_asymmetry
                lines.append(f"â•‘    Q{q:>3}: P(0|1)={cal.prob_meas0_prep1:>5.1%}  P(1|0)={cal.prob_meas1_prep0:>5.1%}  Asymmetry={asym:>5.1%}")
        
        # === CHEMIN OPTIMAL ===
        if show_path:
            lines.append("â•Ÿ" + "â”€" * W + "â•¢")
            lines.append("â•‘  ğŸ›¤ï¸  OPTIMAL QUBIT PATH")
            lines.append("â•‘")
            
            path = self.find_best_contiguous_path(path_length)
            path_scores = [self.qubits[q].quality_score() for q in path if q in self.qubits]
            avg_path_score = np.mean(path_scores) if path_scores else 0
            
            lines.append(f"â•‘    ğŸ“ Length: {len(path)} qubits (requested: {path_length})")
            lines.append(f"â•‘    ğŸ“ Start: Q{path[0]}  â†’  End: Q{path[-1]}")
            lines.append(f"â•‘    â­ Path quality score: {avg_path_score:.1%}")
            lines.append("â•‘")
            
            # Afficher le chemin visuellement
            lines.append("â•‘    Path visualization:")
            
            # Diviser en segments avec flÃ¨ches
            segment_size = 10
            for i in range(0, len(path), segment_size):
                segment = path[i:i+segment_size]
                if i == 0:
                    prefix = "ğŸš€ "
                elif i + segment_size >= len(path):
                    prefix = "ğŸ "
                else:
                    prefix = "â¡ï¸  "
                
                segment_str = " â†’ ".join([f"Q{q}" for q in segment])
                if i + segment_size < len(path):
                    segment_str += " â†’"
                
                lines.append(f"â•‘      {prefix}{segment_str}")
        
        # === TOP 10 CONNEXIONS ===
        lines.append("â•Ÿ" + "â”€" * W + "â•¢")
        lines.append("â•‘  ğŸ”— TOP 10 BEST CONNECTIONS")
        lines.append("â•‘")
        
        conn_ranking = self.get_connection_ranking()[:10]
        for (q1, q2), score in conn_ranking:
            conn = self.connections[(q1, q2)]
            bar_len = 12
            filled = int(score * bar_len)
            bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
            err = conn.error
            lines.append(f"â•‘    Q{q1:>3} â†” Q{q2:>3}: [{bar}] {score:>5.1%}  {conn.gate_type}_err={err:>5.2%}")
        
        # === FOOTER ===
        lines.append("â• " + "â•" * W + "â•£")
        lines.append("â•‘  ğŸ’¡ RECOMMENDATIONS")
        lines.append("â•Ÿ" + "â”€" * W + "â•¢")
        
        if avg_score >= 0.75:
            lines.append("â•‘    âœ… QPU quality is EXCELLENT - optimal for complex circuits")
        elif avg_score >= 0.60:
            lines.append("â•‘    ğŸ™‚ QPU quality is GOOD - suitable for most circuits")
        else:
            lines.append("â•‘    âš ï¸  QPU quality is MODERATE - consider shorter circuits")
        
        lines.append(f"â•‘    ğŸ“ Recommended max circuit depth: ~{int(avg_score * 300)} gates")
        lines.append("â•‘    ğŸ¯ Use qubits from the optimal path for best results")
        
        lines.append("â•š" + "â•" * W + "â•")
        lines.append("")
        
        return "\n".join(lines)
    
    def display_path_visual(self, n_qubits: int = 50) -> str:
        """
        Affiche une visualisation du chemin optimal.
        """
        path = self.find_best_contiguous_path(n_qubits)
        
        lines = []
        lines.append("")
        lines.append("ğŸ›¤ï¸  OPTIMAL QUBIT PATH VISUALIZATION")
        lines.append("â•" * 60)
        
        # Afficher avec scores
        for i, q in enumerate(path):
            cal = self.qubits.get(q, QubitCalibration(q))
            score = cal.quality_score()
            
            # Emoji basÃ© sur le score
            if score >= 0.85:
                emoji = "ğŸŸ¢"
            elif score >= 0.70:
                emoji = "ğŸŸ¡"
            elif score >= 0.50:
                emoji = "ğŸŸ "
            else:
                emoji = "ğŸ”´"
            
            bar_len = 10
            filled = int(score * bar_len)
            bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
            
            arrow = "â†’" if i < len(path) - 1 else "ğŸ"
            lines.append(f"  {emoji} Q{q:>3} [{bar}] {score:.0%} {arrow}")
        
        lines.append("")
        return "\n".join(lines)


# =============================================================================
# DYNAMIC TOPOLOGY
# =============================================================================

class DynamicTopology:
    """
    Analyse dynamique de la topologie du backend.
    
    Identifie:
    - Qubits dÃ©fectueux
    - Connexions cassÃ©es
    - Chemin optimal pour n qubits
    """
    
    def __init__(self, thresholds: QualityThresholds = None, logger: Logger = None):
        self.thresholds = thresholds or QualityThresholds()
        self.logger = logger
        
        self.n_qubits = 0
        self.backend_name = ""
        
        self.faulty_qubits: Set[int] = set()
        self.suspect_qubits: Set[int] = set()
        self.broken_connections: Set[Tuple[int, int]] = set()
        self.critical_connections: Set[Tuple[int, int]] = set()
        
        self._coupling_map: List[Tuple[int, int]] = []
        self._qubit_errors: Dict[int, Dict] = {}
        self._connection_errors: Dict[Tuple[int, int], float] = {}
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='TOPOLOGY')
    
    @classmethod
    def from_backend(cls, backend, thresholds: QualityThresholds = None, 
                     logger: Logger = None) -> 'DynamicTopology':
        """CrÃ©e une topologie depuis un backend IBM"""
        topo = cls(thresholds, logger)
        topo.n_qubits = backend.num_qubits
        topo.backend_name = backend.name
        
        # Coupling map
        try:
            cm = backend.coupling_map
            topo._coupling_map = list(cm.get_edges()) if cm else []
        except:
            topo._coupling_map = []
        
        # Calibration data
        try:
            props = backend.properties()
            if props:
                topo._analyze_properties(props)
        except Exception as e:
            topo._log(f"Could not analyze properties: {e}", LogLevel.WARN)
        
        return topo
    
    def _analyze_properties(self, props):
        """Analyse les propriÃ©tÃ©s du backend"""
        t = self.thresholds
        
        # Analyze qubits
        for i in range(self.n_qubits):
            try:
                readout = props.readout_error(i) or 0
                t1 = (props.t1(i) or 0) * 1e6
                t2 = (props.t2(i) or 0) * 1e6
                
                # Try to get gate error
                sx_error = 0
                try:
                    sx_error = props.gate_error('sx', i) or 0
                except:
                    pass
                
                self._qubit_errors[i] = {
                    'readout': readout,
                    't1': t1,
                    't2': t2,
                    'sx': sx_error,
                }
                
                # Classify
                if readout > t.qubit_readout_critical or sx_error > t.qubit_sx_critical:
                    self.faulty_qubits.add(i)
                elif readout > t.qubit_readout_error or sx_error > t.qubit_sx_error:
                    self.suspect_qubits.add(i)
                
            except Exception as e:
                pass
        
        # Analyze connections
        gate_name = 'cz' if 'heron' in self.backend_name.lower() else 'ecr'
        
        for q1, q2 in self._coupling_map:
            try:
                error = props.gate_error(gate_name, [q1, q2]) or 0
                self._connection_errors[(q1, q2)] = error
                
                if error > t.gate_2q_broken:
                    self.broken_connections.add((q1, q2))
                elif error > t.gate_2q_critical:
                    self.critical_connections.add((q1, q2))
                    
            except:
                pass
        
        self._log(f"Analyzed: {self.n_qubits}Q, "
                  f"{len(self.faulty_qubits)} faulty, "
                  f"{len(self.broken_connections)} broken connections")
    
    def get_best_path(self, n_qubits: int, start_qubit: int = None) -> List[int]:
        """
        [v2.5.2] Trouve le meilleur chemin de n qubits contigus.
        
        Utilise DFS + backtracking au lieu du greedy simple.
        AmÃ©lioration typique: +500-700% de qubits trouvÃ©s sur heavy-hex.
        
        Args:
            n_qubits: Nombre de qubits souhaitÃ©s
            start_qubit: Qubit de dÃ©part optionnel
        
        Returns:
            Liste des indices de qubits formant un chemin contigu optimal
        """
        import time
        
        if n_qubits > self.n_qubits:
            n_qubits = self.n_qubits
        
        # Build adjacency avoiding bad qubits/connections
        adj = defaultdict(set)
        for q1, q2 in self._coupling_map:
            if q1 in self.faulty_qubits or q2 in self.faulty_qubits:
                continue
            if (q1, q2) in self.broken_connections or (q2, q1) in self.broken_connections:
                continue
            adj[q1].add(q2)
            adj[q2].add(q1)
        
        if not adj:
            return list(range(min(n_qubits, self.n_qubits)))
        
        # === DFS + BACKTRACKING ALGORITHM ===
        start_time = time.time()
        max_iterations = 500000
        timeout_seconds = 30.0
        
        global_best_path = []
        total_iterations = 0
        
        # Determine start points (sorted by degree for better heuristic)
        if start_qubit is not None and start_qubit in adj:
            starts = [start_qubit]
        else:
            starts = sorted(adj.keys(), key=lambda x: (-len(adj[x]), x))
        
        def get_connection_score(q1, q2):
            """Score qualitÃ© connexion (bas = meilleur)"""
            if (q1, q2) in self._connection_errors:
                return self._connection_errors[(q1, q2)]
            if (q2, q1) in self._connection_errors:
                return self._connection_errors[(q2, q1)]
            return 0.01
        
        for start in starts:
            # Check timeout
            if time.time() - start_time > timeout_seconds:
                break
            if total_iterations >= max_iterations:
                break
            
            # DFS itÃ©ratif depuis ce start
            best_from_start = []
            local_max_iter = max_iterations // max(len(starts), 1)
            local_iterations = 0
            
            # Stack: (current_node, visited_frozenset, path_list)
            stack = [(start, frozenset([start]), [start])]
            
            while stack and local_iterations < local_max_iter:
                local_iterations += 1
                total_iterations += 1
                
                current, visited, path = stack.pop()
                
                # Update best
                if len(path) > len(best_from_start):
                    best_from_start = path
                    if len(best_from_start) >= n_qubits:
                        break
                
                # Pruning: if path + remaining potential <= best, skip
                remaining_potential = len(adj) - len(visited)
                if len(path) + remaining_potential <= len(best_from_start):
                    continue
                
                # Explore neighbors
                # Sort by: (1) remaining degree desc, (2) connection quality
                neighbors = [n for n in adj[current] if n not in visited]
                
                def neighbor_score(n):
                    unvisited_degree = len([nn for nn in adj[n] if nn not in visited])
                    conn_quality = get_connection_score(current, n)
                    return (-unvisited_degree, conn_quality)
                
                neighbors.sort(key=neighbor_score, reverse=True)  # reverse for LIFO stack
                
                for neighbor in neighbors:
                    new_visited = frozenset(visited | {neighbor})
                    new_path = path + [neighbor]
                    stack.append((neighbor, new_visited, new_path))
            
            if len(best_from_start) > len(global_best_path):
                global_best_path = best_from_start
                
                # Early exit if target reached
                if len(global_best_path) >= n_qubits:
                    break
        
        elapsed = time.time() - start_time
        
        if len(global_best_path) < n_qubits:
            self._log(
                f"Warning: Only found {len(global_best_path)} contiguous qubits, "
                f"requested {n_qubits}. (DFS: {total_iterations:,} iterations in {elapsed:.2f}s)",
                LogLevel.WARN
            )
        
        return global_best_path
    
    def get_best_qubits(self, n_qubits: int, exclude: Set[int] = None) -> List[int]:
        """
        Retourne les N meilleurs qubits triÃ©s par qualitÃ©.
        
        Contrairement Ã  get_best_path(), cette fonction ne requiert PAS
        que les qubits soient contigus/connectÃ©s. Elle retourne simplement
        les qubits avec les meilleurs scores de qualitÃ©.
        
        Args:
            n_qubits: Nombre de qubits Ã  retourner
            exclude: Set de qubits Ã  exclure (optionnel)
        
        Returns:
            Liste des indices des meilleurs qubits
        """
        exclude = exclude or set()
        
        # Calculer un score de qualitÃ© pour chaque qubit
        qubit_scores = []
        for q in range(self.n_qubits):
            if q in self.faulty_qubits or q in exclude:
                continue
            
            # RÃ©cupÃ©rer les mÃ©triques du qubit
            qubit_info = self._qubit_errors.get(q, {})
            readout_err = qubit_info.get('readout', 0.05)
            t1 = qubit_info.get('t1', 100)
            t2 = qubit_info.get('t2', 100)
            sx_err = qubit_info.get('sx', 0.01)
            
            # Score plus Ã©levÃ© = meilleur qubit
            # Faible erreur readout + haute cohÃ©rence = bon
            score = (1 - readout_err) * 0.4 + \
                    min(t1/300, 1) * 0.25 + \
                    min(t2/300, 1) * 0.25 + \
                    (1 - sx_err * 100) * 0.1
            
            # PÃ©nalitÃ© pour qubits suspects
            if q in self.suspect_qubits:
                score *= 0.8
            
            qubit_scores.append((q, score))
        
        # Trier par score dÃ©croissant
        qubit_scores.sort(key=lambda x: -x[1])
        
        # Retourner les N meilleurs
        best_qubits = [q for q, _ in qubit_scores[:n_qubits]]
        
        return best_qubits
    
    def get_qubit_groups(self, n_groups: int, qubits_per_group: int) -> List[List[int]]:
        """
        Divise les meilleurs qubits en groupes pour les clusters QMC.
        
        Cette fonction est optimisÃ©e pour QMC oÃ¹ chaque cluster utilise
        un groupe de qubits indÃ©pendant.
        
        Args:
            n_groups: Nombre de groupes (clusters)
            qubits_per_group: Qubits par groupe
        
        Returns:
            Liste de listes de qubits
        """
        total_needed = n_groups * qubits_per_group
        best_qubits = self.get_best_qubits(total_needed)
        
        if len(best_qubits) < total_needed:
            self._log(f"Warning: Only {len(best_qubits)} qubits available, "
                     f"need {total_needed} for {n_groups} groups of {qubits_per_group}",
                     LogLevel.WARN)
        
        # Diviser en groupes
        groups = []
        for i in range(n_groups):
            start = i * qubits_per_group
            end = start + qubits_per_group
            group = best_qubits[start:end] if end <= len(best_qubits) else best_qubits[start:]
            groups.append(group)
        
        return groups
    
    def get_summary(self) -> Dict:
        """Retourne un rÃ©sumÃ© de la topologie"""
        return {
            'backend': self.backend_name,
            'n_qubits_total': self.n_qubits,
            'n_qubits_usable': self.n_qubits - len(self.faulty_qubits),
            'faulty_qubits': list(self.faulty_qubits),
            'suspect_qubits': list(self.suspect_qubits),
            'broken_connections': [list(c) for c in self.broken_connections],
            'n_connections': len(self._coupling_map),
            'n_broken': len(self.broken_connections),
        }
    
    def print_report(self):
        """Affiche un rapport visuel dÃ©taillÃ© de la topologie"""
        viz = CalibrationVisualizer(self)
        viz.print_full_report()
    
    @property
    def optimal_path(self) -> List[int]:
        """Retourne le chemin optimal prÃ©-calculÃ©"""
        if not hasattr(self, '_optimal_path'):
            self._optimal_path = self.get_best_path(self.n_qubits)
        return self._optimal_path


# =============================================================================
# CALIBRATION VISUALIZER - Affichage Pro Premium
# =============================================================================

class CalibrationVisualizer:
    """
    SystÃ¨me de visualisation PREMIUM pour les donnÃ©es de calibration QPU.
    
    GÃ©nÃ¨re des rapports ASCII professionnels avec:
    - Score global de santÃ© multi-critÃ¨res
    - Barres de progression colorÃ©es
    - Histogrammes de distribution
    - Tableaux formatÃ©s avec classement
    - Carte Heavy-Hex rÃ©aliste
    - Heatmap de qualitÃ© des qubits
    - Sparklines de tendance
    - Recommandations automatiques
    - Comparaison vs idÃ©al
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CaractÃ¨res graphiques
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    BLOCKS = {
        'full': 'â–ˆ', '7_8': 'â–‡', '3_4': 'â–†', '5_8': 'â–…',
        '1_2': 'â–„', '3_8': 'â–ƒ', '1_4': 'â–‚', '1_8': 'â–', 'empty': ' '
    }
    
    HORIZONTAL_BLOCKS = {
        'full': 'â–ˆ', '7_8': 'â–‰', '3_4': 'â–Š', '5_8': 'â–‹',
        '1_2': 'â–Œ', '3_8': 'â–', '1_4': 'â–', '1_8': 'â–', 'empty': ' '
    }
    
    SPARKLINE_CHARS = ['â–', 'â–‚', 'â–ƒ', 'â–„', 'â–…', 'â–†', 'â–‡', 'â–ˆ']
    
    HEATMAP_CHARS = [' ', 'â–‘', 'â–’', 'â–“', 'â–ˆ']
    
    BOX_CHARS = {
        'tl': 'â•”', 'tr': 'â•—', 'bl': 'â•š', 'br': 'â•',
        'h': 'â•', 'v': 'â•‘', 'lt': 'â• ', 'rt': 'â•£',
        'tb': 'â•¦', 'bb': 'â•©', 'x': 'â•¬',
        'tl_s': 'â”Œ', 'tr_s': 'â”', 'bl_s': 'â””', 'br_s': 'â”˜',
        'h_s': 'â”€', 'v_s': 'â”‚', 'lt_s': 'â”œ', 'rt_s': 'â”¤',
        'tb_s': 'â”¬', 'bb_s': 'â”´', 'x_s': 'â”¼',
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Couleurs ANSI
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    COLORS = {
        'reset': '\033[0m',
        'bold': '\033[1m',
        'dim': '\033[2m',
        'italic': '\033[3m',
        'underline': '\033[4m',
        # Couleurs standard
        'black': '\033[30m',
        'red': '\033[91m',
        'green': '\033[92m',
        'yellow': '\033[93m',
        'blue': '\033[94m',
        'magenta': '\033[95m',
        'cyan': '\033[96m',
        'white': '\033[97m',
        'gray': '\033[90m',
        # Backgrounds
        'bg_red': '\033[41m',
        'bg_green': '\033[42m',
        'bg_yellow': '\033[43m',
        'bg_blue': '\033[44m',
        'bg_gray': '\033[100m',
    }
    
    # Indicateurs visuels
    ICONS = {
        'check': 'âœ“',
        'cross': 'âœ—',
        'warning': 'âš ',
        'info': 'â„¹',
        'star': 'â˜…',
        'star_empty': 'â˜†',
        'circle_full': 'â—',
        'circle_half': 'â—',
        'circle_empty': 'â—‹',
        'arrow_up': 'â†‘',
        'arrow_down': 'â†“',
        'arrow_right': 'â†’',
        'lightning': 'âš¡',
        'temp': 'ğŸŒ¡',
        'chip': 'ğŸ’»',
        'link': 'ğŸ”—',
        'broken': 'ğŸ’”',
        'trophy': 'ğŸ†',
        'skull': 'ğŸ’€',
    }
    
    # Seuils de rÃ©fÃ©rence (idÃ©al IBM Heron)
    IDEAL_THRESHOLDS = {
        'readout_excellent': 0.005,
        'readout_good': 0.015,
        'readout_bad': 0.05,
        'gate_2q_excellent': 0.003,
        'gate_2q_good': 0.008,
        'gate_2q_bad': 0.02,
        't1_excellent': 300,  # Î¼s
        't1_good': 150,
        't1_bad': 50,
        't2_excellent': 200,
        't2_good': 100,
        't2_bad': 30,
    }
    
    def __init__(self, topology: 'DynamicTopology', use_colors: bool = True):
        self.topo = topology
        self.use_colors = use_colors
        self._cache = {}
        # Largeur intÃ©rieure des cadres (sans les bordures)
        self.BOX_WIDTH = 72
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Utilitaires de base
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _visible_len(self, text: str) -> int:
        """Calcule la longueur visible d'une chaÃ®ne (sans codes ANSI)"""
        import re
        # Supprimer tous les codes ANSI
        ansi_escape = re.compile(r'\x1b\[[0-9;]*m')
        clean = ansi_escape.sub('', str(text))
        return len(clean)
    
    def _pad_line(self, content: str, target_width: int, align: str = 'left') -> str:
        """Pad une ligne pour atteindre exactement target_width caractÃ¨res visibles"""
        visible = self._visible_len(content)
        padding_needed = target_width - visible
        
        if padding_needed <= 0:
            return content
        
        if align == 'left':
            return content + ' ' * padding_needed
        elif align == 'right':
            return ' ' * padding_needed + content
        elif align == 'center':
            left = padding_needed // 2
            right = padding_needed - left
            return ' ' * left + content + ' ' * right
        return content + ' ' * padding_needed
    
    def _box_line(self, content: str, border: str = 'â•‘', align: str = 'left') -> str:
        """CrÃ©e une ligne de cadre avec contenu alignÃ©"""
        padded = self._pad_line(content, self.BOX_WIDTH, align)
        left_border = self._mc('bold', 'cyan', f"  {border}")
        right_border = self._mc('bold', 'cyan', border)
        return f"{left_border}{padded}{right_border}"
    
    def _box_line_simple(self, content: str, border: str = 'â”‚', align: str = 'left') -> str:
        """CrÃ©e une ligne de cadre simple avec contenu alignÃ©"""
        padded = self._pad_line(content, self.BOX_WIDTH, align)
        left_border = self._mc('bold', 'white', f"  {border}")
        right_border = self._mc('bold', 'white', border)
        return f"{left_border}{padded}{right_border}"
    
    def _section_header(self, title: str, icon: str = "") -> List[str]:
        """GÃ©nÃ¨re un header de section uniforme"""
        W = self.BOX_WIDTH
        lines = []
        lines.append("")
        lines.append(self._mc('bold', 'cyan', "  " + "â•" * W))
        full_title = f"{icon}  {title}" if icon else title
        lines.append(self._mc('bold', 'white', f"  {full_title}"))
        lines.append(self._c('gray', "  " + "â”€" * W))
        return lines
    
    def _c(self, color: str, text: str) -> str:
        """Applique couleur au texte"""
        if not self.use_colors:
            return str(text)
        c = self.COLORS.get(color, '')
        return f"{c}{text}{self.COLORS['reset']}"
    
    def _mc(self, *args) -> str:
        """Multi-color: applique plusieurs couleurs"""
        if not self.use_colors:
            return args[-1] if args else ''
        colors = ''.join(self.COLORS.get(c, '') for c in args[:-1])
        return f"{colors}{args[-1]}{self.COLORS['reset']}"
    
    def _grade_color(self, value: float, thresholds: tuple, low_is_good: bool = True) -> str:
        """Retourne la couleur selon la valeur et les seuils"""
        excellent, good, bad = thresholds
        if low_is_good:
            if value <= excellent:
                return 'green'
            elif value <= good:
                return 'yellow'
            else:
                return 'red'
        else:
            if value >= excellent:
                return 'green'
            elif value >= good:
                return 'yellow'
            else:
                return 'red'
    
    def _grade_letter(self, score: float) -> Tuple[str, str]:
        """Retourne note A-F et couleur"""
        if score >= 0.95:
            return 'A+', 'green'
        elif score >= 0.90:
            return 'A', 'green'
        elif score >= 0.85:
            return 'B+', 'green'
        elif score >= 0.80:
            return 'B', 'yellow'
        elif score >= 0.70:
            return 'C', 'yellow'
        elif score >= 0.60:
            return 'D', 'yellow'
        else:
            return 'F', 'red'
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Composants graphiques
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _progress_bar(self, value: float, width: int = 30, 
                      thresholds: tuple = (0.01, 0.03, 0.05),
                      low_is_good: bool = True,
                      show_percent: bool = True,
                      max_val: float = None) -> str:
        """Barre de progression colorÃ©e avec pourcentage"""
        if max_val is None:
            max_val = thresholds[2] * 1.5
        
        normalized = min(1.0, max(0.0, value / max_val))
        filled = int(normalized * width)
        
        color = self._grade_color(value, thresholds, low_is_good)
        
        bar = self._c(color, self.BLOCKS['full'] * filled)
        bar += self._c('gray', self.BLOCKS['1_4'] * (width - filled))
        
        if show_percent:
            pct = value / thresholds[1] * 100 if thresholds[1] > 0 else 0
            bar += f" {self._c(color, f'{value:.4f}')}"
        
        return bar
    
    def _gauge(self, value: float, max_val: float = 100, width: int = 20, 
               label: str = "") -> str:
        """Jauge circulaire ASCII"""
        pct = min(100, max(0, value / max_val * 100))
        filled = int(pct / 100 * width)
        
        if pct >= 80:
            color = 'green'
        elif pct >= 50:
            color = 'yellow'
        else:
            color = 'red'
        
        gauge = f"[{self._c(color, 'â–ˆ' * filled)}{self._c('gray', 'â–‘' * (width - filled))}]"
        return f"{label}{gauge} {self._c(color, f'{pct:.0f}%')}"
    
    def _sparkline(self, values: List[float], width: int = 20) -> str:
        """Mini graphique de tendance"""
        if not values:
            return "â”€" * width
        
        # Normaliser
        min_v, max_v = min(values), max(values)
        if max_v == min_v:
            max_v = min_v + 1
        
        # Ã‰chantillonner si nÃ©cessaire
        if len(values) > width:
            step = len(values) / width
            sampled = [values[int(i * step)] for i in range(width)]
        else:
            sampled = values + [values[-1]] * (width - len(values))
        
        # Convertir en caractÃ¨res
        chars = []
        for v in sampled:
            idx = int((v - min_v) / (max_v - min_v) * (len(self.SPARKLINE_CHARS) - 1))
            idx = max(0, min(len(self.SPARKLINE_CHARS) - 1, idx))
            chars.append(self.SPARKLINE_CHARS[idx])
        
        return self._c('cyan', ''.join(chars))
    
    def _histogram(self, values: List[float], width: int = 50, height: int = 8,
                   title: str = "", show_stats: bool = True) -> List[str]:
        """Histogramme avec statistiques"""
        if not values:
            return ["  No data available"]
        
        lines = []
        if title:
            lines.append(f"  {self._mc('bold', 'cyan', title)}")
        
        # Stats
        if show_stats:
            avg = np.mean(values)
            std = np.std(values)
            med = np.median(values)
            lines.append(f"  {self._c('gray', f'Î¼={avg:.4f}  Ïƒ={std:.4f}  med={med:.4f}  n={len(values)}')}")
        
        # Bins
        n_bins = min(width // 3, 25)
        min_val, max_val = min(values), max(values)
        if max_val == min_val:
            max_val = min_val + 0.001
        
        bin_width = (max_val - min_val) / n_bins
        bins = [0] * n_bins
        for v in values:
            idx = min(int((v - min_val) / bin_width), n_bins - 1)
            bins[idx] += 1
        
        max_count = max(bins)
        
        # Dessiner
        for row in range(height - 1, -1, -1):
            threshold = (row + 0.5) / height * max_count
            line = f"  {self._c('gray', f'{int(threshold):3d}')}â”‚"
            for i, count in enumerate(bins):
                # Colorer selon la position (dÃ©but=vert, fin=rouge)
                pos = i / n_bins
                if pos < 0.3:
                    color = 'green'
                elif pos < 0.7:
                    color = 'yellow'
                else:
                    color = 'red'
                
                if count >= threshold:
                    line += self._c(color, 'â–ˆâ–ˆ')
                elif count >= threshold - max_count / height / 2:
                    line += self._c(color, 'â–„â–„')
                else:
                    line += '  '
            lines.append(line)
        
        # Axe X
        lines.append(f"     â””{'â”€â”€' * n_bins}")
        lines.append(f"      {min_val:.4f}" + ' ' * (n_bins * 2 - 20) + f"{max_val:.4f}")
        
        return lines
    
    def _heatmap(self, data: Dict[int, float], width: int = 50, height: int = 10,
                 title: str = "") -> List[str]:
        """Heatmap de qualitÃ© des qubits"""
        lines = []
        if title:
            lines.append(f"  {self._mc('bold', 'cyan', title)}")
        
        if not data:
            lines.append("  No qubit data")
            return lines
        
        # Normaliser les valeurs
        values = list(data.values())
        min_v, max_v = min(values), max(values)
        if max_v == min_v:
            max_v = min_v + 0.001
        
        # Calculer la grille
        n_qubits = max(data.keys()) + 1
        cols = min(width // 2, 40)
        rows = (n_qubits + cols - 1) // cols
        
        # Dessiner
        for row in range(min(rows, height)):
            line = "  "
            for col in range(cols):
                q_idx = row * cols + col
                if q_idx >= n_qubits:
                    line += '  '
                elif q_idx not in data:
                    line += self._c('gray', 'â–‘â–‘')
                else:
                    val = data[q_idx]
                    normalized = (val - min_v) / (max_v - min_v)
                    
                    # Inverser (erreur faible = bon = vert)
                    if normalized < 0.2:
                        color = 'green'
                        char = 'â–ˆâ–ˆ'
                    elif normalized < 0.4:
                        color = 'green'
                        char = 'â–“â–“'
                    elif normalized < 0.6:
                        color = 'yellow'
                        char = 'â–’â–’'
                    elif normalized < 0.8:
                        color = 'yellow'
                        char = 'â–‘â–‘'
                    else:
                        color = 'red'
                        char = 'â–‘â–‘'
                    
                    line += self._c(color, char)
            lines.append(line)
        
        # LÃ©gende
        lines.append("")
        legend = "  "
        legend += f"{self._c('green', 'â–ˆâ–ˆ')}Best "
        legend += f"{self._c('green', 'â–“â–“')}Good "
        legend += f"{self._c('yellow', 'â–’â–’')}OK "
        legend += f"{self._c('yellow', 'â–‘â–‘')}Warn "
        legend += f"{self._c('red', 'â–‘â–‘')}Bad"
        lines.append(legend)
        
        return lines
    
    def _table(self, headers: List[str], rows: List[List[str]],
               widths: List[int] = None, 
               align: List[str] = None,
               highlight_rows: List[int] = None) -> List[str]:
        """Tableau formatÃ© avec alignement et highlight (supporte codes ANSI)"""
        if not rows:
            return ["  No data"]
        
        if not widths:
            widths = []
            for i, h in enumerate(headers):
                # Utiliser _visible_len pour calculer la largeur visible
                header_len = self._visible_len(str(h))
                max_cell_len = max(self._visible_len(str(r[i])) for r in rows if i < len(r))
                col_width = max(header_len, max_cell_len)
                widths.append(col_width + 2)
        
        if not align:
            align = ['center'] * len(headers)
        
        highlight_rows = highlight_rows or []
        
        lines = []
        
        # Top border
        lines.append("  â”Œ" + "â”¬".join("â”€" * w for w in widths) + "â”")
        
        # Headers - utiliser _pad_line pour un alignement correct
        header_line = "  â”‚"
        for h, w in zip(headers, widths):
            padded_header = self._pad_line(str(h), w, 'center')
            header_line += self._mc('bold', 'cyan', padded_header) + "â”‚"
        lines.append(header_line)
        
        # Separator
        lines.append("  â”œ" + "â”¼".join("â”€" * w for w in widths) + "â”¤")
        
        # Rows - utiliser _pad_line pour gÃ©rer les codes ANSI
        for idx, row in enumerate(rows):
            row_line = "  â”‚"
            for i, (cell, w, a) in enumerate(zip(row, widths, align)):
                cell_str = str(cell)
                # Utiliser _pad_line qui gÃ¨re correctement les codes ANSI
                formatted = self._pad_line(cell_str, w, a)
                
                if idx in highlight_rows:
                    row_line += self._c('yellow', formatted) + "â”‚"
                else:
                    row_line += formatted + "â”‚"
            lines.append(row_line)
        
        # Bottom border
        lines.append("  â””" + "â”´".join("â”€" * w for w in widths) + "â”˜")
        
        return lines
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Heavy-Hex Topology Map
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _heavy_hex_map(self, width: int = 70) -> List[str]:
        """GÃ©nÃ¨re une vraie carte Heavy-Hex style IBM Heron"""
        t = self.topo
        W = self.BOX_WIDTH
        lines = []
        
        # Bordures
        top_border = "  â•”" + "â•" * W + "â•—"
        bot_border = "  â•š" + "â•" * W + "â•"
        
        lines.append(self._mc('bold', 'cyan', top_border))
        title = "HEAVY-HEX TOPOLOGY MAP"
        lines.append(self._box_line(self._mc('bold', 'white', self._pad_line(title, W, 'center'))))
        lines.append(self._mc('bold', 'cyan', bot_border))
        
        if t.n_qubits == 0:
            lines.append("  No topology data")
            return lines
        
        # IBM Heron 156Q layout approximation
        # Heavy-hex pattern: hexagonal grid with extra qubits
        
        # Pour simplifier, on va crÃ©er une grille qui ressemble au heavy-hex
        # avec des positions dÃ©calÃ©es
        
        if t.n_qubits >= 156:
            # Layout 156Q (13 colonnes x 12 rangÃ©es approximativement)
            cols = 15
            rows = 11
        elif t.n_qubits >= 127:
            cols = 13
            rows = 10
        else:
            cols = int(np.sqrt(t.n_qubits * 1.5))
            rows = (t.n_qubits + cols - 1) // cols
        
        # Construire la map
        q_idx = 0
        for row in range(rows):
            line = "  "
            # DÃ©calage pour pattern hexagonal
            offset = " " if row % 2 == 0 else ""
            line += offset
            
            for col in range(cols):
                if q_idx >= t.n_qubits:
                    line += "   "
                else:
                    # Symbole selon Ã©tat
                    if q_idx in t.faulty_qubits:
                        sym = self._c('red', 'âœ—')
                    elif q_idx in t.suspect_qubits:
                        sym = self._c('yellow', 'â—')
                    else:
                        # VÃ©rifier la qualitÃ©
                        if q_idx in t._qubit_errors:
                            err = t._qubit_errors[q_idx].get('readout', 0)
                            if err < 0.01:
                                sym = self._c('green', 'â—')
                            elif err < 0.02:
                                sym = self._c('cyan', 'â—‰')
                            else:
                                sym = self._c('yellow', 'â—‹')
                        else:
                            sym = self._c('green', 'â—')
                    
                    # Ajouter numÃ©ro pour qubits spÃ©ciaux
                    line += f"{sym}  "
                q_idx += 1
            
            lines.append(line)
            
            # Ligne de connexion (pattern heavy-hex)
            if row < rows - 1:
                conn_line = "  "
                conn_line += " " if row % 2 == 0 else ""
                for col in range(cols):
                    if col < cols - 1:
                        conn_line += self._c('gray', 'â”€â”¼â”€')
                    else:
                        conn_line += "   "
                # lines.append(conn_line)  # Optionnel: lignes de connexion
        
        # LÃ©gende
        lines.append("")
        lines.append(f"  {self._c('green', 'â—')} Excellent  "
                    f"{self._c('cyan', 'â—‰')} Good  "
                    f"{self._c('yellow', 'â—‹')} OK  "
                    f"{self._c('yellow', 'â—')} Suspect  "
                    f"{self._c('red', 'âœ—')} Faulty")
        
        # Stats rapides
        lines.append(f"  {self._c('gray', f'Total: {t.n_qubits}Q | Usable: {t.n_qubits - len(t.faulty_qubits)}Q | Connections: {len(t._coupling_map)}')}")
        
        return lines
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Sections du rapport
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _compute_health_score(self) -> Dict:
        """Calcul dÃ©taillÃ© du score de santÃ©"""
        t = self.topo
        
        scores = {}
        
        # 1. Score qubits utilisables
        if t.n_qubits > 0:
            scores['qubit_availability'] = (t.n_qubits - len(t.faulty_qubits)) / t.n_qubits
        else:
            scores['qubit_availability'] = 0
        
        # 2. Score qubits sains (pas suspects)
        if t.n_qubits > 0:
            scores['qubit_health'] = 1 - (len(t.suspect_qubits) / t.n_qubits)
        else:
            scores['qubit_health'] = 0
        
        # 3. Score connexions
        if t._coupling_map:
            scores['connection_health'] = 1 - (len(t.broken_connections) / len(t._coupling_map))
        else:
            scores['connection_health'] = 0
        
        # 4. Score erreur de lecture moyenne
        readout_errors = [e['readout'] for e in t._qubit_errors.values() if 'readout' in e]
        if readout_errors:
            avg_readout = np.mean(readout_errors)
            # Normaliser: 0.05 = 0, 0.005 = 1
            scores['readout_quality'] = max(0, min(1, (0.05 - avg_readout) / 0.045))
        else:
            scores['readout_quality'] = 0.5
        
        # 5. Score erreur 2Q moyenne
        if t._connection_errors:
            avg_2q = np.mean(list(t._connection_errors.values()))
            scores['gate_quality'] = max(0, min(1, (0.02 - avg_2q) / 0.017))
        else:
            scores['gate_quality'] = 0.5
        
        # 6. Score T1/T2
        t1_values = [e['t1'] for e in t._qubit_errors.values() if 't1' in e and e['t1'] > 0]
        if t1_values:
            avg_t1 = np.mean(t1_values)
            scores['coherence'] = min(1, avg_t1 / 300)  # 300Î¼s = parfait
        else:
            scores['coherence'] = 0.5
        
        # Score global pondÃ©rÃ©
        weights = {
            'qubit_availability': 0.25,
            'qubit_health': 0.15,
            'connection_health': 0.15,
            'readout_quality': 0.20,
            'gate_quality': 0.15,
            'coherence': 0.10,
        }
        
        total = sum(scores[k] * weights[k] for k in weights)
        scores['total'] = total
        
        # Grade
        letter, color = self._grade_letter(total)
        scores['grade'] = letter
        scores['grade_color'] = color
        
        return scores
    
    def _header_section(self) -> List[str]:
        """En-tÃªte du rapport"""
        t = self.topo
        scores = self._compute_health_score()
        W = self.BOX_WIDTH  # Largeur intÃ©rieure
        
        lines = []
        
        # Construire les bordures
        top_border = "  â•”" + "â•" * W + "â•—"
        mid_border = "  â• " + "â•" * W + "â•£"
        bot_border = "  â•š" + "â•" * W + "â•"
        
        lines.append("")
        lines.append(self._mc('bold', 'cyan', top_border))
        
        # Titre centrÃ©
        title = "QMC CALIBRATION ANALYSIS REPORT"
        lines.append(self._box_line(self._mc('bold', 'white', self._pad_line(title, W, 'center'))))
        
        subtitle = "PREMIUM EDITION v2.0"
        lines.append(self._box_line(self._c('gray', self._pad_line(subtitle, W, 'center'))))
        
        lines.append(self._mc('bold', 'cyan', mid_border))
        
        # Info backend - calculer espacement
        backend_str = f"Backend: {t.backend_name}"
        timestamp = f"Analyzed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        spacing = W - len(backend_str) - len(timestamp) - 4  # -4 pour marges
        info_line = f"  {backend_str}{' ' * spacing}{timestamp}  "
        lines.append(self._box_line(info_line))
        
        lines.append(self._mc('bold', 'cyan', bot_border))
        
        return lines
    
    def _score_dashboard(self) -> List[str]:
        """Dashboard des scores"""
        scores = self._compute_health_score()
        W = self.BOX_WIDTH  # Largeur intÃ©rieure
        
        lines = []
        
        # Bordures
        top_border = "  â”Œ" + "â”€" * W + "â”"
        bot_border = "  â””" + "â”€" * W + "â”˜"
        
        lines.append("")
        lines.append(self._mc('bold', 'white', top_border))
        
        # Score principal avec grande lettre
        grade = scores['grade']
        color = scores['grade_color']
        total_pct = scores['total'] * 100
        
        # ASCII art pour la note
        grade_art = {
            'A+': ['  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— ', ' â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—', ' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘+', ' â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘ ', ' â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ ', ' â•šâ•â•  â•šâ•â• '],
            'A':  ['  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— ', ' â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—', ' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ ', ' â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘ ', ' â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ ', ' â•šâ•â•  â•šâ•â• '],
            'B+': [' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  ', ' â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— ', ' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•¦â•+', ' â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— ', ' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•¦â• ', ' â•šâ•â•â•â•â•â•  '],
            'B':  [' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  ', ' â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— ', ' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•¦â• ', ' â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— ', ' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•¦â• ', ' â•šâ•â•â•â•â•â•  '],
            'C':  ['  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— ', ' â–ˆâ–ˆâ•”â•â•â•â•â• ', ' â–ˆâ–ˆâ•‘      ', ' â–ˆâ–ˆâ•‘      ', ' â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— ', '  â•šâ•â•â•â•â•â• '],
            'D':  [' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  ', ' â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— ', ' â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ ', ' â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ ', ' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• ', ' â•šâ•â•â•â•â•â•  '],
            'F':  [' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— ', ' â–ˆâ–ˆâ•”â•â•â•â•â• ', ' â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   ', ' â–ˆâ–ˆâ•”â•â•â•   ', ' â–ˆâ–ˆâ•‘      ', ' â•šâ•â•      '],
        }
        
        art = grade_art.get(grade, grade_art['C'])
        
        # Titre
        title_content = f"  {self._mc('bold', 'cyan', 'OVERALL HEALTH SCORE')}"
        lines.append(self._box_line_simple(self._pad_line(title_content, W)))
        
        # Ligne vide
        lines.append(self._box_line_simple(' ' * W))
        
        # Afficher le grade avec dÃ©tails Ã  droite
        for i, art_line in enumerate(art):
            detail = ""
            if i == 1:
                detail = f"Score: {self._c(color, f'{total_pct:.1f}%')}"
            elif i == 2:
                detail = f"Grade: {self._c(color, grade)}"
            elif i == 3:
                if total_pct >= 90:
                    detail = self._c('green', "EXCELLENT - Production Ready")
                elif total_pct >= 75:
                    detail = self._c('yellow', "GOOD - Minor Issues")
                elif total_pct >= 50:
                    detail = self._c('yellow', "DEGRADED - Use Caution")
                else:
                    detail = self._c('red', "CRITICAL - Not Recommended")
            
            # Construire la ligne: art_line (10 chars) + espace + detail
            art_colored = self._c(color, art_line)
            content = f"     {art_colored}       {detail}"
            lines.append(self._box_line_simple(self._pad_line(content, W)))
        
        # Ligne vide
        lines.append(self._box_line_simple(' ' * W))
        
        # Barre de progression principale
        bar_width = 60
        filled = int(scores['total'] * bar_width)
        bar = (self._c(color, self.BLOCKS['full'] * filled) + 
               self._c('gray', self.BLOCKS['1_4'] * (bar_width - filled)))
        bar_content = f"     [{bar}]"
        lines.append(self._box_line_simple(self._pad_line(bar_content, W)))
        
        # Ligne vide
        lines.append(self._box_line_simple(' ' * W))
        
        # SÃ©parateur
        sep_content = f"  {self._c('gray', 'â”€' * (W - 4))}  "
        lines.append(self._box_line_simple(sep_content))
        
        # Sous-scores
        metrics = [
            ('Qubit Availability', scores['qubit_availability'], '25%'),
            ('Qubit Health', scores['qubit_health'], '15%'),
            ('Connection Health', scores['connection_health'], '15%'),
            ('Readout Quality', scores['readout_quality'], '20%'),
            ('Gate Quality', scores['gate_quality'], '15%'),
            ('Coherence Time', scores['coherence'], '10%'),
        ]
        
        for name, score, weight in metrics:
            letter, col = self._grade_letter(score)
            mini_bar_width = 20
            mini_filled = int(score * mini_bar_width)
            mini_bar = (self._c(col, 'â–ˆ' * mini_filled) + 
                       self._c('gray', 'â–‘' * (mini_bar_width - mini_filled)))
            
            # Format: name (20) + [ + bar (20) + ] + value (7) + weight (6)
            pct_str = f"{score*100:5.1f}%"
            metric_content = f"  {name:<20} [{mini_bar}] {self._c(col, pct_str)} {self._c('gray', f'({weight})')}"
            lines.append(self._box_line_simple(self._pad_line(metric_content, W)))
        
        lines.append(self._mc('bold', 'white', bot_border))
        
        return lines
    
    def _top_bottom_qubits(self) -> List[str]:
        """Top 10 meilleurs et pires qubits"""
        t = self.topo
        lines = []
        
        if not t._qubit_errors:
            return lines
        
        # Calculer score composite pour chaque qubit
        qubit_scores = {}
        for q_idx, errs in t._qubit_errors.items():
            if q_idx in t.faulty_qubits:
                score = 0
            else:
                readout = errs.get('readout', 0.05)
                t1 = errs.get('t1', 50)
                t2 = errs.get('t2', 30)
                
                # Score normalisÃ© (plus haut = meilleur)
                score = (max(0, 0.05 - readout) / 0.05 * 0.5 +
                        min(1, t1 / 300) * 0.3 +
                        min(1, t2 / 200) * 0.2)
                qubit_scores[q_idx] = score
        
        sorted_qubits = sorted(qubit_scores.items(), key=lambda x: x[1], reverse=True)
        
        lines = []
        lines.extend(self._section_header("TOP 10 BEST QUBITS                    ğŸ’€ TOP 10 WORST QUBITS", "ğŸ†"))
        
        # Afficher cÃ´te Ã  cÃ´te
        for i in range(10):
            # Best
            if i < len(sorted_qubits):
                best_q, best_score = sorted_qubits[i]
                best_errs = t._qubit_errors.get(best_q, {})
                best_str = (f"  {self._c('green', f'{i+1:2d}.')} Q{best_q:3d} "
                           f"[{self._c('green', 'â–ˆ' * int(best_score * 10))}{self._c('gray', 'â–‘' * (10 - int(best_score * 10)))}] "
                           f"{best_score*100:5.1f}%")
            else:
                best_str = " " * 35
            
            # Worst
            if i < len(sorted_qubits):
                worst_q, worst_score = sorted_qubits[-(i+1)]
                worst_errs = t._qubit_errors.get(worst_q, {})
                col = 'red' if worst_score < 0.5 else 'yellow'
                worst_str = (f"{self._c(col, f'{i+1:2d}.')} Q{worst_q:3d} "
                            f"[{self._c(col, 'â–ˆ' * int(worst_score * 10))}{self._c('gray', 'â–‘' * (10 - int(worst_score * 10)))}] "
                            f"{worst_score*100:5.1f}%")
            else:
                worst_str = ""
            
            lines.append(f"  {best_str}    {worst_str}")
        
        return lines
    
    def _qubit_quality_heatmap(self) -> List[str]:
        """Heatmap de qualitÃ© des qubits"""
        t = self.topo
        
        if not t._qubit_errors:
            return ["  No qubit error data available"]
        
        # PrÃ©parer les donnÃ©es
        readout_data = {q: e.get('readout', 0) for q, e in t._qubit_errors.items()}
        
        lines = []
        lines.extend(self._section_header("QUBIT READOUT ERROR HEATMAP", "ğŸŒ¡ï¸"))
        
        lines.extend(self._heatmap(readout_data, width=70, height=8, title=""))
        
        return lines
    
    def _connection_analysis(self) -> List[str]:
        """Analyse dÃ©taillÃ©e des connexions"""
        t = self.topo
        lines = []
        
        if not t._connection_errors:
            return ["  No connection data"]
        
        conn_errors = list(t._connection_errors.values())
        
        lines.extend(self._section_header("CONNECTION QUALITY ANALYSIS", "ğŸ”—"))
        
        # Stats
        avg = np.mean(conn_errors)
        std = np.std(conn_errors)
        median = np.median(conn_errors)
        p95 = np.percentile(conn_errors, 95)
        
        lines.append(f"  2-Qubit Gate (CZ) Error Statistics:")
        lines.append(f"    Minimum:  {min(conn_errors):.5f}  {self._sparkline(sorted(conn_errors)[:20])}")
        lines.append(f"    Average:  {avg:.5f}  {self._progress_bar(avg, 30, (0.003, 0.008, 0.02))}")
        lines.append(f"    Median:   {median:.5f}")
        lines.append(f"    Std Dev:  {std:.5f}")
        lines.append(f"    95th %:   {p95:.5f}")
        lines.append(f"    Maximum:  {max(conn_errors):.5f}")
        
        # Histogramme
        lines.append("")
        lines.extend(self._histogram(conn_errors, width=60, height=8, 
                                     title="Gate Error Distribution"))
        
        # Top pires connexions
        sorted_conns = sorted(t._connection_errors.items(), key=lambda x: x[1], reverse=True)
        
        lines.append("")
        lines.append(f"  {self._c('red', 'Worst 5 connections:')}")
        for (q1, q2), err in sorted_conns[:5]:
            bar = self._progress_bar(err, 20, (0.003, 0.008, 0.02))
            lines.append(f"    Q{q1:3d} â†” Q{q2:3d}: {bar}")
        
        return lines
    
    def _coherence_analysis(self) -> List[str]:
        """Analyse des temps de cohÃ©rence"""
        t = self.topo
        lines = []
        
        t1_values = [(q, e['t1']) for q, e in t._qubit_errors.items() if 't1' in e and e['t1'] > 0]
        t2_values = [(q, e['t2']) for q, e in t._qubit_errors.items() if 't2' in e and e['t2'] > 0]
        
        if not t1_values:
            return []
        
        lines.extend(self._section_header("COHERENCE TIME ANALYSIS", "[T]"))
        
        t1_only = [v for _, v in t1_values]
        t2_only = [v for _, v in t2_values]
        
        # T1 stats
        lines.append(f"  T1 (Energy Relaxation):")
        lines.append(f"    Range: {min(t1_only):.1f} - {max(t1_only):.1f} Î¼s")
        lines.append(f"    Mean:  {np.mean(t1_only):.1f} Î¼s  {self._sparkline(sorted(t1_only))}")
        
        # T2 stats
        if t2_only:
            lines.append(f"  T2 (Dephasing):")
            lines.append(f"    Range: {min(t2_only):.1f} - {max(t2_only):.1f} Î¼s")
            lines.append(f"    Mean:  {np.mean(t2_only):.1f} Î¼s  {self._sparkline(sorted(t2_only))}")
        
        # Ratio T2/T1
        if t1_only and t2_only:
            ratios = [t2 / t1 for t1, t2 in zip(t1_only, t2_only) if t1 > 0]
            if ratios:
                lines.append(f"  T2/T1 Ratio: {np.mean(ratios):.2f} (ideal â‰ˆ 2.0)")
        
        return lines
    
    def _recommendations_section(self) -> List[str]:
        """Recommandations automatiques"""
        t = self.topo
        scores = self._compute_health_score()
        
        lines = []
        lines.extend(self._section_header("RECOMMENDATIONS", "[*]"))
        
        recommendations = []
        
        # Analyser et gÃ©nÃ©rer des recommandations
        if t.faulty_qubits:
            recommendations.append((
                'red',
                f"AVOID {len(t.faulty_qubits)} faulty qubits: {sorted(t.faulty_qubits)[:10]}{'...' if len(t.faulty_qubits) > 10 else ''}"
            ))
        
        if scores['readout_quality'] < 0.7:
            recommendations.append((
                'yellow',
                "Consider enabling READOUT ERROR MITIGATION (M3/TREX)"
            ))
        
        if scores['gate_quality'] < 0.7:
            recommendations.append((
                'yellow',
                "Enable PAULI TWIRLING for 2-qubit gates"
            ))
        
        if scores['coherence'] < 0.5:
            recommendations.append((
                'yellow',
                "Use DYNAMICAL DECOUPLING (XY4 sequence) for idle qubits"
            ))
        
        if len(t.suspect_qubits) > t.n_qubits * 0.1:
            recommendations.append((
                'yellow',
                f"High suspect qubit rate ({len(t.suspect_qubits)}). Consider reducing circuit depth."
            ))
        
        # Optimal path
        optimal_path = t.get_best_path(min(100, t.n_qubits))
        recommendations.append((
            'green',
            f"Optimal contiguous region: {len(optimal_path)} qubits starting at Q{optimal_path[0] if optimal_path else '?'}"
        ))
        
        # Recommandations de circuit
        if scores['total'] >= 0.85:
            recommendations.append((
                'green',
                "QPU is in EXCELLENT condition. Safe for production workloads."
            ))
        elif scores['total'] >= 0.70:
            recommendations.append((
                'cyan',
                "QPU is GOOD. Enable error mitigation for best results."
            ))
        else:
            recommendations.append((
                'yellow',
                "QPU is DEGRADED. Consider waiting for next calibration cycle."
            ))
        
        # Afficher
        for color, rec in recommendations:
            icon = {'red': 'âœ—', 'yellow': 'âš ', 'green': 'âœ“', 'cyan': 'â„¹'}.get(color, 'â€¢')
            lines.append(f"  {self._c(color, icon)} {rec}")
        
        return lines
    
    def _comparison_vs_ideal(self) -> List[str]:
        """Comparaison vs calibration idÃ©ale"""
        t = self.topo
        lines = []
        
        lines.extend(self._section_header("COMPARISON VS IDEAL CALIBRATION", "[#]"))
        
        # Collecter donnÃ©es actuelles
        readout_errors = [e['readout'] for e in t._qubit_errors.values() if 'readout' in e]
        conn_errors = list(t._connection_errors.values()) if t._connection_errors else []
        t1_values = [e['t1'] for e in t._qubit_errors.values() if 't1' in e and e['t1'] > 0]
        
        # Tableau de comparaison
        headers = ['Metric', 'Current', 'Ideal', 'Gap', 'Status']
        rows = []
        
        if readout_errors:
            curr = np.mean(readout_errors)
            ideal = self.IDEAL_THRESHOLDS['readout_excellent']
            gap = (curr - ideal) / ideal * 100
            status = self._c('green', 'âœ“') if curr < self.IDEAL_THRESHOLDS['readout_good'] else self._c('yellow', 'âš ')
            rows.append(['Readout Error', f'{curr:.4f}', f'{ideal:.4f}', f'+{gap:.0f}%', status])
        
        if conn_errors:
            curr = np.mean(conn_errors)
            ideal = self.IDEAL_THRESHOLDS['gate_2q_excellent']
            gap = (curr - ideal) / ideal * 100
            status = self._c('green', 'âœ“') if curr < self.IDEAL_THRESHOLDS['gate_2q_good'] else self._c('yellow', 'âš ')
            rows.append(['2Q Gate Error', f'{curr:.4f}', f'{ideal:.4f}', f'+{gap:.0f}%', status])
        
        if t1_values:
            curr = np.mean(t1_values)
            ideal = self.IDEAL_THRESHOLDS['t1_excellent']
            gap = (ideal - curr) / ideal * 100
            status = self._c('green', 'âœ“') if curr > self.IDEAL_THRESHOLDS['t1_good'] else self._c('yellow', 'âš ')
            rows.append(['T1 (Î¼s)', f'{curr:.1f}', f'{ideal:.0f}', f'-{gap:.0f}%', status])
        
        if t.n_qubits > 0:
            curr = len(t.faulty_qubits)
            rows.append(['Faulty Qubits', str(curr), '0', f'+{curr}', 
                        self._c('green', 'âœ“') if curr == 0 else self._c('red', 'âœ—')])
        
        lines.extend(self._table(headers, rows, widths=[15, 10, 10, 10, 8]))
        
        return lines
    
    def _optimal_path_visualization(self) -> List[str]:
        """Visualisation du chemin optimal"""
        t = self.topo
        lines = []
        
        path = t.get_best_path(min(100, t.n_qubits))
        
        lines.extend(self._section_header("OPTIMAL QUBIT PATH", "ğŸ›¤ï¸"))
        
        lines.append(f"  Maximum contiguous good qubits: {self._mc('bold', 'cyan', str(len(path)))}")
        lines.append(f"  Starting qubit: Q{path[0] if path else '?'}")
        lines.append(f"  Ending qubit: Q{path[-1] if path else '?'}")
        
        # Visualiser le path
        if len(path) > 0:
            lines.append("")
            path_viz = "  "
            for i, q in enumerate(path[:30]):
                if i > 0:
                    path_viz += self._c('gray', 'â”€')
                path_viz += self._c('green', f'â—')
            if len(path) > 30:
                path_viz += self._c('gray', f'Â·Â·Â·({len(path)-30} more)')
            lines.append(path_viz)
            
            # NumÃ©ros
            nums = "  "
            for i, q in enumerate(path[:15]):
                nums += f"{q:2d} "
            if len(path) > 15:
                nums += "..."
            lines.append(self._c('gray', nums))
        
        return lines
    
    def _footer(self) -> List[str]:
        """Footer du rapport"""
        lines = []
        lines.append("")
        lines.append(self._c('gray', "  " + "â•" * 72))
        lines.append(self._c('gray', f"  Generated by QMC Framework v2.0 Premium | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"))
        lines.append(self._c('gray', "  Â© QMC Research Lab - Quantum Mandatory Cryptography"))
        lines.append("")
        
        return lines
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Point d'entrÃ©e principal
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def print_full_report(self):
        """Affiche le rapport complet premium"""
        
        # Header
        for line in self._header_section():
            print(line)
        
        # Score Dashboard
        for line in self._score_dashboard():
            print(line)
        
        # Heavy-Hex Map
        for line in self._heavy_hex_map():
            print(line)
        
        # Top/Bottom Qubits
        for line in self._top_bottom_qubits():
            print(line)
        
        # Heatmap
        for line in self._qubit_quality_heatmap():
            print(line)
        
        # Connection Analysis
        for line in self._connection_analysis():
            print(line)
        
        # Coherence
        for line in self._coherence_analysis():
            print(line)
        
        # Comparison vs Ideal
        for line in self._comparison_vs_ideal():
            print(line)
        
        # Optimal Path
        for line in self._optimal_path_visualization():
            print(line)
        
        # Recommendations
        for line in self._recommendations_section():
            print(line)
        
        # Footer
        for line in self._footer():
            print(line)
    
    def print_compact_report(self):
        """Version compacte du rapport"""
        for line in self._header_section():
            print(line)
        
        for line in self._score_dashboard():
            print(line)
        
        for line in self._recommendations_section():
            print(line)
        
        for line in self._footer():
            print(line)
    
    def get_report_string(self) -> str:
        """Retourne le rapport comme string"""
        import io
        import sys
        
        old_stdout = sys.stdout
        sys.stdout = buffer = io.StringIO()
        
        self.print_full_report()
        
        output = buffer.getvalue()
        sys.stdout = old_stdout
        
        return output
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # v2.5.21: MÃ©thodes d'export graphique via QiskitVisualizationWrapper
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def export_gate_map(self, backend, output_dir: Path = None,
                        filename: str = "gate_map.png") -> Optional[Path]:
        """
        Exporte la carte de la topologie du backend (v2.5.21).
        
        Utilise qiskit.visualization.plot_gate_map avec style IBM Carbon.
        
        Args:
            backend: Backend IBM
            output_dir: RÃ©pertoire de sortie
            filename: Nom du fichier
            
        Returns:
            Path vers le fichier gÃ©nÃ©rÃ© ou None
        """
        try:
            out_dir = Path(output_dir) if output_dir else Path('.')
            viz = QiskitVisualizationWrapper(output_dir=out_dir)
            fig = viz.plot_gate_map(backend, filename=filename)
            if fig:
                try:
                    import matplotlib.pyplot as plt
                    plt.close(fig)
                except:
                    pass
                return out_dir / filename
        except Exception as e:
            if self.use_colors:
                print(f"{self.COLORS['red']}[WARN] Gate map export failed: {e}{self.COLORS['reset']}")
        return None
    
    def export_error_map(self, backend, output_dir: Path = None,
                         filename: str = "error_map.png") -> Optional[Path]:
        """
        Exporte la carte des erreurs du backend (v2.5.21).
        
        Utilise qiskit.visualization.plot_error_map avec style IBM Carbon.
        
        Args:
            backend: Backend IBM
            output_dir: RÃ©pertoire de sortie
            filename: Nom du fichier
            
        Returns:
            Path vers le fichier gÃ©nÃ©rÃ© ou None
        """
        try:
            out_dir = Path(output_dir) if output_dir else Path('.')
            viz = QiskitVisualizationWrapper(output_dir=out_dir)
            fig = viz.plot_error_map(backend, filename=filename)
            if fig:
                try:
                    import matplotlib.pyplot as plt
                    plt.close(fig)
                except:
                    pass
                return out_dir / filename
        except Exception as e:
            if self.use_colors:
                print(f"{self.COLORS['red']}[WARN] Error map export failed: {e}{self.COLORS['reset']}")
        return None
    
    def export_calibration_heatmap(self, output_dir: Path = None,
                                   filename: str = "calibration_heatmap.png") -> Optional[Path]:
        """
        Exporte un heatmap de qualitÃ© des qubits (v2.5.21).
        
        GÃ©nÃ¨re un graphique matplotlib avec les scores de qualitÃ©.
        
        Args:
            output_dir: RÃ©pertoire de sortie
            filename: Nom du fichier
            
        Returns:
            Path vers le fichier gÃ©nÃ©rÃ© ou None
        """
        try:
            import matplotlib.pyplot as plt
            import numpy as np
            from matplotlib.colors import LinearSegmentedColormap
            
            # Collecter les scores de qualitÃ©
            scores = self.topo.compute_qubit_scores()
            n_qubits = len(scores)
            
            # CrÃ©er un heatmap simple (ligne unique ou grille)
            side = int(np.ceil(np.sqrt(n_qubits)))
            data = np.full((side, side), np.nan)
            
            for i, score in enumerate(scores.values()):
                row = i // side
                col = i % side
                data[row, col] = score
            
            # Couleurs IBM Carbon
            ibm_cmap = LinearSegmentedColormap.from_list(
                'ibm_quality',
                ['#da1e28', '#ff832b', '#f1c21b', '#42be65', '#0f62fe']
            )
            
            fig, ax = plt.subplots(figsize=(10, 8))
            im = ax.imshow(data, cmap=ibm_cmap, vmin=0, vmax=1, aspect='auto')
            
            # Annotations
            for i in range(side):
                for j in range(side):
                    if not np.isnan(data[i, j]):
                        qubit_idx = i * side + j
                        if qubit_idx < n_qubits:
                            ax.text(j, i, f"Q{qubit_idx}\n{data[i, j]:.2f}",
                                   ha='center', va='center', fontsize=8,
                                   color='white' if data[i, j] < 0.5 else 'black')
            
            ax.set_title(f"Qubit Quality Scores - {self.topo.backend_name}")
            fig.colorbar(im, ax=ax, label='Quality Score')
            
            # Style IBM Carbon
            fig.patch.set_facecolor('white')
            ax.set_facecolor('white')
            
            out_dir = Path(output_dir) if output_dir else Path('.')
            out_dir.mkdir(parents=True, exist_ok=True)
            filepath = out_dir / filename
            fig.savefig(filepath, dpi=150, facecolor='white', bbox_inches='tight')
            plt.close(fig)
            
            return filepath
            
        except Exception as e:
            if self.use_colors:
                print(f"{self.COLORS['red']}[WARN] Heatmap export failed: {e}{self.COLORS['reset']}")
        return None
    
    def export_all_visualizations(self, backend, output_dir: Path = None) -> Dict[str, Path]:
        """
        Exporte toutes les visualisations disponibles (v2.5.21).
        
        Args:
            backend: Backend IBM
            output_dir: RÃ©pertoire de sortie
            
        Returns:
            Dict avec les paths des fichiers gÃ©nÃ©rÃ©s
        """
        out_dir = Path(output_dir) if output_dir else Path('.')
        generated = {}
        
        # Gate map
        path = self.export_gate_map(backend, out_dir, "gate_map.png")
        if path:
            generated['gate_map'] = path
        
        # Error map
        path = self.export_error_map(backend, out_dir, "error_map.png")
        if path:
            generated['error_map'] = path
        
        # Heatmap qualitÃ©
        path = self.export_calibration_heatmap(out_dir, "quality_heatmap.png")
        if path:
            generated['quality_heatmap'] = path
        
        return generated


# =============================================================================
# DYNAMIC CLUSTER OPTIMIZER - QMC OPTIMAL CONFIGURATION
# =============================================================================

class DynamicClusterOptimizer:
    """
    Optimiseur dynamique de clusters pour QMC.
    
    Calcule automatiquement la configuration optimale (qubits, clusters, shots)
    en fonction de l'Ã©tat actuel du QPU et des objectifs de sÃ©curitÃ©.
    
    Formule de collision: avec K shots et N Ã©tats possibles (2^n_qubits),
    la probabilitÃ© de collision est P(collision) â‰ˆ 1 - e^(-KÂ²/2N)
    
    Pour garantir des mesures distinctes, on veut collision_ratio = N/K > 10
    """
    
    # Constantes pour les niveaux de sÃ©curitÃ©
    SECURITY_LEVELS = [
        (4096, "ğŸ”’ğŸ”’ğŸ”’ğŸ”’ğŸ”’ ABSOLUTE", "Beyond any physical limit"),
        (512,  "ğŸ”’ğŸ”’ğŸ”’ğŸ”’ INFO-THEORETIC", "Information-theoretic security"),
        (256,  "ğŸ”’ğŸ”’ğŸ”’ POST-QUANTUM", "Exceeds AES-256"),
        (128,  "ğŸ”’ğŸ”’ QUANTUM-READY", "Resists known quantum attacks"),
        (64,   "ğŸ”’ STANDARD", "â‰ˆ AES-128 level"),
        (0,    "âš ï¸ WEAK", "Below recommended minimum"),
    ]
    
    def __init__(self, framework=None, logger=None):
        """
        Args:
            framework: QMCFramework instance (optionnel)
            logger: Fonction de logging (optionnel)
        """
        self.framework = framework
        self._logger = logger
        self.clusters_found = []
        self.last_optimization = None
    
    def _log(self, msg: str):
        """Log un message."""
        if self._logger:
            self._logger(msg)
        else:
            print(msg)
    
    @staticmethod
    def compute_collision_ratio(n_qubits_per_cluster: int, n_shots: int) -> float:
        """
        Calcule le ratio de collision pour une configuration donnÃ©e.
        
        collision_ratio = 2^n_qubits / n_shots
        
        Un ratio > 10 garantit des mesures quasi-uniques.
        """
        n_states = 2 ** n_qubits_per_cluster
        return n_states / n_shots
    
    @staticmethod
    def get_security_level(bits: int) -> str:
        """Retourne le niveau de sÃ©curitÃ© pour un nombre de bits donnÃ©."""
        for threshold, level, _ in DynamicClusterOptimizer.SECURITY_LEVELS:
            if bits >= threshold:
                return level
        return "âš ï¸ WEAK"
    
    @staticmethod
    def get_security_description(bits: int) -> str:
        """Retourne la description du niveau de sÃ©curitÃ©."""
        for threshold, _, desc in DynamicClusterOptimizer.SECURITY_LEVELS:
            if bits >= threshold:
                return desc
        return "Below recommended minimum"
    
    def find_optimal_clusters(
        self, 
        n_good_qubits: int, 
        n_shots: int,
        target_security_bits: int = 128,
        min_collision_ratio: float = 10.0,
        topology_summary: Dict = None
    ) -> Dict:
        """
        Trouve la configuration optimale de clusters.
        
        Args:
            n_good_qubits: Nombre de qubits utilisables sur le QPU
            n_shots: Nombre de shots par exÃ©cution
            target_security_bits: SÃ©curitÃ© minimale souhaitÃ©e (dÃ©faut: 128)
            min_collision_ratio: Ratio minimum pour Ã©viter collisions (dÃ©faut: 10)
            topology_summary: RÃ©sumÃ© de la topologie (optionnel)
        
        Returns:
            Dict avec la configuration optimale
        """
        import math
        
        # Utiliser au max 80% des qubits disponibles (marge de sÃ©curitÃ©)
        max_usable = int(n_good_qubits * 0.8)
        
        # CRITICAL: Pour le fuzzy extractor, on a besoin de REPRODUCTIBILITÃ‰
        # Les mÃªmes Ã©tats doivent Ãªtre mesurÃ©s plusieurs fois entre encrypt et decrypt
        # Avec distribution quasi-uniforme: freq_moyenne = shots / 2^qpc
        # 
        # BasÃ© sur QMC v10.3 qui a rÃ©ussi Ã  99.7% :
        #   - 14 qubits mesurÃ©s, 200000 shots â†’ 12.2 mesures/Ã©tat
        # 
        # RÃˆGLE: On veut freq_moyenne >= 10 pour reproductibilitÃ© robuste
        # Donc: qpc <= log2(shots/10)
        
        target_measures_per_state = 10.0
        max_qpc_for_reproducibility = int(math.log2(n_shots / target_measures_per_state))
        
        # Min qubits par cluster pour sÃ©curitÃ© minimale
        min_qpc = 8  # Minimum 8 qubits par cluster
        
        # Appliquer la limite de reproductibilitÃ©
        # Si shots = 10000 â†’ max 9 qpc (9.8 mesures/Ã©tat)
        # Si shots = 50000 â†’ max 12 qpc (12.2 mesures/Ã©tat)
        max_qpc = min(max_qpc_for_reproducibility, 14)  # Cap Ã  14 qubits par cluster
        
        # Calculer reproductibilitÃ© attendue
        avg_freq = n_shots / (2 ** max_qpc)
        self._log(f"[OPTIMIZER] Reproducibility: {max_qpc} qpc â†’ ~{avg_freq:.1f} measures/state (target: â‰¥{target_measures_per_state})")
        
        # Chercher la meilleure configuration
        best_config = None
        best_total_qubits = 0
        
        for qpc in range(min_qpc, min(max_qpc + 1, max_usable + 1)):
            collision_ratio = self.compute_collision_ratio(qpc, n_shots)
            
            # Combien de clusters peut-on faire ?
            n_clusters = max_usable // qpc
            
            if n_clusters < 1:
                continue
            
            total_qubits = n_clusters * qpc
            
            # SÃ©curitÃ© = nombre total de qubits
            security_bits = total_qubits
            
            # Garder la config qui maximise les qubits (= sÃ©curitÃ©)
            if total_qubits > best_total_qubits:
                best_total_qubits = total_qubits
                best_config = {
                    "n_qubits": total_qubits,
                    "n_clusters": n_clusters,
                    "qubits_per_cluster": qpc,
                    "n_shots": n_shots,
                    "collision_ratio": collision_ratio,
                    "security_bits": security_bits,
                    "security_level": self.get_security_level(security_bits),
                    "security_description": self.get_security_description(security_bits),
                    "qpu_good_qubits": n_good_qubits,
                    "qpu_utilization": total_qubits / n_good_qubits if n_good_qubits > 0 else 0,
                }
        
        # Fallback si rien trouvÃ©
        if best_config is None:
            qpc = min_qpc
            n_clusters = max(1, max_usable // qpc)
            total_qubits = n_clusters * qpc
            best_config = {
                "n_qubits": total_qubits,
                "n_clusters": n_clusters,
                "qubits_per_cluster": qpc,
                "n_shots": n_shots,
                "collision_ratio": self.compute_collision_ratio(qpc, n_shots),
                "security_bits": total_qubits,
                "security_level": self.get_security_level(total_qubits),
                "security_description": self.get_security_description(total_qubits),
                "qpu_good_qubits": n_good_qubits,
                "qpu_utilization": total_qubits / n_good_qubits if n_good_qubits > 0 else 0,
            }
        
        self.last_optimization = best_config
        return best_config
    
    def find_cluster_groups(self, n_clusters: int, qubits_per_cluster: int, 
                           topology=None) -> List[List[int]]:
        """
        Trouve les groupes de qubits pour chaque cluster.
        
        Utilise la topologie du framework si disponible.
        
        Args:
            n_clusters: Nombre de clusters
            qubits_per_cluster: Qubits par cluster
            topology: DynamicTopology instance (optionnel)
        
        Returns:
            Liste de groupes de qubits
        """
        total_qubits = n_clusters * qubits_per_cluster
        
        if topology and hasattr(topology, 'get_qubit_groups'):
            # Utiliser la nouvelle fonction du framework
            groups = topology.get_qubit_groups(n_clusters, qubits_per_cluster)
        elif topology and hasattr(topology, 'get_best_qubits'):
            # Fallback: utiliser get_best_qubits et diviser
            best_qubits = topology.get_best_qubits(total_qubits)
            groups = []
            for i in range(n_clusters):
                start = i * qubits_per_cluster
                end = start + qubits_per_cluster
                group = best_qubits[start:end] if end <= len(best_qubits) else best_qubits[start:]
                groups.append(group)
        else:
            # Fallback: groupes linÃ©aires simples
            groups = []
            for i in range(n_clusters):
                start = i * qubits_per_cluster
                group = list(range(start, start + qubits_per_cluster))
                groups.append(group)
        
        self.clusters_found = groups
        return groups
    
    def print_optimization_report(self, config: Dict = None, groups: List[List[int]] = None,
                                  show_groups: bool = True):
        """
        Affiche un rapport d'optimisation avec un bel affichage ASCII.
        
        Args:
            config: Configuration d'optimisation (ou utilise last_optimization)
            groups: Groupes de qubits (optionnel)
            show_groups: Afficher les dÃ©tails des groupes
        """
        config = config or self.last_optimization
        groups = groups or self.clusters_found
        
        if not config:
            self._log("âš ï¸ No optimization config available")
            return
        
        # Couleurs ANSI
        C = "\033[96m"   # Cyan
        G = "\033[92m"   # Green
        Y = "\033[93m"   # Yellow
        R = "\033[91m"   # Red
        B = "\033[1m"    # Bold
        X = "\033[0m"    # Reset
        
        # Ligne de sÃ©paration
        SEP = f"{C}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£{X}"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # HEADER
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self._log("")
        self._log(f"{C}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—{X}")
        self._log(f"{C}â•‘{X}          âš›ï¸  {B}DYNAMIC CLUSTER OPTIMIZATION REPORT{X}  âš›ï¸")
        self._log(f"{C}â•‘{X}                       QMC Framework v2.5.1")
        self._log(SEP)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # QPU STATE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        qpu_good = config.get('qpu_good_qubits', 0)
        qpu_util = config.get('qpu_utilization', 0) * 100
        util_bar = "â–ˆ" * int(qpu_util / 5) + "â–‘" * (20 - int(qpu_util / 5))
        
        self._log(f"{C}â•‘{X}  {B}ğŸ“Š QPU STATE{X}")
        self._log(f"{C}â•‘{X}  â”œâ”€ Available Qubits:   {qpu_good}")
        self._log(f"{C}â•‘{X}  â”œâ”€ Shots/Execution:    {config['n_shots']:,}")
        self._log(f"{C}â•‘{X}  â””â”€ Utilization:        [{util_bar}] {qpu_util:.1f}%")
        self._log(SEP)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # OPTIMAL CONFIGURATION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        cr = config['collision_ratio']
        # NOUVEAU: Un ratio < 1 = bonne reproductibilitÃ© (plus de shots que d'Ã©tats)
        # ratio = Ã©tats / shots
        # < 0.5 = excellent (>2 mesures/Ã©tat)
        # < 1.0 = bon (>1 mesure/Ã©tat)
        # > 1.0 = mauvais (certains Ã©tats jamais mesurÃ©s)
        if cr < 0.5:
            cr_status = f"{G}âœ… EXCELLENT{X}"
        elif cr < 1.0:
            cr_status = f"{Y}âš¡ GOOD{X}"
        else:
            cr_status = f"{R}âš ï¸ LOW REPRO{X}"
        
        # Calculer mesures moyennes par Ã©tat
        qpc = config['qubits_per_cluster']
        measures_per_state = config['n_shots'] / (2 ** qpc)
        
        self._log(f"{C}â•‘{X}  {B}ğŸ¯ OPTIMAL CONFIGURATION{X}")
        self._log(f"{C}â•‘{X}  â”œâ”€ Total Qubits:       {config['n_qubits']}")
        self._log(f"{C}â•‘{X}  â”œâ”€ Clusters:           {config['n_clusters']}")
        self._log(f"{C}â•‘{X}  â”œâ”€ Qubits/Cluster:     {config['qubits_per_cluster']}")
        self._log(f"{C}â•‘{X}  â””â”€ Reproducibility:    ~{measures_per_state:.1f} measures/state  {cr_status}")
        self._log(SEP)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SECURITY ANALYSIS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        sec_bits = config['security_bits']
        sec_level = config['security_level']
        
        # Barre de progression sÃ©curitÃ©
        sec_pct = min(sec_bits / 256 * 100, 100)
        sec_bar = "â–ˆ" * int(sec_pct / 5) + "â–‘" * (20 - int(sec_pct / 5))
        
        self._log(f"{C}â•‘{X}  {B}ğŸ” SECURITY ANALYSIS{X}")
        self._log(f"{C}â•‘{X}  â”œâ”€ Security Bits:      {sec_bits}")
        self._log(f"{C}â•‘{X}  â”œâ”€ Level:              {sec_level}")
        self._log(f"{C}â•‘{X}  â””â”€ [{sec_bar}]")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # CLUSTER ALLOCATION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if show_groups and groups:
            self._log(SEP)
            self._log(f"{C}â•‘{X}  {B}ğŸ“¦ CLUSTER ALLOCATION{X}")
            
            max_show = min(len(groups), 8)
            for i, group in enumerate(groups[:max_show]):
                if group:
                    q_start = group[0]
                    q_end = group[-1]
                    n_q = len(group)
                    prefix = "â”œâ”€" if i < max_show - 1 else "â””â”€"
                    self._log(f"{C}â•‘{X}  {prefix} Cluster {i+1:2d}: Q{q_start:3d} â†’ Q{q_end:3d}  ({n_q} qubits)")
            
            if len(groups) > 8:
                self._log(f"{C}â•‘{X}  â””â”€ ... +{len(groups)-8} more clusters")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # COMPARISON TABLE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self._log(SEP)
        self._log(f"{C}â•‘{X}  {B}ğŸ“ˆ COMPARISON WITH CLASSICAL CRYPTO{X}")
        self._log(f"{C}â•‘{X}")
        self._log(f"{C}â•‘{X}  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        self._log(f"{C}â•‘{X}  â”‚  Algorithm  â”‚  Security  â”‚  vs QMC {sec_bits:3d} bits  â”‚")
        self._log(f"{C}â•‘{X}  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        
        comparisons = [
            ("AES-128", 128, "128 bits"),
            ("AES-256", 256, "256 bits"),
            ("RSA-2048", 112, "~112 bits*"),
            ("ECDSA-256", 128, "~128 bits*"),
        ]
        
        for name, bits, display in comparisons:
            if sec_bits > bits:
                status = f"{G}QMC wins{X}        "
            elif sec_bits == bits:
                status = f"{Y}Equal{X}           "
            else:
                status = f"{R}Lower{X}           "
            self._log(f"{C}â•‘{X}  â”‚ {name:<11} â”‚ {display:>10} â”‚ {status} â”‚")
        
        self._log(f"{C}â•‘{X}  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        self._log(f"{C}â•‘{X}")
        self._log(f"{C}â•‘{X}  * RSA/ECDSA vulnerable to Shor's algorithm (quantum threat)")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FOOTER
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self._log(SEP)
        
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self._log(f"{C}â•‘{X}  Generated: {timestamp}")
        self._log(f"{C}â•‘{X}  Â© QMC Research Lab - Quantum Mandatory Cryptography")
        self._log(f"{C}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{X}")
        self._log("")
    
    def get_recommendation(self, config: Dict = None) -> str:
        """Retourne une recommandation basÃ©e sur la configuration."""
        config = config or self.last_optimization
        if not config:
            return "No optimization data available"
        
        cr = config['collision_ratio']
        sec = config['security_bits']
        
        if cr < 5:
            return "âš ï¸ INCREASE shots or REDUCE qubits_per_cluster"
        elif cr < 10:
            return "âš¡ Consider increasing shots for better reliability"
        elif sec < 64:
            return "ğŸ”“ Security below recommended - add more clusters"
        elif sec < 128:
            return "ğŸ”’ Standard security achieved"
        elif sec < 256:
            return "ğŸ” Strong post-quantum security"
        else:
            return "ğŸ›¡ï¸ Maximum security configuration"


# =============================================================================
# ERROR MITIGATION MANAGER
# =============================================================================

class ErrorMitigationManager:
    """
    Gestionnaire des techniques de mitigation d'erreurs (v2.5.21).
    
    Supporte deux modes de configuration:
    1. MitigationConfig (legacy) - Configuration interne QMC
    2. RuntimeErrorMitigationConfig (v2.5.21) - Configuration Qiskit Runtime native
    
    Le mode Runtime dÃ©lÃ¨gue ZNE, PEC, TREX Ã  IBM Runtime cÃ´tÃ© serveur.
    """
    
    def __init__(self, config: MitigationConfig = None, 
                 runtime_config: RuntimeErrorMitigationConfig = None,
                 logger: Logger = None):
        """
        Args:
            config: Configuration MitigationConfig (legacy)
            runtime_config: Configuration RuntimeErrorMitigationConfig (v2.5.21)
            logger: Logger pour messages
        """
        self.config = config or MitigationConfig()
        self.runtime_config = runtime_config  # v2.5.21
        self.logger = logger
        self.readout_calibration_matrix = None
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='MITIGATION')
    
    # v2.5.21: Nouvelle mÃ©thode pour configuration Runtime
    def set_runtime_level(self, level: int) -> 'ErrorMitigationManager':
        """
        Configure le niveau de rÃ©silience Runtime (v2.5.21).
        
        Args:
            level: Niveau 0-2
                0: Aucune mitigation
                1: DD + TREX (dÃ©faut)
                2: DD + TREX + ZNE + Gate Twirling
                
        Returns:
            self pour chaÃ®nage
        """
        self.runtime_config = RuntimeErrorMitigationConfig.from_level(level)
        self._log(f"Runtime error mitigation level set to {level}")
        return self
    
    def configure_estimator(self, estimator) -> None:
        """
        Configure un EstimatorV2 avec la mitigation (v2.5.21).
        
        Utilise RuntimeErrorMitigationConfig si disponible,
        sinon applique les options MitigationConfig legacy.
        
        Args:
            estimator: Instance EstimatorV2
        """
        if self.runtime_config:
            self._log(f"Applying Runtime config level {self.runtime_config.resilience_level}")
            self.runtime_config.apply_to_estimator(estimator)
        else:
            # Legacy: appliquer ce qu'on peut
            self._log("Applying legacy MitigationConfig to estimator")
            try:
                if self.config.enable_dd:
                    estimator.options.dynamical_decoupling.enable = True
                    estimator.options.dynamical_decoupling.sequence_type = self.config.dd_sequence
            except Exception as e:
                self._log(f"Could not apply DD to estimator: {e}", LogLevel.WARN)
    
    def configure_sampler(self, sampler, circuits=None) -> None:
        """
        Configure un SamplerV2 avec la mitigation (v2.5.21).
        
        Args:
            sampler: Instance SamplerV2
            circuits: Circuits pour dÃ©tection dynamique
        """
        if self.runtime_config:
            self._log(f"Applying Runtime config level {self.runtime_config.resilience_level}")
            self.runtime_config.apply_to_sampler(sampler)
        else:
            # Legacy: utiliser configure_sampler_options
            try:
                self.configure_sampler_options(sampler.options, circuits)
            except Exception as e:
                self._log(f"Could not apply config to sampler: {e}", LogLevel.WARN)
    
    def configure_sampler_options(self, options, circuits=None):
        """
        Configure les options du Sampler IBM avec mitigation.
        
        [v2.5.13] AmÃ©liorations:
        - Applique shots_per_randomization pour twirling
        - DÃ©tecte les circuits dynamiques et dÃ©sactive les mitigations incompatibles
        - Log des warnings pour les features non implÃ©mentÃ©es si activÃ©es
        
        Args:
            options: SamplerOptions Ã  configurer
            circuits: Liste de circuits (optionnel, pour dÃ©tection dynamic)
        """
        # [v2.5.13] DÃ©tecter si les circuits sont dynamiques
        has_dynamic_circuits = False
        if circuits:
            has_dynamic_circuits = self._detect_dynamic_circuits(circuits)
            if has_dynamic_circuits:
                self._log("Dynamic circuits detected - some mitigations incompatible", 
                         LogLevel.WARN)
        
        # Twirling
        if self.config.enable_twirling:
            # [v2.5.13] Twirling incompatible avec circuits dynamiques
            if has_dynamic_circuits:
                self._log("Twirling disabled (incompatible with dynamic circuits)", 
                         LogLevel.WARN)
            else:
                try:
                    options.twirling.enable_gates = True
                    options.twirling.num_randomizations = self.config.twirling_num_randomizations
                    
                    # [v2.5.13] Appliquer shots_per_randomization si dÃ©fini
                    if self.config.twirling_shots_per_randomization:
                        options.twirling.shots_per_randomization = self.config.twirling_shots_per_randomization
                        self._log(f"Twirling enabled: {self.config.twirling_num_randomizations} rand x "
                                 f"{self.config.twirling_shots_per_randomization} shots/rand")
                    else:
                        self._log(f"Twirling enabled: {self.config.twirling_num_randomizations} randomizations")
                except Exception as e:
                    self._log(f"Could not enable twirling: {e}", LogLevel.WARN)
        
        # Dynamical Decoupling
        if self.config.enable_dd:
            # [v2.5.13] DD incompatible avec circuits dynamiques
            if has_dynamic_circuits:
                self._log("DD disabled (incompatible with dynamic circuits)", 
                         LogLevel.WARN)
            else:
                try:
                    options.dynamical_decoupling.enable = True
                    options.dynamical_decoupling.sequence_type = self.config.dd_sequence
                    self._log(f"DD enabled: {self.config.dd_sequence}")
                except Exception as e:
                    self._log(f"Could not enable DD: {e}", LogLevel.WARN)
        
        # [v2.5.21] Si on a une config Runtime, l'appliquer aussi
        if self.runtime_config:
            self._log("Applying additional Runtime config to options")
            try:
                if self.runtime_config.dynamical_decoupling and not has_dynamic_circuits:
                    options.dynamical_decoupling.enable = True
                    options.dynamical_decoupling.sequence_type = self.runtime_config.dd_sequence
            except Exception:
                pass
        
        # [v2.5.13] Warnings explicites pour features non implÃ©mentÃ©es localement
        if self.config.enable_zne:
            if self.runtime_config and self.runtime_config.zne_mitigation:
                self._log("ZNE will be applied by IBM Runtime (level 2)")
            else:
                self._log("ZNE enabled in config but requires Runtime level 2", LogLevel.WARN)
        
        if self.config.enable_pec:
            self._log("PEC requires IBM Runtime - not available in Sampler", LogLevel.WARN)
        
        if self.config.enable_readout_mitigation:
            if self.runtime_config and self.runtime_config.measure_mitigation:
                self._log("TREX readout mitigation will be applied by Runtime")
            else:
                self._log("Readout mitigation requires Runtime level 1+", LogLevel.WARN)
    
    def _detect_dynamic_circuits(self, circuits) -> bool:
        """
        [v2.5.13] DÃ©tecte si des circuits contiennent des Ã©lÃ©ments dynamiques.
        
        Circuits dynamiques = conditionnels, mid-circuit measurement, control flow
        Ces circuits sont incompatibles avec twirling et DD.
        """
        for circuit in circuits if isinstance(circuits, list) else [circuits]:
            try:
                # VÃ©rifier les instructions conditionnelles
                for instruction in circuit.data:
                    # c_if est la marque des conditionnels classiques
                    if hasattr(instruction, 'operation'):
                        op = instruction.operation
                        if hasattr(op, 'condition') and op.condition is not None:
                            return True
                        # Control flow operations
                        if op.name in ('if_else', 'while_loop', 'for_loop', 'switch_case'):
                            return True
            except Exception:
                pass  # En cas d'erreur, on assume non-dynamique
        return False
    
    def get_summary(self) -> Dict:
        """
        Retourne la configuration active avec transparence sur ce qui est implÃ©mentÃ©.
        
        [v2.5.21] Ajout des informations Runtime
        """
        summary = {
            'twirling': {
                'enabled': self.config.enable_twirling,
                'implemented': True,
                'num_randomizations': self.config.twirling_num_randomizations if self.config.enable_twirling else None,
            },
            'dynamical_decoupling': {
                'enabled': self.config.enable_dd,
                'implemented': True,
                'sequence': self.config.dd_sequence if self.config.enable_dd else None,
            },
            'zne': {
                'enabled': self.config.enable_zne,
                'implemented': False,
                'runtime_available': self.runtime_config.zne_mitigation if self.runtime_config else False,
                'note': 'ZNE requires Runtime level 2' if not (self.runtime_config and self.runtime_config.zne_mitigation) else 'Applied via Runtime',
            },
            'pec': {
                'enabled': self.config.enable_pec,
                'implemented': False,
                'note': 'PEC not available in current Runtime version',
            },
            'readout_mitigation': {
                'enabled': self.config.enable_readout_mitigation,
                'implemented': False,
                'runtime_available': self.runtime_config.measure_mitigation if self.runtime_config else False,
                'note': 'TREX available via Runtime level 1+' if not (self.runtime_config and self.runtime_config.measure_mitigation) else 'TREX applied via Runtime',
            },
        }
        
        # v2.5.21: Ajouter rÃ©sumÃ© Runtime si configurÃ©
        if self.runtime_config:
            summary['runtime_config'] = self.runtime_config.to_dict()
        
        return summary


# =============================================================================
# SMART RETRY MANAGER
# =============================================================================

class SmartRetryManager:
    """Gestion intelligente des retry avec backoff exponentiel et jitter optionnel"""
    
    def __init__(self, max_retries: int = 3, base_delay: float = 5.0,
                 max_delay: float = 300.0, jitter: bool = True, logger: Logger = None):
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.max_delay = max_delay
        self.jitter = jitter  # [v2.5.14] Ajout du support jitter
        self.logger = logger
        
        self._retry_count = 0
        self._total_retries = 0
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='RETRY')
    
    def execute_with_retry(self, func: Callable, operation_name: str = "operation",
                          *args, **kwargs) -> Any:
        """ExÃ©cute une fonction avec retry"""
        last_error = None
        
        for attempt in range(self.max_retries + 1):
            try:
                result = func(*args, **kwargs)
                if attempt > 0:
                    self._log(f"[OK] {operation_name} succeeded on attempt {attempt + 1}")
                return result
                
            except Exception as e:
                last_error = e
                error_type = type(e).__name__
                
                if error_type not in RETRIABLE_ERRORS and attempt == 0:
                    raise
                
                if attempt < self.max_retries:
                    delay = min(self.base_delay * (2 ** attempt), self.max_delay)
                    
                    # [v2.5.14] Appliquer jitter multiplicatif (0.5 Ã  1.5x)
                    if self.jitter:
                        import random
                        delay *= (0.5 + random.random())
                    
                    self._log(f"â³ {operation_name} failed ({error_type}), "
                             f"retrying in {delay:.1f}s (attempt {attempt + 1}/{self.max_retries})",
                             LogLevel.WARN)
                    time.sleep(delay)
                    self._retry_count = attempt + 1
                    self._total_retries += 1
        
        self._log(f"[XX] {operation_name} failed after {self.max_retries + 1} attempts",
                 LogLevel.ERROR)
        raise last_error


# =============================================================================
# JOB MONITOR
# =============================================================================

class JobMonitor:
    """
    Monitoring temps rÃ©el des jobs IBM Quantum avec animation.
    
    [v2.5.13] Injection clock pour tests unitaires.
    """
    
    def __init__(self, update_interval: float = 5.0, logger: Logger = None,
                 clock=None, sleep_fn=None):
        """
        Args:
            update_interval: Intervalle de polling en secondes
            logger: Logger pour les messages
            clock: Fonction time.time() injectable (dÃ©faut: time.time)
            sleep_fn: Fonction time.sleep() injectable (dÃ©faut: time.sleep)
        """
        self.update_interval = update_interval
        self.logger = logger
        self.metrics = {}
        self._stop_event = threading.Event()
        self._spinner = None
        self._spinner_thread = None
        
        # [v2.5.13] Injection pour tests
        self._clock = clock or time.time
        self._sleep = sleep_fn or time.sleep
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='MONITOR')
    
    def _start_spinner(self, status: str, elapsed: float):
        """DÃ©marre le spinner pour un statut donnÃ©"""
        import sys
        
        # ArrÃªter le spinner prÃ©cÃ©dent si existant
        self._stop_spinner()
        
        # Choisir le style selon le statut
        if status == 'QUEUED':
            style = 'bounce'
            msg = f"En file d'attente"
        elif status == 'RUNNING':
            style = 'quantum'
            msg = "Execution QPU"
        else:
            return
        
        self._spinner_stop = threading.Event()
        self._spinner_status = status
        self._spinner_start_time = self._clock() - elapsed  # [v2.5.13] Utilise clock injectÃ©
        
        def animate():
            frames = {
                'bounce': ['[=   ]', '[ =  ]', '[  = ]', '[   =]', '[  = ]', '[ =  ]'],
                'quantum': ['|0>', '|+>', '|1>', '|->'],
            }
            frame_list = frames.get(style, frames['bounce'])
            idx = 0
            
            while not self._spinner_stop.is_set():
                elapsed_now = self._clock() - self._spinner_start_time  # [v2.5.13]
                frame = frame_list[idx % len(frame_list)]
                
                # Format: [MONITOR] [=] |0> Execution QPU (125s)
                line = f"\r  {frame} {msg} ({elapsed_now:.0f}s)   "
                try:
                    sys.stdout.write(line)
                    sys.stdout.flush()
                except:
                    pass
                
                idx += 1
                self._spinner_stop.wait(0.2)
            
            # Effacer la ligne
            try:
                sys.stdout.write("\r" + " " * 50 + "\r")
                sys.stdout.flush()
            except:
                pass
        
        self._spinner_thread = threading.Thread(target=animate, daemon=True)
        self._spinner_thread.start()
    
    def _stop_spinner(self):
        """ArrÃªte le spinner actuel"""
        if hasattr(self, '_spinner_stop') and self._spinner_stop:
            self._spinner_stop.set()
        if hasattr(self, '_spinner_thread') and self._spinner_thread:
            self._spinner_thread.join(timeout=0.5)
            self._spinner_thread = None
    
    def monitor_job(self, job, timeout: float = None, animate: bool = True) -> Dict:
        """
        Monitor un job jusqu'Ã  complÃ©tion avec animation optionnelle.
        
        [v2.5.13] Utilise clock/sleep injectÃ©s pour testabilitÃ©.
        
        Args:
            job: Job IBM Quantum Ã  monitorer
            timeout: Timeout en secondes (optionnel)
            animate: Afficher une animation pendant QUEUED/RUNNING (dÃ©faut: True)
        
        Returns:
            Dict avec mÃ©triques: total_time_s, final_status, timeout_triggered
        """
        start_time = self._clock()  # [v2.5.13] Utilise clock injectÃ©
        last_status = None
        timeout_triggered = False
        
        while not self._stop_event.is_set():
            try:
                status = str(job.status())
                elapsed = self._clock() - start_time  # [v2.5.13]
                
                if timeout and elapsed > timeout:
                    self._stop_spinner()
                    self._log(f"[!!] Timeout after {elapsed:.0f}s", LogLevel.WARN)
                    timeout_triggered = True
                    try:
                        job.cancel()
                    except:
                        pass
                    break
                
                if status != last_status:
                    # ArrÃªter le spinner prÃ©cÃ©dent avant de logger
                    self._stop_spinner()
                    
                    # Logger le changement de statut
                    self._log(f"[{elapsed:6.0f}s] Status: {status}")
                    last_status = status
                    
                    # DÃ©marrer un nouveau spinner si nÃ©cessaire
                    if animate and status in ['QUEUED', 'RUNNING']:
                        self._start_spinner(status, elapsed)
                
                if status in ['DONE', 'ERROR', 'CANCELLED']:
                    self._stop_spinner()
                    break
                
                self._sleep(self.update_interval)  # [v2.5.13] Utilise sleep injectÃ©
                
            except Exception as e:
                self._stop_spinner()
                self._log(f"Monitor error: {e}", LogLevel.WARN)
                self._sleep(self.update_interval)  # [v2.5.13]
        
        self._stop_spinner()
        
        self.metrics = {
            'total_time_s': self._clock() - start_time,  # [v2.5.13]
            'final_status': last_status,
            'timeout_triggered': timeout_triggered,  # [v2.5.13] Nouveau champ
        }
        
        return self.metrics
    
    def stop(self):
        self._stop_spinner()
        self._stop_event.set()
    
    def reset(self):
        self._stop_spinner()
        self._stop_event.clear()
        self.metrics = {}


# =============================================================================
# FAKE JOB & FAKE SAMPLER - Pour tests unitaires sans IBM
# =============================================================================

class FakeJob:
    """
    [v2.5.13] Job simulÃ© pour tests unitaires sans connexion IBM.
    
    Simule le comportement d'un RuntimeJob IBM avec:
    - SÃ©quence de statuts configurable (QUEUED -> RUNNING -> DONE)
    - PossibilitÃ© de simuler des erreurs
    - RÃ©sultats configurables
    
    Usage:
        job = FakeJob(
            job_id='fake_123',
            status_sequence=['QUEUED', 'RUNNING', 'DONE'],
            result_counts=[{'00': 500, '11': 500}]
        )
    """
    
    def __init__(self, job_id: str = 'fake_job_001',
                 status_sequence: List[str] = None,
                 result_counts: List[Dict] = None,
                 error_on_result: bool = False):
        """
        Args:
            job_id: ID du job
            status_sequence: SÃ©quence de statuts Ã  retourner
            result_counts: Liste de counts par circuit
            error_on_result: Si True, result() lÃ¨ve une exception
        """
        self._job_id = job_id
        self._status_sequence = status_sequence or ['QUEUED', 'RUNNING', 'DONE']
        self._status_index = 0
        self._result_counts = result_counts or [{'00': 4096, '11': 4096}]
        self._error_on_result = error_on_result
        self._cancelled = False
    
    def job_id(self) -> str:
        return self._job_id
    
    def status(self) -> str:
        """Retourne le statut actuel, avance dans la sÃ©quence"""
        if self._cancelled:
            return 'CANCELLED'
        
        status = self._status_sequence[min(self._status_index, len(self._status_sequence) - 1)]
        
        # Avancer automatiquement dans la sÃ©quence
        if self._status_index < len(self._status_sequence) - 1:
            self._status_index += 1
        
        return status
    
    def cancel(self):
        """Annule le job"""
        self._cancelled = True
    
    def result(self):
        """Retourne un rÃ©sultat simulÃ©"""
        if self._error_on_result:
            raise RuntimeError("FakeJob: Simulated error on result()")
        
        if self._cancelled:
            raise RuntimeError("Job was cancelled")
        
        return FakeResult(self._result_counts)


class FakeResult:
    """
    [v2.5.13] RÃ©sultat simulÃ© compatible avec le format Qiskit Runtime.
    """
    
    def __init__(self, counts_list: List[Dict]):
        self._counts_list = counts_list
    
    def __len__(self):
        return len(self._counts_list)
    
    def __getitem__(self, idx):
        return FakePubResult(self._counts_list[idx])


class FakePubResult:
    """
    [v2.5.13] RÃ©sultat d'un circuit simulÃ© (PUB = Primitive Unified Bloc).
    """
    
    def __init__(self, counts: Dict):
        self._counts = counts
        self.data = FakeDataBundle(counts)


class FakeDataBundle:
    """
    [v2.5.13] Bundle de donnÃ©es simulÃ©.
    """
    
    def __init__(self, counts: Dict):
        self._counts = counts
    
    @property
    def meas(self):
        return FakeBitArray(self._counts)


class FakeBitArray:
    """
    [v2.5.13] BitArray simulÃ© pour get_counts().
    """
    
    def __init__(self, counts: Dict):
        self._counts = counts
    
    def get_counts(self) -> Dict:
        return self._counts


class FakeSamplerV2:
    """
    [v2.5.13] SamplerV2 simulÃ© pour tests unitaires sans connexion IBM.
    
    Simule le comportement de SamplerV2 avec:
    - PossibilitÃ© de simuler des Ã©checs de soumission (pour tester retry)
    - Jobs configurables
    
    Usage:
        sampler = FakeSamplerV2(
            fail_first_n_runs=2,  # Les 2 premiers run() Ã©chouent
            job_status_sequence=['QUEUED', 'RUNNING', 'DONE']
        )
        job = sampler.run(circuits, shots=4096)  # Ã‰choue
        job = sampler.run(circuits, shots=4096)  # Ã‰choue
        job = sampler.run(circuits, shots=4096)  # RÃ©ussit
    """
    
    def __init__(self, mode=None, 
                 fail_first_n_runs: int = 0,
                 job_status_sequence: List[str] = None,
                 result_counts: List[Dict] = None):
        """
        Args:
            mode: Backend (ignorÃ© dans le fake)
            fail_first_n_runs: Nombre de runs qui Ã©chouent avant succÃ¨s
            job_status_sequence: SÃ©quence de statuts pour les jobs
            result_counts: Counts Ã  retourner
        """
        self.mode = mode
        self._fail_first_n = fail_first_n_runs
        self._run_count = 0
        self._job_status_sequence = job_status_sequence or ['QUEUED', 'RUNNING', 'DONE']
        self._result_counts = result_counts
        
        # Options simulÃ©es
        self.options = FakeSamplerOptions()
    
    def run(self, circuits, shots: int = 4096) -> FakeJob:
        """
        Soumet des circuits (simulÃ©).
        
        Raises:
            RuntimeError: Si dans les N premiers runs (fail_first_n_runs)
        """
        self._run_count += 1
        
        if self._run_count <= self._fail_first_n:
            raise RuntimeError(f"FakeSamplerV2: Simulated failure (run #{self._run_count})")
        
        # GÃ©nÃ©rer des counts par dÃ©faut si non fournis
        n_circuits = len(circuits) if isinstance(circuits, list) else 1
        
        if self._result_counts:
            counts = self._result_counts
        else:
            # Counts par dÃ©faut: distribution uniforme
            counts = [{'00': shots//2, '11': shots//2} for _ in range(n_circuits)]
        
        return FakeJob(
            job_id=f'fake_job_{self._run_count:03d}',
            status_sequence=self._job_status_sequence,
            result_counts=counts
        )


class FakeSamplerOptions:
    """
    [v2.5.13] Options simulÃ©es pour FakeSamplerV2.
    """
    
    def __init__(self):
        self.twirling = FakeTwirlingOptions()
        self.dynamical_decoupling = FakeDDOptions()


class FakeTwirlingOptions:
    """Options de twirling simulÃ©es."""
    
    def __init__(self):
        self.enable_gates = False
        self.num_randomizations = 32
        self.shots_per_randomization = None
        self.strategy = 'active'


class FakeDDOptions:
    """Options de dynamical decoupling simulÃ©es."""
    
    def __init__(self):
        self.enable = False
        self.sequence_type = 'XY4'


# =============================================================================
# CHECKPOINT MANAGER
# =============================================================================

class CheckpointManager:
    """Gestionnaire de checkpoints"""
    
    def __init__(self, checkpoint_dir: Path = None, logger: Logger = None):
        self.checkpoint_dir = checkpoint_dir or Path('.qmc_checkpoints')
        self.checkpoint_dir.mkdir(exist_ok=True)
        self.logger = logger
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='CHECKPOINT')
    
    def save_checkpoint(self, state: Dict, name: str = None) -> Path:
        """Sauvegarde un checkpoint"""
        name = name or f"checkpoint_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        path = self.checkpoint_dir / f"{name}.json"
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'name': name,
                'state': state,
            }, f, indent=2, default=str)
        
        self._log(f"ğŸ’¾ Checkpoint saved: {path.name}")
        return path
    
    def load_checkpoint(self, name: str = None) -> Optional[Dict]:
        """Charge un checkpoint"""
        if name:
            path = self.checkpoint_dir / f"{name}.json"
        else:
            checkpoints = sorted(self.checkpoint_dir.glob("*.json"))
            if not checkpoints:
                return None
            path = checkpoints[-1]
        
        if not path.exists():
            return None
        
        with open(path, encoding='utf-8') as f:
            data = json.load(f)
        
        self._log(f"ğŸ“‚ Checkpoint loaded: {path.name}")
        return data.get('state')


# =============================================================================
# QPU TIME ESTIMATOR
# =============================================================================

class QPUTimeEstimator:
    """Estimation du temps QPU"""
    
    # Temps de base par type de processeur (en secondes)
    BASE_TIMES = {
        'heron2': {'shot': 0.0012, 'circuit_overhead': 0.5, 'gate_2q': 0.00007},
        'heron': {'shot': 0.0015, 'circuit_overhead': 0.6, 'gate_2q': 0.00008},
        'eagle': {'shot': 0.002, 'circuit_overhead': 0.8, 'gate_2q': 0.0007},
        'default': {'shot': 0.002, 'circuit_overhead': 1.0, 'gate_2q': 0.0005},
    }
    
    @classmethod
    def estimate(cls, n_circuits: int, n_qubits: int, shots: int,
                 depth: int = 100, processor_type: str = 'default') -> Dict:
        """Estime le temps QPU"""
        times = cls.BASE_TIMES.get(processor_type, cls.BASE_TIMES['default'])
        
        shot_time = shots * times['shot']
        circuit_time = n_circuits * times['circuit_overhead']
        gate_time = depth * n_qubits * times['gate_2q'] * n_circuits
        
        total = shot_time + circuit_time + gate_time
        
        return {
            'estimated_qpu_s': round(total, 1),
            'estimated_queue_s': 60,  # Conservative
            'estimated_total_s': round(total + 60, 0),
            'breakdown': {
                'shots': round(shot_time, 2),
                'circuits': round(circuit_time, 2),
                'gates': round(gate_time, 2),
            },
        }
    
    @classmethod
    def format_estimate(cls, estimate: Dict) -> str:
        """Formate l'estimation pour affichage"""
        return (f"[T] Estimation: QPU={estimate['estimated_qpu_s']:.1f}s, "
                f"Queueâ‰ˆ{estimate['estimated_queue_s']}s, "
                f"Totalâ‰ˆ{estimate['estimated_total_s']:.0f}s")


# =============================================================================
# RESULT VISUALIZER
# =============================================================================

class ResultVisualizer:
    """
    GÃ©nÃ©ration de visualisations avec intÃ©gration Qiskit native (v2.5.21).
    
    Utilise QiskitVisualizationWrapper pour les visualisations Qiskit
    avec style IBM Carbon automatique.
    """
    
    def __init__(self, output_dir: Path = None, logger: Logger = None):
        self.output_dir = output_dir or Path('plots')
        self.output_dir.mkdir(exist_ok=True)
        self.logger = logger
        
        # v2.5.21: IntÃ©gration QiskitVisualizationWrapper
        self._qiskit_viz = QiskitVisualizationWrapper(output_dir=self.output_dir)
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='VISUALIZER')
    
    def plot_histogram(self, counts: CountsType, title: str = "Distribution",
                       top_n: int = 20, use_qiskit: bool = True) -> Optional[Path]:
        """
        GÃ©nÃ¨re un histogramme des counts.
        
        Args:
            counts: Distribution de counts
            title: Titre du graphique
            top_n: Nombre de barres Ã  afficher
            use_qiskit: Si True, utilise qiskit.visualization (v2.5.21)
            
        Returns:
            Path vers le fichier gÃ©nÃ©rÃ©
        """
        # v2.5.21: Utiliser Qiskit si disponible et demandÃ©
        if use_qiskit:
            try:
                filename = f"{title.lower().replace(' ', '_')}.png"
                fig = self._qiskit_viz.plot_histogram(
                    counts, 
                    title=title,
                    filename=filename,
                    max_bars=top_n  # v2.5.21: Utiliser max_bars au lieu de number_to_keep
                )
                if fig:
                    try:
                        import matplotlib.pyplot as plt
                        plt.close(fig)
                    except:
                        pass
                    path = self.output_dir / filename
                    self._log(f"[#] Saved Qiskit histogram: {path.name}")
                    return path
            except Exception as e:
                self._log(f"Qiskit histogram failed, using fallback: {e}", LogLevel.WARN)
        
        # Fallback: matplotlib manuel
        try:
            import matplotlib.pyplot as plt
            
            sorted_counts = sorted(counts.items(), key=lambda x: -x[1])[:top_n]
            labels, values = zip(*sorted_counts) if sorted_counts else ([], [])
            
            fig, ax = plt.subplots(figsize=(12, 6))
            # v2.5.21: Couleur IBM Blue
            ax.bar(range(len(labels)), values, color='#0f62fe')
            ax.set_xticks(range(len(labels)))
            ax.set_xticklabels(labels, rotation=45, ha='right', fontsize=8)
            ax.set_xlabel('States')
            ax.set_ylabel('Counts')
            ax.set_title(title)
            ax.set_facecolor('white')
            fig.patch.set_facecolor('white')
            
            path = self.output_dir / f"{title.lower().replace(' ', '_')}.png"
            fig.savefig(path, dpi=150, bbox_inches='tight', facecolor='white')
            plt.close(fig)
            
            self._log(f"[#] Saved histogram: {path.name}")
            return path
            
        except ImportError:
            self._log("matplotlib not available", LogLevel.WARN)
            return None
    
    # v2.5.21: Nouvelles mÃ©thodes utilisant Qiskit
    def plot_state_visualization(self, state, viz_type: str = "city",
                                  title: str = None, 
                                  filename: str = None) -> Optional[Path]:
        """
        GÃ©nÃ¨re une visualisation d'Ã©tat quantique (v2.5.21).
        
        Args:
            state: Statevector ou DensityMatrix
            viz_type: Type de visualisation ('city', 'qsphere', 'hinton', 'paulivec', 'bloch')
            title: Titre optionnel
            filename: Nom de fichier optionnel
            
        Returns:
            Path vers le fichier gÃ©nÃ©rÃ©
        """
        if filename is None:
            filename = f"state_{viz_type}.png"
        
        try:
            if viz_type == "city":
                fig = self._qiskit_viz.plot_state_city(state, title=title, filename=filename)
            elif viz_type == "qsphere":
                fig = self._qiskit_viz.plot_state_qsphere(state, filename=filename)
            elif viz_type == "hinton":
                fig = self._qiskit_viz.plot_state_hinton(state, title=title, filename=filename)
            elif viz_type == "paulivec":
                fig = self._qiskit_viz.plot_state_paulivec(state, title=title, filename=filename)
            elif viz_type == "bloch":
                fig = self._qiskit_viz.plot_bloch_multivector(state, title=title or "", filename=filename)
            else:
                self._log(f"Unknown visualization type: {viz_type}", LogLevel.WARN)
                return None
            
            if fig:
                try:
                    import matplotlib.pyplot as plt
                    plt.close(fig)
                except:
                    pass
                path = self.output_dir / filename
                self._log(f"[#] Saved state visualization ({viz_type}): {path.name}")
                return path
            
        except Exception as e:
            self._log(f"State visualization failed: {e}", LogLevel.WARN)
        
        return None
    
    def plot_all_state_visualizations(self, state, prefix: str = "state") -> Dict[str, Path]:
        """
        GÃ©nÃ¨re toutes les visualisations d'Ã©tat disponibles (v2.5.21).
        
        Args:
            state: Statevector ou DensityMatrix
            prefix: PrÃ©fixe pour les noms de fichiers
            
        Returns:
            Dict avec les paths des fichiers gÃ©nÃ©rÃ©s
        """
        generated = self._qiskit_viz.generate_all_state_visualizations(
            state, prefix=prefix, output_dir=self.output_dir
        )
        
        result = {}
        for name, path_str in generated.items():
            result[name] = Path(path_str)
            self._log(f"[#] Generated {name}: {Path(path_str).name}")
        
        return result
    
    def plot_backend_topology(self, backend, filename: str = "topology.png") -> Optional[Path]:
        """
        GÃ©nÃ¨re une visualisation de la topologie du backend (v2.5.21).
        
        Args:
            backend: Backend IBM
            filename: Nom du fichier
            
        Returns:
            Path vers le fichier gÃ©nÃ©rÃ©
        """
        try:
            fig = self._qiskit_viz.plot_gate_map(backend, filename=filename)
            if fig:
                try:
                    import matplotlib.pyplot as plt
                    plt.close(fig)
                except:
                    pass
                path = self.output_dir / filename
                self._log(f"[#] Saved topology: {path.name}")
                return path
        except Exception as e:
            self._log(f"Topology visualization failed: {e}", LogLevel.WARN)
        return None
    
    def plot_error_map(self, backend, filename: str = "error_map.png") -> Optional[Path]:
        """
        GÃ©nÃ¨re une carte d'erreurs du backend (v2.5.21).
        
        Args:
            backend: Backend IBM
            filename: Nom du fichier
            
        Returns:
            Path vers le fichier gÃ©nÃ©rÃ©
        """
        try:
            fig = self._qiskit_viz.plot_error_map(backend, filename=filename)
            if fig:
                try:
                    import matplotlib.pyplot as plt
                    plt.close(fig)
                except:
                    pass
                path = self.output_dir / filename
                self._log(f"[#] Saved error map: {path.name}")
                return path
        except Exception as e:
            self._log(f"Error map visualization failed: {e}", LogLevel.WARN)
        return None
    
    def plot_circuit_layout(self, circuit, backend, 
                            filename: str = "circuit_layout.png") -> Optional[Path]:
        """
        GÃ©nÃ¨re une visualisation du layout de circuit (v2.5.21).
        
        Args:
            circuit: Circuit transpilÃ©
            backend: Backend cible
            filename: Nom du fichier
            
        Returns:
            Path vers le fichier gÃ©nÃ©rÃ©
        """
        try:
            fig = self._qiskit_viz.plot_circuit_layout(circuit, backend, filename=filename)
            if fig:
                try:
                    import matplotlib.pyplot as plt
                    plt.close(fig)
                except:
                    pass
                path = self.output_dir / filename
                self._log(f"[#] Saved circuit layout: {path.name}")
                return path
        except Exception as e:
            self._log(f"Circuit layout visualization failed: {e}", LogLevel.WARN)
        return None
    
    def generate_html_report(self, results: Dict, plots: List[Path],
                             title: str = "QMC Report") -> Path:
        """GÃ©nÃ¨re un rapport HTML"""
        html = f"""<!DOCTYPE html>
<html>
<head>
    <title>{title}</title>
    <style>
        body {{ font-family: 'IBM Plex Sans', Arial, sans-serif; margin: 40px; background: white; }}
        h1 {{ color: #161616; }}
        h2 {{ color: #525252; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #e0e0e0; padding: 12px; text-align: left; }}
        th {{ background-color: #0f62fe; color: white; }}
        .metric {{ font-size: 24px; font-weight: bold; color: #198038; }}
        img {{ max-width: 100%; height: auto; margin: 10px 0; }}
        pre {{ background: #f4f4f4; padding: 16px; overflow-x: auto; }}
    </style>
</head>
<body>
    <h1>{title}</h1>
    <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    
    <h2>Summary</h2>
    <pre>{json.dumps(results.get('summary', results), indent=2)}</pre>
    
    <h2>Plots</h2>
"""
        
        for plot in plots:
            if plot.exists():
                html += f'<img src="{plot.name}" alt="{plot.stem}"><br>\n'
        
        html += """
</body>
</html>"""
        
        path = self.output_dir / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        with open(path, 'w') as f:
            f.write(html)
        
        self._log(f"Generated HTML report: {path.name}")
        return path


# =============================================================================
# REPORT EXPORTER
# =============================================================================

class ReportExporter:
    """
    Export des rÃ©sultats dans diffÃ©rents formats.
    
    [v2.5.12] ConsolidÃ©: JSON, CSV, Markdown, HTML, LaTeX
    
    Note: EnhancedReportExporter est dÃ©prÃ©ciÃ©, utiliser cette classe.
    """
    
    def __init__(self, output_dir: Path = None, logger: Logger = None):
        self.output_dir = output_dir or Path('exports')
        self.output_dir.mkdir(exist_ok=True)
        self.logger = logger
    
    def _log(self, msg: str):
        if self.logger:
            self.logger.info(f"[EXPORT] {msg}")
    
    def export_json(self, data: Dict, filename: str) -> Path:
        path = self.output_dir / f"{filename}.json"
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, default=str)
        self._log(f"JSON: {path}")
        return path
    
    def export_csv(self, data: List[Dict], filename: str) -> Path:
        path = self.output_dir / f"{filename}.csv"
        if data:
            with open(path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=data[0].keys())
                writer.writeheader()
                writer.writerows(data)
            self._log(f"CSV: {path}")
        return path
    
    def export_markdown(self, data: Dict, filename: str) -> Path:
        path = self.output_dir / f"{filename}.md"
        
        md = f"# QMC Report\n\n"
        md += f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        
        def dict_to_md(d, level=2):
            result = ""
            for k, v in d.items():
                if isinstance(v, dict):
                    result += f"{'#' * level} {k}\n\n"
                    result += dict_to_md(v, level + 1)
                else:
                    result += f"- **{k}**: {v}\n"
            return result + "\n"
        
        md += dict_to_md(data)
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write(md)
        self._log(f"Markdown: {path}")
        return path
    
    # [v2.5.12] Nouvelles mÃ©thodes consolidÃ©es
    def export_html(self, data: Dict, filename: str) -> Path:
        """Export au format HTML."""
        path = self.output_dir / f"{filename}.html"
        
        html = """<!DOCTYPE html>
<html>
<head>
    <title>QMC Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        h1 { color: #2c3e50; }
        table { border-collapse: collapse; width: 100%; margin: 20px 0; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #3498db; color: white; }
        tr:nth-child(even) { background-color: #f2f2f2; }
        .timestamp { color: #7f8c8d; font-size: 0.9em; }
    </style>
</head>
<body>
"""
        html += f"<h1>QMC Report: {filename}</h1>\n"
        html += f"<p class='timestamp'>Generated: {datetime.now()}</p>\n"
        
        # Table des rÃ©sultats
        html += "<table>\n<tr><th>Key</th><th>Value</th></tr>\n"
        
        def flatten_dict(d, prefix=''):
            items = []
            for k, v in d.items():
                key = f"{prefix}.{k}" if prefix else k
                if isinstance(v, dict):
                    items.extend(flatten_dict(v, key))
                else:
                    items.append((key, v))
            return items
        
        for key, value in flatten_dict(data):
            html += f"<tr><td>{key}</td><td>{value}</td></tr>\n"
        
        html += "</table>\n</body>\n</html>"
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write(html)
        self._log(f"HTML: {path}")
        return path
    
    def export_latex(self, data: Dict, filename: str) -> Path:
        """Export au format LaTeX."""
        path = self.output_dir / f"{filename}.tex"
        
        tex = r"""\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
\usepackage{longtable}
\begin{document}
"""
        tex += f"\\title{{QMC Report: {filename}}}\n"
        tex += "\\author{QMC Framework}\n"
        tex += f"\\date{{{datetime.now().strftime('%Y-%m-%d')}}}\n"
        tex += "\\maketitle\n\n"
        tex += "\\section{Results}\n\n"
        tex += "\\begin{longtable}{ll}\n\\toprule\n"
        tex += "Key & Value \\\\\n\\midrule\n"
        
        def escape_latex(s):
            return str(s).replace('_', '\\_').replace('%', '\\%').replace('&', '\\&')
        
        for key, value in data.items():
            if not isinstance(value, (dict, list)):
                tex += f"{escape_latex(key)} & {escape_latex(value)} \\\\\n"
        
        tex += "\\bottomrule\n\\end{longtable}\n\\end{document}"
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write(tex)
        self._log(f"LaTeX: {path}")
        return path
    
    def export_all(self, data: Dict, filename: str) -> Dict[str, Path]:
        """
        [v2.5.12] Export dans tous les formats supportÃ©s.
        
        Returns:
            Dict des chemins par format
        """
        return {
            'json': self.export_json(data, filename),
            'markdown': self.export_markdown(data, filename),
            'html': self.export_html(data, filename),
            'latex': self.export_latex(data, filename),
        }


# =============================================================================
# QMC FRAMEWORK v2.0 - CLASSE PRINCIPALE
# =============================================================================

class QMCFramework:
    """
    Framework principal QMC v2.0 avec systÃ¨me de plugins.
    
    FonctionnalitÃ©s:
    - Plugin system pour modules QMC (Core, Shield, Biometric, etc.)
    - Circuit builders extensibles
    - Experiment engine pour tests complexes
    - Protocol tester pour validation cryptographique
    - Benchmark suite standardisÃ©e
    - Data pipeline pour transformations
    
    Usage:
        fw = QMCFramework(project="QMC_CORE", backend_name="ibm_fez")
        fw.initialize(RunMode.QPU, config)
        fw.connect()
        fw.analyze_calibration()
        
        # Utiliser un module
        module = fw.load_module('qmc_core')
        results = module.run(plaintext=b"secret", n_qubits=50)
        
        # Ou utiliser l'experiment engine
        exp_id = fw.experiment.create_experiment("test", config)
        fw.experiment.run_experiment(exp_id)
    """
    
    def __init__(self,
                 project: str = "QMC",
                 backend_name: str = "ibm_fez",
                 shots: int = 4096,
                 thresholds: QualityThresholds = None,
                 mitigation_config: MitigationConfig = None,
                 base_dir: str = "qmc_runs",
                 plugin_dir: str = None,
                 private: bool = False,
                 auto_delete_job: bool = False,
                 redact_logs: bool = False,
                 production_mode: bool = False,
                 auto_confirm: bool = False):
        """
        Initialize QMC Framework.
        
        Args:
            project: Nom du projet
            backend_name: Backend IBM cible
            shots: [v2.5.22] Nombre de shots par dÃ©faut (dÃ©faut: 4096)
            thresholds: Seuils de qualitÃ©
            mitigation_config: Configuration de mitigation d'erreur
            base_dir: RÃ©pertoire de base pour les runs
            plugin_dir: RÃ©pertoire des plugins
            private: [v2.5.14] Marquer les jobs comme privÃ©s (tags IBM)
            auto_delete_job: [v2.5.14] Supprimer automatiquement le job aprÃ¨s 
                            rÃ©cupÃ©ration des rÃ©sultats (sÃ©curitÃ© cryptographique)
            redact_logs: [v2.5.14] Masquer les donnÃ©es sensibles dans les logs
            production_mode: [v2.5.14] Active le triptyque sÃ©curitÃ© complet
                            (private + auto_delete_job + redact_logs)
            auto_confirm: [v2.5.14] Si False (dÃ©faut), demande confirmation avant
                         chaque envoi QPU. Si True, envoie sans confirmation.
                         âš ï¸ SÃ‰CURITÃ‰: Laisser Ã  False pour Ã©viter les envois accidentels!
        """
        
        self.project = project
        self.backend_name = backend_name
        self.default_shots = shots  # [v2.5.22] Shots par dÃ©faut
        self.thresholds = thresholds or QualityThresholds()
        self.mitigation_config = mitigation_config or MitigationConfig()
        self.base_dir = base_dir
        
        # [v2.5.14] Confirmation obligatoire avant envoi QPU
        self.auto_confirm = auto_confirm
        
        # [v2.5.14] Options de sÃ©curitÃ© pour calculs cryptographiques
        # production_mode active automatiquement les 3 options
        if production_mode:
            self.private = True
            self.auto_delete_job = True
            self.redact_logs = True
        else:
            self.private = private
            self.auto_delete_job = auto_delete_job
            self.redact_logs = redact_logs
        
        self.production_mode = production_mode
        
        # Composants de base
        self.credentials = CredentialsManager()
        self.dir_manager = DirectoryManager(base_dir)
        self.logger: Optional[Logger] = None
        self.report: Optional[ReportManager] = None
        
        # Ã‰tat
        self._mode: Optional[RunMode] = None
        self._config: Dict = {}
        self._connected = False
        self.service = None
        self.backend = None
        self.topology: Optional[DynamicTopology] = None
        
        # Composants v1.1
        self.error_mitigation: Optional[ErrorMitigationManager] = None
        self.retry_manager: Optional[SmartRetryManager] = None
        self.job_monitor: Optional[JobMonitor] = None
        self.checkpoint_manager: Optional[CheckpointManager] = None
        self.visualizer: Optional[ResultVisualizer] = None
        
        # Composants v2.0
        self.experiment: Optional[ExperimentEngine] = None
        self.protocol: Optional[ProtocolTester] = None
        self.benchmark: Optional[BenchmarkSuite] = None
        self.noise: Optional[NoiseAnalyzer] = None
        self.pipeline: Optional[DataPipeline] = None
        
        # [v2.5.15] Estimateur de coÃ»t
        self.cost_estimator = None  # InitialisÃ© dans initialize()
        
        # Plugin registry
        self._registry = PluginRegistry.instance()
        self._loaded_modules: Dict[str, QMCModule] = {}
        
        # Error Handler v2.5.8
        self.error_handler: Optional[QMCErrorHandler] = None
        
        # Retry config par dÃ©faut
        self.retry_config = RetryConfig(
            max_attempts=3,
            initial_delay_s=2.0,
            max_delay_s=60.0,
            exponential_base=2.0,
            jitter=True
        )
        
        # Discover plugins
        if plugin_dir:
            self._registry.discover_plugins(plugin_dir)
        
        # [v2.5.12] Lazy registration si QMC_LAZY_REGISTER=1
        if _QMC_LAZY_REGISTER:
            self._perform_lazy_registration()
    
    def _perform_lazy_registration(self):
        """
        [v2.5.12] Enregistrement diffÃ©rÃ© des plugins.
        
        AppelÃ© uniquement si QMC_LAZY_REGISTER=1 est dÃ©fini.
        Cela Ã©vite les side effects Ã  l'import du module.
        """
        try:
            register_new_circuit_builders()
        except Exception:
            pass
        try:
            register_new_analyzers()
        except Exception:
            pass
        try:
            register_new_modules()
            register_new_builders_v24()
            register_new_analyzers_v24()
        except Exception:
            pass
    
    def initialize(self, mode: RunMode, config: Dict = None):
        """
        Initialise le framework.
        
        Args:
            mode: Mode d'exÃ©cution (VALIDATE, QPU, BENCHMARK, etc.)
            config: Configuration additionnelle
        """
        self._mode = mode
        self._config = config or {}
        
        # Extraire les paramÃ¨tres communs (utiliser self._config aprÃ¨s le fallback!)
        scales = self._config.get('scales', [50, 75, 100])
        shots = self._config.get('shots', 4096)
        
        # CrÃ©er le rÃ©pertoire d'exÃ©cution
        self.dir_manager.create_run_directory(
            mode=mode.value,
            project=self.project,
            scales=scales,
            shots=shots
        )
        
        # [v2.5.14] DÃ©terminer le niveau de log selon redact_logs
        # Si redact_logs est activÃ©, on passe en WARNING pour masquer les donnÃ©es sensibles
        if self.redact_logs:
            log_level = LogLevel.WARN
        elif self._config.get('debug'):
            log_level = LogLevel.DEBUG
        else:
            log_level = LogLevel.INFO
        
        # Initialiser le logger
        self.logger = Logger(
            log_file=self.dir_manager.get_file('framework.log'),
            min_level=log_level
        )
        
        # [v2.5.14] Afficher un avertissement si redact_logs est activÃ©
        if self.redact_logs:
            self.logger.warn("ğŸ”’ REDACT_LOGS activÃ© - Logs rÃ©duits au minimum (niveau WARNING)")
        
        # Configurer le registry
        self._registry.set_logger(self.logger)
        
        # Initialiser le report manager
        self.report = ReportManager(
            report_path=self.dir_manager.get_file('report.json')
        )
        
        # Initialiser les composants v1.1
        self.error_mitigation = ErrorMitigationManager(
            config=self.mitigation_config, 
            runtime_config=None,  # v2.5.21: Peut Ãªtre configurÃ© via set_runtime_level()
            logger=self.logger
        )
        
        self.retry_manager = SmartRetryManager(
            max_retries=self._config.get('max_retries', 3),
            logger=self.logger
        )
        
        self.job_monitor = JobMonitor(logger=self.logger)
        
        self.checkpoint_manager = CheckpointManager(
            checkpoint_dir=self.dir_manager.get_file('checkpoints'),
            logger=self.logger
        )
        
        self.visualizer = ResultVisualizer(
            output_dir=self.dir_manager.get_file('plots'),
            logger=self.logger
        )
        
        # Initialiser les composants v2.0
        self.experiment = ExperimentEngine(self)
        self.protocol = ProtocolTester(self)
        self.benchmark = BenchmarkSuite(self)
        self.noise = NoiseAnalyzer(self)
        self.pipeline = DataPipeline(self.logger)
        
        # Initialiser le gestionnaire d'erreurs v2.5.8
        self.error_handler = QMCErrorHandler(
            logger=self.logger,
            max_history=100
        )
        
        # [v2.5.15] Initialiser l'estimateur de coÃ»t
        self.cost_estimator = CircuitCostEstimator(framework=self, logger=self.logger)
        
        # BanniÃ¨re
        print(FRAMEWORK_BANNER)
        
        self.logger.section(f"QMC FRAMEWORK v{__version__} - {self.project}")
        self.logger.info(f"Mode: {mode.value}")
        self.logger.info(f"Backend cible: {self.backend_name}")
        self.logger.info(f"RÃ©pertoire: {self.dir_manager.run_dir}")
        
        # Log plugins disponibles
        self.logger.info(f"Circuit Builders: {self._registry.list_circuit_builders()}")
        self.logger.info(f"Analyzers: {self._registry.list_analyzers()}")
        self.logger.info(f"Modules: {self._registry.list_modules()}")
        
        # Sauvegarder config
        self.report.set('project', self.project)
        self.report.set('mode', mode.value)
        self.report.set('user_config', self._config)  # RenommÃ© pour Ã©viter collision avec section 'config'
        self.report.set('backend_target', self.backend_name)
        self.report.set('mitigation', self.mitigation_config.to_dict(), section='config')
        self.report.set('framework_version', __version__)
    
    def connect(self) -> bool:
        """
        Connexion au backend IBM Quantum.
        
        Returns:
            True si connexion rÃ©ussie
        """
        self.logger.section("CONNEXION IBM QUANTUM")
        
        creds = self.credentials.load()
        if not creds:
            error = QMCCredentialsError(
                "Credentials IBM non trouvÃ©s dans .env",
                suggestion="CrÃ©ez un fichier .env avec IBM_API_KEY_ACTIVE_*"
            )
            if self.error_handler:
                self.error_handler.handle(error, context="connect", raise_exception=False)
            self.logger.error(error.format_message())
            return False
        
        # Affichage clair du compte utilisÃ©
        masked = self.credentials.get_masked_info()
        account_name = masked.get('account', 'DEFAULT')
        key_prefix = masked.get('api_key_prefix', '***')
        self.logger.info(f"ğŸ”‘ Compte: {account_name} (clÃ©: {key_prefix})")
        
        try:
            from qiskit_ibm_runtime import QiskitRuntimeService
            
            # Retry automatique pour la connexion
            max_attempts = self.retry_config.max_attempts
            last_error = None
            
            for attempt in range(1, max_attempts + 1):
                try:
                    self.service = QiskitRuntimeService(**creds)
                    self.backend = self.service.backend(self.backend_name)
                    break
                except Exception as e:
                    last_error = e
                    if attempt < max_attempts:
                        delay = self.retry_config.initial_delay_s * (2 ** (attempt - 1))
                        self.logger.warn(f"[RETRY] Tentative {attempt}/{max_attempts} Ã©chouÃ©e. "
                                        f"Nouvelle tentative dans {delay:.1f}s...")
                        time.sleep(delay)
                    else:
                        raise QMCConnectionError(
                            f"Connexion impossible aprÃ¨s {max_attempts} tentatives",
                            backend=self.backend_name,
                            details={'last_error': str(last_error)}
                        )
            
            self.logger.info(f"[OK] ConnectÃ©: {self.backend.name} ({self.backend.num_qubits}Q)")
            
            backend_info = {
                'name': self.backend.name,
                'num_qubits': self.backend.num_qubits,
                'version': getattr(self.backend, 'version', 'N/A'),
            }
            
            try:
                status = self.backend.status()
                backend_info['operational'] = status.operational
                backend_info['pending_jobs'] = status.pending_jobs
                self.logger.info(f"Queue: {status.pending_jobs} jobs en attente")
                
                if not status.operational:
                    self.logger.warn(f"âš ï¸ Backend {self.backend_name} n'est pas opÃ©rationnel!")
            except:
                pass
            
            self.report.set('backend', backend_info, section='connection')
            self._connected = True
            
            return True
            
        except QMCConnectionError as e:
            if self.error_handler:
                self.error_handler.handle(e, context="connect", raise_exception=False)
            self.report.set('connection_error', e.to_dict(), section='connection')
            return False
            
        except Exception as e:
            error = QMCConnectionError(
                f"Erreur inattendue lors de la connexion: {str(e)}",
                backend=self.backend_name
            )
            if self.error_handler:
                self.error_handler.handle(error, context="connect", raise_exception=False)
            self.report.set('connection_error', str(e), section='connection')
            return False
    
    def analyze_calibration(self, force: bool = False) -> DynamicTopology:
        """
        Analyse la calibration du backend.
        
        Returns:
            DynamicTopology avec les donnÃ©es
            
        Raises:
            QMCCalibrationError: Si non connectÃ© ou erreur d'analyse
        """
        self.logger.section("ANALYSE CALIBRATION")
        
        if not self._connected:
            raise QMCCalibrationError(
                "Non connectÃ© au backend IBM",
                backend=self.backend_name,
                suggestion="Appelez connect() avant analyze_calibration()"
            )
        
        try:
            self.topology = DynamicTopology.from_backend(
                self.backend,
                self.thresholds,
                self.logger
            )
            
            self.topology.print_report()
            
            # Sauvegarder
            summary = self.topology.get_summary()
            self.dir_manager.save_json('calibration', summary)
            self.report.set('topology', summary, section='calibration')
            
            # Analyser le bruit
            noise_analysis = self.noise.analyze_calibration()
            self.report.set('noise', noise_analysis, section='calibration')
            
            return self.topology
            
        except QMCCalibrationError:
            raise
        except Exception as e:
            error = QMCCalibrationError(
                f"Erreur lors de l'analyse de calibration: {str(e)}",
                backend=self.backend_name
            )
            if self.error_handler:
                self.error_handler.handle(error, context="analyze_calibration", raise_exception=True)
            raise error
    
    def get_optimal_path(self, n_qubits: int, **kwargs) -> List[int]:
        """Obtient le chemin optimal pour n qubits"""
        if not self.topology:
            raise QMCCalibrationError(
                "Calibration non analysÃ©e",
                suggestion="Appelez analyze_calibration() d'abord"
            )
        return self.topology.get_best_path(n_qubits, **kwargs)
    
    def get_best_qubits(self, n_qubits: int, exclude: Set[int] = None) -> List[int]:
        """
        Obtient les N meilleurs qubits (pas forcÃ©ment contigus).
        
        Args:
            n_qubits: Nombre de qubits souhaitÃ©s
            exclude: Set de qubits Ã  exclure
        
        Returns:
            Liste des meilleurs qubits
        """
        if not self.topology:
            raise QMCCalibrationError(
                "Calibration non analysÃ©e",
                suggestion="Appelez analyze_calibration() d'abord"
            )
        return self.topology.get_best_qubits(n_qubits, exclude)
    
    def get_qubit_groups(self, n_groups: int, qubits_per_group: int) -> List[List[int]]:
        """
        Obtient des groupes de qubits pour les clusters QMC.
        
        Args:
            n_groups: Nombre de groupes (clusters)
            qubits_per_group: Qubits par groupe
        
        Returns:
            Liste de groupes de qubits
        """
        if not self.topology:
            raise RuntimeError("Calibration non analysÃ©e! Appelez analyze_calibration() d'abord.")
        return self.topology.get_qubit_groups(n_groups, qubits_per_group)
    
    def optimize_clusters(self, n_shots: int, target_security_bits: int = 128,
                         show_report: bool = True) -> Dict:
        """
        Optimise automatiquement la configuration des clusters QMC.
        
        Cette mÃ©thode analyse la calibration du QPU et calcule la configuration
        optimale pour maximiser la sÃ©curitÃ© tout en garantissant la fiabilitÃ©.
        
        Args:
            n_shots: Nombre de shots par exÃ©cution
            target_security_bits: SÃ©curitÃ© minimale souhaitÃ©e (dÃ©faut: 128)
            show_report: Afficher le rapport d'optimisation
        
        Returns:
            Dict avec:
                - n_qubits: Nombre total de qubits
                - n_clusters: Nombre de clusters
                - qubits_per_cluster: Qubits par cluster
                - collision_ratio: Ratio de collision
                - security_bits: Bits de sÃ©curitÃ©
                - security_level: Niveau de sÃ©curitÃ©
                - groups: Groupes de qubits assignÃ©s
        
        Example:
            fw = QMCFramework()
            fw.connect()
            config = fw.optimize_clusters(n_shots=10000, target_security_bits=128)
            print(f"Use {config['n_qubits']} qubits in {config['n_clusters']} clusters")
        """
        if not self._connected:
            raise RuntimeError("Non connectÃ©! Appelez connect() d'abord.")
        
        # Analyser la calibration si pas dÃ©jÃ  fait
        if not self.topology:
            self.analyze_calibration()
        
        # Obtenir le rÃ©sumÃ© de la topologie
        topo_summary = self.topology.get_summary()
        n_good_qubits = topo_summary.get('n_qubits_usable', 
                                         topo_summary.get('n_good_qubits', 100))
        
        # CrÃ©er l'optimiseur
        optimizer = DynamicClusterOptimizer(
            framework=self,
            logger=lambda msg: self.logger.log(msg, LogLevel.INFO)
        )
        
        # Trouver la configuration optimale
        config = optimizer.find_optimal_clusters(
            n_good_qubits=n_good_qubits,
            n_shots=n_shots,
            target_security_bits=target_security_bits
        )
        
        # Trouver les groupes de qubits
        groups = optimizer.find_cluster_groups(
            n_clusters=config['n_clusters'],
            qubits_per_cluster=config['qubits_per_cluster'],
            topology=self.topology
        )
        
        config['groups'] = groups
        
        # Afficher le rapport si demandÃ©
        if show_report:
            optimizer.print_optimization_report(config, groups)
        
        return config
    
    def _print_transpilation_report(self, before: dict, after: dict, pipeline: list):
        """
        Affiche un rapport visuel avant/aprÃ¨s transpilation.
        Version 2.8: Design Ã©purÃ© sans bordures droites.
        
        Args:
            before: Stats avant {qubits, depth, gates_1q, gates_2q}
            after: Stats aprÃ¨s {qubits, depth, gates_1q, gates_2q, physical_qubits, swap_count, transpile_time}
            pipeline: Liste des Ã©tapes appliquÃ©es
        """
        # Couleurs ANSI
        C = "\033[36m"   # Cyan
        G = "\033[32m"   # Green  
        Y = "\033[33m"   # Yellow
        R = "\033[31m"   # Red
        B = "\033[1m"    # Bold
        DIM = "\033[2m"  # Dim
        X = "\033[0m"    # Reset
        
        # Calculs des deltas
        depth_delta = after['depth'] - before['depth']
        depth_pct = (depth_delta / before['depth'] * 100) if before['depth'] > 0 else 0
        gates_2q_delta = after['gates_2q'] - before['gates_2q']
        gates_2q_pct = (gates_2q_delta / before['gates_2q'] * 100) if before['gates_2q'] > 0 else 0
        gates_1q_delta = after['gates_1q'] - before['gates_1q']
        
        # Couleurs selon amÃ©lioration/dÃ©gradation
        depth_color = G if depth_delta <= 0 else (Y if depth_pct < 20 else R)
        gates_color = G if gates_2q_delta <= 0 else (Y if gates_2q_pct < 20 else R)
        
        # Score de qualitÃ© (0-100)
        quality_score = 100
        if gates_2q_pct > 0:
            quality_score -= min(50, gates_2q_pct)
        if depth_pct > 20:
            quality_score -= min(30, (depth_pct - 20) / 2)
        quality_score = max(0, int(quality_score))
        
        # Grade
        if quality_score >= 90:
            grade, grade_color = "A+", G
        elif quality_score >= 80:
            grade, grade_color = "A", G
        elif quality_score >= 70:
            grade, grade_color = "B", Y
        elif quality_score >= 50:
            grade, grade_color = "C", Y
        else:
            grade, grade_color = "D", R
        
        # SWAP count estimÃ©
        swap_estimate = max(0, gates_2q_delta // 3) if gates_2q_delta > 0 else 0
        
        # Temps de transpilation
        transpile_time = after.get('transpile_time', 0)
        
        # Rapport
        self.logger.info("")
        self.logger.info(f"{C}â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        self.logger.info(f"{C}â”‚{X} {B}ğŸ”§ TRANSPILATION REPORT{X}")
        self.logger.info(f"{C}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        self.logger.info(f"{C}â”‚{X}")
        self.logger.info(f"{C}â”‚{X}   {B}METRIC{X}            {DIM}BEFORE{X}        {DIM}AFTER{X}          {DIM}CHANGE{X}")
        self.logger.info(f"{C}â”‚{X}   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        
        # Qubits
        self.logger.info(f"{C}â”‚{X}   Qubits            {before['qubits']:<13} {after['qubits']:<14} {DIM}(physical){X}")
        
        # Depth
        depth_change = f"{depth_color}{depth_delta:+d}{X} ({depth_color}{depth_pct:+.1f}%{X})"
        self.logger.info(f"{C}â”‚{X}   Depth             {before['depth']:<13} {after['depth']:<14} {depth_change}")
        
        # 1Q Gates  
        g1_change = f"{gates_1q_delta:+d}" if gates_1q_delta != 0 else "="
        self.logger.info(f"{C}â”‚{X}   1Q Gates          {before['gates_1q']:<13} {after['gates_1q']:<14} {DIM}{g1_change}{X}")
        
        # 2Q Gates (le plus important!)
        g2q_change = f"{gates_color}{gates_2q_delta:+d}{X} ({gates_color}{gates_2q_pct:+.1f}%{X})"
        self.logger.info(f"{C}â”‚{X}   {B}2Q Gates{X}          {before['gates_2q']:<13} {after['gates_2q']:<14} {g2q_change}")
        
        # SWAP estimate (si augmentation)
        if swap_estimate > 0:
            self.logger.info(f"{C}â”‚{X}   {DIM}SWAP inserted{X}     {DIM}-{X}             ~{swap_estimate:<13} {R}routing overhead{X}")
        
        self.logger.info(f"{C}â”‚{X}")
        self.logger.info(f"{C}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        
        # MÃ©triques avancÃ©es
        self.logger.info(f"{C}â”‚{X} {B}ğŸ“Š QUALITY METRICS{X}")
        self.logger.info(f"{C}â”‚{X}")
        
        # Quality Score avec barre
        bar_len = quality_score // 5
        bar = f"{grade_color}{'â–ˆ' * bar_len}{DIM}{'â–‘' * (20 - bar_len)}{X}"
        self.logger.info(f"{C}â”‚{X}   Score    [{bar}]  {grade_color}{quality_score:>3}/100{X} ({grade_color}{grade}{X})")
        
        # 2Q Efficiency
        if before['gates_2q'] > 0:
            efficiency = (before['gates_2q'] / max(1, after['gates_2q'])) * 100
            eff_color = G if efficiency >= 95 else (Y if efficiency >= 80 else R)
            self.logger.info(f"{C}â”‚{X}   2Q Eff.  {eff_color}{efficiency:>6.1f}%{X} {DIM}(original / transpiled){X}")
        
        # Depth ratio
        if before['depth'] > 0:
            depth_ratio = after['depth'] / before['depth']
            dr_color = G if depth_ratio <= 1.2 else (Y if depth_ratio <= 2 else R)
            self.logger.info(f"{C}â”‚{X}   Depth    {dr_color}{depth_ratio:>6.2f}x{X} {DIM}expansion factor{X}")
        
        # Gate density
        total_gates = after['gates_1q'] + after['gates_2q']
        density = total_gates / max(1, after['qubits'])
        self.logger.info(f"{C}â”‚{X}   Density  {density:>6.1f}  {DIM}gates/qubit{X}")
        
        # Transpile time
        if transpile_time > 0:
            self.logger.info(f"{C}â”‚{X}   Time     {transpile_time:>6.2f}s")
        
        self.logger.info(f"{C}â”‚{X}")
        self.logger.info(f"{C}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        
        # Pipeline
        self.logger.info(f"{C}â”‚{X} {B}âš™ï¸  PIPELINE{X}")
        
        for step in pipeline:
            status = f"{G}âœ“{X}" if step['applied'] else f"{DIM}â—‹{X}"
            detail = f" {DIM}({step['detail']}){X}" if step.get('detail') else ""
            self.logger.info(f"{C}â”‚{X}   {status} {step['name']}{detail}")
        
        # Physical qubits (preview)
        if after.get('physical_qubits'):
            phys = after['physical_qubits']
            self.logger.info(f"{C}â”‚{X}")
            self.logger.info(f"{C}â”‚{X}   {DIM}Layout: Q{min(phys)}â†’Q{max(phys)} ({len(phys)} qubits){X}")
        
        # Verdict final
        self.logger.info(f"{C}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        if gates_2q_pct <= 0:
            verdict = f"{G}âœ“ EXCELLENT{X} - No routing overhead"
        elif gates_2q_pct < 10:
            verdict = f"{G}âœ“ GOOD{X} - Minimal routing ({gates_2q_pct:+.1f}%)"
        elif gates_2q_pct < 50:
            verdict = f"{Y}âš  OK{X} - Moderate routing ({gates_2q_pct:+.1f}%)"
        else:
            verdict = f"{R}âœ— POOR{X} - High overhead ({gates_2q_pct:+.1f}%)"
        
        self.logger.info(f"{C}â”‚{X} {verdict}")
        self.logger.info(f"{C}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        self.logger.info("")
    
    def _calculate_transpilation_score(self, before: Dict, after: Dict) -> int:
        """
        [v2.5.14] Calcule un score de qualitÃ© de transpilation (0-100).
        
        CritÃ¨res:
        - Overhead 2Q gates: 0% = 100pts, >100% = 0pts (50% du score)
        - Depth expansion: 1x = 100pts, >10x = 0pts (30% du score)
        - Efficiency 2Q: 100% = 100pts (20% du score)
        
        Returns:
            Score 0-100, avec:
            - 70-100: GO (vert)
            - 40-69: WARN (jaune)
            - 0-39: NO-GO (rouge)
        """
        score = 0
        
        # Overhead 2Q gates (50% du score)
        gates_2q_before = before.get('gates_2q', 0)
        gates_2q_after = after.get('gates_2q', 0)
        if gates_2q_before > 0:
            overhead = (gates_2q_after - gates_2q_before) / gates_2q_before * 100
            # 0% overhead = 50pts, 100% overhead = 0pts
            overhead_score = max(0, 50 - overhead * 0.5)
            score += overhead_score
        else:
            score += 50  # Pas de 2Q gates avant = parfait
        
        # Depth expansion (30% du score)
        depth_before = before.get('depth', 1)
        depth_after = after.get('depth', 1)
        if depth_before > 0:
            expansion = depth_after / depth_before
            # 1x = 30pts, 10x = 0pts
            depth_score = max(0, 30 - (expansion - 1) * 3.33)
            score += depth_score
        else:
            score += 30
        
        # Efficiency 2Q (20% du score)
        if gates_2q_after > 0 and gates_2q_before > 0:
            efficiency = gates_2q_before / gates_2q_after * 100
            # 100% = 20pts, 50% = 10pts, 0% = 0pts
            eff_score = efficiency * 0.2
            score += min(20, eff_score)
        else:
            score += 20
        
        return int(min(100, max(0, score)))

    def transpile_circuits(self, circuits: List, 
                          optimization_level: int = 3,
                          use_optimal_layout: bool = False,  # DÃ‰SACTIVÃ‰ - notre algo dÃ©grade +37%
                          layout_strategy: str = 'auto',     # [v2.5.14] AUTO par dÃ©faut!
                          use_vf2_post_layout: bool = True,  # ACTIVÃ‰ - amÃ©liore de -1.9%
                          vf2_max_trials: int = 100000) -> List:  # 100k trials par dÃ©faut
        """
        Transpile les circuits avec Qiskit SabreLayout + VF2PostLayout.
        
        [v2.5.5] RÃ©sultats de tests (80q, depth 40):
        ============================================
        - Qiskit O3 + VF2Post:  6208 gates 2Q  ğŸ† MEILLEUR (-1.9%)
        - Qiskit O3 standard:   6327 gates 2Q  (baseline)
        - Notre prÃ©-layout:     8707 gates 2Q  âŒ +37% CATASTROPHE
        
        [v2.5.14] Mode AUTO:
        ===================
        - Compare transpilation AVEC et SANS prÃ©-layout
        - Garde automatiquement la meilleure (moins de 2Q gates)
        - Ã‰vite les catastrophes de routing (+120% overhead)
        
        Pipeline par dÃ©faut:
        --------------------
        1. Qiskit O3 avec SabreLayout (excellent pour minimiser SWAPs)
        2. VF2PostLayout (re-mappe sur qubits Ã  moindre erreur, -1.9% gates)
        
        Args:
            circuits: Liste de circuits Ã  transpiler
            optimization_level: Niveau d'optimisation Qiskit (0-3, dÃ©faut: 3)
            use_optimal_layout: Notre prÃ©-layout custom (dÃ©faut: False)
                               âš ï¸ DÃ‰CONSEILLÃ‰ - dÃ©grade de +37%!
            layout_strategy: 'auto' (dÃ©faut - compare et garde le meilleur)
                            'none' (Sabre seul), 'topology_aware', 'best_qubits'
            use_vf2_post_layout: VF2PostLayout aprÃ¨s routing (dÃ©faut: True)
            vf2_max_trials: Trials VF2 (dÃ©faut: 100000)
        
        Returns:
            Liste de circuits transpilÃ©s
            
        Example:
            # MÃ©thode recommandÃ©e (AUTO - compare et garde le meilleur)
            optimized = fw.transpile_circuits(circuits)
            
            # Forcer Sabre seul
            optimized = fw.transpile_circuits(circuits, layout_strategy='none')
        """
        if not self._connected:
            raise RuntimeError("Non connectÃ©!")
        
        from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager
        from qiskit.transpiler import Layout, PassManager
        from qiskit import QuantumCircuit
        
        # [v2.5.14] Auto-wrapping: accepte circuit unique OU liste
        if isinstance(circuits, QuantumCircuit):
            circuits = [circuits]
        
        # [v2.5.14] Mode AUTO: Compare avec/sans prÃ©-layout et garde le meilleur
        if layout_strategy == 'auto' and use_optimal_layout:
            return self._transpile_smart_comparison(circuits, optimization_level, 
                                                    use_vf2_post_layout, vf2_max_trials)
        
        # Import VF2PostLayout
        VF2PostLayout = None
        if use_vf2_post_layout:
            try:
                from qiskit.transpiler.passes import VF2PostLayout as _VF2
                VF2PostLayout = _VF2
            except ImportError:
                self.logger.warn("[OPTIMIZER] VF2PostLayout non disponible")
        
        self.logger.subsection(f"Transpilation ({len(circuits)} circuits)")
        
        # RÃ©trocompatibilitÃ©: mapper 'contiguous' vers 'topology_aware'
        if layout_strategy == 'contiguous':
            layout_strategy = 'topology_aware'
        
        # [v2.5.14] Mode AUTO sans use_optimal_layout = juste Sabre (meilleur par dÃ©faut)
        if layout_strategy == 'auto':
            layout_strategy = 'none'
        
        # Charger la calibration si nÃ©cessaire
        if use_optimal_layout and layout_strategy != 'none':
            if not hasattr(self, 'circuit_optimizer') or self.circuit_optimizer is None:
                try:
                    self.circuit_optimizer = CircuitOptimizer.from_backend(self.backend, self.logger)
                    self.logger.info(f"[OPTIMIZER] Calibration chargÃ©e: {len(self.circuit_optimizer.qubits)} qubits")
                except Exception as e:
                    self.logger.warn(f"[OPTIMIZER] Calibration non disponible: {e}")
                    use_optimal_layout = False
        
        # Qubits faulty Ã  Ã©viter
        faulty_qubits = set()
        if hasattr(self, 'circuit_optimizer') and self.circuit_optimizer:
            faulty_qubits = self.circuit_optimizer.get_faulty_qubits()
        
        # VF2 trials depuis config ou argument
        vf2_trials = getattr(self, '_vf2_max_trials', vf2_max_trials)
        
        transpiled = []
        circuits_info = []
        
        for i, qc in enumerate(circuits):
            n_qubits = qc.num_qubits
            initial_layout = None
            layout_qubits = None
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Ã‰TAPE 1: PRÃ‰-LAYOUT INTELLIGENT (rÃ©duit les SWAPs)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if use_optimal_layout and layout_strategy != 'none' and self.circuit_optimizer:
                try:
                    if layout_strategy == 'topology_aware':
                        # Analyse la structure du circuit
                        circuit_connections = self._extract_circuit_connections(qc)
                        
                        # Trouve un layout qui minimise les SWAPs
                        layout_map = self._find_topology_aware_layout(
                            n_qubits,
                            circuit_connections,
                            faulty_qubits
                        )
                    else:  # 'best_qubits'
                        # Utilise simplement les meilleurs qubits
                        layout_map = self.circuit_optimizer.find_optimal_layout(
                            n_qubits, strategy='contiguous'
                        )
                    
                    if layout_map and len(layout_map) == n_qubits:
                        layout_qubits = [layout_map[j] for j in range(n_qubits)]
                        initial_layout = Layout.from_intlist(layout_qubits, *qc.qregs)
                        
                        if i == 0:
                            self.logger.info(f"[OPTIMIZER] PrÃ©-layout ({layout_strategy}): Q{layout_qubits[:3]}...Q{layout_qubits[-1]}")
                            
                except Exception as e:
                    if i == 0:
                        self.logger.debug(f"[OPTIMIZER] PrÃ©-layout skipped: {e}")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # STATS AVANT TRANSPILATION (pour rapport)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            depth_before = qc.depth()
            ops_before = dict(qc.count_ops())
            gates_1q_before = sum(v for k, v in ops_before.items() 
                                  if k in ['h', 'x', 'y', 'z', 'rz', 'rx', 'ry', 's', 't', 'sdg', 'tdg', 'u1', 'u2', 'u3'])
            gates_2q_before = sum(v for k, v in ops_before.items() 
                                  if k in ['cz', 'cx', 'ecr', 'swap', 'rzz', 'rxx', 'ryy'])
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Ã‰TAPE 2: TRANSPILATION QISKIT
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            pm = generate_preset_pass_manager(
                optimization_level=optimization_level,
                backend=self.backend,
                initial_layout=initial_layout  # Notre prÃ©-layout ou None
            )
            
            # [v2.5.15] Gestion des erreurs de transpilation
            try:
                t_qc = pm.run(qc)
            except Exception as transpile_error:
                error_msg = str(transpile_error)
                self.logger.error(f"âŒ Erreur de transpilation sur circuit {i+1}:")
                self.logger.error(f"   Message: {error_msg}")
                self.logger.error(f"   Circuit: {qc.num_qubits}q, depth={qc.depth()}, ops={qc.size()}")
                
                # Analyser la cause probable
                if "coupling" in error_msg.lower() or "layout" in error_msg.lower():
                    self.logger.error("   ğŸ’¡ Cause probable: IncompatibilitÃ© avec la topologie du backend")
                    self.logger.error("   ğŸ’¡ Solution: VÃ©rifier que les qubits sont connectÃ©s dans le coupling_map")
                elif "gate" in error_msg.lower() or "instruction" in error_msg.lower():
                    self.logger.error("   ğŸ’¡ Cause probable: Porte non supportÃ©e par le backend")
                    self.logger.error("   ğŸ’¡ Solution: Utiliser uniquement les portes natives (CZ, SX, RZ)")
                elif "qubit" in error_msg.lower():
                    self.logger.error("   ğŸ’¡ Cause probable: Nombre de qubits insuffisant")
                    self.logger.error(f"   ğŸ’¡ Solution: Backend a {self.backend.num_qubits}q disponibles")
                
                raise QMCTranspilationError(
                    f"Transpilation Ã©chouÃ©e pour circuit {i+1}: {error_msg}",
                    circuit_name=qc.name if hasattr(qc, 'name') else f"circuit_{i}"
                )
            
            # Stats aprÃ¨s transpilation
            depth_after_transpile = t_qc.depth()
            ops_after = dict(t_qc.count_ops())
            n_2q_after = sum(v for k, v in ops_after.items() if k in ['cz', 'ecr', 'cx', 'swap'])
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Ã‰TAPE 3: VF2PostLayout (amÃ©liore la fidelitÃ©)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            vf2_applied = False
            
            if VF2PostLayout is not None and use_vf2_post_layout:
                try:
                    target = getattr(self.backend, 'target', None)
                    
                    if target:
                        vf2_pm = PassManager([
                            VF2PostLayout(
                                target=target,
                                strict_direction=False,
                                max_trials=vf2_trials)
                        ])
                        
                        t_qc_vf2 = vf2_pm.run(t_qc)
                        t_qc = t_qc_vf2
                        vf2_applied = True
                        
                        if i == 0:
                            self.logger.debug(f"[OPTIMIZER] VF2PostLayout appliquÃ© ({vf2_trials} trials)")
                            
                except Exception as e:
                    if i == 0:
                        self.logger.debug(f"[OPTIMIZER] VF2PostLayout skipped: {e}")
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Ã‰TAPE 4: EXTRACTION DES STATS FINALES
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Qubits physiques utilisÃ©s
            used_physical = set()
            if hasattr(t_qc, 'layout') and t_qc.layout:
                try:
                    for j in range(n_qubits):
                        phys = t_qc.layout.final_index_layout()[j]
                        used_physical.add(phys)
                except:
                    pass
            
            # VÃ©rifier qubits faulty
            faulty_used = used_physical & faulty_qubits
            if faulty_used and i == 0:
                self.logger.warn(f"[OPTIMIZER] âš ï¸ Circuit utilise qubits faulty: {sorted(faulty_used)}")
            
            transpiled.append(t_qc)
            
            # Stats finales
            depth = t_qc.depth()
            ops = dict(t_qc.count_ops())
            n_2q = sum(v for k, v in ops.items() if k in ['cz', 'ecr', 'cx', 'swap'])
            n_1q = sum(v for k, v in ops.items() if k in ['h', 'x', 'y', 'z', 'rz', 'rx', 'ry', 's', 't', 'sdg', 'tdg', 'sx', 'sxdg', 'u1', 'u2', 'u3'])
            
            # Afficher le rapport visuel pour le premier circuit
            if i == 0:
                before_stats = {
                    'qubits': n_qubits,
                    'depth': depth_before,
                    'gates_1q': gates_1q_before,
                    'gates_2q': gates_2q_before,
                }
                after_stats = {
                    'qubits': n_qubits,
                    'depth': depth,
                    'gates_1q': n_1q,
                    'gates_2q': n_2q,
                    'physical_qubits': sorted(list(used_physical)) if used_physical else [],
                }
                pipeline_steps = [
                    {'name': f'Qiskit O{optimization_level} (SabreLayout)', 'applied': True, 'detail': f'level={optimization_level}'},
                    {'name': 'VF2PostLayout', 'applied': vf2_applied, 'detail': f'{vf2_trials:,} trials' if vf2_applied else 'skipped'},
                    {'name': 'Custom Pre-Layout', 'applied': layout_qubits is not None, 'detail': layout_strategy if layout_qubits else 'disabled'},
                ]
                self._print_transpilation_report(before_stats, after_stats, pipeline_steps)
                
                # [v2.5.14] Stocker les stats pour la confirmation QPU
                overhead_2q = ((n_2q - gates_2q_before) / gates_2q_before * 100) if gates_2q_before > 0 else 0
                self._last_transpilation_stats = {
                    'before': before_stats,
                    'after': after_stats,
                    'overhead_2q_percent': overhead_2q,
                    'swaps_estimated': max(0, (n_2q - gates_2q_before) // 3),  # 1 SWAP = 3 CZ
                    'depth_expansion': depth / depth_before if depth_before > 0 else 1,
                    'score': self._calculate_transpilation_score(before_stats, after_stats),
                    'recommendation': 'GO' if overhead_2q < 50 else ('WARN' if overhead_2q < 100 else 'NO-GO'),
                }
            
            circuits_info.append({
                'index': i,
                'name': getattr(qc, 'name', f'circuit_{i}'),
                'n_qubits': n_qubits,  # [v2.5.21] Nombre de qubits logiques
                'transpiled_depth': depth,
                'gates_2q': n_2q,
                'gates_1q': n_1q,  # [v2.5.21] Ajout gates 1Q
                'physical_qubits': list(used_physical) if used_physical else None,
                'pre_layout': layout_qubits,
                'vf2_applied': vf2_applied,
                'faulty_qubits_used': list(faulty_used) if faulty_used else None,
            })
        
        self.dir_manager.save_json('circuits', {'circuits': circuits_info})
        self.report.set('circuits_transpiled', circuits_info, section='transpilation')
        
        return transpiled
    
    def _extract_circuit_connections(self, circuit) -> List[Tuple[int, int]]:
        """
        Extrait les connexions 2Q du circuit (quels qubits interagissent).
        
        C'est essentiel pour trouver un bon layout initial!
        """
        connections = set()
        
        for instruction in circuit.data:
            if len(instruction.qubits) == 2:
                q1 = circuit.qubits.index(instruction.qubits[0])
                q2 = circuit.qubits.index(instruction.qubits[1])
                edge = (min(q1, q2), max(q1, q2))
                connections.add(edge)
        
        return list(connections)
    
    def _transpile_smart_comparison(self, circuits: List, optimization_level: int,
                                     use_vf2_post_layout: bool, vf2_max_trials: int) -> List:
        """
        [v2.5.14] Compare transpilation AVEC et SANS prÃ©-layout, garde le meilleur.
        
        Cette mÃ©thode:
        1. Transpile le premier circuit avec Sabre seul
        2. Transpile le premier circuit avec topology_aware
        3. Compare le nombre de 2Q gates
        4. Utilise la stratÃ©gie gagnante pour tous les circuits
        
        Ã‰vite les catastrophes oÃ¹ topology_aware ajoute +120% de SWAPs!
        """
        if not circuits:
            return []
        
        self.logger.info("[SMART] ğŸ§  Mode AUTO: Comparaison avec/sans prÃ©-layout...")
        
        # Test sur le premier circuit seulement (perf)
        test_circuit = circuits[0]
        
        # Option A: Sabre seul (souvent meilleur)
        try:
            result_sabre = self.transpile_circuits(
                [test_circuit], 
                optimization_level=optimization_level,
                use_optimal_layout=False,
                layout_strategy='none',
                use_vf2_post_layout=use_vf2_post_layout,
                vf2_max_trials=vf2_max_trials
            )
            gates_2q_sabre = sum(1 for inst in result_sabre[0].data if len(inst.qubits) == 2)
        except Exception as e:
            self.logger.warn(f"[SMART] Sabre Ã©chouÃ©: {e}")
            gates_2q_sabre = float('inf')
        
        # Option B: Avec topology_aware
        try:
            result_topo = self.transpile_circuits(
                [test_circuit], 
                optimization_level=optimization_level,
                use_optimal_layout=True,
                layout_strategy='topology_aware',
                use_vf2_post_layout=use_vf2_post_layout,
                vf2_max_trials=vf2_max_trials
            )
            gates_2q_topo = sum(1 for inst in result_topo[0].data if len(inst.qubits) == 2)
        except Exception as e:
            self.logger.warn(f"[SMART] Topology_aware Ã©chouÃ©: {e}")
            gates_2q_topo = float('inf')
        
        # Comparer et choisir
        if gates_2q_sabre <= gates_2q_topo:
            winner = 'none'
            winner_gates = gates_2q_sabre
            loser_gates = gates_2q_topo
            use_layout = False
        else:
            winner = 'topology_aware'
            winner_gates = gates_2q_topo
            loser_gates = gates_2q_sabre
            use_layout = True
        
        improvement = ((loser_gates - winner_gates) / max(1, loser_gates)) * 100
        self.logger.info(f"[SMART] ğŸ† Gagnant: {winner} ({winner_gates} vs {loser_gates} 2Q gates, {improvement:.1f}% mieux)")
        
        # Transpiler tous les circuits avec la stratÃ©gie gagnante
        if len(circuits) == 1:
            # On a dÃ©jÃ  le rÃ©sultat
            return result_sabre if not use_layout else result_topo
        else:
            return self.transpile_circuits(
                circuits,
                optimization_level=optimization_level,
                use_optimal_layout=use_layout,
                layout_strategy=winner,
                use_vf2_post_layout=use_vf2_post_layout,
                vf2_max_trials=vf2_max_trials
            )

    def _find_topology_aware_layout(self, 
                                     n_qubits: int,
                                     circuit_connections: List[Tuple[int, int]],
                                     faulty_qubits: set) -> Dict[int, int]:
        """
        Trouve un layout qui MINIMISE les SWAPs en respectant la topologie.
        
        Algorithme glouton:
        1. Identifier les "hubs" du circuit (qubits avec beaucoup de connexions)
        2. Placer les hubs sur les meilleurs qubits physiques bien connectÃ©s
        3. Placer leurs voisins sur des qubits adjacents dans la topologie
        
        C'est une heuristique - pas optimale mais rapide et efficace.
        """
        if not hasattr(self, 'circuit_optimizer') or not self.circuit_optimizer:
            return None
        
        opt = self.circuit_optimizer
        
        # Si pas de connexions, utiliser simplement les meilleurs qubits
        if not circuit_connections:
            return opt.find_optimal_layout(n_qubits, strategy='contiguous')
        
        # Construire le graphe d'interaction du circuit
        from collections import defaultdict
        circuit_adj = defaultdict(set)
        for q1, q2 in circuit_connections:
            circuit_adj[q1].add(q2)
            circuit_adj[q2].add(q1)
        
        # DegrÃ© de chaque qubit logique (combien de voisins)
        degrees = {q: len(circuit_adj.get(q, set())) for q in range(n_qubits)}
        
        # Trier par degrÃ© dÃ©croissant (hubs d'abord)
        logical_order = sorted(range(n_qubits), key=lambda q: -degrees.get(q, 0))
        
        # Construire la liste des qubits physiques disponibles (triÃ©s par qualitÃ©)
        qubit_ranking = opt.get_qubit_ranking()
        available_physical = []
        for q, score in qubit_ranking:
            if q not in faulty_qubits:
                available_physical.append(q)
        
        # Construire l'adjacence physique
        physical_adj = defaultdict(set)
        for (q1, q2), conn in opt.connections.items():
            physical_adj[q1].add(q2)
            physical_adj[q2].add(q1)
        
        layout = {}
        used_physical = set()
        
        for logical_q in logical_order:
            required_neighbors = circuit_adj.get(logical_q, set())
            mapped_neighbors = [layout[n] for n in required_neighbors if n in layout]
            
            best_physical = None
            best_score = -float('inf')
            
            for phys_q in available_physical:
                if phys_q in used_physical:
                    continue
                
                cal = opt.qubits.get(phys_q)
                if not cal or not cal.operational:
                    continue
                
                # Score de base: qualitÃ© du qubit (0-1)
                score = cal.quality_score()
                
                # BONUS pour connexions directes aux voisins dÃ©jÃ  mappÃ©s
                # C'est LE critÃ¨re clÃ© pour rÃ©duire les SWAPs!
                adjacency_bonus = 0
                for mapped in mapped_neighbors:
                    if mapped in physical_adj.get(phys_q, set()):
                        # Connexion directe existe = pas besoin de SWAP
                        adjacency_bonus += 1.0
                        
                        # Bonus supplÃ©mentaire si bonne qualitÃ© de connexion
                        conn_key = (min(phys_q, mapped), max(phys_q, mapped))
                        conn = opt.connections.get(conn_key)
                        if conn:
                            adjacency_bonus += conn.quality_score() * 0.5
                    else:
                        # Pas de connexion directe = SWAP nÃ©cessaire
                        adjacency_bonus -= 0.3
                
                # Combiner qualitÃ© + adjacence
                # Le facteur 2.0 priorise l'adjacence sur la qualitÃ© pure
                total_score = score + adjacency_bonus * 2.0
                
                if total_score > best_score:
                    best_score = total_score
                    best_physical = phys_q
            
            if best_physical is not None:
                layout[logical_q] = best_physical
                used_physical.add(best_physical)
            else:
                # Fallback: prendre le prochain disponible
                for phys_q in available_physical:
                    if phys_q not in used_physical:
                        cal = opt.qubits.get(phys_q)
                        if cal and cal.operational:
                            layout[logical_q] = phys_q
                            used_physical.add(phys_q)
                            break
        
        return layout if len(layout) == n_qubits else None
        
        return transpiled
    
    def run_on_qpu(self, circuits, shots: int = None,
                   save_counts: bool = True,
                   timeout: float = None,
                   auto_transpile: bool = True,
                   optimize_layout: bool = False,
                   show_calibration: bool = True,
                   layout_strategy: str = 'none',
                   sampler_factory=None,
                   generate_report: bool = True,
                   generate_archive: bool = True) -> Optional[List[Dict]]:
        """
        ExÃ©cute les circuits sur le QPU avec gÃ©nÃ©ration automatique de rapport ET archive.
        
        [v2.5.18] PROTECTION DES RÃ‰SULTATS:
        âš ï¸ Les paramÃ¨tres generate_report et generate_archive sont IGNORÃ‰S!
        La configuration est lue depuis le fichier .env pour Ã©viter les pertes 
        accidentelles de donnÃ©es QPU prÃ©cieuses.
        
        Pour dÃ©sactiver (dÃ©conseillÃ©), crÃ©ez un fichier .env:
            QMC_GENERATE_REPORT=false
            QMC_GENERATE_ARCHIVE=false
        
        Args:
            circuits: Circuit unique OU liste de circuits Ã  exÃ©cuter
            shots: Nombre de shots par circuit (dÃ©faut: self.default_shots ou 4096)
            save_counts: Sauvegarder les counts (dÃ©faut: True)
            timeout: Timeout optionnel en secondes
            auto_transpile: Transpiler automatiquement (dÃ©faut: True)
            optimize_layout: Notre prÃ©-layout custom (dÃ©faut: False)
            show_calibration: Afficher le rÃ©sumÃ© calibration (dÃ©faut: True)
            layout_strategy: 'none' (dÃ©faut=Sabre), 'topology_aware', 'best_qubits'
            sampler_factory: Callable pour crÃ©er le sampler (tests)
            generate_report: âš ï¸ IGNORÃ‰ - ContrÃ´lÃ© par .env (QMC_GENERATE_REPORT)
            generate_archive: âš ï¸ IGNORÃ‰ - ContrÃ´lÃ© par .env (QMC_GENERATE_ARCHIVE)
        
        Returns:
            Liste de rÃ©sultats ou None si Ã©chec
            
        Example:
            results = fw.run_on_qpu(circuit, shots=4096)  # Rapport + archive AUTO
            results = fw.run_on_qpu(circuit)  # Utilise self.default_shots
        """
        # [v2.5.22] Utiliser default_shots si non spÃ©cifiÃ©
        if shots is None:
            shots = getattr(self, 'default_shots', 4096)
        
        # [v2.5.18] PROTECTION: Utiliser la config environnement, PAS les paramÃ¨tres
        # Les paramÃ¨tres generate_report/generate_archive sont IGNORÃ‰S pour Ã©viter
        # les pertes accidentelles de rÃ©sultats QPU prÃ©cieux
        actual_generate_report = QMC_GENERATE_REPORT
        actual_generate_archive = QMC_GENERATE_ARCHIVE
        
        # Warning si le programmeur essaie de dÃ©sactiver via code
        if not generate_report and actual_generate_report:
            self.logger.warn(
                "âš ï¸ ParamÃ¨tre generate_report=False IGNORÃ‰! "
                "Pour dÃ©sactiver: QMC_GENERATE_REPORT=false dans .env"
            )
        if not generate_archive and actual_generate_archive:
            self.logger.warn(
                "âš ï¸ ParamÃ¨tre generate_archive=False IGNORÃ‰! "
                "Pour dÃ©sactiver: QMC_GENERATE_ARCHIVE=false dans .env"
            )
        
        # [v2.5.17] Contexte d'exÃ©cution pour le rapport
        run_context = {
            'shots': shots,
            'circuits_count': 0,
            'optimization_level': 3,
            'layout_strategy': layout_strategy,
            'job_id': None,
            'submitted_at': None,
            'completed_at': None,
            'total_time_s': 0,
            'queue_time_s': 0,
            'execution_time_s': 0,
            'qpu_time_s': 0,
            'transpile_time_s': 0,
            'status': 'STARTING',
        }
        global_start_time = time.time()
        execution_error = None
        results = None
        
        # [v2.5.17] Pour l'archive: sauvegarder circuits avant/aprÃ¨s transpilation
        original_circuits = None
        transpiled_circuits = None
        
        try:
            # === VÃ‰RIFICATIONS INITIALES ===
            if not self._connected:
                raise QMCExecutionError(
                    "Non connectÃ© au backend IBM",
                    suggestion="Appelez connect() avant run_on_qpu()"
                )
            
            if self._mode == RunMode.VALIDATE:
                self.logger.warn("Mode VALIDATE - pas d'exÃ©cution QPU")
                run_context['status'] = 'SKIPPED_VALIDATE'
                return None
            
            # Auto-wrapping: accepte circuit unique OU liste
            from qiskit import QuantumCircuit
            if isinstance(circuits, QuantumCircuit):
                circuits = [circuits]
                self.logger.debug("[AUTO] Circuit unique wrappÃ© en liste")
            
            # [v2.5.17] Sauvegarder les circuits originaux pour l'archive
            original_circuits = circuits.copy() if circuits else None
            
            run_context['circuits_count'] = len(circuits)
            
            from qiskit_ibm_runtime import SamplerV2
            
            self.logger.section("EXÃ‰CUTION QPU")
            
            # Banner de sÃ©curitÃ© si mode sÃ©curisÃ©
            if self.private or self.auto_delete_job or self.redact_logs or self.production_mode:
                self._display_security_banner()
            
            # === OPTIMISATION AUTOMATIQUE ===
            if optimize_layout and auto_transpile:
                if not hasattr(self, 'circuit_optimizer') or self.circuit_optimizer is None:
                    try:
                        self.circuit_optimizer = CircuitOptimizer.from_backend(self.backend, self.logger)
                    except Exception as e:
                        self.logger.warn(f"[OPTIMIZER] Calibration non disponible: {e}")
                        optimize_layout = False
                
                if show_calibration and self.circuit_optimizer:
                    self._display_calibration_summary_compact()
            
            # === TRANSPILATION ===
            transpile_start = time.time()
            if auto_transpile:
                try:
                    circuits = self.transpile_circuits(
                        circuits, 
                        use_optimal_layout=optimize_layout,
                        layout_strategy=layout_strategy
                    )
                    # [v2.5.17] Sauvegarder les circuits transpilÃ©s
                    transpiled_circuits = circuits
                    # [v2.5.21] Stocker pour AutoReportGenerator
                    self._last_transpiled_circuits = transpiled_circuits
                except Exception as e:
                    error = QMCTranspilationError(f"Ã‰chec de la transpilation: {str(e)}")
                    if self.error_handler:
                        self.error_handler.handle(error, context="run_on_qpu.transpile", raise_exception=True)
                    raise error
            else:
                transpiled_circuits = circuits
                # [v2.5.21] Stocker pour AutoReportGenerator
                self._last_transpiled_circuits = transpiled_circuits
            run_context['transpile_time_s'] = time.time() - transpile_start
            
            # === SOUMISSION DU JOB ===
            if sampler_factory is not None:
                sampler = sampler_factory(mode=self.backend)
            else:
                sampler = SamplerV2(mode=self.backend)
            
            self.error_mitigation.configure_sampler_options(sampler.options, circuits=circuits)
            
            # [v2.5.18] PROTECTION: Utiliser la config .env, PAS self.auto_confirm
            # Le paramÃ¨tre auto_confirm dans le code est IGNORÃ‰ pour Ã©viter le gaspillage QPU
            actual_auto_confirm = QMC_AUTO_CONFIRM
            
            # Warning si le programmeur essaie d'activer auto_confirm via code
            if self.auto_confirm and not actual_auto_confirm:
                self.logger.warn(
                    "âš ï¸ ParamÃ¨tre auto_confirm=True IGNORÃ‰! "
                    "Pour dÃ©sactiver la confirmation: QMC_AUTO_CONFIRM=true dans .env"
                )
            
            # Confirmation obligatoire avant envoi QPU (sauf si .env dit autrement)
            if not actual_auto_confirm:
                if not self._confirm_qpu_submission(circuits, shots):
                    self.logger.warn("âŒ Envoi QPU ANNULÃ‰ par l'utilisateur")
                    print("\n  âŒ JOB ANNULÃ‰ - Aucun temps QPU consommÃ©\n")
                    run_context['status'] = 'CANCELLED_BY_USER'
                    return None
            
            self.logger.info(f"Soumission: {len(circuits)} circuits, {shots} shots")
            run_context['submitted_at'] = datetime.now().strftime('%H:%M:%S')
            
            self._display_upload_animation(len(circuits), shots)
            
            retry_manager = SmartRetryManager(
                max_retries=self.retry_config.max_attempts - 1,
                base_delay=self.retry_config.initial_delay_s,
                jitter=self.retry_config.jitter,
                logger=self.logger
            )
            
            job = self._submit_with_upload_animation(sampler, circuits, shots, retry_manager)
            
            if job is None:
                error = QMCExecutionError(
                    f"Soumission impossible aprÃ¨s {self.retry_config.max_attempts} tentatives",
                    details={'retry_config': str(self.retry_config)},
                    recoverable=False
                )
                if self.error_handler:
                    self.error_handler.handle(error, context="run_on_qpu.submit", raise_exception=True)
                raise error
            
            job_id = job.job_id()
            self._last_job_id = job_id
            run_context['job_id'] = job_id
            self.logger.info(f"Job ID: {job_id}")
            self.report.set('job_id', job_id, section='execution')
            
            if self.private:
                self._apply_private_tags(job, job_id)
            
            self._display_job_submitted_banner(job_id, len(circuits), shots)
            
            # Checkpoint
            circuits_hash = None
            try:
                circuit_reprs = [f"{c.num_qubits}q_{c.depth()}d_{c.size()}ops" for c in circuits[:5]]
                circuits_hash = hashlib.sha256('|'.join(circuit_reprs).encode()).hexdigest()[:16]
            except Exception:
                circuits_hash = 'unknown'
            
            mitigation_snapshot = self.error_mitigation.get_summary() if self.error_mitigation else {}
            
            self.checkpoint_manager.save_checkpoint({
                'job_id': job_id,
                'n_circuits': len(circuits),
                'shots': shots,
                'timestamp': datetime.now().isoformat(),
                'backend_name': self.backend_name,
                'circuits_hash': circuits_hash,
                'mitigation_options': {
                    'twirling': mitigation_snapshot.get('twirling', {}).get('enabled', False),
                    'dd': mitigation_snapshot.get('dynamical_decoupling', {}).get('enabled', False),
                },
                'framework_version': __version__,
            }, name=f"job_{job_id[:8]}")
            
            # === MONITORING DU JOB ===
            # [v2.5.21] Option monitoring robuste via .env
            # [v2.5.21] Monitoring robuste ACTIVÃ‰ PAR DÃ‰FAUT (dÃ©sactiver avec QMC_ROBUST_MONITORING=false)
            use_robust_monitoring = os.environ.get("QMC_ROBUST_MONITORING", "true").lower() not in ("false", "0", "no")
            
            try:
                if use_robust_monitoring:
                    # Monitoring avec timeout par appel et reconnexion auto
                    metrics = self._monitor_job_with_reconnect(
                        job, 
                        timeout=timeout,
                        poll_interval=10.0,
                        status_timeout=45.0
                    )
                    
                    # Si connexion perdue, lever une erreur avec instructions
                    if metrics.get('connection_lost'):
                        raise QMCTimeoutError(
                            f"Connexion perdue - utilisez --recover-job {job_id}",
                            job_id=job_id
                        )
                else:
                    # Monitoring standard avec animations
                    metrics = self._monitor_job_with_animation(job, timeout=timeout, 
                                                               n_circuits=len(circuits), 
                                                               shots=shots)
            except Exception as e:
                error = QMCTimeoutError(
                    f"Timeout lors de l'attente du job: {str(e)}",
                    job_id=job_id,
                    timeout_s=timeout
                )
                if self.error_handler:
                    self.error_handler.handle(error, context="run_on_qpu.monitor", raise_exception=False)
                self.logger.error(f"â±ï¸ Job timeout - vous pouvez reprendre avec job_id: {job_id}")
                run_context['status'] = 'TIMEOUT'
                raise error
            
            run_context['completed_at'] = datetime.now().strftime('%H:%M:%S')
            run_context['execution_time_s'] = time.time() - global_start_time
            
            final_status = metrics.get('final_status', str(job.status()))
            run_context['status'] = final_status
            
            # === TRAITEMENT DU RÃ‰SULTAT ===
            if final_status == 'DONE':
                qpu_times = self.get_job_execution_times(job_id)
                qpu_time_s = qpu_times.get('qpu_time_s', 0) or 0
                queue_time_s = qpu_times.get('queue_time_s', 0) or 0
                
                run_context['qpu_time_s'] = qpu_time_s
                run_context['queue_time_s'] = queue_time_s
                
                self.report.set('qpu_time_s', qpu_time_s, section='execution')
                self.report.set('queue_time_s', queue_time_s, section='execution')
                
                elapsed = run_context['execution_time_s']
                self.logger.info(f"[OK] Job terminÃ©!")
                self.logger.info(f"     â±ï¸  Temps total:    {elapsed:.1f}s")
                self.logger.info(f"     ğŸš€ Temps QPU rÃ©el: {qpu_time_s:.2f}s")
                if queue_time_s > 0:
                    self.logger.info(f"     â³ Temps queue:    {queue_time_s:.1f}s")
                
                # [v2.5.21] Utiliser _safe_get_job_result avec timeout pour Ã©viter blocage
                try:
                    raw_result = self._safe_get_job_result(job, timeout_seconds=120.0)
                    results = self._process_results(raw_result, circuits, save_counts)
                except QMCTimeoutError:
                    # Le message d'erreur avec instructions de reprise est dÃ©jÃ  affichÃ©
                    run_context['status'] = 'RESULT_TIMEOUT'
                    execution_error = QMCTimeoutError(
                        "Timeout rÃ©cupÃ©ration rÃ©sultats - utilisez retrieve_job_results()",
                        job_id=job_id
                    )
                    # Continuer pour gÃ©nÃ©rer l'archive avec les infos qu'on a
                
                if self.auto_delete_job:
                    self._secure_delete_job(job, job_id)
                
            elif final_status == 'CANCELLED':
                error = QMCJobCancelledError(
                    "Job annulÃ©",
                    job_id=job_id,
                    reason=metrics.get('cancel_reason', 'Unknown')
                )
                if self.error_handler:
                    self.error_handler.handle(error, context="run_on_qpu", raise_exception=False)
                execution_error = error
                
            else:
                # Erreur IBM
                error_details = self._get_job_error_details(job)
                
                error_msg = f"Job Ã©chouÃ© avec statut: {final_status}"
                if error_details.get('error_message'):
                    error_msg += f"\n  ğŸ“‹ Message IBM: {error_details['error_message']}"
                
                # Afficher banner d'erreur
                print()
                print(f"  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
                print(f"  â•‘  âŒ DÃ‰TAILS DE L'ERREUR IBM QUANTUM                                        â•‘")
                print(f"  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
                print(f"  â•‘  ğŸ†” Job ID:  {job_id:<60} â•‘")
                print(f"  â•‘  ğŸ“Š Status:  {final_status:<60} â•‘")
                if error_details.get('error_message'):
                    err_msg = error_details['error_message'][:55] + "..." if len(error_details.get('error_message', '')) > 55 else error_details.get('error_message', 'N/A')
                    print(f"  â•‘  ğŸ’¬ Message: {err_msg:<60} â•‘")
                print(f"  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
                print(f"  â•‘  ğŸ’¡ CAUSES POSSIBLES:                                                      â•‘")
                print(f"  â•‘     â€¢ Circuit trop profond ou complexe pour le backend                     â•‘")
                print(f"  â•‘     â€¢ Qubits demandÃ©s non disponibles/dÃ©fectueux                           â•‘")
                print(f"  â•‘     â€¢ ProblÃ¨me de calibration sur le backend                               â•‘")
                print(f"  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
                print()
                
                self.logger.error(f"Job ERROR - DÃ©tails:")
                for key, value in error_details.items():
                    if value:
                        self.logger.error(f"  {key}: {value}")
                
                error = QMCExecutionError(
                    error_msg,
                    job_id=job_id,
                    details={'metrics': metrics, 'ibm_error': error_details},
                    recoverable=True
                )
                if self.error_handler:
                    self.error_handler.handle(error, context="run_on_qpu", raise_exception=False)
                execution_error = error
                
        except Exception as e:
            # Capturer toute exception pour le rapport
            execution_error = e
            run_context['status'] = 'ERROR'
            run_context['total_time_s'] = time.time() - global_start_time
            raise
            
        finally:
            # [v2.5.21] GÃ‰NÃ‰RATION AUTOMATIQUE - ORDRE OPTIMISÃ‰ POUR SÃ‰CURITÃ‰
            # 1. Archive JSON EN PREMIER (rapide, sÃ©curise les donnÃ©es brutes)
            # 2. Rapport HTML ENSUITE (plus lent, peut Ã©chouer sans perdre les donnÃ©es)
            run_context['total_time_s'] = time.time() - global_start_time
            
            # === 1. ARCHIVE JSON - PRIORITÃ‰ MAXIMALE ===
            # SÃ©curise immÃ©diatement les rÃ©sultats bruts avant tout traitement
            if actual_generate_archive:
                try:
                    self._generate_auto_archive(
                        results=results,
                        original_circuits=original_circuits,
                        transpiled_circuits=transpiled_circuits,
                        run_context=run_context,
                        error=execution_error
                    )
                except Exception as archive_error:
                    self.logger.warn(f"âš ï¸ Erreur gÃ©nÃ©ration archive: {archive_error}")
            
            # === 2. RAPPORT HTML - APRÃˆS SÃ‰CURISATION ===
            # GÃ©nÃ¨re les visualisations (peut Ã©chouer sans risque de perte de donnÃ©es)
            if actual_generate_report:
                try:
                    self._generate_auto_report(
                        results, run_context, execution_error,
                        transpiled_circuits=transpiled_circuits  # [v2.5.18] Pour visualisation
                    )
                except Exception as report_error:
                    self.logger.warn(f"âš ï¸ Erreur gÃ©nÃ©ration rapport: {report_error}")
                    # Les donnÃ©es sont dÃ©jÃ  sÃ©curisÃ©es dans l'archive JSON
        
        return results
    
    def run_on_qpu_batched(self, circuits, shots: int = 4096,
                           max_per_job: int = 100,
                           delay_between_jobs: float = 10.0,
                           generate_report: bool = True,
                           generate_archive: bool = True,
                           report_title: Optional[str] = None) -> List[Dict]:
        """
        [v2.5.21] ExÃ©cute les circuits en PLUSIEURS JOBS SÃ‰PARÃ‰S.
        
        Utile pour les grandes expÃ©riences (>100 circuits) qui peuvent
        timeout ou Ã©chouer avec un seul job massif.
        
        Args:
            circuits: Liste des circuits Ã  exÃ©cuter
            shots: Nombre de shots par circuit
            max_per_job: Nombre maximum de circuits par job (dÃ©faut: 100)
            delay_between_jobs: Pause en secondes entre les jobs (dÃ©faut: 10s)
            generate_report: GÃ©nÃ©rer un rapport HTML global Ã  la fin
            generate_archive: GÃ©nÃ©rer une archive JSON globale Ã  la fin
            report_title: Titre optionnel pour le rapport
            
        Returns:
            Liste combinÃ©e de tous les rÃ©sultats
            
        Example:
            >>> results = fw.run_on_qpu_batched(
            ...     circuits,
            ...     shots=4096,
            ...     max_per_job=100,
            ...     delay_between_jobs=15
            ... )
        """
        import time
        
        n_total = len(circuits)
        if n_total == 0:
            self.logger.warn("âš ï¸ Aucun circuit Ã  exÃ©cuter")
            return []
        
        n_jobs = (n_total + max_per_job - 1) // max_per_job
        
        self.logger.info(f"")
        self.logger.info(f"{'â•' * 60}")
        self.logger.info(f"  ğŸ”„ MULTI-JOB EXECUTION")
        self.logger.info(f"{'â•' * 60}")
        self.logger.info(f"  ğŸ“Š {n_total} circuits â†’ {n_jobs} jobs")
        self.logger.info(f"  ğŸ“¦ Max {max_per_job} circuits/job")
        self.logger.info(f"  â±ï¸  DÃ©lai entre jobs: {delay_between_jobs}s")
        self.logger.info(f"{'â•' * 60}")
        self.logger.info(f"")
        
        all_results = []
        job_ids = []
        job_usages = []
        start_time = time.time()
        
        for job_idx in range(n_jobs):
            batch_start = job_idx * max_per_job
            batch_end = min((job_idx + 1) * max_per_job, n_total)
            batch_circuits = circuits[batch_start:batch_end]
            
            self.logger.info(f"")
            self.logger.info(f"ğŸ“¤ JOB {job_idx + 1}/{n_jobs}: circuits [{batch_start}, {batch_end - 1}] ({len(batch_circuits)} circuits)")
            
            try:
                # ExÃ©cuter ce batch (sans rapport/archive individuel)
                batch_results = self.run_on_qpu(
                    batch_circuits,
                    shots=shots,
                    generate_report=False,
                    generate_archive=False
                )
                
                if batch_results:
                    all_results.extend(batch_results)
                    if hasattr(self, 'last_job_id') and self.last_job_id:
                        job_ids.append(self.last_job_id)
                    if hasattr(self, 'last_usage') and self.last_usage:
                        job_usages.append(self.last_usage)
                    self.logger.info(f"   âœ… Job {job_idx + 1} terminÃ©: {len(batch_results)} rÃ©sultats")
                else:
                    self.logger.warn(f"   âš ï¸ Job {job_idx + 1}: aucun rÃ©sultat")
                    
            except Exception as e:
                self.logger.error(f"   âŒ Job {job_idx + 1} Ã©chouÃ©: {e}")
                # Continuer avec les autres jobs
            
            # Pause entre les jobs (sauf le dernier)
            if job_idx < n_jobs - 1:
                self.logger.info(f"   â¸ï¸  Pause {delay_between_jobs}s avant le prochain job...")
                time.sleep(delay_between_jobs)
        
        total_time = time.time() - start_time
        total_usage = sum(job_usages) if job_usages else 0
        
        self.logger.info(f"")
        self.logger.info(f"{'â•' * 60}")
        self.logger.info(f"  âœ… MULTI-JOB TERMINÃ‰")
        self.logger.info(f"{'â•' * 60}")
        self.logger.info(f"  ğŸ“Š {len(all_results)}/{n_total} rÃ©sultats collectÃ©s")
        self.logger.info(f"  ğŸ†” Jobs: {len(job_ids)}")
        self.logger.info(f"  â±ï¸  Temps total: {total_time:.1f}s")
        self.logger.info(f"  ğŸ’° Usage QPU total: {total_usage:.2f}s")
        self.logger.info(f"{'â•' * 60}")
        
        # Stocker les mÃ©tadonnÃ©es multi-job
        self.last_multijob_ids = job_ids
        self.last_multijob_usage = total_usage
        
        # GÃ©nÃ©rer rapport/archive global si demandÃ©
        if generate_archive or generate_report:
            run_context = {
                "multijob": True,
                "n_jobs": n_jobs,
                "job_ids": job_ids,
                "total_circuits": n_total,
                "max_per_job": max_per_job,
                "total_time": total_time,
                "total_usage": total_usage,
                "shots": shots,
                "backend": self.backend_name,
                "timestamp": datetime.now().isoformat(),
            }
            
            if generate_archive:
                try:
                    self._generate_auto_archive(
                        results=all_results,
                        original_circuits=circuits,
                        transpiled_circuits=None,  # Pas de transpilation globale
                        run_context=run_context
                    )
                except Exception as e:
                    self.logger.warn(f"âš ï¸ Erreur gÃ©nÃ©ration archive: {e}")
            
            if generate_report:
                try:
                    self._generate_auto_report(
                        results=all_results,
                        run_context=run_context,
                        title=report_title or f"Multi-Job Report ({n_jobs} jobs)"
                    )
                except Exception as e:
                    self.logger.warn(f"âš ï¸ Erreur gÃ©nÃ©ration rapport: {e}")
        
        return all_results
    
    def _generate_auto_archive(self, results: List[Dict], original_circuits, transpiled_circuits,
                               run_context: Dict, error: Exception = None):
        """
        [v2.5.17] GÃ©nÃ¨re automatiquement une archive JSON COMPLÃˆTE.
        
        L'archive contient TOUT ce qui s'est passÃ© pendant l'exÃ©cution:
        - Circuits originaux et transpilÃ©s (QASM, mÃ©triques)
        - Ã‰tat complet du QPU (calibration 156 qubits)
        - Configuration de mitigation et transpilation
        - RÃ©sultats complets avec statistiques
        - Timing dÃ©taillÃ©
        - Erreurs avec traceback
        
        Args:
            results: RÃ©sultats de l'exÃ©cution
            original_circuits: Circuits avant transpilation
            transpiled_circuits: Circuits aprÃ¨s transpilation
            run_context: Contexte d'exÃ©cution
            error: Exception si erreur
        """
        # Initialiser le gÃ©nÃ©rateur d'archive si nÃ©cessaire
        if not hasattr(self, '_archive_generator') or self._archive_generator is None:
            self._archive_generator = ExecutionArchive(framework=self, logger=self.logger)
        
        # GÃ©nÃ©rer l'archive
        archive_path = self._archive_generator.generate(
            results=results,
            circuits=original_circuits,
            transpiled_circuits=transpiled_circuits,
            run_context=run_context,
            error=error
        )
        
        # Afficher le lien vers l'archive
        size_kb = archive_path.stat().st_size / 1024
        size_str = f"{size_kb:.1f} KB" if size_kb < 1024 else f"{size_kb/1024:.1f} MB"
        
        print()
        print(f"  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print(f"  â•‘  ğŸ“¦ ARCHIVE JSON COMPLÃˆTE GÃ‰NÃ‰RÃ‰E                                          â•‘")
        print(f"  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  ğŸ“ {str(archive_path):<70} â•‘")
        print(f"  â•‘  ğŸ“Š Taille: {size_str:<62} â•‘")
        print(f"  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
        
        # Sauvegarder le chemin de la derniÃ¨re archive
        self._last_archive_path = archive_path
        
        return archive_path
    
    @property
    def archive_generator(self) -> 'ExecutionArchive':
        """[v2.5.17] AccÃ¨s au gÃ©nÃ©rateur d'archives."""
        if not hasattr(self, '_archive_generator') or self._archive_generator is None:
            self._archive_generator = ExecutionArchive(framework=self, logger=self.logger)
        return self._archive_generator
    
    @property
    def last_archive_path(self) -> Optional[Path]:
        """[v2.5.17] Chemin de la derniÃ¨re archive gÃ©nÃ©rÃ©e."""
        return getattr(self, '_last_archive_path', None)
    
    def _generate_auto_report(self, results: List[Dict], run_context: Dict, error: Exception = None,
                               transpiled_circuits: List = None):
        """
        [v2.5.17] GÃ©nÃ¨re automatiquement un rapport HTML ultra-complet.
        
        AppelÃ© automatiquement Ã  la fin de run_on_qpu() dans le bloc finally,
        donc gÃ©nÃ¨re le rapport mÃªme en cas d'erreur.
        
        Args:
            results: RÃ©sultats de l'exÃ©cution (peut Ãªtre None en cas d'erreur)
            run_context: Contexte d'exÃ©cution (timing, job_id, etc.)
            error: Exception si erreur pendant l'exÃ©cution
            transpiled_circuits: [v2.5.18] Circuits transpilÃ©s pour visualisation
        """
        # Initialiser le gÃ©nÃ©rateur de rapport si nÃ©cessaire
        if not hasattr(self, '_report_generator') or self._report_generator is None:
            self._report_generator = AutoReportGenerator(framework=self, logger=self.logger)
        
        # GÃ©nÃ©rer le rapport
        report_path = self._report_generator.generate(
            results=results,
            run_context=run_context,
            error=error,
            title=None,  # Titre auto-gÃ©nÃ©rÃ© basÃ© sur le statut
            transpiled_circuits=transpiled_circuits  # [v2.5.18] Pour visualisation
        )
        
        # Afficher le lien vers le rapport
        status_emoji = "âŒ" if error else "âœ…"
        status_text = "ERROR" if error else "SUCCESS"
        
        print()
        print(f"  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print(f"  â•‘  ğŸ“Š RAPPORT HTML GÃ‰NÃ‰RÃ‰                          {status_emoji} {status_text:<20}     â•‘")
        print(f"  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  ğŸ“ {str(report_path):<70} â•‘")
        print(f"  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
        
        # Sauvegarder le chemin du dernier rapport
        self._last_report_path = report_path
        
        return report_path
    
    @property
    def report_generator(self) -> 'AutoReportGenerator':
        """[v2.5.17] AccÃ¨s au gÃ©nÃ©rateur de rapports."""
        if not hasattr(self, '_report_generator') or self._report_generator is None:
            self._report_generator = AutoReportGenerator(framework=self, logger=self.logger)
        return self._report_generator
    
    @property  
    def last_report_path(self) -> Optional[Path]:
        """[v2.5.17] Chemin du dernier rapport gÃ©nÃ©rÃ©."""
        return getattr(self, '_last_report_path', None)
    
    def open_last_report(self):
        """[v2.5.17] Ouvre le dernier rapport dans le navigateur."""
        if self.last_report_path and self.last_report_path.exists():
            self.report_generator.open_in_browser(self.last_report_path)
        else:
            self.logger.warn("Aucun rapport disponible. ExÃ©cutez run_on_qpu() d'abord.")
    
    def _get_job_error_details(self, job) -> Dict[str, Any]:
        """
        [v2.5.15] RÃ©cupÃ¨re les dÃ©tails d'erreur d'un job IBM Quantum.
        
        Extrait toutes les informations disponibles sur l'erreur:
        - Message d'erreur
        - Code d'erreur
        - Raison de l'Ã©chec
        - MÃ©tadonnÃ©es supplÃ©mentaires
        
        Args:
            job: Objet job IBM Runtime
            
        Returns:
            Dict avec les dÃ©tails de l'erreur
        """
        error_details = {
            'error_message': None,
            'error_code': None,
            'reason': None,
            'status': None,
            'backend': None,
            'creation_date': None,
            'raw_error': None,
            'job_tags': None,
        }
        
        try:
            # Status du job
            if hasattr(job, 'status'):
                try:
                    error_details['status'] = str(job.status())
                except:
                    pass
            
            # Message d'erreur - plusieurs mÃ©thodes possibles
            # MÃ©thode 1: error_message() (Qiskit Runtime rÃ©cent)
            if hasattr(job, 'error_message'):
                try:
                    msg = job.error_message()
                    if msg:
                        error_details['error_message'] = str(msg)
                except Exception as e:
                    error_details['raw_error'] = str(e)
            
            # MÃ©thode 2: result().get_error() ou similar
            if not error_details['error_message'] and hasattr(job, 'result'):
                try:
                    result = job.result()
                    if hasattr(result, 'get_error'):
                        error_details['error_message'] = str(result.get_error())
                except Exception as e:
                    # Le result() peut lever une exception avec le message d'erreur
                    error_str = str(e)
                    if error_str and len(error_str) > 5:
                        error_details['error_message'] = error_str
            
            # MÃ©thode 3: Attribut _error ou _error_message
            for attr in ['_error', '_error_message', 'error', '_api_error']:
                if hasattr(job, attr):
                    try:
                        val = getattr(job, attr)
                        if val:
                            error_details['error_message'] = str(val)
                            break
                    except:
                        pass
            
            # MÃ©tadonnÃ©es du job
            if hasattr(job, 'backend'):
                try:
                    backend = job.backend()
                    if hasattr(backend, 'name'):
                        error_details['backend'] = backend.name
                    else:
                        error_details['backend'] = str(backend)
                except:
                    pass
            
            # Date de crÃ©ation
            if hasattr(job, 'creation_date'):
                try:
                    error_details['creation_date'] = str(job.creation_date())
                except:
                    pass
            
            # Tags du job (peut contenir des infos utiles)
            if hasattr(job, 'tags'):
                try:
                    error_details['job_tags'] = job.tags()
                except:
                    pass
            
            # MÃ©thode 4: VÃ©rifier les mÃ©tadonnÃ©es/propriÃ©tÃ©s
            if hasattr(job, 'properties'):
                try:
                    props = job.properties()
                    if props and isinstance(props, dict):
                        if 'error' in props:
                            error_details['error_message'] = str(props['error'])
                        if 'error_code' in props:
                            error_details['error_code'] = str(props['error_code'])
                except:
                    pass
            
            # MÃ©thode 5: AccÃ¨s direct aux attributs internes (fallback)
            if not error_details['error_message']:
                for attr in dir(job):
                    if 'error' in attr.lower() and not attr.startswith('__'):
                        try:
                            val = getattr(job, attr)
                            if callable(val):
                                val = val()
                            if val and str(val) not in ['None', '']:
                                if not error_details['error_message']:
                                    error_details['error_message'] = f"{attr}: {val}"
                                break
                        except:
                            pass
            
            # MÃ©thode 6: VÃ©rifier le job_id pour des patterns d'erreur connus
            if hasattr(job, 'job_id'):
                try:
                    job_id = job.job_id()
                    error_details['job_id'] = job_id
                except:
                    pass
                    
        except Exception as e:
            error_details['extraction_error'] = str(e)
        
        # Log les dÃ©tails pour debug
        if self.logger:
            self.logger.debug(f"Job error details extracted: {error_details}")
        
        return error_details
    
    def _extract_ibm_error_details(self, exception: Exception) -> Dict[str, Any]:
        """
        [v2.5.15] Extrait les dÃ©tails d'erreur d'une exception IBM.
        
        Analyse l'exception pour extraire:
        - Code d'erreur HTTP
        - Message IBM
        - DÃ©tails supplÃ©mentaires
        
        Args:
            exception: Exception levÃ©e par IBM Runtime
            
        Returns:
            Dict avec les dÃ©tails extraits
        """
        details = {
            'error_code': None,
            'ibm_message': None,
            'http_status': None,
            'request_id': None,
            'raw_response': None,
        }
        
        try:
            error_str = str(exception)
            error_type = type(exception).__name__
            
            # Extraire le code HTTP si prÃ©sent (ex: "401", "403", "500")
            import re
            http_match = re.search(r'\b(4\d{2}|5\d{2})\b', error_str)
            if http_match:
                details['http_status'] = int(http_match.group(1))
            
            # Chercher un code d'erreur IBM (ex: "ERROR_CODE_XXX")
            code_match = re.search(r'(ERROR[_\-]?CODE[_\-]?\w+|IBM\w+Error)', error_str, re.IGNORECASE)
            if code_match:
                details['error_code'] = code_match.group(1)
            
            # Extraire le message IBM s'il est dans un format JSON
            json_match = re.search(r'\{[^}]*"message"\s*:\s*"([^"]+)"', error_str)
            if json_match:
                details['ibm_message'] = json_match.group(1)
            
            # Chercher un request_id pour le support IBM
            req_id_match = re.search(r'request[_\-]?id["\s:]+([a-zA-Z0-9\-]+)', error_str, re.IGNORECASE)
            if req_id_match:
                details['request_id'] = req_id_match.group(1)
            
            # VÃ©rifier les attributs de l'exception
            for attr in ['message', 'error_message', 'detail', 'response', 'status_code']:
                if hasattr(exception, attr):
                    try:
                        val = getattr(exception, attr)
                        if val:
                            if attr == 'status_code' and not details['http_status']:
                                details['http_status'] = val
                            elif attr == 'message' and not details['ibm_message']:
                                details['ibm_message'] = str(val)
                            elif attr == 'response':
                                details['raw_response'] = str(val)[:500]
                    except:
                        pass
            
            # VÃ©rifier si c'est une exception chaÃ®nÃ©e (__cause__)
            if hasattr(exception, '__cause__') and exception.__cause__:
                cause_details = self._extract_ibm_error_details(exception.__cause__)
                for key, val in cause_details.items():
                    if val and not details.get(key):
                        details[key] = val
                        
        except Exception as e:
            details['extraction_error'] = str(e)
        
        return details
    
    def _secure_delete_job(self, job, job_id: str):
        """
        [v2.5.14] Suppression sÃ©curisÃ©e du job IBM aprÃ¨s rÃ©cupÃ©ration des rÃ©sultats.
        
        ğŸ”’ SÃ‰CURITÃ‰ CRYPTOGRAPHIQUE:
        Cette fonction supprime le job du cloud IBM pour Ã©viter que les calculs
        cryptographiques sensibles ne soient accessibles aprÃ¨s exÃ©cution.
        
        âš ï¸ IMPORTANT: Les rÃ©sultats doivent Ãªtre sauvegardÃ©s LOCALEMENT avant l'appel
        car la suppression est IRRÃ‰VERSIBLE.
        
        Args:
            job: Objet job IBM Runtime
            job_id: ID du job pour logging
        """
        try:
            print()
            print("  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            print("  â”‚  ğŸ”’ MODE SÃ‰CURISÃ‰ - SUPPRESSION DU JOB IBM                               â”‚")
            print("  â”‚                                                                          â”‚")
            print(f"  â”‚  Job ID: {job_id:<58} â”‚")
            print("  â”‚                                                                          â”‚")
            print("  â”‚  âš ï¸  Les rÃ©sultats ont Ã©tÃ© sauvegardÃ©s localement.                       â”‚")
            print("  â”‚  ğŸ—‘ï¸  Suppression du job IBM en cours...                                  â”‚")
            print("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            
            # Tenter la suppression via l'API IBM
            deleted = False
            
            # MÃ©thode 1: job.delete() si disponible (Qiskit Runtime rÃ©cent)
            if hasattr(job, 'delete'):
                try:
                    job.delete()
                    deleted = True
                    self.logger.info(f"ğŸ”’ Job {job_id} supprimÃ© via job.delete()")
                except Exception as e:
                    self.logger.debug(f"job.delete() non disponible: {e}")
            
            # MÃ©thode 2: service.delete_job() si disponible
            if not deleted and self.service and hasattr(self.service, 'delete_job'):
                try:
                    self.service.delete_job(job_id)
                    deleted = True
                    self.logger.info(f"ğŸ”’ Job {job_id} supprimÃ© via service.delete_job()")
                except Exception as e:
                    self.logger.debug(f"service.delete_job() non disponible: {e}")
            
            # MÃ©thode 3: Marquer pour suppression via tags (fallback)
            if not deleted:
                try:
                    # Certaines versions permettent de mettre Ã  jour les tags
                    if hasattr(job, 'update_tags'):
                        job.update_tags(['QMC_TO_DELETE', 'CONFIDENTIAL'])
                        self.logger.warn(f"âš ï¸ Job {job_id} marquÃ© pour suppression manuelle (tags)")
                    else:
                        self.logger.warn(f"âš ï¸ Suppression automatique non supportÃ©e - "
                                        f"supprimez manuellement le job {job_id} sur IBM Quantum Dashboard")
                except Exception as e:
                    self.logger.warn(f"âš ï¸ Impossible de marquer le job: {e}")
            
            if deleted:
                print("  âœ… Job supprimÃ© avec succÃ¨s - DonnÃ©es effacÃ©es du cloud IBM")
            else:
                print("  âš ï¸  Suppression auto non disponible - Supprimez manuellement sur IBM Dashboard")
            print()
            
        except Exception as e:
            self.logger.error(f"Erreur lors de la suppression du job: {e}")
            print(f"  âŒ Erreur suppression: {e}")
            print(f"  ğŸ’¡ Supprimez manuellement le job {job_id} sur IBM Quantum Dashboard")
            print()
    
    def _apply_private_tags(self, job, job_id: str):
        """
        [v2.5.14] Applique les tags de confidentialitÃ© au job IBM.
        
        ğŸ” SÃ‰CURITÃ‰: Marque le job avec des tags spÃ©ciaux pour indiquer
        qu'il contient des calculs cryptographiques sensibles.
        
        Args:
            job: Objet job IBM Runtime
            job_id: ID du job pour logging
        """
        private_tags = ['QMC_PRIVATE', 'QMC_CONFIDENTIAL', 'CRYPTO_SENSITIVE']
        
        try:
            applied = False
            
            # MÃ©thode 1: job.update_tags() si disponible (Qiskit Runtime rÃ©cent)
            if hasattr(job, 'update_tags'):
                try:
                    job.update_tags(private_tags)
                    applied = True
                    self.logger.info(f"ğŸ” Tags privÃ©s appliquÃ©s via job.update_tags(): {private_tags}")
                except Exception as e:
                    self.logger.debug(f"job.update_tags() Ã©chouÃ©: {e}")
            
            # MÃ©thode 2: service.update_job() si disponible
            if not applied and self.service:
                # Essayer diffÃ©rentes API selon la version de Qiskit Runtime
                if hasattr(self.service, 'update_job'):
                    try:
                        self.service.update_job(job_id, tags=private_tags)
                        applied = True
                        self.logger.info(f"ğŸ” Tags privÃ©s appliquÃ©s via service.update_job(): {private_tags}")
                    except Exception as e:
                        self.logger.debug(f"service.update_job() Ã©chouÃ©: {e}")
                
                # Alternative: _api_client si disponible
                if not applied and hasattr(self.service, '_api_client'):
                    try:
                        self.service._api_client.job_update(job_id, tags=private_tags)
                        applied = True
                        self.logger.info(f"ğŸ” Tags privÃ©s appliquÃ©s via _api_client: {private_tags}")
                    except Exception as e:
                        self.logger.debug(f"_api_client.job_update() Ã©chouÃ©: {e}")
            
            if applied:
                print(f"  ğŸ” Tags privÃ©s appliquÃ©s: {', '.join(private_tags)}")
            else:
                self.logger.warn(f"âš ï¸ Impossible d'appliquer les tags privÃ©s (API non supportÃ©e)")
                print(f"  âš ï¸ Tags privÃ©s non appliquÃ©s (API IBM non supportÃ©e)")
                print(f"  ğŸ’¡ Le job sera marquÃ© pour suppression manuelle")
                
        except Exception as e:
            self.logger.warn(f"Erreur lors de l'application des tags privÃ©s: {e}")

    def _confirm_qpu_submission(self, circuits: List, shots: int) -> bool:
        """
        [v2.5.14] Demande confirmation OBLIGATOIRE avant envoi QPU.
        
        âš ï¸ SÃ‰CURITÃ‰: Cette confirmation est OBLIGATOIRE par dÃ©faut pour Ã©viter
        les envois accidentels qui consomment du temps QPU.
        
        Affiche un rÃ©sumÃ© du job INCLUANT les stats de transpilation pour 
        permettre Ã  l'utilisateur de juger si le circuit est viable.
        
        Args:
            circuits: Liste des circuits Ã  soumettre (dÃ©jÃ  transpilÃ©s!)
            shots: Nombre de shots par circuit
            
        Returns:
            True si l'utilisateur confirme, False sinon
        """
        n_circuits = len(circuits)
        total_shots = n_circuits * shots
        
        # Calculer les stats des circuits TRANSPILÃ‰S
        total_depth = sum(c.depth() for c in circuits)
        total_2q = sum(
            sum(1 for inst in c.data if len(inst.qubits) == 2)
            for c in circuits
        )
        max_qubits = max(c.num_qubits for c in circuits) if circuits else 0
        
        # Calculer les moyennes par circuit
        avg_depth = total_depth / n_circuits if n_circuits > 0 else 0
        avg_2q = total_2q / n_circuits if n_circuits > 0 else 0
        
        # Estimer le coÃ»t approximatif
        estimated_time_s = n_circuits * 2.0 + (total_shots / 100000) * 5.0
        
        # RÃ©cupÃ©rer les stats de transpilation si disponibles
        trans_stats = getattr(self, '_last_transpilation_stats', None)
        
        print()
        print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print("  â•‘     âš ï¸âš ï¸âš ï¸  CONFIRMATION OBLIGATOIRE AVANT ENVOI QPU  âš ï¸âš ï¸âš ï¸")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        # Section TRANSPILATION avec recommandation
        if trans_stats:
            score = trans_stats.get('score', 50)
            overhead = trans_stats.get('overhead_2q_percent', 0)
            swaps = trans_stats.get('swaps_estimated', 0)
            recommendation = trans_stats.get('recommendation', 'WARN')
            
            # Couleur et emoji selon recommandation
            if recommendation == 'GO':
                rec_display = "ğŸŸ¢ GO"
                rec_msg = "Circuit bien optimisÃ©, exÃ©cution recommandÃ©e"
            elif recommendation == 'WARN':
                rec_display = "ğŸŸ¡ WARN"
                rec_msg = "Overhead modÃ©rÃ©, vÃ©rifiez si acceptable"
            else:  # NO-GO
                rec_display = "ğŸ”´ NO-GO"
                rec_msg = "âš ï¸ OVERHEAD EXCESSIF - Annulation recommandÃ©e!"
            
            print(f"  â•‘  ğŸ“ QUALITÃ‰ TRANSPILATION:")
            print(f"  â•‘     â€¢ Score:         {score}/100 ({rec_display})")
            print(f"  â•‘     â€¢ Overhead 2Q:   {overhead:+.1f}%")
            print(f"  â•‘     â€¢ SWAPs estimÃ©s: ~{swaps}")
            print(f"  â•‘     â†’ {rec_msg}")
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        print(f"  â•‘  ğŸ“Š RÃ‰SUMÃ‰ DU JOB:")
        print(f"  â•‘     â€¢ Circuits:      {n_circuits}")
        print(f"  â•‘     â€¢ Shots/circuit: {shots:,}")
        print(f"  â•‘     â€¢ Total shots:   {total_shots:,}")
        print(f"  â•‘     â€¢ Max qubits:    {max_qubits}")
        print(f"  â•‘     â€¢ Profondeur:    {avg_depth:.0f} moy/circuit ({total_depth} total)")
        print(f"  â•‘     â€¢ Portes 2Q:     {avg_2q:.0f} moy/circuit ({total_2q} total)")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print(f"  â•‘  ğŸ–¥ï¸  Backend:         {self.backend_name}")
        print(f"  â•‘  â±ï¸  Temps estimÃ©:    ~{estimated_time_s:.0f}s (hors file d'attente)")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print("  â•‘  ğŸ’° ATTENTION: Cet envoi va CONSOMMER du temps QPU!")
        
        # Avertissement spÃ©cial si NO-GO
        if trans_stats and trans_stats.get('recommendation') == 'NO-GO':
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            print("  â•‘  ğŸš¨ ATTENTION: Le circuit a un overhead excessif (>100%)!")
            print("  â•‘     â†’ L'exÃ©cution risque de donner des rÃ©sultats inutilisables")
            print("  â•‘     â†’ Recommandation: Annuler et revoir la topologie du circuit")
        
        print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
        
        # Demander confirmation
        try:
            while True:
                if trans_stats and trans_stats.get('recommendation') == 'NO-GO':
                    response = input("  ğŸ”´ Circuit dÃ©conseillÃ©! Confirmer quand mÃªme? [oui/non]: ").strip().lower()
                else:
                    response = input("  ğŸ”´ Confirmer l'envoi sur QPU? [oui/non]: ").strip().lower()
                
                if response in ['oui', 'o', 'yes', 'y', '1']:
                    print()
                    print("  âœ… Envoi CONFIRMÃ‰ - Soumission en cours...")
                    print()
                    return True
                elif response in ['non', 'n', 'no', '0']:
                    print()
                    print("  âŒ Envoi ANNULÃ‰ par l'utilisateur")
                    return False
                else:
                    print("  âš ï¸ RÃ©pondez 'oui' ou 'non'")
                    
        except KeyboardInterrupt:
            print("\n  âŒ Envoi ANNULÃ‰ (Ctrl+C)")
            return False
        except EOFError:
            # Mode non-interactif (pipe, etc.) - annuler par sÃ©curitÃ©
            print("\n  âŒ Envoi ANNULÃ‰ (mode non-interactif dÃ©tectÃ©)")
            print("  ğŸ’¡ Utilisez auto_confirm=True pour les scripts automatisÃ©s")
            return False

    def _display_security_banner(self):
        """
        [v2.5.14] Affiche un banner de sÃ©curitÃ© si mode privÃ©/auto_delete/redact activÃ©.
        
        Informe l'utilisateur que le mode sÃ©curisÃ© est actif pour protÃ©ger
        les calculs cryptographiques sensibles.
        """
        print()
        print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        if self.production_mode:
            print("  â•‘     ğŸ”’ğŸ”’ğŸ”’ MODE PRODUCTION SÃ‰CURISÃ‰ ACTIVÃ‰ (TRIPTYQUE) ğŸ”’ğŸ”’ğŸ”’")
        else:
            print("  â•‘         ğŸ”’ MODE SÃ‰CURITÃ‰ CRYPTOGRAPHIQUE ACTIVÃ‰ ğŸ”’")
        
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        if self.private:
            print("  â•‘  ğŸ” PRIVATE MODE: Job marquÃ© comme confidentiel (tags IBM)")
        
        if self.auto_delete_job:
            print("  â•‘  ğŸ—‘ï¸  AUTO-DELETE: Job supprimÃ© aprÃ¨s rÃ©cupÃ©ration des rÃ©sultats")
        
        if self.redact_logs:
            print("  â•‘  ğŸ“ REDACT-LOGS: Logs rÃ©duits au minimum (niveau WARNING)")
        
        if self.auto_delete_job:
            print("  â•‘")
            print("  â•‘  âš ï¸  Les rÃ©sultats seront sauvegardÃ©s LOCALEMENT uniquement")
            print("  â•‘  âš ï¸  Le job sera EFFACÃ‰ du cloud IBM aprÃ¨s exÃ©cution")
        
        print("  â•‘")
        print("  â•‘  ğŸ’¡ Protection contre l'accÃ¨s IBM aux calculs cryptographiques")
        print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
        sys.stdout.flush()

    def _display_upload_animation(self, n_circuits: int, shots: int):
        """
        [v2.5.14] Affiche un message d'upload visible.
        """
        total_shots = n_circuits * shots
        estimated_size_mb = (n_circuits * 50) / 1024  # ~50KB par circuit transpilÃ©
        
        print()
        print("  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print("  â”‚  ğŸ“¤ UPLOAD VERS IBM QUANTUM...")
        print(f"  â”‚     Circuits: {n_circuits}  Shots: {shots:,}")
        print(f"  â”‚     Total: {total_shots:,} mesures (~{estimated_size_mb:.1f} MB de donnÃ©es)")
        print("  â”‚     â³ Veuillez patienter...")
        print("  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        sys.stdout.flush()
    
    def _submit_with_upload_animation(self, sampler, circuits, shots: int, 
                                       retry_manager) -> Any:
        """
        [v2.5.14] Soumet le job avec une animation pendant l'upload.
        """
        import threading
        
        result = {'job': None, 'error': None}
        upload_done = threading.Event()
        
        # Animation frames
        upload_frames = [
            'ğŸ“¤ [â– â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡]  10%',
            'ğŸ“¤ [â– â– â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡]  20%',
            'ğŸ“¤ [â– â– â– â–¡â–¡â–¡â–¡â–¡â–¡â–¡]  30%',
            'ğŸ“¤ [â– â– â– â– â–¡â–¡â–¡â–¡â–¡â–¡]  40%',
            'ğŸ“¤ [â– â– â– â– â– â–¡â–¡â–¡â–¡â–¡]  50%',
            'ğŸ“¤ [â– â– â– â– â– â– â–¡â–¡â–¡â–¡]  60%',
            'ğŸ“¤ [â– â– â– â– â– â– â– â–¡â–¡â–¡]  70%',
            'ğŸ“¤ [â– â– â– â– â– â– â– â– â–¡â–¡]  80%',
            'ğŸ“¤ [â– â– â– â– â– â– â– â– â– â–¡]  90%',
            'ğŸ“¤ [â– â– â– â– â– â– â– â– â– â– ] 100%',
        ]
        
        def animate():
            """Thread d'animation pendant upload"""
            frame_idx = 0
            start = time.time()
            
            while not upload_done.is_set():
                elapsed = time.time() - start
                
                # Progression simulÃ©e (on ne connaÃ®t pas la vraie progression)
                # Monte progressivement vers 90%, puis reste Ã  90% jusqu'Ã  la fin
                progress = min(0.9, elapsed / 30)  # 30s pour atteindre 90%
                frame_idx = int(progress * (len(upload_frames) - 1))
                frame_idx = min(frame_idx, len(upload_frames) - 2)  # Max 90%
                
                frame = upload_frames[frame_idx]
                line = f"\r  {frame}  Envoi... ({elapsed:.0f}s)          "
                
                try:
                    sys.stdout.write(line)
                    sys.stdout.flush()
                except:
                    pass
                
                upload_done.wait(0.5)
            
            # Afficher 100% Ã  la fin
            try:
                elapsed = time.time() - start
                sys.stdout.write(f"\r  ğŸ“¤ [â– â– â– â– â– â– â– â– â– â– ] 100%  EnvoyÃ©! ({elapsed:.1f}s)          \n")
                sys.stdout.flush()
            except:
                pass
        
        def submit():
            """Thread de soumission"""
            try:
                def submit_job():
                    return sampler.run(circuits, shots=shots)
                
                result['job'] = retry_manager.execute_with_retry(
                    submit_job,
                    operation_name="QPU_SUBMISSION"
                )
            except Exception as e:
                result['error'] = e
                # [v2.5.15] Extraire les dÃ©tails d'erreur IBM
                result['error_details'] = self._extract_ibm_error_details(e)
            finally:
                upload_done.set()
        
        # DÃ©marrer les deux threads
        anim_thread = threading.Thread(target=animate, daemon=True)
        submit_thread = threading.Thread(target=submit)
        
        anim_thread.start()
        submit_thread.start()
        
        # Attendre la fin de la soumission
        submit_thread.join()
        anim_thread.join(timeout=1)
        
        if result['error']:
            # [v2.5.15] Afficher les dÃ©tails de l'erreur de soumission
            error = result['error']
            error_details = result.get('error_details', {})
            
            print()
            print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
            print("  â•‘  âŒ ERREUR DE SOUMISSION IBM QUANTUM                                       â•‘")
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            
            # Type d'erreur
            error_type = type(error).__name__
            print(f"  â•‘  ğŸ”´ Type:     {error_type:<58} â•‘")
            
            # Message d'erreur (tronquÃ© si nÃ©cessaire)
            error_msg = str(error)
            if len(error_msg) > 65:
                # DÃ©couper en lignes
                words = error_msg.split()
                lines = []
                current_line = ""
                for word in words:
                    if len(current_line) + len(word) + 1 <= 65:
                        current_line += (" " if current_line else "") + word
                    else:
                        if current_line:
                            lines.append(current_line)
                        current_line = word
                if current_line:
                    lines.append(current_line)
                
                for i, line in enumerate(lines[:4]):
                    prefix = "  â•‘  ğŸ’¬ Message: " if i == 0 else "  â•‘             "
                    print(f"{prefix}{line:<58} â•‘")
            else:
                print(f"  â•‘  ğŸ’¬ Message: {error_msg:<58} â•‘")
            
            # DÃ©tails IBM si disponibles
            if error_details:
                if error_details.get('error_code'):
                    print(f"  â•‘  ğŸ”¢ Code:    {error_details['error_code']:<58} â•‘")
                if error_details.get('ibm_message'):
                    ibm_msg = error_details['ibm_message'][:55] + "..." if len(error_details.get('ibm_message', '')) > 55 else error_details.get('ibm_message', '')
                    print(f"  â•‘  ğŸ“‹ IBM:     {ibm_msg:<58} â•‘")
            
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            print("  â•‘  ğŸ’¡ CAUSES POSSIBLES:                                                      â•‘")
            
            # Analyser la cause probable
            error_lower = str(error).lower()
            causes_shown = 0
            
            if "authentication" in error_lower or "credential" in error_lower or "401" in error_lower:
                print("  â•‘     â€¢ ProblÃ¨me d'authentification - vÃ©rifiez votre API key                 â•‘")
                causes_shown += 1
            if "quota" in error_lower or "limit" in error_lower or "exceeded" in error_lower:
                print("  â•‘     â€¢ Quota dÃ©passÃ© - attendez ou utilisez un autre compte                 â•‘")
                causes_shown += 1
            if "backend" in error_lower or "not found" in error_lower or "unavailable" in error_lower:
                print("  â•‘     â€¢ Backend indisponible - essayez un autre backend                      â•‘")
                causes_shown += 1
            if "circuit" in error_lower or "too" in error_lower:
                print("  â•‘     â€¢ Circuit trop complexe - rÃ©duisez la profondeur ou le nombre de qubitsâ•‘")
                causes_shown += 1
            if "timeout" in error_lower or "connection" in error_lower:
                print("  â•‘     â€¢ ProblÃ¨me rÃ©seau - vÃ©rifiez votre connexion Internet                  â•‘")
                causes_shown += 1
            if "rate" in error_lower:
                print("  â•‘     â€¢ Rate limiting - attendez quelques secondes et rÃ©essayez              â•‘")
                causes_shown += 1
            
            if causes_shown == 0:
                print("  â•‘     â€¢ Erreur inconnue - consultez la documentation IBM Quantum             â•‘")
            
            print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            print()
            
            # Logger les dÃ©tails complets
            if hasattr(self, 'logger') and self.logger:
                self.logger.error(f"Erreur soumission: {error_type}: {error}")
                if error_details:
                    self.logger.error(f"DÃ©tails IBM: {error_details}")
            
            raise error
        
        return result['job']

    def _display_job_submitted_banner(self, job_id: str, n_circuits: int, shots: int):
        """
        [v2.5.14] Affiche un banner bien visible quand un job est soumis.
        
        Donne les informations essentielles et prÃ©pare l'utilisateur Ã  attendre.
        """
        # Estimation du temps (trÃ¨s approximative)
        # IBM Heron: ~0.5-2s par circuit selon profondeur + queue time
        estimated_execution = n_circuits * 1.5  # secondes d'exÃ©cution pure
        
        total_shots = n_circuits * shots
        
        # Mode sÃ©curitÃ©
        security_mode = []
        if self.private:
            security_mode.append("ğŸ” PRIVATE")
        if self.auto_delete_job:
            security_mode.append("ğŸ—‘ï¸ AUTO-DELETE")
        security_str = " + ".join(security_mode) if security_mode else "Standard"
        
        print()
        print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        if security_mode:
            print("  â•‘        ğŸš€ğŸ”’ JOB SOUMIS - MODE SÃ‰CURISÃ‰ ACTIVÃ‰ ğŸ”’ğŸš€                         â•‘")
        else:
            print("  â•‘           ğŸš€ JOB SOUMIS Ã€ IBM QUANTUM - EN ATTENTE ğŸš€                      â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  ğŸ“‹ Job ID:     {job_id:<54} â•‘")
        print(f"  â•‘  ğŸ”¢ Circuits:   {n_circuits:<10} Ã— {shots:,} shots = {total_shots:,} mesures       â•‘")
        print(f"  â•‘  ğŸ–¥ï¸  Backend:    {self.backend_name:<54} â•‘")
        if security_mode:
            print(f"  â•‘  ğŸ”’ SÃ©curitÃ©:   {security_str:<54} â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  â³ Statut: QUEUED â†’ RUNNING â†’ DONE                                        â•‘")
        print("  â•‘  ğŸ’¡ Le job peut prendre plusieurs minutes selon la file d'attente IBM     â•‘")
        if self.auto_delete_job:
            print("  â•‘  ğŸ—‘ï¸  Le job sera SUPPRIMÃ‰ aprÃ¨s rÃ©cupÃ©ration des rÃ©sultats                â•‘")
        print("  â•‘  ğŸ”„ Animation ci-dessous pour suivre la progression...                    â•‘")
        print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
        sys.stdout.flush()
    
    def _monitor_job_with_animation(self, job, timeout: float = None, 
                                    n_circuits: int = 1, shots: int = 4096) -> Dict:
        """
        [v2.5.14] Monitor un job avec animation d'attente visible.
        
        Affiche une progression continue pour que l'utilisateur sache que Ã§a fonctionne.
        """
        import sys
        import threading
        
        start_time = time.time()
        last_status = None
        stop_animation = threading.Event()
        
        # Animation frames
        quantum_frames = ['|0âŸ©', '|+âŸ©', '|1âŸ©', '|-âŸ©', '|ÏˆâŸ©', '|Ï†âŸ©']
        progress_frames = ['[â– â–¡â–¡â–¡â–¡]', '[â– â– â–¡â–¡â–¡]', '[â– â– â– â–¡â–¡]', '[â– â– â– â– â–¡]', '[â– â– â– â– â– ]', '[â–¡â– â– â– â– ]', '[â–¡â–¡â– â– â– ]', '[â–¡â–¡â–¡â– â– ]', '[â–¡â–¡â–¡â–¡â– ]', '[â–¡â–¡â–¡â–¡â–¡]']
        
        def animate():
            """Thread d'animation"""
            frame_idx = 0
            while not stop_animation.is_set():
                elapsed = time.time() - start_time
                
                # Choisir l'animation selon le statut
                if last_status == 'QUEUED':
                    anim = progress_frames[frame_idx % len(progress_frames)]
                    msg = f"En file d'attente IBM..."
                elif last_status == 'RUNNING':
                    anim = quantum_frames[frame_idx % len(quantum_frames)]
                    msg = f"ExÃ©cution QPU en cours..."
                else:
                    anim = "â³"
                    msg = "Initialisation..."
                
                # Formater la ligne
                line = f"\r  {anim} {msg} ({elapsed:.0f}s)                    "
                
                try:
                    sys.stdout.write(line)
                    sys.stdout.flush()
                except:
                    pass
                
                frame_idx += 1
                stop_animation.wait(0.3)
            
            # Effacer la ligne d'animation
            try:
                sys.stdout.write("\r" + " " * 70 + "\r")
                sys.stdout.flush()
            except:
                pass
        
        # DÃ©marrer l'animation
        anim_thread = threading.Thread(target=animate, daemon=True)
        anim_thread.start()
        
        # Monitoring du job
        metrics = {'phases': []}
        phase_start = start_time
        
        try:
            while True:
                try:
                    status = str(job.status())
                    elapsed = time.time() - start_time
                    
                    # Timeout
                    if timeout and elapsed > timeout:
                        stop_animation.set()
                        anim_thread.join(timeout=1)
                        print(f"\n  âš ï¸  TIMEOUT aprÃ¨s {elapsed:.0f}s - Job ID: {job.job_id()}")
                        print(f"  ğŸ’¡ Vous pouvez reprendre les rÃ©sultats plus tard avec ce Job ID")
                        try:
                            job.cancel()
                        except:
                            pass
                        metrics['timeout'] = True
                        break
                    
                    # Changement de statut
                    if status != last_status:
                        phase_duration = time.time() - phase_start
                        
                        if last_status:
                            metrics['phases'].append({
                                'status': last_status,
                                'duration_s': round(phase_duration, 1)
                            })
                        
                        # Afficher le changement
                        stop_animation.set()
                        anim_thread.join(timeout=1)
                        
                        if status == 'QUEUED':
                            print(f"  ğŸ“‹ [{elapsed:>6.0f}s] Status: QUEUED - En file d'attente IBM")
                        elif status == 'RUNNING':
                            print(f"  âš¡ [{elapsed:>6.0f}s] Status: RUNNING - ExÃ©cution sur {self.backend_name}")
                        elif status == 'DONE':
                            print(f"  âœ… [{elapsed:>6.0f}s] Status: DONE - TerminÃ©!")
                        elif status == 'ERROR':
                            print(f"  âŒ [{elapsed:>6.0f}s] Status: ERROR - Ã‰chec du job")
                        elif status == 'CANCELLED':
                            print(f"  ğŸš« [{elapsed:>6.0f}s] Status: CANCELLED - Job annulÃ©")
                        else:
                            print(f"  ğŸ“Š [{elapsed:>6.0f}s] Status: {status}")
                        
                        last_status = status
                        phase_start = time.time()
                        
                        # Relancer l'animation si pas terminÃ©
                        if status not in ['DONE', 'ERROR', 'CANCELLED']:
                            stop_animation.clear()
                            anim_thread = threading.Thread(target=animate, daemon=True)
                            anim_thread.start()
                    
                    # Job terminÃ©
                    if status in ['DONE', 'ERROR', 'CANCELLED']:
                        break
                    
                    time.sleep(5)  # Polling interval
                    
                except Exception as e:
                    self.logger.warn(f"Monitor error: {e}")
                    time.sleep(5)
        
        finally:
            stop_animation.set()
            try:
                anim_thread.join(timeout=1)
            except:
                pass
        
        total_time = time.time() - start_time
        metrics['total_time_s'] = round(total_time, 1)
        metrics['final_status'] = last_status
        
        # Afficher un rÃ©sumÃ© final
        print()
        print(f"  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print(f"  â•‘  ğŸ“Š RÃ‰SUMÃ‰ EXÃ‰CUTION QPU                                                   â•‘")
        print(f"  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  ğŸ†” Job:     {job.job_id():<58} â•‘")
        print(f"  â•‘  â±ï¸  DurÃ©e:   {total_time:.1f}s total                                              â•‘")
        
        # DÃ©tail des phases
        for phase in metrics.get('phases', []):
            status_emoji = {'QUEUED': 'ğŸ“‹', 'RUNNING': 'âš¡'}.get(phase['status'], 'ğŸ“Š')
            print(f"  â•‘     {status_emoji} {phase['status']}: {phase['duration_s']:.1f}s                                           â•‘")
        
        status_emoji = {'DONE': 'âœ…', 'ERROR': 'âŒ', 'CANCELLED': 'ğŸš«'}.get(last_status, 'ğŸ“Š')
        print(f"  â•‘  {status_emoji} Final:  {last_status:<58} â•‘")
        print(f"  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
        
        return metrics

    def _display_calibration_summary_compact(self):
        """
        Affiche un rÃ©sumÃ© compact et visuel de la calibration du backend.
        
        [v2.5.3] AppelÃ© automatiquement avant l'exÃ©cution QPU.
        """
        if not hasattr(self, 'circuit_optimizer') or not self.circuit_optimizer:
            return
        
        opt = self.circuit_optimizer
        
        # Statistiques rapides
        n_qubits = len(opt.qubits)
        n_operational = sum(1 for c in opt.qubits.values() if c.operational)
        faulty = opt.get_faulty_qubits()
        n_faulty = len(faulty)
        
        # Score moyen
        scores = [c.quality_score() for c in opt.qubits.values() if c.operational]
        avg_score = sum(scores) / len(scores) if scores else 0
        
        # Top 5 meilleurs
        ranking = opt.get_qubit_ranking()[:5]
        
        # Qubits biaisÃ©s
        biased = [q for q, c in opt.qubits.items() if c.is_biased]
        
        # Emoji de qualitÃ© globale
        if avg_score >= 0.80:
            quality_emoji = "ğŸŸ¢"
            quality_text = "EXCELLENT"
        elif avg_score >= 0.65:
            quality_emoji = "ğŸŸ¡"
            quality_text = "GOOD"
        elif avg_score >= 0.50:
            quality_emoji = "ğŸŸ "
            quality_text = "MODERATE"
        else:
            quality_emoji = "ğŸ”´"
            quality_text = "POOR"
        
        # Barre de progression
        bar_len = 20
        filled = int(avg_score * bar_len)
        bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
        
        # Affichage compact mais visuel
        lines = []
        lines.append("")
        lines.append("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        lines.append("  â•‘         ğŸ”¬ CIRCUIT OPTIMIZER v2.5.3 - PRE-EXECUTION ANALYSIS ğŸ”¬            â•‘")
        lines.append("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        lines.append(f"  â•‘  ğŸ“¡ Backend: {self.backend_name:<20}  {quality_emoji} Status: {quality_text}")
        lines.append(f"  â•‘  ğŸ“Š Quality: [{bar}] {avg_score:.1%}")
        lines.append(f"  â•‘  ğŸ”¢ Qubits: {n_operational}/{n_qubits} operational   ğŸ’€ Faulty: {n_faulty}   âš ï¸ Biased: {len(biased)}")
        lines.append("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        
        # Top 5 avec barres
        lines.append("  â•‘  ğŸ† TOP 5 QUBITS:")
        for i, (q, score) in enumerate(ranking):
            medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"][i]
            mini_bar = "â–ˆ" * int(score * 10) + "â–‘" * (10 - int(score * 10))
            lines.append(f"  â•‘     {medal} Q{q:>3} [{mini_bar}] {score:.0%}")
        
        lines.append("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        
        # Faulty
        if faulty:
            faulty_str = ", ".join([f"Q{q}" for q in sorted(faulty)[:6]])
            if len(faulty) > 6:
                faulty_str += f"... (+{len(faulty)-6})"
            lines.append(f"  â•‘  ğŸ’€ AVOID: {faulty_str}")
        
        if biased:
            biased_str = ", ".join([f"Q{q}" for q in sorted(biased)[:4]])
            if len(biased) > 4:
                biased_str += f"... (+{len(biased)-4})"
            lines.append(f"  â•‘  âš ï¸  BIASED: {biased_str}")
        
        lines.append("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        lines.append("  â•‘  âœ… Optimal layout will be calculated automatically for your circuits")
        lines.append("  â•‘  ğŸ¯ Circuits will be placed on highest-quality qubits")
        lines.append("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        lines.append("")
        
        for line in lines:
            print(line)
    
    def _process_results(self, result, circuits: List, save_counts: bool) -> List[Dict]:
        """
        Traite les rÃ©sultats du job.
        
        [v2.5.3] Inclut maintenant transpiled_depth et gates_2q dans les rÃ©sultats.
        [v2.5.21] Ajout warning si plusieurs registres classiques dÃ©tectÃ©s.
        [v2.5.21] Support multi-format: QPU, StatevectorSampler, AerSimulator, QuasiDistribution.
        
        Formats supportÃ©s:
        - SamplerV2 IBM Runtime (QPU): pub_result.data.c.get_counts() â†’ {'00': 500}
        - StatevectorSampler: pub_result.data.meas.get_counts() â†’ {'00': 500}
        - BackendSamplerV2 + Aer: pub_result.data.<reg>.get_counts() â†’ {'00': 500}
        - Ancien Sampler (quasi_dists): {0: 0.5, 1: 0.5} â†’ converti en counts
        """
        results = []
        all_counts = {}
        
        # RÃ©cupÃ©rer les infos de transpilation si disponibles
        circuits_info = self.report.get('circuits_transpiled', section='transpilation') or []
        
        # [v2.5.21] DÃ©tecter le nombre de qubits depuis les circuits si disponible
        n_qubits_from_circuits = None
        if circuits:
            try:
                if hasattr(circuits[0], 'num_qubits'):
                    n_qubits_from_circuits = circuits[0].num_qubits
            except:
                pass
        
        for i, pub_result in enumerate(result):
            counts = {}
            found_register = None
            result_format = 'unknown'
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # FORMAT 1: PubResult avec BitArray (SamplerV2 / StatevectorSampler)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if hasattr(pub_result, 'data'):
                # Essayer diffÃ©rents noms de registres classiques
                possible_names = ['c', 'meas', 'c_data', 'c_anc', 'cr', 'classical', 'measure']
                
                for name in possible_names:
                    try:
                        cr_data = getattr(pub_result.data, name, None)
                        if cr_data is not None:
                            counts = cr_data.get_counts()
                            if counts:
                                found_register = name
                                result_format = 'BitArray'
                                break
                    except:
                        pass
                
                # Si toujours vide, essayer d'itÃ©rer sur tous les attributs de data
                if not counts:
                    found_registers = []
                    try:
                        for attr_name in dir(pub_result.data):
                            if not attr_name.startswith('_'):
                                try:
                                    attr = getattr(pub_result.data, attr_name)
                                    if hasattr(attr, 'get_counts'):
                                        c = attr.get_counts()
                                        if c:
                                            found_registers.append(attr_name)
                                            result_format = 'BitArray'
                                            # Fusionner les counts de tous les registres
                                            for k, v in c.items():
                                                counts[k] = counts.get(k, 0) + v
                                except:
                                    pass
                    except:
                        pass
                    
                    # [v2.5.21] Warning si plusieurs registres dÃ©tectÃ©s
                    if len(found_registers) > 1:
                        self.logger.warn(
                            f"âš ï¸ Circuit {i}: {len(found_registers)} registres classiques dÃ©tectÃ©s "
                            f"({', '.join(found_registers)}). Les counts ont Ã©tÃ© fusionnÃ©s - "
                            f"vÃ©rifiez qu'il n'y a pas de collision de bitstrings."
                        )
                    elif found_registers:
                        found_register = found_registers[0]
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # FORMAT 2: QuasiDistribution (ancien Sampler - clÃ©s entiÃ¨res!)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if not counts:
                # VÃ©rifier si c'est une QuasiDistribution ou dict avec clÃ©s entiÃ¨res
                if hasattr(pub_result, 'items') or isinstance(pub_result, dict):
                    quasi_dist = pub_result if isinstance(pub_result, dict) else dict(pub_result)
                    if quasi_dist:
                        # DÃ©tecter si les clÃ©s sont des entiers
                        first_key = next(iter(quasi_dist.keys()))
                        if isinstance(first_key, int):
                            result_format = 'QuasiDistribution'
                            self.logger.info(f"  ğŸ“Š Circuit {i}: Format QuasiDistribution dÃ©tectÃ© (clÃ©s entiÃ¨res)")
                            
                            # DÃ©terminer le nombre de qubits
                            max_key = max(quasi_dist.keys())
                            n_qubits = max(max_key.bit_length(), 1)
                            if n_qubits_from_circuits:
                                n_qubits = n_qubits_from_circuits
                            
                            # Convertir entiers â†’ bitstrings, probas â†’ counts
                            total_prob = sum(abs(v) for v in quasi_dist.values())
                            shots_estimate = 1024  # Estimation par dÃ©faut
                            
                            for key_int, prob in quasi_dist.items():
                                bitstring = format(key_int, f'0{n_qubits}b')
                                # Convertir proba en count (arrondi)
                                count = int(round(abs(prob) * shots_estimate))
                                if count > 0:
                                    counts[bitstring] = count
                            
                            self.logger.debug(
                                f"  â†’ Converti {len(quasi_dist)} Ã©tats (entiers) â†’ "
                                f"{len(counts)} bitstrings ({n_qubits} qubits)"
                            )
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # FORMAT 3: Dict direct avec bitstrings (certains simulateurs)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if not counts and isinstance(pub_result, dict):
                first_key = next(iter(pub_result.keys()), None)
                if first_key and isinstance(first_key, str) and all(c in '01' for c in first_key):
                    counts = pub_result.copy()
                    result_format = 'dict_bitstrings'
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # NORMALISATION FINALE DES COUNTS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            counts = self._normalize_counts_format(counts, circuit_index=i)
            
            total = sum(counts.values()) if counts else 0
            unique = len(counts)
            
            res = {
                'circuit_index': i,
                'shots': total,
                'unique_states': unique,
                'counts': counts,
                'result_format': result_format,  # [v2.5.21] TraÃ§abilitÃ© du format
            }
            
            if counts:
                first_key = next(iter(counts.keys()))
                res['n_qubits'] = len(first_key)
            
            # [v2.5.3] Ajouter les infos de transpilation
            if i < len(circuits_info):
                info = circuits_info[i]
                res['transpiled_depth'] = info.get('transpiled_depth')
                res['gates_2q'] = info.get('gates_2q')
                res['optimal_layout'] = info.get('optimal_layout')
                res['vf2_applied'] = info.get('vf2_applied', False)
            
            results.append(res)
            all_counts[f'circuit_{i}'] = counts
        
        if save_counts:
            self.dir_manager.save_json('counts', all_counts)
        
        self.report.set('results', results, section='execution')
        return results
    
    def _normalize_counts_format(self, counts: Dict, circuit_index: int = 0) -> Dict[str, int]:
        """
        [v2.5.22] Normalise les counts pour un format uniforme SI NÃ‰CESSAIRE.
        
        âš ï¸ GARANTIE DE NON-ALTÃ‰RATION:
        Si les counts sont DÃ‰JÃ€ au format correct (clÃ©s=bitstrings str, valeurs=int positifs),
        cette fonction retourne les counts ORIGINAUX sans modification.
        
        Cas oÃ¹ la normalisation est appliquÃ©e:
        - ClÃ©s entiÃ¨res (QuasiDistribution): {0: 500, 3: 500} â†’ {'00': 500, '11': 500}
        - Valeurs float (probas): {'00': 0.5} â†’ {'00': 512}
        - PrÃ©fixe '0b': {'0b00': 500} â†’ {'00': 500}
        - Valeurs nÃ©gatives (quasi-probas): {0: -0.1} â†’ {'00': 102}
        
        Cas oÃ¹ les counts sont retournÃ©s AS-IS (aucune modification):
        - Format QPU standard: {'00': 500, '11': 500} â†’ IDENTIQUE
        - Format simulateur standard: {'000': 1024} â†’ IDENTIQUE
        
        Args:
            counts: Dict potentiellement mal formatÃ©
            circuit_index: Index du circuit (pour logging)
            
        Returns:
            Dict normalisÃ© {bitstring: int} - IDENTIQUE Ã  l'original si dÃ©jÃ  correct
        """
        if not counts:
            return {}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FAST PATH: VÃ©rifier si le format est dÃ©jÃ  correct (cas QPU normal)
        # Si oui, retourner les counts ORIGINAUX sans aucune modification
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        needs_conversion = False
        
        for key, value in counts.items():
            # VÃ©rifier la clÃ©
            if not isinstance(key, str):
                needs_conversion = True
                break
            if key.startswith('0b') or not all(c in '01' for c in key):
                needs_conversion = True
                break
            
            # VÃ©rifier la valeur
            if not isinstance(value, int) or value < 0:
                needs_conversion = True
                break
        
        # Si format dÃ©jÃ  correct, retourner l'original SANS COPIE
        if not needs_conversion:
            return counts  # â† IDENTIQUE, pas de modification
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SLOW PATH: Conversion nÃ©cessaire (format exotique dÃ©tectÃ©)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.logger.debug(f"  ğŸ”„ Circuit {circuit_index}: Conversion de format dÃ©tectÃ©e")
        
        normalized = {}
        
        # DÃ©terminer n_qubits pour les clÃ©s entiÃ¨res
        n_qubits_hint = None
        for key in counts.keys():
            if isinstance(key, str) and all(c in '01' for c in key.replace('0b', '')):
                n_qubits_hint = len(key.replace('0b', ''))
                break
        
        # Calculer le max pour les clÃ©s entiÃ¨res
        max_int_key = 0
        for key in counts.keys():
            if isinstance(key, int):
                max_int_key = max(max_int_key, key)
        
        n_bits = n_qubits_hint or max(max_int_key.bit_length(), 1)
        
        # DÃ©tecter si ce sont des probabilitÃ©s
        total_value = sum(abs(v) for v in counts.values() if isinstance(v, (int, float)))
        is_probabilities = 0 < total_value <= 1.1
        shots_estimate = 1024  # Pour conversion proba â†’ counts
        
        for key, value in counts.items():
            # === Normaliser la clÃ© ===
            if isinstance(key, int):
                new_key = format(key, f'0{n_bits}b')
            elif isinstance(key, str):
                new_key = key.strip()
                if new_key.startswith('0b'):
                    new_key = new_key[2:]
                if not all(c in '01' for c in new_key):
                    self.logger.warn(f"âš ï¸ Circuit {circuit_index}: ClÃ© invalide '{key}' ignorÃ©e")
                    continue
            else:
                self.logger.warn(f"âš ï¸ Circuit {circuit_index}: Type de clÃ© non supportÃ© {type(key)}")
                continue
            
            # === Normaliser la valeur ===
            if isinstance(value, float):
                if is_probabilities:
                    new_value = int(round(abs(value) * shots_estimate))
                else:
                    new_value = int(round(abs(value)))
            elif isinstance(value, int):
                new_value = abs(value)
            else:
                try:
                    new_value = int(abs(float(value)))
                except:
                    self.logger.warn(f"âš ï¸ Circuit {circuit_index}: Valeur invalide {value} pour '{key}'")
                    continue
            
            if new_value > 0:
                normalized[new_key] = normalized.get(new_key, 0) + new_value
        
        self.logger.info(
            f"  ğŸ“Š Circuit {circuit_index}: Format converti "
            f"({len(counts)} entrÃ©es â†’ {len(normalized)} bitstrings)"
        )
        
        return normalized
    
    # =========================================================================
    # MODULE SYSTEM
    # =========================================================================
    
    def load_module(self, name: str, config: Dict = None) -> QMCModule:
        """
        Charge et initialise un module QMC.
        
        Args:
            name: Nom du module
            config: Configuration du module
        
        Returns:
            Instance du module initialisÃ©
        """
        if name in self._loaded_modules:
            return self._loaded_modules[name]
        
        module_cls = self._registry.get_module(name)
        if module_cls is None:
            raise ValueError(f"Module '{name}' not found. Available: {self._registry.list_modules()}")
        
        module = module_cls(self)
        module.initialize(config)
        
        self._loaded_modules[name] = module
        self.logger.info(f"Loaded module: {name} v{module.get_version()}")
        
        return module
    
    def get_circuit_builder(self, name: str) -> CircuitBuilder:
        """
        Obtient un circuit builder.
        
        Args:
            name: Nom du builder (ghz, iqp, bell, random, etc.)
        
        Returns:
            Instance du builder
        """
        builder_cls = self._registry.get_circuit_builder(name)
        if builder_cls is None:
            raise ValueError(f"Builder '{name}' not found. Available: {self._registry.list_circuit_builders()}")
        
        return builder_cls(self.topology, self.logger)
    
    def get_analyzer(self, name: str) -> Analyzer:
        """
        Obtient un analyzer.
        
        Args:
            name: Nom de l'analyzer (fidelity, entropy, correlation, etc.)
        
        Returns:
            Instance de l'analyzer
        """
        analyzer_cls = self._registry.get_analyzer(name)
        if analyzer_cls is None:
            raise ValueError(f"Analyzer '{name}' not found. Available: {self._registry.list_analyzers()}")
        
        return analyzer_cls(self.logger)
    
    # =========================================================================
    # CONVENIENCE METHODS
    # =========================================================================
    
    def quick_test(self, circuit_type: str = 'ghz', n_qubits: int = 50,
                   shots: int = 4096, analyses: List[str] = None) -> Dict:
        """
        ExÃ©cute un test rapide.
        
        Args:
            circuit_type: Type de circuit (ghz, iqp, bell, random)
            n_qubits: Nombre de qubits
            shots: Nombre de shots
            analyses: Analyses Ã  effectuer
        
        Returns:
            RÃ©sultats complets
        """
        self.logger.section(f"QUICK TEST: {circuit_type.upper()} {n_qubits}Q")
        
        # Build circuit
        builder = self.get_circuit_builder(circuit_type)
        circuit = builder.build(n_qubits)
        
        # Transpile
        transpiled = self.transpile_circuits([circuit])
        
        # Execute
        results = self.run_on_qpu(transpiled, shots)
        
        if not results:
            return {'error': 'Execution failed'}
        
        # Analyze
        analyses = analyses or ['fidelity', 'entropy', 'correlation']
        analysis_results = {}
        
        for name in analyses:
            try:
                analyzer = self.get_analyzer(name)
                counts = results[0].get('counts', {})
                analysis_results[name] = analyzer.analyze(counts, n_qubits)
            except Exception as e:
                analysis_results[name] = {'error': str(e)}
        
        return {
            'circuit_type': circuit_type,
            'n_qubits': n_qubits,
            'shots': shots,
            'raw_results': results,
            'analyses': analysis_results,
        }
    
    def run_benchmark_suite(self) -> Dict:
        """ExÃ©cute la suite complÃ¨te de benchmarks"""
        return self.benchmark.run_full_benchmark()
    
    def export_results(self, base_name: str = None) -> Dict[str, Path]:
        """Exporte tous les rÃ©sultats"""
        base_name = base_name or f"{self.project}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        exporter = ReportExporter(
            output_dir=self.dir_manager.get_file('exports'),
            logger=self.logger
        )
        
        report_data = self.report.to_dict()
        
        return {
            'json': exporter.export_json(report_data, base_name),
            'markdown': exporter.export_markdown(report_data, base_name),
        }
    
    # =========================================================================
    # CLEANUP
    # =========================================================================
    
    def _cleanup(self):
        """Nettoyage des ressources"""
        if self.logger:
            self.logger.flush()
        if self.report:
            self.report.save()
        if self.job_monitor:
            self.job_monitor.stop()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self._cleanup()


# =============================================================================
# QMC MODULES - IMPLEMENTATIONS
# =============================================================================

# =============================================================================
# CLI v2.0
# =============================================================================

def main():
    """CLI principal du framework v2.0"""
    parser = argparse.ArgumentParser(
        description=f'QMC Quantum Testing Framework v{__version__}',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  QMC FRAMEWORK v2.0 - EXAMPLES                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                               â•‘
â•‘  # Check connection                                           â•‘
â•‘  python qmc_framework_v2.py --check                           â•‘
â•‘                                                               â•‘
â•‘  # Analyze calibration                                        â•‘
â•‘  python qmc_framework_v2.py --calibration                     â•‘
â•‘                                                               â•‘
â•‘  # Quick test (GHZ)                                           â•‘
â•‘  python qmc_framework_v2.py --quick-test ghz --qubits 50      â•‘
â•‘                                                               â•‘
â•‘  # Run module (QMC Core)                                      â•‘
â•‘                                                               â•‘
â•‘  # Run benchmark suite                                        â•‘
â•‘  python qmc_framework_v2.py --benchmark                       â•‘
â•‘                                                               â•‘
â•‘  # Run experiment with parameter sweep                        â•‘
â•‘  python qmc_framework_v2.py --experiment config.yaml          â•‘
â•‘                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """
    )
    
    # Mode
    mode_group = parser.add_mutually_exclusive_group(required=True)
    mode_group.add_argument('--check', action='store_true', help='Check connection')
    mode_group.add_argument('--check-deps', action='store_true', 
                           help='Check dependencies and show install commands')
    mode_group.add_argument('--recover-job', type=str, metavar='JOB_ID',
                           help='Recover results from an existing job by ID')
    mode_group.add_argument('--list-jobs', action='store_true',
                           help='List recent jobs on IBM Quantum')
    mode_group.add_argument('--calibration', action='store_true', help='Analyze calibration')
    mode_group.add_argument('--quick-test', type=str, metavar='TYPE', 
                           help='Quick test (ghz, iqp, bell, random)')
    mode_group.add_argument('--benchmark', action='store_true', help='Run benchmark suite')
    mode_group.add_argument('--experiment', type=str, metavar='CONFIG',
                           help='Run experiment from YAML config')
    mode_group.add_argument('--list-plugins', action='store_true', help='List available plugins')
    
    # Options
    parser.add_argument('--backend', type=str, default='ibm_fez', help='IBM backend')
    parser.add_argument('--qubits', type=int, default=50, help='Number of qubits')
    parser.add_argument('--shots', type=int, default=8192, help='Number of shots')
    parser.add_argument('--depth', type=int, default=10, help='Circuit depth (for IQP)')
    parser.add_argument('--validate', action='store_true', help='Validate only (no QPU)')
    parser.add_argument('--debug', action='store_true', help='Enable debug logging')
    
    # Mitigation options
    parser.add_argument('--no-twirling', action='store_true', help='Disable twirling')
    parser.add_argument('--no-dd', action='store_true', help='Disable dynamical decoupling')
    
    # [v2.5.14] Security options for cryptographic jobs
    parser.add_argument('--private', action='store_true', 
                       help='ğŸ” Mark job as private/confidential')
    parser.add_argument('--auto-delete-job', action='store_true',
                       help='ğŸ—‘ï¸ Auto-delete job after results retrieval (crypto security)')
    parser.add_argument('--redact-logs', action='store_true',
                       help='ğŸ“ Redact sensitive data from logs (WARNING level only)')
    parser.add_argument('--production-mode', action='store_true',
                       help='ğŸ”’ Enable full security triptyque (private + auto-delete + redact-logs)')
    parser.add_argument('--auto-confirm', action='store_true',
                       help='âš ï¸ Skip QPU submission confirmation (DANGEROUS - use for automated scripts only)')
    
    args = parser.parse_args()
    
    # Mitigation config
    mitigation = MitigationConfig(
        enable_twirling=not args.no_twirling,
        enable_dd=not args.no_dd)
    
    # Handle list-plugins
    if args.list_plugins:
        registry = PluginRegistry.instance()
        print("\nğŸ“¦ AVAILABLE PLUGINS")
        print("=" * 50)
        print(f"\nğŸ”§ Circuit Builders: {registry.list_circuit_builders()}")
        print(f"[#] Analyzers: {registry.list_analyzers()}")
        print(f"ğŸ”Œ Modules: {registry.list_modules()}")
        return
    
    # [v2.5.21] Check dependencies
    if args.check_deps:
        print(FRAMEWORK_BANNER)
        results = check_dependencies(auto_install=True, verbose=True)
        if results["missing"]:
            sys.exit(1)
        return
    
    # [v2.5.21] List recent jobs
    if args.list_jobs:
        print(FRAMEWORK_BANNER)
        fw = QMCFramework(project="QMC_CLI", backend_name=args.backend)
        fw.initialize(RunMode.CALIBRATION, {})
        if fw.connect():
            fw.list_recent_jobs(n=20)
        return
    
    # [v2.5.21] Recover job by ID
    if args.recover_job:
        print(FRAMEWORK_BANNER)
        print(f"\nğŸ”„ RÃ©cupÃ©ration du job: {args.recover_job}")
        fw = QMCFramework(project="QMC_CLI", backend_name=args.backend)
        fw.initialize(RunMode.QPU, {})
        if fw.connect():
            results = fw.retrieve_job_results(args.recover_job)
            if results:
                print(f"\nâœ… {len(results)} rÃ©sultats rÃ©cupÃ©rÃ©s!")
                print(f"ğŸ“ Rapport: {fw.last_report_path}")
            else:
                print(f"\nâŒ Ã‰chec de la rÃ©cupÃ©ration")
                sys.exit(1)
        return
    
    # Create framework
    mode = RunMode.VALIDATE if args.validate else RunMode.QPU
    
    fw = QMCFramework(
        project="QMC_CLI",
        backend_name=args.backend,
        mitigation_config=mitigation,
        private=args.private,  # [v2.5.14] Security option
        auto_delete_job=args.auto_delete_job,  # [v2.5.14] Security option
        redact_logs=args.redact_logs,  # [v2.5.14] Redact logs
        production_mode=args.production_mode,  # [v2.5.14] Full security mode
        auto_confirm=args.auto_confirm,  # [v2.5.14] Skip confirmation (dangerous!)
    )
    
    config = {
        'scales': [args.qubits],
        'shots': args.shots,
        'debug': args.debug,
    }
    
    try:
        if args.check:
            fw.initialize(RunMode.CALIBRATION, config)
            if fw.connect():
                print(f"\n[OK] Connection OK")
                print(f"   Backend: {fw.backend.name} ({fw.backend.num_qubits}Q)")
            else:
                print(f"\n[XX] Connection failed")
                sys.exit(1)
        
        elif args.calibration:
            fw.initialize(RunMode.CALIBRATION, config)
            if fw.connect():
                fw.analyze_calibration()
                print(f"\nğŸ“ Results: {fw.dir_manager.run_dir}")
        
        elif args.quick_test:
            fw.initialize(mode, config)
            if fw.connect():
                fw.analyze_calibration()
                results = fw.quick_test(
                    circuit_type=args.quick_test,
                    n_qubits=args.qubits,
                    shots=args.shots
                )
                
                print(f"\n[OK] Quick test completed")
                if 'analyses' in results:
                    for name, analysis in results['analyses'].items():
                        if isinstance(analysis, dict):
                            print(f"   {name}: {analysis}")
                
                fw.export_results()
                print(f"\nğŸ“ Results: {fw.dir_manager.run_dir}")
        
        elif args.module:
            fw.initialize(mode, config)
            if fw.connect():
                fw.analyze_calibration()
                
                module = fw.load_module(args.module)
                results = module.run(
                    n_qubits=args.qubits,
                    shots=args.shots,
                    iqp_depth=args.depth
                )
                
                print(f"\n[OK] Module {args.module} completed")
                print(f"   Success: {results.get('success', 'N/A')}")
                
                fw.export_results()
                print(f"\nğŸ“ Results: {fw.dir_manager.run_dir}")
        
        elif args.benchmark:
            fw.initialize(RunMode.BENCHMARK, config)
            if fw.connect():
                fw.analyze_calibration()
                results = fw.run_benchmark_suite()
                
                print(f"\n[OK] Benchmark suite completed")
                if 'summary' in results:
                    print(f"   Summary: {results['summary']}")
                
                fw.export_results()
                print(f"\nğŸ“ Results: {fw.dir_manager.run_dir}")
        
        elif args.experiment:
            exp_config = ExperimentConfig.from_yaml(args.experiment)
            fw.initialize(RunMode.EXPERIMENT, config)
            if fw.connect():
                fw.analyze_calibration()
                
                exp_id = fw.experiment.create_experiment(
                    name=exp_config.name,
                    config=exp_config
                )
                
                results = fw.experiment.run_experiment(exp_id)
                
                print(f"\n[OK] Experiment completed")
                print(f"   Configurations: {results.get('successful', 0)}/{results.get('total_configurations', 0)}")
                
                fw.experiment.export_experiment(
                    exp_id, 
                    fw.dir_manager.get_file('exports') / f"{exp_id}.json"
                )
                print(f"\nğŸ“ Results: {fw.dir_manager.run_dir}")
        
    except KeyboardInterrupt:
        print("\n\n[!!] Interrupted by user")
    except Exception as e:
        print(f"\n[XX] Error: {e}")
        if args.debug:
            traceback.print_exc()
        sys.exit(1)
    finally:
        fw._cleanup()


if __name__ == "__main__":
    main()


# ============================================================================
# QMC QUANTUM FRAMEWORK v2.3.1 - EXTENSIONS
# IBM Quantum Jobs Analytics + Multi-API Keys + Multi-Account Usage Audit
# ============================================================================
#
# Cette section Ã©tend les classes v2.0 sans casser la compatibilitÃ©.
# Elle redÃ©finit CredentialsManager et QMCFramework en sous-classes des versions
# prÃ©cÃ©dentes afin d'ajouter :
#   - Support multi-comptes via variables d'environnement / .env
#   - SÃ©lection de compte actif (IBM_API_KEY_ACTIVE_LABEL)
#   - TolÃ©rance au format IBM_API_KEY_ACTIVE_<LABEL>=<KEY>
#   - Listing / inspection / statistiques des jobs Runtime
#   - Estimation du temps QPU restant (budget Open Plan)
#   - Audit multi-comptes sur 30 jours (lecture API uniquement)
#
# IMPORTANT : aucune de ces fonctions ne dÃ©clenche un job par elle-mÃªme.
# ============================================================================

from typing import Optional, Dict, Any, List, Callable
from datetime import datetime, timedelta
from collections import defaultdict
import os

try:
    from qiskit_ibm_runtime import QiskitRuntimeService
except Exception:  # pragma: no cover
    QiskitRuntimeService = None  # type: ignore


# ---------------------------------------------------------------------------
# CredentialsManager (extended)
# ---------------------------------------------------------------------------

_BaseCredentialsManager = CredentialsManager

class CredentialsManager(_BaseCredentialsManager):
    """Gestionnaire d'identifiants IBM Quantum avec support multi-clÃ©s.

    Styles supportÃ©s :

    1) RecommandÃ© :
        IBM_API_KEY=<key>                        # compte default
        IBM_API_KEY_<LABEL>=<key>               # ex: IBM_API_KEY_WORK
        IBM_CHANNEL_<LABEL>=...                 # optionnel
        IBM_CRN_<LABEL>=... / IBM_INSTANCE_<LABEL>=...  # optionnel
        IBM_API_KEY_ACTIVE_<LABEL>=<key>        # ex: IBM_API_KEY_ACTIVE_SEB2
        
    IMPORTANT: Seules les clÃ©s avec ACTIVE_ sont utilisÃ©es!
        [OK] IBM_API_KEY_ACTIVE_SEB2=xxx    â†’ AcceptÃ©e
        [OK] IBM_API_KEY_ACTIVE_WORK=xxx    â†’ AcceptÃ©e  
        [XX] IBM_API_KEY_SEB3=xxx           â†’ IgnorÃ©e (pas ACTIVE)
        [XX] IBM_API_KEY=xxx                â†’ IgnorÃ©e (pas ACTIVE)
        
    Si plusieurs clÃ©s ACTIVE, la premiÃ¨re (ordre alphabÃ©tique) est utilisÃ©e.
    Si aucune clÃ© ACTIVE, une erreur est levÃ©e.
    """

    def _get_active_credentials_from_env(self) -> Dict[str, Dict[str, Any]]:
        """RÃ©cupÃ¨re UNIQUEMENT les credentials avec IBM_API_KEY_ACTIVE_*"""
        accounts: Dict[str, Dict[str, Any]] = {}

        # Charge .env si prÃ©sent
        try:
            self._load_from_dotenv()
        except Exception:
            pass

        # SEULEMENT les clÃ©s IBM_API_KEY_ACTIVE_<LABEL>
        for k, v in os.environ.items():
            if not k.startswith("IBM_API_KEY_ACTIVE_"):
                continue

            suffix = k[len("IBM_API_KEY_ACTIVE_"):]
            if not suffix:
                continue

            label = suffix.lower()
            raw = {
                "api_key": v,
                "instance": os.environ.get(f"IBM_CRN_{suffix}") or os.environ.get(f"IBM_INSTANCE_{suffix}"),
                "channel": os.environ.get(f"IBM_CHANNEL_{suffix}"),
            }
            try:
                accounts[label] = self._format_credentials(raw)
            except Exception:
                continue

        return accounts

    def _get_credentials_for_label(self, label: str) -> Optional[Dict[str, Any]]:
        label = (label or "").strip().lower()
        accounts = self._get_active_credentials_from_env()
        if not accounts:
            return None
        return accounts.get(label)

    def list_accounts(self) -> Dict[str, Dict[str, Any]]:
        """Liste tous les comptes ACTIVE disponibles"""
        return self._get_active_credentials_from_env()

    def list_available_labels(self) -> List[str]:
        """Liste les labels ACTIVE disponibles"""
        return sorted(self.list_accounts().keys())

    def set_active_label(self, label: str) -> None:
        label = (label or "").strip().lower()
        self._selected_label = label

    @property
    def active_label(self) -> str:
        """Retourne le label actif (premier par ordre alphabÃ©tique si non spÃ©cifiÃ©)"""
        # Si un label a Ã©tÃ© sÃ©lectionnÃ© manuellement
        if hasattr(self, '_selected_label') and self._selected_label:
            return self._selected_label
        
        # Sinon, prendre le premier ACTIVE_* par ordre alphabÃ©tique
        labels = self.list_available_labels()
        if labels:
            return labels[0]
        
        return ""

    def get_active_label(self) -> str:
        return self.active_label

    def get_active_credentials(self) -> Optional[Dict[str, Any]]:
        return self._get_credentials_for_label(self.active_label)

    def load(self, label: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """Charge les credentials pour un label donnÃ© ou le premier label ACTIVE.
        
        Args:
            label: Label du compte Ã  charger. Si None, utilise le premier ACTIVE.
        
        Returns:
            Dict avec les credentials formatÃ©s ou None si non trouvÃ©.
            
        Raises:
            ValueError: Si aucune clÃ© IBM_API_KEY_ACTIVE_* n'est trouvÃ©e.
        """
        accounts = self._get_active_credentials_from_env()
        
        # VÃ©rifier qu'il y a au moins une clÃ© ACTIVE
        if not accounts:
            raise ValueError(
                "[XX] Aucune clÃ© IBM_API_KEY_ACTIVE_* trouvÃ©e!\n"
                "   Ajoutez 'ACTIVE_' Ã  votre clÃ© dans le fichier .env:\n"
                "   IBM_API_KEY_ACTIVE_MONCOMPTE=votre_clÃ©_ici\n"
                "   \n"
                "   [OK] IBM_API_KEY_ACTIVE_SEB2=xxx  â†’ AcceptÃ©e\n"
                "   [XX] IBM_API_KEY_SEB3=xxx         â†’ IgnorÃ©e (pas ACTIVE)"
            )
        
        if label is not None:
            # Si un label est fourni, le dÃ©finir comme actif
            self.set_active_label(label)
        
        target_label = self.active_label
        
        # VÃ©rifier que le label demandÃ© existe
        if target_label not in accounts:
            available = ", ".join(accounts.keys())
            raise ValueError(
                f"[XX] Label '{target_label}' non trouvÃ©!\n"
                f"   Labels ACTIVE disponibles: {available}"
            )
        
        creds = accounts[target_label]
        if creds:
            self._credentials = creds
            return creds
        return None

    def get_masked_info(self) -> Dict:
        """Retourne les infos masquÃ©es pour les logs, incluant le label actif."""
        if not self._credentials:
            return {'status': 'not_loaded'}
        
        api_key = self._credentials.get('api_key', '')
        label = self.active_label
        
        # Format: "LABEL (abc12...)" pour identifier facilement le compte
        return {
            'status': 'loaded',
            'account': label.upper(),
            'api_key_prefix': api_key[:5] + '...' if len(api_key) > 5 else '***',
            'instance': self._credentials.get('instance', 'default'),
        }


# ---------------------------------------------------------------------------
# SpinnerAnimation - Animation d'attente ASCII
# ---------------------------------------------------------------------------

class SpinnerAnimation:
    """
    Animation ASCII pendant les opÃ©rations longues.
    
    Usage:
        with SpinnerAnimation("Chargement des donnÃ©es"):
            # opÃ©ration longue
            time.sleep(5)
    """
    
    # DiffÃ©rents styles de spinner (ASCII compatible Windows)
    STYLES = {
        'line': ['|', '/', '-', '\\'],
        'dots': ['.  ', '.. ', '...', '.. '],
        'arrows': ['<', '^', '>', 'v'],
        'bounce': ['[=  ]', '[ = ]', '[  =]', '[ = ]'],
        'pulse': ['(o)', '(O)', '(o)', '( )'],
        'bar': ['[#   ]', '[##  ]', '[### ]', '[####]', '[### ]', '[##  ]', '[#   ]'],
        'quantum': ['|0>', '|+>', '|1>', '|->'],
        'wave': ['~', '~~', '~~~', '~~'],
        'spin': ['-', '\\', '|', '/'],
    }
    
    def __init__(self, message: str = "Chargement", style: str = 'line', 
                 show_elapsed: bool = True, stream=None):
        """
        Args:
            message: Message Ã  afficher
            style: Style du spinner ('line', 'dots', 'quantum', etc.)
            show_elapsed: Afficher le temps Ã©coulÃ©
            stream: Stream de sortie (dÃ©faut: sys.stdout)
        """
        import sys
        import threading
        
        self.message = message
        self.frames = self.STYLES.get(style, self.STYLES['line'])
        self.show_elapsed = show_elapsed
        self.stream = stream or sys.stdout
        self._stop_event = threading.Event()
        self._thread = None
        self._start_time = None
        self._frame_idx = 0
    
    def _animate(self):
        """Thread d'animation."""
        import time
        import sys
        
        while not self._stop_event.is_set():
            elapsed = ""
            if self.show_elapsed and self._start_time:
                secs = time.time() - self._start_time
                elapsed = f" ({secs:.1f}s)"
            
            frame = self.frames[self._frame_idx % len(self.frames)]
            line = f"\r  {frame} {self.message}{elapsed}  "
            
            try:
                self.stream.write(line)
                self.stream.flush()
            except:
                pass
            
            self._frame_idx += 1
            self._stop_event.wait(0.1)  # 100ms entre frames
    
    def start(self):
        """DÃ©marre l'animation."""
        import time
        import threading
        
        self._start_time = time.time()
        self._stop_event.clear()
        self._thread = threading.Thread(target=self._animate, daemon=True)
        self._thread.start()
    
    def stop(self, final_message: str = None):
        """ArrÃªte l'animation."""
        import time
        
        self._stop_event.set()
        if self._thread:
            self._thread.join(timeout=0.5)
        
        # Effacer la ligne et afficher le message final
        elapsed = ""
        if self.show_elapsed and self._start_time:
            secs = time.time() - self._start_time
            elapsed = f" ({secs:.1f}s)"
        
        if final_message:
            try:
                self.stream.write(f"\r  [OK] {final_message}{elapsed}          \n")
                self.stream.flush()
            except:
                pass
        else:
            # Juste effacer la ligne
            try:
                self.stream.write(f"\r" + " " * 60 + "\r")
                self.stream.flush()
            except:
                pass
    
    def __enter__(self):
        self.start()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.stop(f"{self.message} - Erreur!")
        else:
            self.stop()
        return False


# ---------------------------------------------------------------------------
# QMCFramework (extended)
# ---------------------------------------------------------------------------

_BaseQMCFramework = QMCFramework

class QMCFramework(_BaseQMCFramework):
    """Framework principal QMC avec extensions IBM Quantum v2.3.x."""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.credentials = CredentialsManager()
        self.cost_estimator = None  # [v2.5.15] InitialisÃ© dans initialize()

    # -----------------------------
    # Connexion multi-comptes
    # -----------------------------

    def connect(self,
                api_key: Optional[str] = None,
                instance: Optional[str] = None,
                channel: Optional[str] = None,
                label: Optional[str] = None,
                show_monthly_stats: bool = True,
                **kwargs) -> bool:
        """Connexion IBM Quantum.

        PrioritÃ© :
          1) api_key explicite
          2) label explicite
          3) label actif (IBM_API_KEY_ACTIVE_LABEL)
          4) sinon fallback via credentials.load()

        Args:
            api_key: ClÃ© API IBM Quantum (optionnelle)
            instance: Instance CRN (optionnelle)
            channel: Canal ibm_quantum ou ibm_cloud (optionnel)
            label: Label du compte Ã  utiliser (optionnel)
            show_monthly_stats: Afficher les stats d'utilisation 30j (dÃ©faut: True)
            **kwargs: TolÃ©rance signature pour compat tests/runner.
        """
        # Si api_key explicite, crÃ©er une clÃ© ACTIVE temporaire
        if api_key:
            import os
            os.environ["IBM_API_KEY_ACTIVE_TEMP"] = api_key
            if instance:
                os.environ["IBM_CRN_TEMP"] = instance
            if channel:
                os.environ["IBM_CHANNEL_TEMP"] = channel
            self.credentials.set_active_label("temp")

        # Charger les credentials (lÃ¨ve ValueError si pas de clÃ© ACTIVE)
        try:
            target_label = label if label else None
            cfg = self.credentials.load(target_label)
        except ValueError as e:
            # Pas de clÃ© ACTIVE trouvÃ©e
            if hasattr(self, 'logger'):
                self.logger.error(str(e))
            return False

        if not cfg:
            if hasattr(self, 'logger'):
                self.logger.error("[XX] Impossible de charger les credentials!")
            return False
        
        # Connexion via la classe de base
        result = super().connect()
        
        # Afficher les stats d'utilisation du mois si connexion rÃ©ussie
        if result and getattr(self, '_connected', False) and show_monthly_stats:
            try:
                self.get_monthly_usage(display=True, animate=True)
            except Exception as e:
                # Ne pas bloquer si l'affichage Ã©choue
                if hasattr(self, 'logger'):
                    self.logger.debug(f"Stats mensuelles non disponibles: {e}")
        
        return result

    def get_monthly_usage(self, days: int = 30, display: bool = False, 
                          animate: bool = True) -> Dict[str, Any]:
        """
        RÃ©cupÃ¨re les statistiques d'utilisation QPU sur les N derniers jours.
        
        Args:
            days: Nombre de jours Ã  analyser (dÃ©faut: 30)
            display: Afficher les rÃ©sultats dans les logs
            animate: Afficher une animation pendant le chargement (dÃ©faut: True)
            
        Returns:
            Dict avec les statistiques d'utilisation
        """
        if not getattr(self, "_connected", False):
            raise RuntimeError("Non connectÃ©! Appelez connect() d'abord.")
        
        from datetime import datetime, timedelta, timezone
        
        # PÃ©riode d'analyse
        now = datetime.now(timezone.utc)
        start_date = now - timedelta(days=days)
        
        # RÃ©cupÃ©rer les jobs avec animation
        spinner = None
        if animate:
            spinner = SpinnerAnimation(
                f"RÃ©cupÃ©ration jobs IBM Quantum ({days}j)", 
                style='quantum',
                show_elapsed=True
            )
            spinner.start()
        
        try:
            jobs = list(self.service.jobs(
                created_after=start_date,
                limit=500,  # Max raisonnable
                descending=True
            ))
            
            if spinner:
                spinner.stop(f"RÃ©cupÃ©ration terminÃ©e: {len(jobs)} jobs trouvÃ©s")
        except Exception as e:
            if spinner:
                spinner.stop(f"Erreur: {e}")
            return {'error': str(e), 'total_jobs': 0, 'total_time_s': 0}
        
        # Analyser les jobs - [v2.5.21] OPTIMISATION avec parallÃ©lisation
        spinner2 = None
        if animate and len(jobs) > 5:
            spinner2 = SpinnerAnimation(
                f"Analyse des temps QPU ({len(jobs)} jobs)", 
                style='dots',
                show_elapsed=True
            )
            spinner2.start()
        
        total_time_s = 0.0
        completed_jobs = 0
        failed_jobs = 0
        pending_jobs = 0
        backends_used = {}
        jobs_per_day = {}
        job_times = []  # Pour stats min/max/avg
        
        def analyze_job(job):
            """Analyse un job (exÃ©cutÃ© en parallÃ¨le)."""
            result = {
                'status': None,
                'qpu_time': 0,
                'backend': None,
                'day': None
            }
            try:
                # [v2.5.21] Extraire le statut correctement
                # job.status() retourne un enum JobStatus, pas une string
                try:
                    status_obj = job.status()
                    # Essayer .name (enum standard), sinon convertir en string et extraire
                    if hasattr(status_obj, 'name'):
                        result['status'] = status_obj.name.upper()
                    else:
                        # Fallback: "JobStatus.DONE" -> "DONE"
                        status_str = str(status_obj).upper()
                        if '.' in status_str:
                            result['status'] = status_str.split('.')[-1]
                        else:
                            result['status'] = status_str
                except Exception:
                    pass
                
                # Backend
                try:
                    backend = job.backend().name if callable(getattr(job, 'backend', None)) else str(getattr(job, 'backend', 'unknown'))
                    result['backend'] = backend
                except:
                    pass
                
                # Date du job
                try:
                    created = job.creation_date()
                    if created:
                        result['day'] = created.strftime('%Y-%m-%d')
                except:
                    pass
                
                # Temps QPU (seulement pour DONE)
                if result['status'] == 'DONE':
                    try:
                        metrics = job.metrics()
                        if metrics:
                            qpu_time = metrics.get('usage', {}).get('quantum_seconds', 0)
                            if qpu_time:
                                result['qpu_time'] = self._safe_float(qpu_time)
                    except:
                        pass
            except:
                pass
            return result
        
        try:
            # [v2.5.21] ParallÃ©liser l'analyse avec ThreadPoolExecutor
            from concurrent.futures import ThreadPoolExecutor, as_completed
            
            with ThreadPoolExecutor(max_workers=10) as executor:
                futures = {executor.submit(analyze_job, job): job for job in jobs}
                
                for future in as_completed(futures):
                    try:
                        result = future.result(timeout=5)  # Timeout par job
                        
                        status = result.get('status')
                        if status == 'DONE':
                            completed_jobs += 1
                            qpu_time = result.get('qpu_time', 0)
                            if qpu_time > 0:
                                total_time_s += qpu_time
                                job_times.append(qpu_time)
                        elif status in ('ERROR', 'CANCELLED'):
                            failed_jobs += 1
                        elif status in ('QUEUED', 'RUNNING', 'PENDING'):
                            pending_jobs += 1
                        
                        # Backend
                        backend = result.get('backend')
                        if backend:
                            backends_used[backend] = backends_used.get(backend, 0) + 1
                        
                        # Date
                        day = result.get('day')
                        if day:
                            jobs_per_day[day] = jobs_per_day.get(day, 0) + 1
                            
                    except Exception:
                        continue
        finally:
            if spinner2:
                spinner2.stop(f"Analyse terminÃ©e: {total_time_s/60:.1f}min QPU")
        
        total_jobs = completed_jobs + failed_jobs + pending_jobs
        
        # Calculer stats avancÃ©es
        avg_time = total_time_s / completed_jobs if completed_jobs > 0 else 0
        max_time = max(job_times) if job_times else 0
        min_time = min(job_times) if job_times else 0
        
        # RÃ©sultats
        results = {
            'period_days': days,
            'start_date': start_date.isoformat(),
            'end_date': now.isoformat(),
            'total_jobs': total_jobs,
            'completed_jobs': completed_jobs,
            'failed_jobs': failed_jobs,
            'pending_jobs': pending_jobs,
            'total_time_s': round(total_time_s, 2),
            'total_time_min': round(total_time_s / 60, 2),
            'total_time_hours': round(total_time_s / 3600, 3),
            'avg_time_s': round(avg_time, 2),
            'max_time_s': round(max_time, 2),
            'min_time_s': round(min_time, 2),
            'backends_used': backends_used,
            'jobs_per_day': jobs_per_day,
        }
        
        # Affichage COOL
        if display and hasattr(self, 'logger'):
            self._display_usage_stats(results)
        
        return results

    def _display_usage_stats(self, stats: Dict[str, Any]) -> None:
        """Affiche les statistiques d'utilisation de maniÃ¨re visuelle (ASCII compatible Windows)."""
        
        def bar(value: float, max_val: float, width: int = 20) -> str:
            """GÃ©nÃ¨re une barre de progression ASCII."""
            if max_val <= 0:
                return '-' * width
            filled = int((value / max_val) * width)
            return '#' * filled + '-' * (width - filled)
        
        def format_time(seconds: float) -> str:
            """Formate le temps de maniÃ¨re lisible."""
            if seconds < 60:
                return f"{seconds:.1f}s"
            elif seconds < 3600:
                return f"{seconds/60:.1f}min"
            else:
                return f"{seconds/3600:.2f}h"
        
        # Extraire les donnÃ©es
        total_jobs = stats.get('total_jobs', 0)
        completed = stats.get('completed_jobs', 0)
        failed = stats.get('failed_jobs', 0)
        pending = stats.get('pending_jobs', 0)
        total_time = stats.get('total_time_s', 0)
        avg_time = stats.get('avg_time_s', 0)
        max_time = stats.get('max_time_s', 0)
        backends = stats.get('backends_used', {})
        jobs_per_day = stats.get('jobs_per_day', {})
        days = stats.get('period_days', 30)
        
        # Calculer les pourcentages
        pct_completed = (completed / total_jobs * 100) if total_jobs > 0 else 0
        pct_failed = (failed / total_jobs * 100) if total_jobs > 0 else 0
        pct_pending = (pending / total_jobs * 100) if total_jobs > 0 else 0
        
        # Compte actif
        account = "N/A"
        try:
            account = self.credentials.active_label.upper()
        except:
            pass
        
        # Construction de l'affichage (largeur fixe 68 caractÃ¨res)
        W = 68
        
        lines = []
        lines.append("")
        lines.append("  +" + "=" * W + "+")
        title = f" STATISTIQUES UTILISATION {days}J - Compte: {account} "
        lines.append("  |" + title.center(W) + "|")
        lines.append("  +" + "=" * W + "+")
        
        # Section RESUME
        lines.append("  |" + " " * W + "|")
        lines.append("  |  " + "RESUME".ljust(W - 4) + "  |")
        lines.append("  |  " + "-" * (W - 4) + "  |")
        lines.append("  |  " + f"Total Jobs:      {total_jobs:>4}".ljust(W - 4) + "  |")
        lines.append("  |  " + f"[OK] Completes:  {completed:>4}  ({pct_completed:>5.1f}%)  {bar(completed, total_jobs, 15)}".ljust(W - 4) + "  |")
        lines.append("  |  " + f"[XX] Echoues:    {failed:>4}  ({pct_failed:>5.1f}%)  {bar(failed, total_jobs, 15)}".ljust(W - 4) + "  |")
        lines.append("  |  " + f"[..] En attente: {pending:>4}  ({pct_pending:>5.1f}%)  {bar(pending, total_jobs, 15)}".ljust(W - 4) + "  |")
        
        # Section TEMPS QPU
        lines.append("  |" + " " * W + "|")
        lines.append("  |  " + "TEMPS QPU".ljust(W - 4) + "  |")
        lines.append("  |  " + "-" * (W - 4) + "  |")
        lines.append("  |  " + f"Total:         {format_time(total_time):>10}  ({total_time:.1f}s)".ljust(W - 4) + "  |")
        lines.append("  |  " + f"Moyenne/job:   {format_time(avg_time):>10}".ljust(W - 4) + "  |")
        lines.append("  |  " + f"Plus long:     {format_time(max_time):>10}".ljust(W - 4) + "  |")
        
        # Section BACKENDS
        if backends:
            lines.append("  |" + " " * W + "|")
            lines.append("  |  " + "BACKENDS UTILISES".ljust(W - 4) + "  |")
            lines.append("  |  " + "-" * (W - 4) + "  |")
            
            max_backend_jobs = max(backends.values()) if backends else 1
            for backend, count in sorted(backends.items(), key=lambda x: -x[1]):
                pct = (count / total_jobs * 100) if total_jobs > 0 else 0
                backend_bar = bar(count, max_backend_jobs, 12)
                line = f"{backend:<15} {backend_bar} {count:>3} jobs ({pct:>4.1f}%)"
                lines.append("  |  " + line.ljust(W - 4) + "  |")
        
        # Section ACTIVITE (7 derniers jours)
        if jobs_per_day:
            lines.append("  |" + " " * W + "|")
            lines.append("  |  " + "ACTIVITE (7 derniers jours)".ljust(W - 4) + "  |")
            lines.append("  |  " + "-" * (W - 4) + "  |")
            
            # Obtenir les 7 derniers jours
            from datetime import datetime, timedelta
            today = datetime.now()
            last_7_days = [(today - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(6, -1, -1)]
            day_names = ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim']
            
            max_day_jobs = max([jobs_per_day.get(d, 0) for d in last_7_days]) if jobs_per_day else 1
            max_day_jobs = max(max_day_jobs, 1)
            
            for day_str in last_7_days:
                try:
                    day_date = datetime.strptime(day_str, '%Y-%m-%d')
                    day_name = day_names[day_date.weekday()]
                    count = jobs_per_day.get(day_str, 0)
                    day_bar = bar(count, max_day_jobs, 20)
                    line = f"{day_name} {day_str[5:]} {day_bar} {count:>2}"
                    lines.append("  |  " + line.ljust(W - 4) + "  |")
                except:
                    pass
        
        # Fermeture
        lines.append("  |" + " " * W + "|")
        lines.append("  +" + "=" * W + "+")
        lines.append("")
        
        # Afficher
        for line in lines:
            print(line)

    # -----------------------------
    # Helpers retry safe
    # -----------------------------

    def _retry(self, fn: Callable[[], Any], operation_name: str = "operation"):
        rm = getattr(self, "retry_manager", None)
        if rm:
            return rm.execute_with_retry(fn, operation_name=operation_name)
        return fn()

    @staticmethod
    def _safe_float(value) -> float:
        """Convertit une valeur en float de maniÃ¨re sÃ»re (gÃ¨re numpy arrays)."""
        if value is None:
            return 0.0
        try:
            # Si c'est un numpy array, utiliser .item()
            if hasattr(value, 'item'):
                return float(value.item())
            # Si c'est un array/list, prendre le premier Ã©lÃ©ment
            if hasattr(value, '__iter__') and not isinstance(value, (str, bytes)):
                try:
                    first = next(iter(value))
                    if hasattr(first, 'item'):
                        return float(first.item())
                    return float(first)
                except StopIteration:
                    return 0.0
            # Conversion directe
            return float(value)
        except (TypeError, ValueError):
            return 0.0

    def _safe_get_job_status(self, job, timeout_seconds: float = 30.0) -> Optional[str]:
        """
        [v2.5.21] RÃ©cupÃ¨re le statut d'un job avec timeout.
        
        Ã‰vite les blocages si la connexion rÃ©seau est perdue.
        
        Args:
            job: Job IBM Quantum
            timeout_seconds: Timeout en secondes (dÃ©faut: 30s)
            
        Returns:
            Statut du job ('QUEUED', 'RUNNING', 'DONE', 'ERROR', 'CANCELLED')
            ou None si timeout/erreur
        """
        try:
            with ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(lambda: str(job.status()))
                return future.result(timeout=timeout_seconds)
        except FutureTimeout:
            self.logger.warn(f"âš ï¸ Timeout ({timeout_seconds}s) en rÃ©cupÃ©rant le statut du job")
            return None
        except Exception as e:
            self.logger.warn(f"âš ï¸ Erreur rÃ©cupÃ©ration statut: {e}")
            return None

    def _safe_get_job_result(self, job, timeout_seconds: float = 120.0):
        """
        [v2.5.21] RÃ©cupÃ¨re les rÃ©sultats d'un job avec timeout.
        
        Ã‰vite les blocages si la connexion rÃ©seau est perdue.
        Si timeout, affiche un message avec le job_id pour reprise manuelle.
        
        Args:
            job: Job IBM Quantum
            timeout_seconds: Timeout en secondes (dÃ©faut: 120s)
            
        Returns:
            RÃ©sultats du job ou None si timeout/erreur
            
        Raises:
            QMCTimeoutError: Si le timeout est atteint
        """
        job_id = job.job_id() if hasattr(job, 'job_id') else 'unknown'
        
        try:
            with ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(job.result)
                return future.result(timeout=timeout_seconds)
                
        except FutureTimeout:
            self.logger.error(f"")
            self.logger.error(f"{'â•' * 70}")
            self.logger.error(f"  â±ï¸  TIMEOUT - La rÃ©cupÃ©ration des rÃ©sultats a pris trop de temps")
            self.logger.error(f"{'â•' * 70}")
            self.logger.error(f"  ğŸ†” Job ID: {job_id}")
            self.logger.error(f"  â±ï¸  Timeout: {timeout_seconds}s")
            self.logger.error(f"")
            self.logger.error(f"  ğŸ’¡ Le job est probablement terminÃ© sur IBM.")
            self.logger.error(f"     Pour rÃ©cupÃ©rer les rÃ©sultats, utilisez:")
            self.logger.error(f"")
            self.logger.error(f"     python qmc_framework.py --recover-job {job_id}")
            self.logger.error(f"")
            self.logger.error(f"     OU en Python:")
            self.logger.error(f"     results = fw.retrieve_job_results('{job_id}')")
            self.logger.error(f"{'â•' * 70}")
            
            raise QMCTimeoutError(
                f"Timeout ({timeout_seconds}s) en rÃ©cupÃ©rant les rÃ©sultats",
                job_id=job_id,
                timeout_s=timeout_seconds
            )
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur rÃ©cupÃ©ration rÃ©sultats: {e}")
            self.logger.error(f"   Job ID pour reprise: {job_id}")
            raise

    def _monitor_job_with_reconnect(self, job, timeout: float = None, 
                                     poll_interval: float = 10.0,
                                     status_timeout: float = 45.0,
                                     queue_update_interval: float = 45.0,
                                     max_consecutive_failures: int = 5) -> Dict:
        """
        [v2.5.21] Monitore un job avec reconnexion automatique ET animation.
        
        VÃ©rifie pÃ©riodiquement le statut du job avec timeout sur chaque appel.
        Si plusieurs Ã©checs consÃ©cutifs, tente une reconnexion.
        Affiche une animation pour indiquer la progression.
        [v2.5.21] Met Ã  jour la file d'attente pÃ©riodiquement.
        
        Args:
            job: Job IBM Quantum
            timeout: Timeout global (None = infini)
            poll_interval: Intervalle entre les vÃ©rifications (dÃ©faut: 10s)
            status_timeout: Timeout par appel status() (dÃ©faut: 45s)
            queue_update_interval: Intervalle mise Ã  jour file d'attente (dÃ©faut: 45s)
            max_consecutive_failures: Max Ã©checs avant reconnexion (dÃ©faut: 5)
            
        Returns:
            Dict avec mÃ©triques (final_status, total_time_s, etc.)
        """
        import sys
        import threading
        
        job_id = job.job_id() if hasattr(job, 'job_id') else 'unknown'
        start_time = time.time()
        last_status = None
        consecutive_failures = 0
        stop_animation = threading.Event()
        
        # [v2.5.21] Variables partagÃ©es pour l'animation (thread-safe via simple lecture)
        queue_info = {'pending': 0, 'last_update': 0}
        
        def _update_queue_info():
            """Met Ã  jour les infos de file d'attente."""
            try:
                backend_status = getattr(self.backend, 'status', lambda: None)()
                if backend_status and hasattr(backend_status, 'pending_jobs'):
                    queue_info['pending'] = backend_status.pending_jobs
                    queue_info['last_update'] = time.time()
                    return True
            except:
                pass
            return False
        
        # PremiÃ¨re rÃ©cupÃ©ration de la file d'attente
        if _update_queue_info():
            self.logger.info(f"  ğŸ“Š File d'attente {self.backend_name}: {queue_info['pending']} jobs en attente")
        
        self.logger.info(f"  ğŸ”’ Mode monitoring robuste activÃ© (timeout {status_timeout}s)")
        self.logger.info(f"")
        
        # Animation frames
        quantum_frames = ['|0âŸ©', '|+âŸ©', '|1âŸ©', '|-âŸ©', '|ÏˆâŸ©', '|Ï†âŸ©']
        progress_frames = ['[â– â–¡â–¡â–¡â–¡]', '[â– â– â–¡â–¡â–¡]', '[â– â– â– â–¡â–¡]', '[â– â– â– â– â–¡]', '[â– â– â– â– â– ]', '[â–¡â– â– â– â– ]', '[â–¡â–¡â– â– â– ]', '[â–¡â–¡â–¡â– â– ]', '[â–¡â–¡â–¡â–¡â– ]', '[â–¡â–¡â–¡â–¡â–¡]']
        
        def animate():
            """Thread d'animation avec affichage file d'attente."""
            frame_idx = 0
            while not stop_animation.is_set():
                elapsed = time.time() - start_time
                
                # Choisir l'animation selon le statut
                if last_status == 'QUEUED':
                    anim = progress_frames[frame_idx % len(progress_frames)]
                    # [v2.5.21] Afficher le nombre de jobs en attente
                    if queue_info['pending'] > 0:
                        msg = f"En file d'attente IBM ({queue_info['pending']} jobs)..."
                    else:
                        msg = f"En file d'attente IBM..."
                elif last_status == 'RUNNING':
                    anim = quantum_frames[frame_idx % len(quantum_frames)]
                    msg = f"ExÃ©cution QPU en cours..."
                elif consecutive_failures > 0:
                    anim = "âš ï¸"
                    msg = f"Reconnexion en cours ({consecutive_failures}/{max_consecutive_failures})..."
                else:
                    anim = "â³"
                    msg = "Initialisation..."
                
                # Formater la ligne
                line = f"\r  {anim} {msg} ({elapsed:.0f}s)                    "
                
                try:
                    sys.stdout.write(line)
                    sys.stdout.flush()
                except:
                    pass
                
                frame_idx += 1
                stop_animation.wait(0.3)
            
            # Effacer la ligne d'animation
            try:
                sys.stdout.write("\r" + " " * 70 + "\r")
                sys.stdout.flush()
            except:
                pass
        
        # DÃ©marrer l'animation
        anim_thread = threading.Thread(target=animate, daemon=True)
        anim_thread.start()
        
        try:
            while True:
                elapsed = time.time() - start_time
                
                # Timeout global
                if timeout and elapsed > timeout:
                    stop_animation.set()
                    anim_thread.join(timeout=1)
                    self.logger.warn(f"  â±ï¸  Timeout global ({timeout}s) atteint")
                    return {
                        'final_status': last_status or 'TIMEOUT',
                        'total_time_s': elapsed,
                        'timeout_triggered': True
                    }
                
                # [v2.5.21] Mise Ã  jour pÃ©riodique de la file d'attente (seulement si QUEUED)
                if last_status == 'QUEUED':
                    time_since_queue_update = time.time() - queue_info['last_update']
                    if time_since_queue_update >= queue_update_interval:
                        # Stopper l'animation temporairement pour le log
                        stop_animation.set()
                        anim_thread.join(timeout=1)
                        
                        if _update_queue_info():
                            self.logger.info(
                                f"  ğŸ“Š [{int(elapsed):>5d}s] File d'attente mise Ã  jour: "
                                f"{queue_info['pending']} jobs en attente"
                            )
                        
                        # Relancer l'animation
                        stop_animation.clear()
                        anim_thread = threading.Thread(target=animate, daemon=True)
                        anim_thread.start()
                
                # RÃ©cupÃ©rer le statut avec timeout
                status = self._safe_get_job_status(job, timeout_seconds=status_timeout)
                
                if status is None:
                    consecutive_failures += 1
                    stop_animation.set()
                    anim_thread.join(timeout=1)
                    self.logger.warn(f"  âš ï¸  Ã‰chec {consecutive_failures}/{max_consecutive_failures} "
                                   f"- pas de rÃ©ponse du serveur IBM")
                    
                    if consecutive_failures >= max_consecutive_failures:
                        self.logger.warn(f"  ğŸ”Œ Tentative de reconnexion...")
                        try:
                            # Tenter de rÃ©cupÃ©rer le job Ã  nouveau
                            job = self.service.job(job_id)
                            consecutive_failures = 0
                            self.logger.info(f"  âœ… Reconnexion rÃ©ussie!")
                            # Relancer l'animation
                            stop_animation.clear()
                            anim_thread = threading.Thread(target=animate, daemon=True)
                            anim_thread.start()
                        except Exception as e:
                            self.logger.error(f"  âŒ Reconnexion Ã©chouÃ©e: {e}")
                            self.logger.error(f"  ğŸ’¡ Pour reprendre: --recover-job {job_id}")
                            return {
                                'final_status': 'CONNECTION_LOST',
                                'total_time_s': elapsed,
                                'job_id': job_id,
                                'timeout_triggered': False,
                                'connection_lost': True
                            }
                    else:
                        # Relancer l'animation
                        stop_animation.clear()
                        anim_thread = threading.Thread(target=animate, daemon=True)
                        anim_thread.start()
                    
                    time.sleep(poll_interval)
                    continue
                
                # Reset compteur si succÃ¨s
                if consecutive_failures > 0:
                    consecutive_failures = 0
                
                # Log changement de statut
                if status != last_status:
                    stop_animation.set()
                    anim_thread.join(timeout=1)
                    
                    if status == 'QUEUED':
                        # [v2.5.21] Mettre Ã  jour la queue quand on passe Ã  QUEUED
                        _update_queue_info()
                        self.logger.info(f"  ğŸ“‹ [{int(elapsed):>5d}s] Status: QUEUED - En file d'attente IBM")
                    elif status == 'RUNNING':
                        self.logger.info(f"  âš¡ [{int(elapsed):>5d}s] Status: RUNNING - ExÃ©cution sur {self.backend_name}")
                    elif status == 'DONE':
                        self.logger.info(f"  âœ… [{int(elapsed):>5d}s] Status: DONE - TerminÃ©!")
                    elif status == 'ERROR':
                        self.logger.info(f"  âŒ [{int(elapsed):>5d}s] Status: ERROR - Ã‰chec du job")
                    elif status == 'CANCELLED':
                        self.logger.info(f"  ğŸš« [{int(elapsed):>5d}s] Status: CANCELLED - AnnulÃ©")
                    else:
                        self.logger.info(f"  ğŸ“Š [{int(elapsed):>5d}s] Status: {status}")
                    
                    last_status = status
                    
                    # Relancer l'animation si job pas terminÃ©
                    if status not in ['DONE', 'ERROR', 'CANCELLED']:
                        stop_animation.clear()
                        anim_thread = threading.Thread(target=animate, daemon=True)
                        anim_thread.start()
                
                # Job terminÃ© ?
                if status in ['DONE', 'ERROR', 'CANCELLED']:
                    return {
                        'final_status': status,
                        'total_time_s': elapsed,
                        'timeout_triggered': False
                    }
                
                # Attendre avant prochain poll
                time.sleep(poll_interval)
        
        finally:
            stop_animation.set()
            try:
                anim_thread.join(timeout=1)
            except:
                pass

    # -----------------------------
    # Jobs analytics
    # -----------------------------

    def list_job_ids(self,
                     created_after: Optional[datetime] = None,
                     created_before: Optional[datetime] = None,
                     backend_name: Optional[str] = None,
                     job_tags: Optional[List[str]] = None,
                     pending: Optional[bool] = None,
                     limit: Optional[int] = 100) -> List[str]:
        if not getattr(self, "_connected", False):
            raise RuntimeError("Non connectÃ©! Appelez connect() d'abord.")

        def _fetch():
            return self.service.jobs(
                limit=limit,
                backend_name=backend_name,
                job_tags=job_tags,
                pending=pending,
                created_after=created_after,
                created_before=created_before,
                descending=True
            )

        jobs = self._retry(_fetch, "RÃ©cupÃ©ration liste jobs") or []
        ids: List[str] = []

        for j in jobs:
            try:
                ids.append(j.job_id())
            except Exception:
                jid = getattr(j, "job_id", None)
                jid = jid() if callable(jid) else jid
                if isinstance(jid, str):
                    ids.append(jid)

        if getattr(self, "report", None):
            try:
                self.report.set("job_ids_count", len(ids), section="jobs")
                if ids:
                    self.report.set("job_ids_sample", ids[:10], section="jobs")
            except Exception:
                pass

        return ids

    def get_job_info(self,
                     job_id: str,
                     with_metrics: bool = True,
                     with_logs: bool = False,
                     with_inputs: bool = False) -> Dict[str, Any]:  # [v2.5.14] Default False pour sÃ©curitÃ©
        """
        RÃ©cupÃ¨re les informations dÃ©taillÃ©es d'un job.
        
        [v2.5.14] SÃ‰CURITÃ‰: En production_mode, with_inputs et with_logs sont 
        forcÃ©s Ã  False pour Ã©viter les fuites de donnÃ©es cryptographiques.
        """
        if not getattr(self, "_connected", False):
            raise RuntimeError("Non connectÃ©! Appelez connect() d'abord.")
        
        # [v2.5.14] En mode production, forcer la non-rÃ©cupÃ©ration des donnÃ©es sensibles
        if getattr(self, 'production_mode', False):
            if with_inputs:
                if hasattr(self, 'logger') and self.logger:
                    self.logger.warn("ğŸ”’ PRODUCTION_MODE: with_inputs forcÃ© Ã  False (sÃ©curitÃ© crypto)")
                with_inputs = False
            if with_logs:
                if hasattr(self, 'logger') and self.logger:
                    self.logger.warn("ğŸ”’ PRODUCTION_MODE: with_logs forcÃ© Ã  False (sÃ©curitÃ© crypto)")
                with_logs = False

        def _fetch():
            return self.service.job(job_id)

        job = self._retry(_fetch, f"RÃ©cupÃ©ration job {job_id}")

        info: Dict[str, Any] = {
            "job_id": job_id,
            "status": str(job.status()) if hasattr(job, "status") else None,
            "backend": getattr(job, "backend_name", None),
            "session_id": getattr(job, "session_id", None),
            "primitive_id": getattr(job, "primitive_id", None),
            "tags": getattr(job, "tags", None),
        }

        try:
            cd = getattr(job, "creation_date", None)
            cd = cd() if callable(cd) else cd
            info["creation_date"] = cd.isoformat() if isinstance(cd, datetime) else (str(cd) if cd else None)
        except Exception:
            info["creation_date"] = None

        if with_inputs:
            try:
                inp = getattr(job, "inputs", None)
                inp = inp() if callable(inp) else inp
                info["inputs"] = inp
            except Exception:
                pass

        if with_metrics:
            try:
                info["usage_seconds"] = self._safe_float(job.usage())
            except Exception:
                info["usage_seconds"] = None
            try:
                info["metrics"] = job.metrics()
            except Exception:
                pass
            try:
                ue = getattr(job, "usage_estimation", None)
                ue = ue() if callable(ue) else ue
                if ue:
                    info["usage_estimation"] = ue
            except Exception:
                pass

        if with_logs:
            try:
                info["logs"] = job.logs()
            except Exception:
                info["logs"] = None

        if getattr(self, "report", None):
            try:
                self.report.set(f"job_{job_id}", info, section="job_details")
            except Exception:
                pass

        return info

    def get_job_execution_times(self, job_id: str) -> Dict[str, Any]:
        """
        Recupere les temps d'execution REELS du QPU pour un job.
        
        Retourne:
        - qpu_time_s: Temps QPU reel en secondes (sans queue)
        - queue_time_s: Temps d'attente dans la queue
        - total_time_s: Temps total (queue + execution)
        - timestamps: Dict avec created, started, completed
        - metrics: Metriques brutes du job
        
        Usage:
            times = framework.get_job_execution_times("job_id_here")
            print(f"Temps QPU reel: {times['qpu_time_s']:.2f}s")
        """
        if not getattr(self, "_connected", False):
            raise RuntimeError("Non connecte! Appelez connect() d'abord.")
        
        def _fetch():
            return self.service.job(job_id)
        
        job = self._retry(_fetch, f"Recuperation job {job_id}")
        
        result = {
            'job_id': job_id,
            'qpu_time_s': None,
            'queue_time_s': None,
            'total_time_s': None,
            'timestamps': {},
            'metrics': {},
            'status': None
        }
        
        # Status
        try:
            result['status'] = str(job.status())
        except Exception:
            pass
        
        # Temps QPU reel via job.usage()
        try:
            usage = job.usage()
            if usage is not None:
                result['qpu_time_s'] = self._safe_float(usage)
        except Exception as e:
            self.logger.warn(f"Impossible de recuperer usage(): {e}")
        
        # Metriques detaillees
        try:
            metrics = job.metrics()
            if metrics:
                result['metrics'] = metrics
                
                # Extraire les timestamps si disponibles
                if 'timestamps' in metrics:
                    ts = metrics['timestamps']
                    result['timestamps'] = ts
                    
                    # Calculer les temps a partir des timestamps
                    if 'created' in ts and 'running' in ts:
                        try:
                            created = datetime.fromisoformat(ts['created'].replace('Z', '+00:00'))
                            running = datetime.fromisoformat(ts['running'].replace('Z', '+00:00'))
                            result['queue_time_s'] = (running - created).total_seconds()
                        except Exception:
                            pass
                    
                    if 'running' in ts and 'finished' in ts:
                        try:
                            running = datetime.fromisoformat(ts['running'].replace('Z', '+00:00'))
                            finished = datetime.fromisoformat(ts['finished'].replace('Z', '+00:00'))
                            # Si qpu_time_s pas dispo, utiliser les timestamps
                            if result['qpu_time_s'] is None:
                                result['qpu_time_s'] = (finished - running).total_seconds()
                        except Exception:
                            pass
                    
                    if 'created' in ts and 'finished' in ts:
                        try:
                            created = datetime.fromisoformat(ts['created'].replace('Z', '+00:00'))
                            finished = datetime.fromisoformat(ts['finished'].replace('Z', '+00:00'))
                            result['total_time_s'] = (finished - created).total_seconds()
                        except Exception:
                            pass
                
                # Extraire billed_time si disponible (temps facture IBM)
                if 'billed_execution_time' in metrics:
                    result['billed_time_s'] = metrics['billed_execution_time']
                    
        except Exception as e:
            self.logger.warn(f"Impossible de recuperer metrics(): {e}")
        
        # Log
        if result['qpu_time_s'] is not None:
            self.logger.info(f"Job {job_id}: QPU time = {result['qpu_time_s']:.2f}s")
        
        return result

    def retrieve_job_results(self, job_id: str, 
                             timeout: float = 600.0,
                             wait_if_running: bool = True,
                             generate_report: bool = True,
                             generate_archive: bool = True) -> Optional[List[Dict]]:
        """
        [v2.5.21] RÃ©cupÃ¨re les rÃ©sultats d'un job existant par son ID.
        
        Utile pour :
        - Reprendre aprÃ¨s une dÃ©connexion rÃ©seau
        - RÃ©cupÃ©rer les rÃ©sultats d'un job soumis prÃ©cÃ©demment
        - RÃ©cupÃ©rer les rÃ©sultats d'un job depuis un autre script
        
        Args:
            job_id: ID du job IBM (ex: 'd58l911smlfc739jogmg')
            timeout: Timeout en secondes si le job n'est pas terminÃ© (dÃ©faut: 600s)
            wait_if_running: Si True, attend que le job termine (dÃ©faut: True)
            generate_report: GÃ©nÃ©rer un rapport HTML (dÃ©faut: True)
            generate_archive: GÃ©nÃ©rer une archive JSON (dÃ©faut: True)
            
        Returns:
            Liste des rÃ©sultats (counts) ou None si erreur
            
        Example:
            # AprÃ¨s une dÃ©connexion, rÃ©cupÃ©rer le job
            results = fw.retrieve_job_results('d58l911smlfc739jogmg')
            
            # Sans attendre (vÃ©rifier seulement si DONE)
            results = fw.retrieve_job_results('d58l911smlfc739jogmg', wait_if_running=False)
        """
        if not getattr(self, "_connected", False):
            self.logger.warn("âš ï¸ Non connectÃ© - tentative de reconnexion...")
            if not self.connect():
                raise RuntimeError("Impossible de se reconnecter Ã  IBM Quantum")
        
        self.logger.info(f"")
        self.logger.info(f"{'â•' * 60}")
        self.logger.info(f"  ğŸ”„ RÃ‰CUPÃ‰RATION JOB: {job_id}")
        self.logger.info(f"{'â•' * 60}")
        
        try:
            # RÃ©cupÃ©rer le job
            job = self.service.job(job_id)
            status = str(job.status())
            
            self.logger.info(f"  ğŸ“Š Statut actuel: {status}")
            
            # Si pas terminÃ© et wait_if_running=True, attendre
            if status not in ['DONE', 'ERROR', 'CANCELLED']:
                if not wait_if_running:
                    self.logger.warn(f"  âš ï¸ Job pas encore terminÃ© (status={status})")
                    self.logger.info(f"  ğŸ’¡ Utilisez wait_if_running=True pour attendre")
                    return None
                
                self.logger.info(f"  â³ Attente de la fin du job (timeout={timeout}s)...")
                
                # Attendre avec timeout
                start_time = time.time()
                while status not in ['DONE', 'ERROR', 'CANCELLED']:
                    elapsed = time.time() - start_time
                    if elapsed > timeout:
                        self.logger.error(f"  âŒ Timeout aprÃ¨s {timeout}s")
                        self.logger.info(f"  ğŸ’¡ Le job continue sur IBM - rÃ©essayez plus tard")
                        return None
                    
                    time.sleep(5)  # Poll toutes les 5 secondes
                    try:
                        job = self.service.job(job_id)  # Refresh
                        status = str(job.status())
                        self.logger.info(f"  â³ [{int(elapsed)}s] Status: {status}")
                    except Exception as e:
                        self.logger.warn(f"  âš ï¸ Erreur refresh: {e} - retry...")
                        time.sleep(10)
            
            # Traiter selon le statut final
            if status == 'DONE':
                self.logger.info(f"  âœ… Job terminÃ©!")
                
                # RÃ©cupÃ©rer les temps d'exÃ©cution
                qpu_times = self.get_job_execution_times(job_id)
                qpu_time_s = qpu_times.get('qpu_time_s', 0) or 0
                
                self.logger.info(f"  ğŸš€ Temps QPU: {qpu_time_s:.2f}s")
                
                # RÃ©cupÃ©rer les rÃ©sultats
                raw_result = job.result()
                
                # Compter les circuits
                n_circuits = 0
                if hasattr(raw_result, '__iter__'):
                    try:
                        n_circuits = len(list(raw_result))
                        # Re-fetch car on a consommÃ© l'itÃ©rateur
                        raw_result = job.result()
                    except:
                        n_circuits = 1
                
                # Traiter les rÃ©sultats
                results = self._process_results(raw_result, circuits=None, save_counts=True)
                
                self.logger.info(f"  ğŸ“¦ {len(results)} rÃ©sultats rÃ©cupÃ©rÃ©s")
                
                # Stocker les mÃ©tadonnÃ©es
                self.last_job_id = job_id
                self.last_usage = qpu_time_s
                
                # GÃ©nÃ©rer rapport/archive si demandÃ©
                run_context = {
                    'job_id': job_id,
                    'backend': self.backend_name,
                    'qpu_time_s': qpu_time_s,
                    'recovered': True,
                    'timestamp': datetime.now().isoformat(),
                }
                
                if generate_archive:
                    try:
                        self._generate_auto_archive(
                            results=results,
                            original_circuits=None,
                            transpiled_circuits=None,
                            run_context=run_context
                        )
                    except Exception as e:
                        self.logger.warn(f"  âš ï¸ Erreur gÃ©nÃ©ration archive: {e}")
                
                if generate_report:
                    try:
                        self._generate_auto_report(
                            results=results,
                            run_context=run_context,
                            title=f"Recovered Job {job_id[:10]}..."
                        )
                    except Exception as e:
                        self.logger.warn(f"  âš ï¸ Erreur gÃ©nÃ©ration rapport: {e}")
                
                self.logger.info(f"{'â•' * 60}")
                return results
                
            elif status == 'ERROR':
                self.logger.error(f"  âŒ Job en erreur!")
                diagnosis = self.diagnose_job_error(job_id, verbose=True)
                return None
                
            elif status == 'CANCELLED':
                self.logger.warn(f"  âš ï¸ Job annulÃ©")
                return None
                
        except Exception as e:
            self.logger.error(f"  âŒ Erreur rÃ©cupÃ©ration: {e}")
            import traceback
            self.logger.debug(traceback.format_exc())
            return None
    
    def list_recent_jobs(self, n: int = 10, 
                         status_filter: str = None,
                         backend_filter: str = None) -> List[Dict]:
        """
        [v2.5.21] Liste les jobs rÃ©cents sur IBM Quantum.
        
        Args:
            n: Nombre de jobs Ã  rÃ©cupÃ©rer (dÃ©faut: 10)
            status_filter: Filtrer par statut ('DONE', 'ERROR', 'RUNNING', 'QUEUED')
            backend_filter: Filtrer par backend (ex: 'ibm_fez')
            
        Returns:
            Liste de dicts avec info sur chaque job
            
        Example:
            # Lister les 10 derniers jobs
            jobs = fw.list_recent_jobs(n=10)
            for j in jobs:
                print(f"{j['job_id']}: {j['status']} ({j['backend']})")
            
            # Filtrer les jobs terminÃ©s
            done_jobs = fw.list_recent_jobs(status_filter='DONE')
        """
        if not getattr(self, "_connected", False):
            raise RuntimeError("Non connectÃ©! Appelez connect() d'abord.")
        
        self.logger.info(f"ğŸ“‹ RÃ©cupÃ©ration des {n} derniers jobs...")
        
        try:
            # RÃ©cupÃ©rer les jobs via le service
            jobs_iter = self.service.jobs(limit=n)
            
            jobs_list = []
            for job in jobs_iter:
                try:
                    job_info = {
                        'job_id': job.job_id(),
                        'status': str(job.status()),
                        'backend': getattr(job, 'backend_name', None) or getattr(job, 'backend', lambda: 'unknown')(),
                        'creation_date': None,
                        'qpu_time_s': None,
                    }
                    
                    # Date de crÃ©ation
                    try:
                        cd = job.creation_date
                        if callable(cd):
                            cd = cd()
                        job_info['creation_date'] = cd.isoformat() if cd else None
                    except:
                        pass
                    
                    # Temps QPU si disponible
                    try:
                        if job_info['status'] == 'DONE':
                            usage = job.usage()
                            job_info['qpu_time_s'] = float(usage) if usage else None
                    except:
                        pass
                    
                    # Appliquer les filtres
                    if status_filter and job_info['status'] != status_filter:
                        continue
                    if backend_filter and job_info['backend'] != backend_filter:
                        continue
                    
                    jobs_list.append(job_info)
                    
                except Exception as e:
                    self.logger.debug(f"Erreur lecture job: {e}")
                    continue
            
            # Afficher un rÃ©sumÃ©
            self.logger.info(f"")
            self.logger.info(f"{'â•' * 70}")
            self.logger.info(f"  ğŸ“‹ {len(jobs_list)} JOBS RÃ‰CENTS")
            self.logger.info(f"{'â•' * 70}")
            self.logger.info(f"  {'JOB ID':<25} {'STATUS':<12} {'BACKEND':<15} {'QPU (s)':<10}")
            self.logger.info(f"  {'-'*25} {'-'*12} {'-'*15} {'-'*10}")
            
            for j in jobs_list[:10]:  # Afficher max 10
                qpu = f"{j['qpu_time_s']:.1f}" if j['qpu_time_s'] else "-"
                self.logger.info(f"  {j['job_id']:<25} {j['status']:<12} {j['backend'] or 'N/A':<15} {qpu:<10}")
            
            if len(jobs_list) > 10:
                self.logger.info(f"  ... et {len(jobs_list) - 10} autres")
            
            self.logger.info(f"{'â•' * 70}")
            
            return jobs_list
            
        except Exception as e:
            self.logger.error(f"Erreur listing jobs: {e}")
            return []

    def diagnose_job_error(self, job_id: str, verbose: bool = True) -> Dict[str, Any]:
        """
        [v2.5.15] Diagnostique un job en erreur et affiche les dÃ©tails.
        
        RÃ©cupÃ¨re toutes les informations disponibles sur un job qui a Ã©chouÃ©:
        - Message d'erreur IBM
        - Code d'erreur
        - Timestamps
        - MÃ©triques
        - Logs du job
        
        Args:
            job_id: ID du job Ã  diagnostiquer
            verbose: Afficher les dÃ©tails formatÃ©s (dÃ©faut: True)
            
        Returns:
            Dict avec tous les dÃ©tails du diagnostic
            
        Usage:
            # AprÃ¨s une erreur
            diag = fw.diagnose_job_error("d521odgnsj9s73avgfg0")
            
            # Ou pour un job connu
            diag = fw.diagnose_job_error("crnxxxxxx")
        """
        if not getattr(self, "_connected", False):
            raise RuntimeError("Non connectÃ©! Appelez connect() d'abord.")
        
        diagnosis = {
            'job_id': job_id,
            'status': None,
            'error_message': None,
            'error_code': None,
            'backend': None,
            'creation_date': None,
            'timestamps': {},
            'metrics': {},
            'logs': None,
            'circuits_info': {},
            'possible_causes': [],
            'recommendations': [],
        }
        
        try:
            # RÃ©cupÃ©rer le job
            job = self.service.job(job_id)
            
            # Status
            try:
                diagnosis['status'] = str(job.status())
            except:
                pass
            
            # Utiliser notre mÃ©thode de rÃ©cupÃ©ration d'erreurs
            error_details = self._get_job_error_details(job)
            diagnosis.update({
                'error_message': error_details.get('error_message'),
                'error_code': error_details.get('error_code'),
                'backend': error_details.get('backend'),
                'creation_date': error_details.get('creation_date'),
            })
            
            # MÃ©triques dÃ©taillÃ©es
            try:
                metrics = job.metrics()
                diagnosis['metrics'] = metrics
                
                if 'timestamps' in metrics:
                    diagnosis['timestamps'] = metrics['timestamps']
            except:
                pass
            
            # Logs du job (peuvent contenir des dÃ©tails d'erreur)
            try:
                logs = job.logs()
                diagnosis['logs'] = logs
                
                # Chercher des messages d'erreur dans les logs
                if logs and not diagnosis['error_message']:
                    log_str = str(logs)
                    if 'error' in log_str.lower() or 'fail' in log_str.lower():
                        # Extraire la partie pertinente
                        for line in log_str.split('\n'):
                            if 'error' in line.lower() or 'fail' in line.lower():
                                diagnosis['error_message'] = line.strip()
                                break
            except:
                pass
            
            # Informations sur les circuits
            try:
                inputs = job.inputs
                if inputs:
                    if 'circuits' in inputs:
                        circuits = inputs['circuits']
                        if isinstance(circuits, list):
                            diagnosis['circuits_info']['count'] = len(circuits)
                    if 'options' in inputs:
                        diagnosis['circuits_info']['options'] = inputs['options']
            except:
                pass
            
            # Analyse des causes possibles
            error_msg = diagnosis.get('error_message', '') or ''
            error_msg_lower = error_msg.lower()
            
            if 'timeout' in error_msg_lower or 'time limit' in error_msg_lower:
                diagnosis['possible_causes'].append("â±ï¸ Timeout: Circuit trop profond ou trop de shots")
                diagnosis['recommendations'].append("RÃ©duire la profondeur des circuits ou le nombre de shots")
            
            if 'qubit' in error_msg_lower and ('not available' in error_msg_lower or 'faulty' in error_msg_lower):
                diagnosis['possible_causes'].append("ğŸ”´ Qubits indisponibles ou dÃ©fectueux")
                diagnosis['recommendations'].append("Utiliser analyze_calibration() pour voir les qubits OK")
            
            if 'calibration' in error_msg_lower:
                diagnosis['possible_causes'].append("ğŸ“Š ProblÃ¨me de calibration du backend")
                diagnosis['recommendations'].append("Attendre la prochaine calibration ou changer de backend")
            
            if 'memory' in error_msg_lower or 'resource' in error_msg_lower:
                diagnosis['possible_causes'].append("ğŸ’¾ Ressources insuffisantes sur le backend")
                diagnosis['recommendations'].append("RÃ©duire la taille du batch ou le nombre de circuits")
            
            if 'transpil' in error_msg_lower:
                diagnosis['possible_causes'].append("ğŸ”§ Erreur de transpilation")
                diagnosis['recommendations'].append("VÃ©rifier que les circuits sont compatibles avec le backend")
            
            if not diagnosis['possible_causes']:
                diagnosis['possible_causes'].append("â“ Cause non identifiÃ©e automatiquement")
                diagnosis['recommendations'].append("Consulter les logs IBM Quantum ou contacter le support")
            
            # Affichage formatÃ©
            if verbose:
                self._display_job_diagnosis(diagnosis)
                
        except Exception as e:
            diagnosis['diagnostic_error'] = str(e)
            if verbose:
                print(f"\nâŒ Erreur lors du diagnostic: {e}")
                print(f"   VÃ©rifiez que le job_id '{job_id}' est correct et que vous Ãªtes connectÃ©.")
        
        return diagnosis
    
    def _display_job_diagnosis(self, diagnosis: Dict):
        """Affiche le diagnostic de job de maniÃ¨re formatÃ©e."""
        print()
        print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("  â•‘  ğŸ” DIAGNOSTIC JOB IBM QUANTUM                                             â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  ğŸ†” Job ID:     {diagnosis['job_id']:<56} â•‘")
        print(f"  â•‘  ğŸ“Š Status:     {diagnosis.get('status', 'N/A'):<56} â•‘")
        print(f"  â•‘  ğŸ–¥ï¸  Backend:    {diagnosis.get('backend', 'N/A'):<56} â•‘")
        
        if diagnosis.get('creation_date'):
            print(f"  â•‘  ğŸ“… CrÃ©Ã©:       {diagnosis['creation_date'][:56]:<56} â•‘")
        
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  âŒ ERREUR                                                                 â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        
        error_msg = diagnosis.get('error_message', 'Aucun message d\'erreur disponible')
        # Wrap long messages
        if error_msg:
            words = error_msg.split()
            lines = []
            current_line = ""
            for word in words:
                if len(current_line) + len(word) + 1 <= 70:
                    current_line += (" " if current_line else "") + word
                else:
                    if current_line:
                        lines.append(current_line)
                    current_line = word
            if current_line:
                lines.append(current_line)
            
            for i, line in enumerate(lines[:5]):  # Max 5 lignes
                prefix = "  â•‘  ğŸ’¬ " if i == 0 else "  â•‘     "
                print(f"{prefix}{line:<68} â•‘")
        
        if diagnosis.get('error_code'):
            print(f"  â•‘  ğŸ”¢ Code:       {diagnosis['error_code']:<56} â•‘")
        
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  ğŸ” CAUSES POSSIBLES                                                       â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        
        for cause in diagnosis.get('possible_causes', ['Inconnue'])[:4]:
            print(f"  â•‘     {cause:<67} â•‘")
        
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  ğŸ’¡ RECOMMANDATIONS                                                        â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        
        for rec in diagnosis.get('recommendations', ['VÃ©rifier les logs'])[:4]:
            print(f"  â•‘     â€¢ {rec:<65} â•‘")
        
        if diagnosis.get('timestamps'):
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            print("  â•‘  â±ï¸  TIMESTAMPS                                                            â•‘")
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            ts = diagnosis['timestamps']
            for key in ['created', 'running', 'finished']:
                if key in ts:
                    val = ts[key][:25] if ts[key] else 'N/A'
                    print(f"  â•‘     {key.capitalize():<12}: {val:<52} â•‘")
        
        if diagnosis.get('circuits_info'):
            ci = diagnosis['circuits_info']
            if ci.get('count'):
                print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
                print(f"  â•‘  ğŸ“‹ Circuits:   {ci['count']} circuits soumis                                     â•‘")
        
        print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
        print("  ğŸ’¡ TIP: Pour plus de dÃ©tails, examinez diagnosis['logs'] et diagnosis['metrics']")
        print()

    def get_jobs_statistics(self,
                            created_after: Optional[datetime] = None,
                            created_before: Optional[datetime] = None,
                            backend_name: Optional[str] = None,
                            job_tags: Optional[List[str]] = None,
                            limit: Optional[int] = 200) -> Dict[str, Any]:
        if not getattr(self, "_connected", False):
            raise RuntimeError("Non connectÃ©! Appelez connect() d'abord.")

        def _fetch():
            return self.service.jobs(
                limit=limit,
                backend_name=backend_name,
                job_tags=job_tags,
                created_after=created_after,
                created_before=created_before,
                descending=True
            )

        jobs = self._retry(_fetch, "RÃ©cupÃ©ration jobs pour stats") or []

        status_counts = defaultdict(int)
        backend_counts = defaultdict(int)
        total_usage = 0.0
        summary: List[Dict[str, Any]] = []

        for j in jobs:
            try:
                jid = j.job_id()
            except Exception:
                jid = getattr(j, "job_id", None)
                jid = jid() if callable(jid) else jid

            try:
                status = str(j.status())
            except Exception:
                status = "UNKNOWN"

            backend = None
            try:
                backend = getattr(j, "backend_name", None)
                backend = backend() if callable(backend) else backend
            except Exception:
                pass

            cdate_iso = None
            try:
                cd = getattr(j, "creation_date", None)
                cd = cd() if callable(cd) else cd
                cdate_iso = cd.isoformat() if isinstance(cd, datetime) else (str(cd) if cd else None)
            except Exception:
                pass

            status_counts[status] += 1
            if backend:
                backend_counts[backend] += 1

            try:
                total_usage += self._safe_float(j.usage())
            except Exception:
                pass

            summary.append({
                "job_id": jid,
                "status": status,
                "backend": backend,
                "creation_date": cdate_iso,
            })

        stats = {
            "window": {
                "created_after": created_after.isoformat() if isinstance(created_after, datetime) else None,
                "created_before": created_before.isoformat() if isinstance(created_before, datetime) else None,
                "backend_name": backend_name,
                "job_tags": job_tags,
                "limit": limit,
            },
            "counts": {
                "total_jobs": len(summary),
                "by_status": dict(status_counts),
                "by_backend": dict(backend_counts),
            },
            "usage": {
                "total_usage_seconds": round(total_usage, 3),
                "total_usage_minutes": round(total_usage / 60.0, 3),
            },
            "jobs": summary,
        }

        if getattr(self, "report", None):
            try:
                self.report.set("jobs_statistics", stats, section="jobs")
            except Exception:
                pass

        return stats

    def estimate_remaining_qpu_time(self,
                                    budget_minutes: float = 10.0,
                                    window_days: int = 28,
                                    backend_name: Optional[str] = None,
                                    job_tags: Optional[List[str]] = None,
                                    limit: int = 500) -> Dict[str, Any]:
        if not getattr(self, "_connected", False):
            raise RuntimeError("Non connectÃ©! Appelez connect() d'abord.")

        now = datetime.now()
        created_after = now - timedelta(days=window_days)

        stats = self.get_jobs_statistics(
            created_after=created_after,
            created_before=now,
            backend_name=backend_name,
            job_tags=job_tags,
            limit=limit
        )

        used_seconds = float(stats.get("usage", {}).get("total_usage_seconds", 0.0))
        budget_seconds = float(budget_minutes) * 60.0
        remaining_seconds = max(0.0, budget_seconds - used_seconds)

        remaining = {
            "window_days": window_days,
            "budget_minutes": float(budget_minutes),
            "budget_seconds": budget_seconds,
            "used_seconds": used_seconds,
            "used_minutes": used_seconds / 60.0,
            "remaining_seconds": remaining_seconds,
            "remaining_minutes": remaining_seconds / 60.0,
            "backend_filter": backend_name,
            "job_tags_filter": job_tags,
        }

        if getattr(self, "report", None):
            try:
                self.report.set("qpu_remaining_estimate", remaining, section="jobs")
            except Exception:
                pass

        return remaining

    # -----------------------------
    # Multi-accounts wrappers
    # -----------------------------

    def get_available_accounts(self) -> Dict[str, Dict[str, Any]]:
        return self.credentials.list_accounts()

    def list_available_account_labels(self) -> List[str]:
        return self.credentials.list_available_labels()

    def set_active_account_label(self, label: str) -> None:
        self.credentials.set_active_label(label)

    # -----------------------------
    # Audit multi-comptes (lecture API)
    # -----------------------------

    def analyze_all_accounts_usage(self,
                                   window_days: int = 30,
                                   budget_minutes: float = 10.0,
                                   backend_name: Optional[str] = None,
                                   job_tags: Optional[List[str]] = None,
                                   limit: int = 500,
                                   service_factory: Optional[Callable[[str, Dict[str, Any]], Any]] = None
                                   ) -> Dict[str, Any]:
        accounts = self.get_available_accounts()
        now = datetime.now()
        created_after = now - timedelta(days=window_days)

        results: Dict[str, Any] = {
            "window_days": window_days,
            "budget_minutes": float(budget_minutes),
            "accounts": {},
            "usage": {
                "budget_minutes": float(budget_minutes),
                "total_used_minutes_all_accounts": 0.0,
                "total_remaining_minutes_all_accounts": 0.0,
            }
        }

        for label, cfg in accounts.items():
            try:
                if service_factory:
                    service = service_factory(label, cfg)
                else:
                    if QiskitRuntimeService is None:
                        raise RuntimeError("QiskitRuntimeService indisponible.")
                    service = QiskitRuntimeService(**cfg)

                jobs = service.jobs(
                    limit=limit,
                    backend_name=backend_name,
                    job_tags=job_tags,
                    created_after=created_after,
                    created_before=now,
                    descending=True
                ) or []

                status_counts = defaultdict(int)
                total_usage = 0.0
                job_ids: List[str] = []

                for j in jobs:
                    try:
                        jid = j.job_id()
                    except Exception:
                        jid = getattr(j, "job_id", None)
                        jid = jid() if callable(jid) else jid

                    if jid:
                        job_ids.append(jid)

                    try:
                        status_counts[str(j.status())] += 1
                    except Exception:
                        status_counts["UNKNOWN"] += 1

                    try:
                        total_usage += self._safe_float(j.usage())
                    except Exception:
                        pass

                used_minutes = total_usage / 60.0
                remaining_minutes = max(0.0, float(budget_minutes) - used_minutes)

                results["accounts"][label] = {
                    "jobs_count": len(jobs),
                    "by_status": dict(status_counts),
                    "usage_seconds": round(total_usage, 3),
                    "usage_minutes": round(used_minutes, 3),
                    "remaining_minutes": round(remaining_minutes, 3),
                    "job_ids_sample": job_ids[:10],

                    # Compat tests : expose aussi un sous-bloc "usage"
                    "usage": {
                        "budget_minutes": float(budget_minutes),
                        "total_usage_seconds": round(total_usage, 3),
                        "total_usage_minutes": round(used_minutes, 3),
                        "remaining_minutes": round(remaining_minutes, 3),
                    }
                }

            except Exception as e:
                results["accounts"][label] = {
                    "error": str(e),
                    "jobs_count": 0,
                    "by_status": {},
                    "usage_seconds": 0.0,
                    "usage_minutes": 0.0,
                    "remaining_minutes": float(budget_minutes),
                    "job_ids_sample": [],

                    "usage": {
                        "budget_minutes": float(budget_minutes),
                        "total_usage_seconds": 0.0,
                        "total_usage_minutes": 0.0,
                        "remaining_minutes": float(budget_minutes),
                    }
                }

        # agrÃ©gats globaux
        try:
            total_used = 0.0
            total_remaining = 0.0
            for _lab, _data in results.get("accounts", {}).items():
                u = _data.get("usage", {})
                used_m = float(u.get("total_usage_minutes", _data.get("usage_minutes", 0.0)) or 0.0)
                rem_m = float(u.get("remaining_minutes", _data.get("remaining_minutes", 0.0)) or 0.0)
                total_used += used_m
                total_remaining += rem_m

            results["usage"]["total_used_minutes_all_accounts"] = round(total_used, 3)
            results["usage"]["total_remaining_minutes_all_accounts"] = round(total_remaining, 3)
        except Exception:
            pass

        if getattr(self, "report", None):
            try:
                self.report.set("multi_account_usage", results, section="jobs")
            except Exception:
                pass

        return results

    def test_all_accounts_usage(self, *args, **kwargs) -> Dict[str, Any]:
        """Alias public."""
        return self.analyze_all_accounts_usage(*args, **kwargs)

    def download_all_accounts_jobs(self,
                                   output_dir: str = "jobs",
                                   window_days: int = 30,
                                   budget_minutes: float = 10.0,
                                   backend_name: Optional[str] = None,
                                   job_tags: Optional[List[str]] = None,
                                   limit: int = 500,
                                   with_metrics: bool = True,
                                   with_logs: bool = False,
                                   verbose: bool = True,
                                   service_factory: Optional[Callable[[str, Dict[str, Any]], Any]] = None
                                   ) -> Dict[str, Any]:
        """
        TÃ©lÃ©charge tous les jobs de tous les comptes et gÃ©nÃ¨re des rapports.
        
        CrÃ©e une structure de rÃ©pertoires:
            {output_dir}/
            â”œâ”€â”€ {label1}/
            â”‚   â”œâ”€â”€ jobs/
            â”‚   â”‚   â”œâ”€â”€ job_{id1}.json
            â”‚   â”‚   â”œâ”€â”€ job_{id2}.json
            â”‚   â”‚   â””â”€â”€ ...
            â”‚   â”œâ”€â”€ report.json
            â”‚   â””â”€â”€ report.txt
            â”œâ”€â”€ {label2}/
            â”‚   â””â”€â”€ ...
            â””â”€â”€ global_report.json
        
        Args:
            output_dir: RÃ©pertoire de sortie (dÃ©faut: "jobs")
            window_days: Nombre de jours Ã  analyser (dÃ©faut: 30)
            budget_minutes: Budget en minutes par compte (dÃ©faut: 10.0)
            backend_name: Filtrer par backend (optionnel)
            job_tags: Filtrer par tags (optionnel)
            limit: Nombre max de jobs par compte (dÃ©faut: 500)
            with_metrics: Inclure les mÃ©triques des jobs (dÃ©faut: True)
            with_logs: Inclure les logs des jobs (dÃ©faut: False)
            verbose: Afficher la progression (dÃ©faut: True)
            service_factory: Factory pour crÃ©er les services (pour tests)
        
        Returns:
            Dict avec le rÃ©sumÃ© global et les chemins des fichiers crÃ©Ã©s
        """
        # [v2.5.14] SÃ‰CURITÃ‰: Bloquer la rÃ©cupÃ©ration des logs en mode production
        if getattr(self, 'production_mode', False) and with_logs:
            raise SecurityError(
                "ğŸ”’ PRODUCTION_MODE: with_logs=True interdit en mode production!\n"
                "   Les logs peuvent contenir des informations cryptographiques sensibles.\n"
                "   DÃ©sactivez production_mode ou utilisez with_logs=False."
            )
        
        from pathlib import Path
        import json
        
        accounts = self.get_available_accounts()
        now = datetime.now()
        created_after = now - timedelta(days=window_days)
        
        # CrÃ©er le rÃ©pertoire principal
        base_path = Path(output_dir)
        base_path.mkdir(parents=True, exist_ok=True)
        
        global_results: Dict[str, Any] = {
            "generated_at": now.isoformat(),
            "window_days": window_days,
            "budget_minutes": float(budget_minutes),
            "filters": {
                "backend_name": backend_name,
                "job_tags": job_tags,
                "limit": limit,
            },
            "accounts": {},
            "totals": {
                "total_accounts": len(accounts),
                "total_jobs": 0,
                "total_usage_minutes": 0.0,
                "total_files_created": 0,
            }
        }
        
        if verbose:
            print(f"\n{'â•' * 70}")
            print(f"  ğŸ“¥ TÃ‰LÃ‰CHARGEMENT DES JOBS - {len(accounts)} COMPTE(S)")
            print(f"  [D] PÃ©riode: {window_days} derniers jours")
            print(f"  ğŸ“ RÃ©pertoire: {base_path.absolute()}")
            print(f"{'â•' * 70}\n")
        
        for label, cfg in accounts.items():
            if verbose:
                print(f"\nğŸ” [{label}] Connexion et rÃ©cupÃ©ration des jobs...")
            
            # CrÃ©er le rÃ©pertoire du compte
            account_path = base_path / label
            account_path.mkdir(parents=True, exist_ok=True)
            jobs_path = account_path / "jobs"
            jobs_path.mkdir(parents=True, exist_ok=True)
            
            account_result = {
                "label": label,
                "path": str(account_path),
                "jobs_count": 0,
                "jobs_downloaded": 0,
                "usage_seconds": 0.0,
                "usage_minutes": 0.0,
                "remaining_minutes": float(budget_minutes),
                "by_status": {},
                "by_backend": {},
                "job_files": [],
                "errors": [],
            }
            
            try:
                # CrÃ©er le service
                if service_factory:
                    service = service_factory(label, cfg)
                else:
                    if QiskitRuntimeService is None:
                        raise RuntimeError("QiskitRuntimeService indisponible.")
                    service = QiskitRuntimeService(**cfg)
                
                # RÃ©cupÃ©rer la liste des jobs
                jobs = service.jobs(
                    limit=limit,
                    backend_name=backend_name,
                    job_tags=job_tags,
                    created_after=created_after,
                    created_before=now,
                    descending=True
                ) or []
                
                account_result["jobs_count"] = len(jobs)
                
                if verbose:
                    print(f"   [=] {len(jobs)} jobs trouvÃ©s")
                
                # Traiter chaque job
                for idx, job in enumerate(jobs):
                    try:
                        # Extraire job_id
                        try:
                            jid = job.job_id()
                        except Exception:
                            jid = getattr(job, "job_id", None)
                            jid = jid() if callable(jid) else jid
                        
                        if not jid:
                            continue
                        
                        # Extraire les informations du job
                        job_info: Dict[str, Any] = {
                            "job_id": jid,
                            "account_label": label,
                            "downloaded_at": now.isoformat(),
                        }
                        
                        # Status
                        try:
                            status = str(job.status())
                            job_info["status"] = status
                            account_result["by_status"][status] = account_result["by_status"].get(status, 0) + 1
                        except Exception:
                            job_info["status"] = "UNKNOWN"
                            account_result["by_status"]["UNKNOWN"] = account_result["by_status"].get("UNKNOWN", 0) + 1
                        
                        # Backend
                        try:
                            backend = getattr(job, "backend", None)
                            if callable(backend):
                                backend = backend()
                            if hasattr(backend, "name"):
                                backend = backend.name
                            job_info["backend"] = str(backend) if backend else None
                            if backend:
                                account_result["by_backend"][str(backend)] = account_result["by_backend"].get(str(backend), 0) + 1
                        except Exception:
                            job_info["backend"] = None
                        
                        # Dates
                        try:
                            cd = getattr(job, "creation_date", None)
                            cd = cd() if callable(cd) else cd
                            job_info["creation_date"] = cd.isoformat() if isinstance(cd, datetime) else str(cd) if cd else None
                        except Exception:
                            job_info["creation_date"] = None
                        
                        # Usage
                        try:
                            usage = self._safe_float(job.usage())
                            job_info["usage_seconds"] = usage
                            account_result["usage_seconds"] += usage
                        except Exception:
                            job_info["usage_seconds"] = 0.0
                        
                        # Session, tags, primitive
                        job_info["session_id"] = getattr(job, "session_id", None)
                        job_info["tags"] = getattr(job, "tags", None)
                        job_info["primitive_id"] = getattr(job, "primitive_id", None)
                        
                        # MÃ©triques (optionnel)
                        if with_metrics:
                            try:
                                job_info["metrics"] = job.metrics()
                            except Exception:
                                job_info["metrics"] = None
                        
                        # Logs (optionnel)
                        if with_logs:
                            try:
                                job_info["logs"] = job.logs()
                            except Exception:
                                job_info["logs"] = None
                        
                        # Sauvegarder le fichier JSON du job
                        job_file = jobs_path / f"job_{jid}.json"
                        with open(job_file, 'w', encoding='utf-8') as f:
                            json.dump(job_info, f, indent=2, default=str)
                        
                        account_result["job_files"].append(str(job_file))
                        account_result["jobs_downloaded"] += 1
                        
                        if verbose and (idx + 1) % 10 == 0:
                            print(f"   â³ {idx + 1}/{len(jobs)} jobs traitÃ©s...")
                        
                    except Exception as e:
                        account_result["errors"].append(f"Job {idx}: {str(e)}")
                
                # Calculer les totaux
                account_result["usage_minutes"] = round(account_result["usage_seconds"] / 60.0, 3)
                account_result["remaining_minutes"] = round(max(0.0, float(budget_minutes) - account_result["usage_minutes"]), 3)
                
                if verbose:
                    print(f"   [OK] {account_result['jobs_downloaded']} jobs tÃ©lÃ©chargÃ©s")
                    print(f"   [T]  Usage: {account_result['usage_minutes']:.2f} min")
                
            except Exception as e:
                account_result["errors"].append(f"Connection error: {str(e)}")
                if verbose:
                    print(f"   [XX] Erreur: {e}")
            
            # GÃ©nÃ©rer le rapport du compte
            report_json_path = account_path / "report.json"
            with open(report_json_path, 'w', encoding='utf-8') as f:
                json.dump(account_result, f, indent=2, default=str)
            
            # GÃ©nÃ©rer le rapport texte du compte
            report_txt_path = account_path / "report.txt"
            self._generate_account_text_report(account_result, report_txt_path, budget_minutes, window_days)
            
            # Ajouter au rÃ©sultat global
            global_results["accounts"][label] = {
                "path": str(account_path),
                "jobs_count": account_result["jobs_count"],
                "jobs_downloaded": account_result["jobs_downloaded"],
                "usage_minutes": account_result["usage_minutes"],
                "remaining_minutes": account_result["remaining_minutes"],
                "by_status": account_result["by_status"],
                "by_backend": account_result["by_backend"],
                "errors_count": len(account_result["errors"]),
            }
            
            global_results["totals"]["total_jobs"] += account_result["jobs_count"]
            global_results["totals"]["total_usage_minutes"] += account_result["usage_minutes"]
            global_results["totals"]["total_files_created"] += account_result["jobs_downloaded"] + 2  # +2 pour reports
        
        # Sauvegarder le rapport global
        global_report_path = base_path / "global_report.json"
        with open(global_report_path, 'w', encoding='utf-8') as f:
            json.dump(global_results, f, indent=2, default=str)
        
        # GÃ©nÃ©rer le rapport texte global
        global_report_txt_path = base_path / "global_report.txt"
        self._generate_global_text_report(global_results, global_report_txt_path, budget_minutes, window_days)
        
        if verbose:
            print(f"\n{'â•' * 70}")
            print(f"  [OK] TÃ‰LÃ‰CHARGEMENT TERMINÃ‰")
            print(f"{'â•' * 70}")
            print(f"  [#] {global_results['totals']['total_jobs']} jobs au total")
            print(f"  ğŸ“ {global_results['totals']['total_files_created']} fichiers crÃ©Ã©s")
            print(f"  [T]  Usage total: {global_results['totals']['total_usage_minutes']:.2f} minutes")
            print(f"  ğŸ“‚ RÃ©pertoire: {base_path.absolute()}")
            print(f"{'â•' * 70}\n")
        
        return global_results

    def _generate_account_text_report(self, 
                                      account_result: Dict[str, Any], 
                                      output_path: Path,
                                      budget_minutes: float,
                                      window_days: int):
        """GÃ©nÃ¨re un rapport texte pour un compte."""
        lines = []
        lines.append("=" * 70)
        lines.append(f"  RAPPORT DE COMPTE: {account_result['label'].upper()}")
        lines.append(f"  GÃ©nÃ©rÃ© le: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("=" * 70)
        lines.append("")
        lines.append(f"  [D] PÃ©riode analysÃ©e: {window_days} derniers jours")
        lines.append(f"  ğŸ’° Budget: {budget_minutes} minutes")
        lines.append("")
        lines.append("-" * 70)
        lines.append("  RÃ‰SUMÃ‰")
        lines.append("-" * 70)
        lines.append(f"  Jobs trouvÃ©s:      {account_result['jobs_count']}")
        lines.append(f"  Jobs tÃ©lÃ©chargÃ©s:  {account_result['jobs_downloaded']}")
        lines.append(f"  Usage total:       {account_result['usage_minutes']:.2f} minutes")
        lines.append(f"  Temps restant:     {account_result['remaining_minutes']:.2f} minutes")
        
        pct = (account_result['usage_minutes'] / budget_minutes * 100) if budget_minutes > 0 else 0
        lines.append(f"  Utilisation:       {pct:.1f}%")
        lines.append("")
        
        if account_result["by_status"]:
            lines.append("-" * 70)
            lines.append("  PAR STATUS")
            lines.append("-" * 70)
            for status, count in sorted(account_result["by_status"].items()):
                lines.append(f"    {status:<20} {count:>5}")
            lines.append("")
        
        if account_result["by_backend"]:
            lines.append("-" * 70)
            lines.append("  PAR BACKEND")
            lines.append("-" * 70)
            for backend, count in sorted(account_result["by_backend"].items()):
                lines.append(f"    {backend:<20} {count:>5}")
            lines.append("")
        
        if account_result["errors"]:
            lines.append("-" * 70)
            lines.append("  ERREURS")
            lines.append("-" * 70)
            for err in account_result["errors"][:10]:
                lines.append(f"    [!!]  {err}")
            if len(account_result["errors"]) > 10:
                lines.append(f"    ... et {len(account_result['errors']) - 10} autres erreurs")
            lines.append("")
        
        lines.append("=" * 70)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))

    def _generate_global_text_report(self,
                                     global_results: Dict[str, Any],
                                     output_path: Path,
                                     budget_minutes: float,
                                     window_days: int):
        """GÃ©nÃ¨re un rapport texte global."""
        lines = []
        lines.append("=" * 70)
        lines.append("  RAPPORT GLOBAL - TOUS LES COMPTES IBM QUANTUM")
        lines.append(f"  GÃ©nÃ©rÃ© le: {global_results['generated_at']}")
        lines.append("=" * 70)
        lines.append("")
        lines.append(f"  [D] PÃ©riode analysÃ©e: {window_days} derniers jours")
        lines.append(f"  ğŸ’° Budget par compte: {budget_minutes} minutes")
        lines.append("")
        lines.append("-" * 70)
        lines.append("  TOTAUX")
        lines.append("-" * 70)
        totals = global_results["totals"]
        lines.append(f"  Comptes analysÃ©s:    {totals['total_accounts']}")
        lines.append(f"  Jobs au total:       {totals['total_jobs']}")
        lines.append(f"  Usage total:         {totals['total_usage_minutes']:.2f} minutes")
        lines.append(f"  Fichiers crÃ©Ã©s:      {totals['total_files_created']}")
        
        total_budget = budget_minutes * totals['total_accounts']
        if total_budget > 0:
            pct = (totals['total_usage_minutes'] / total_budget * 100)
            lines.append(f"  Budget total:        {total_budget:.2f} minutes")
            lines.append(f"  Utilisation globale: {pct:.1f}%")
        lines.append("")
        
        lines.append("-" * 70)
        lines.append("  DÃ‰TAIL PAR COMPTE")
        lines.append("-" * 70)
        lines.append(f"  {'Compte':<20} {'Jobs':>8} {'Usage (min)':>12} {'Restant':>12} {'Status':>10}")
        lines.append(f"  {'-' * 20} {'-' * 8} {'-' * 12} {'-' * 12} {'-' * 10}")
        
        for label, data in sorted(global_results["accounts"].items()):
            jobs = data["jobs_count"]
            usage = data["usage_minutes"]
            remaining = data["remaining_minutes"]
            
            pct = (usage / budget_minutes * 100) if budget_minutes > 0 else 0
            if pct >= 90:
                status = "CRITIQUE"
            elif pct >= 70:
                status = "ATTENTION"
            elif pct >= 50:
                status = "MODÃ‰RÃ‰"
            else:
                status = "OK"
            
            lines.append(f"  {label:<20} {jobs:>8} {usage:>10.2f}m {remaining:>10.2f}m {status:>10}")
            
            if data.get("errors_count", 0) > 0:
                lines.append(f"    â””â”€ {data['errors_count']} erreur(s)")
        
        lines.append("")
        lines.append("=" * 70)
        lines.append("  Fin du rapport")
        lines.append("=" * 70)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))
    
    # =========================================================================
    # [v2.5.15] MÃ‰THODES D'ESTIMATION DE COÃ›T (dÃ©placÃ©es de QMCFrameworkV2_4)
    # =========================================================================
    
    def estimate_cost(self, circuits, shots: int = 4096,
                      display: bool = True) -> Dict:
        """
        Estime le coÃ»t d'exÃ©cution avant soumission.
        
        [v2.5.14] Accepte circuit unique OU liste.
        [v2.5.15] Maintenant disponible dans QMCFramework (pas juste V2_4).
        
        Args:
            circuits: Circuit unique OU liste de circuits Ã  estimer
            shots: Nombre de shots
            display: Afficher l'estimation
        
        Returns:
            Dict avec estimations dÃ©taillÃ©es
        """
        # [v2.5.14] Auto-wrapping
        from qiskit import QuantumCircuit
        if isinstance(circuits, QuantumCircuit):
            circuits = [circuits]
        
        # VÃ©rifier que cost_estimator est initialisÃ©
        if not hasattr(self, 'cost_estimator') or self.cost_estimator is None:
            # Initialisation tardive si nÃ©cessaire
            self.cost_estimator = CircuitCostEstimator(framework=self, logger=self.logger)
        
        estimate = self.cost_estimator.estimate(circuits, shots)
        
        if display:
            self.cost_estimator.display_estimate(estimate)
        
        return estimate
    
    def run_on_qpu_with_confirm(self, circuits, shots: int = 4096,
                                **kwargs) -> Optional[List[Dict]]:
        """
        ExÃ©cute sur QPU avec confirmation du coÃ»t.
        
        Affiche l'estimation et demande confirmation avant d'exÃ©cuter.
        [v2.5.14] Accepte circuit unique OU liste.
        [v2.5.15] Maintenant disponible dans QMCFramework (pas juste V2_4).
        """
        # [v2.5.14] Auto-wrapping
        from qiskit import QuantumCircuit
        if isinstance(circuits, QuantumCircuit):
            circuits = [circuits]
        
        # VÃ©rifier que cost_estimator est initialisÃ©
        if not hasattr(self, 'cost_estimator') or self.cost_estimator is None:
            self.cost_estimator = CircuitCostEstimator(framework=self, logger=self.logger)
        
        estimate = self.cost_estimator.estimate(circuits, shots)
        
        confirmed = self.cost_estimator.display_estimate(estimate, confirm=True)
        
        if confirmed:
            return self.run_on_qpu(circuits, shots, **kwargs)
        else:
            if hasattr(self, 'logger') and self.logger:
                self.logger.info("Execution annulÃ©e par l'utilisateur")
            return None


# =============================================================================
#                          EXTENSIONS v2.4.0                         
# =============================================================================

# =============================================================================
# VERSION & METADATA v2.4.0
# =============================================================================

# FRAMEWORK_VERSION dÃ©jÃ  dÃ©fini
FRAMEWORK_AUTHOR = "QMC Research Lab"
FRAMEWORK_LICENSE = "Proprietary"
FRAMEWORK_DATE = "2025-12-11"

# Override __version__ from v2.3.1
# __version__ dÃ©jÃ  dÃ©fini

FRAMEWORK_BANNER_V2_4 = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            QMC QUANTUM TESTING FRAMEWORK v{version}                         â•‘
â•‘                      QMC Research Lab 2025                                â•‘
â•‘                                                                           â•‘
â•‘  ğŸ”Œ PLUGIN SYSTEM    ğŸ”§ CIRCUIT BUILDERS    ğŸ§ª EXPERIMENT ENGINE           â•‘
â•‘  [K] CRYPTO VALID.    [#] BENCHMARK SUITE     [A] ADVANCED ANALYSIS           â•‘
â•‘                                                                           â•‘
â•‘  âœ¨ NEW: Signatures, ZKP, TimeLock, Threshold, ML Optimizer               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""".format(version=__version__)


# =============================================================================
# NOUVELLES ENUMS
# =============================================================================

class SignatureScheme(Enum):
    """SchÃ©mas de signature quantique"""
    LAMPORT_IQP = "lamport_iqp"
    MERKLE_IQP = "merkle_iqp"
    WINTERNITZ_IQP = "winternitz_iqp"


class ZKPProtocol(Enum):
    """Protocoles de preuve Ã  divulgation nulle"""
    SIGMA_IQP = "sigma_iqp"
    SCHNORR_QUANTUM = "schnorr_quantum"
    RANGE_PROOF = "range_proof"
    SET_MEMBERSHIP = "set_membership"


class TimeLockMode(Enum):
    """Modes de verrouillage temporel"""
    FORWARD = "forward"      # Ne peut pas dÃ©chiffrer AVANT une date
    EXPIRING = "expiring"    # Ne peut pas dÃ©chiffrer APRÃˆS une date
    WINDOW = "window"        # DÃ©chiffrement possible dans une fenÃªtre


class QuantumPlatform(Enum):
    """Plateformes quantiques supportÃ©es"""
    IBM_SUPERCONDUCTING = "ibm"
    IONQ_TRAPPED_ION = "ionq"
    PASQAL_NEUTRAL_ATOM = "pasqal"
    RIGETTI_SUPERCONDUCTING = "rigetti"
    QUANTINUUM_TRAPPED_ION = "quantinuum"
    SIMULATOR = "simulator"


# =============================================================================
# NOUVEAUX CIRCUIT BUILDERS
# =============================================================================

class QuantumSignatureBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour signatures numÃ©riques quantiques.
    
    - Signature basÃ©e sur IQP avec paramÃ¨tres dÃ©rivÃ©s du hash du message
    - Taille de signature indÃ©pendante de la longueur du message
    - VÃ©rification par batch via exÃ©cution combinÃ©e
    
    Architecture:
    HâŠ—n â†’ RZ(Î¸_key) â†’ CZ(pattern) â†’ RZ(Ï†_hash) â†’ HâŠ—n â†’ Mesure
    
    La signature = distribution quantique unique au couple (clÃ©, message)
    """
    
    name = "quantum_signature"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
        self._signature_scheme = SignatureScheme.LAMPORT_IQP
    
    def build(self, message_hash: bytes, n_qubits: int = 50,
              key_seed: bytes = None, verification_mode: bool = False,
              add_measurements: bool = True) -> 'CircuitType':
        """
        Construit un circuit de signature quantique.
        
        Args:
            message_hash: Hash SHA-256 du message Ã  signer
            n_qubits: Nombre de qubits
            key_seed: Graine de la clÃ© privÃ©e (256 bits)
            verification_mode: Si True, circuit pour vÃ©rification
            add_measurements: Ajouter les mesures
        
        Returns:
            Circuit quantique de signature
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        if key_seed is None:
            key_seed = secrets.token_bytes(32)
        
        if len(message_hash) < 32:
            message_hash = hashlib.sha256(message_hash).digest()
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        mode_str = "verify" if verification_mode else "sign"
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"QSig_{mode_str}_{n_qubits}Q")
        else:
            qc = QuantumCircuit(qr, name=f"QSig_{mode_str}_{n_qubits}Q")
        
        # Layer 1: Hadamard initial
        for q in path:
            qc.h(q)
        
        qc.barrier()
        
        # Layer 2: Rotations RZ dÃ©rivÃ©es de la clÃ©
        key_angles = self._derive_angles_from_bytes(key_seed, n_qubits)
        for i, q in enumerate(path):
            qc.rz(key_angles[i], q)
        
        qc.barrier()
        
        # Layer 3: Portes CZ - pattern dÃ©rivÃ© de la clÃ©
        cz_pairs = self._derive_cz_pattern(key_seed, path, self.topology)
        for q1, q2 in cz_pairs:
            qc.cz(q1, q2)
        
        qc.barrier()
        
        # Layer 4: Rotations RZ dÃ©rivÃ©es du hash du message
        hash_angles = self._derive_angles_from_bytes(message_hash, n_qubits)
        for i, q in enumerate(path):
            qc.rz(hash_angles[i], q)
        
        qc.barrier()
        
        # Layer 5: Hadamard final
        for q in path:
            qc.h(q)
        
        # Layer 6: Mesures
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['signature_scheme'] = self._signature_scheme.value
        self._metadata['message_hash'] = message_hash.hex()[:16] + "..."
        self._metadata['verification_mode'] = verification_mode
        self._log(f"Built Quantum Signature circuit: {n_qubits}Q, mode={mode_str}")
        
        return qc
    
    def build_batch_verification(self, signatures: List[Tuple[bytes, bytes]], 
                                  n_qubits: int = 50) -> 'CircuitType':
        """
        Construit un circuit pour vÃ©rification batch de plusieurs signatures.
        
        Args:
            signatures: Liste de tuples (message_hash, key_seed)
            n_qubits: Nombre de qubits par signature
        
        Returns:
            Circuit combinÃ© pour vÃ©rification batch
        """
        from qiskit import QuantumCircuit
        
        circuits = []
        for msg_hash, key_seed in signatures:
            circuit = self.build(msg_hash, n_qubits, key_seed, 
                                verification_mode=True, add_measurements=False)
            circuits.append(circuit)
        
        # Combiner les circuits (simplification: on retourne le premier)
        # En production: utiliser parallel execution
        if circuits:
            combined = circuits[0]
            combined.name = f"QSig_batch_{len(signatures)}sigs"
            return combined
        
        return None
    
    def _derive_angles_from_bytes(self, data: bytes, n: int) -> List[float]:
        """DÃ©rive n angles depuis des bytes via SHAKE-256"""
        extended = hashlib.shake_256(data).digest(n * 4)
        angles = []
        for i in range(n):
            val = struct.unpack('>I', extended[i*4:(i+1)*4])[0]
            angle = (val / (2**32)) * 2 * np.pi
            angles.append(angle)
        return angles
    
    def _derive_cz_pattern(self, seed: bytes, path: List[int], 
                           topology: 'DynamicTopology') -> List[Tuple[int, int]]:
        """DÃ©rive le pattern CZ depuis la seed et la topologie"""
        pairs = []
        n = len(path)
        
        # Utiliser la seed pour sÃ©lectionner ~50% des connexions possibles
        hash_val = int.from_bytes(hashlib.sha256(seed).digest()[:8], 'big')
        
        for i in range(n - 1):
            # Pattern linÃ©aire avec sÃ©lection basÃ©e sur la seed
            if (hash_val >> (i % 64)) & 1:
                pairs.append((path[i], path[i + 1]))
        
        return pairs


class ZKPBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour preuves Ã  divulgation nulle quantiques.
    
    - Protocole Sigma Ã  3 phases: Commitment â†’ Challenge â†’ Response
    - Preuves de connaissance de clÃ© secrÃ¨te
    - Range proofs et set membership
    
    PropriÃ©tÃ©s:
    - Completeness: Prouveur honnÃªte convainc toujours
    - Soundness: Prouveur malhonnÃªte Ã©choue avec haute probabilitÃ©
    - Zero-Knowledge: VÃ©rificateur n'apprend rien d'autre
    """
    
    name = "zkp"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
        self._protocol = ZKPProtocol.SIGMA_IQP
    
    def build(self, n_qubits: int = 50, **params) -> 'CircuitType':
        """
        MÃ©thode build() par dÃ©faut - construit un commitment.
        
        Pour un contrÃ´le plus fin, utiliser build_commitment(), 
        build_challenge(), ou build_response().
        """
        secret = params.get('secret', secrets.token_bytes(16))
        nonce = params.get('nonce', secrets.token_bytes(32))
        return self.build_commitment(secret, nonce, n_qubits)
    
    def build_commitment(self, secret_value: bytes, nonce: bytes = None,
                         n_qubits: int = 50, add_measurements: bool = True) -> 'CircuitType':
        """
        Phase 1: GÃ©nÃ¨re un circuit de commitment.
        
        Le commitment cache la valeur secrÃ¨te tout en permettant
        une vÃ©rification ultÃ©rieure.
        
        Args:
            secret_value: Valeur Ã  prouver
            nonce: Valeur alÃ©atoire pour le binding
            n_qubits: Nombre de qubits
        
        Returns:
            Circuit de commitment
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        if nonce is None:
            nonce = secrets.token_bytes(32)
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"ZKP_commit_{n_qubits}Q")
        else:
            qc = QuantumCircuit(qr, name=f"ZKP_commit_{n_qubits}Q")
        
        # Combiner secret et nonce
        combined = hashlib.sha256(secret_value + nonce).digest()
        
        # Hadamard initial
        for q in path:
            qc.h(q)
        
        qc.barrier()
        
        # Rotations basÃ©es sur le commitment
        commit_angles = self._derive_angles(combined, n_qubits)
        for i, q in enumerate(path):
            qc.rz(commit_angles[i], q)
        
        # Intrication
        for i in range(len(path) - 1):
            qc.cz(path[i], path[i + 1])
        
        qc.barrier()
        
        # Hadamard final
        for q in path:
            qc.h(q)
        
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['phase'] = 'commitment'
        self._metadata['nonce_hash'] = hashlib.sha256(nonce).hexdigest()[:16]
        self._log(f"Built ZKP Commitment circuit: {n_qubits}Q")
        
        return qc
    
    def build_challenge(self, commitment_result: Dict, 
                        n_qubits: int = 50) -> Tuple['CircuitType', bytes]:
        """
        Phase 2: GÃ©nÃ¨re un challenge basÃ© sur le commitment.
        
        Args:
            commitment_result: RÃ©sultat de l'exÃ©cution du commitment
            n_qubits: Nombre de qubits
        
        Returns:
            Tuple (circuit_challenge, challenge_bytes)
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        # GÃ©nÃ©rer le challenge depuis les counts du commitment
        counts = commitment_result.get('counts', {})
        counts_hash = hashlib.sha256(json.dumps(counts, sort_keys=True).encode()).digest()
        
        # Ajouter de l'alÃ©atoire du vÃ©rificateur
        verifier_random = secrets.token_bytes(16)
        challenge = hashlib.sha256(counts_hash + verifier_random).digest()
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c')
        
        qc = QuantumCircuit(qr, cr, name=f"ZKP_challenge_{n_qubits}Q")
        
        # Circuit minimaliste pour le challenge
        challenge_angles = self._derive_angles(challenge, n_qubits)
        
        for i, q in enumerate(path):
            qc.h(q)
            qc.rz(challenge_angles[i], q)
            qc.h(q)
            qc.measure(q, i)
        
        self._metadata['phase'] = 'challenge'
        self._log(f"Built ZKP Challenge circuit: {n_qubits}Q")
        
        return qc, challenge
    
    def build_response(self, secret_value: bytes, nonce: bytes, 
                       challenge: bytes, n_qubits: int = 50,
                       add_measurements: bool = True) -> 'CircuitType':
        """
        Phase 3: GÃ©nÃ¨re la rÃ©ponse du prouveur.
        
        Args:
            secret_value: Valeur secrÃ¨te originale
            nonce: Nonce du commitment
            challenge: Challenge du vÃ©rificateur
            n_qubits: Nombre de qubits
        
        Returns:
            Circuit de rÃ©ponse
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"ZKP_response_{n_qubits}Q")
        else:
            qc = QuantumCircuit(qr, name=f"ZKP_response_{n_qubits}Q")
        
        # RÃ©ponse = f(secret, nonce, challenge)
        response_data = hashlib.sha256(secret_value + nonce + challenge).digest()
        response_angles = self._derive_angles(response_data, n_qubits)
        
        # Hadamard
        for q in path:
            qc.h(q)
        
        qc.barrier()
        
        # Rotations de rÃ©ponse
        for i, q in enumerate(path):
            qc.rz(response_angles[i], q)
        
        # Intrication conditionnÃ©e par le challenge
        challenge_bits = int.from_bytes(challenge[:8], 'big')
        for i in range(len(path) - 1):
            if (challenge_bits >> (i % 64)) & 1:
                qc.cz(path[i], path[i + 1])
        
        qc.barrier()
        
        # Hadamard final
        for q in path:
            qc.h(q)
        
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['phase'] = 'response'
        self._log(f"Built ZKP Response circuit: {n_qubits}Q")
        
        return qc
    
    def build_range_proof(self, value: int, lower: int, upper: int,
                          n_qubits: int = 50) -> 'CircuitType':
        """
        Construit une preuve que value âˆˆ [lower, upper] sans rÃ©vÃ©ler value.
        
        Args:
            value: Valeur Ã  prouver
            lower: Borne infÃ©rieure
            upper: Borne supÃ©rieure
            n_qubits: Nombre de qubits
        
        Returns:
            Circuit de range proof
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        # Encoder la preuve
        proof_data = struct.pack('>QQQ', value, lower, upper)
        nonce = secrets.token_bytes(16)
        commitment = hashlib.sha256(proof_data + nonce).digest()
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c')
        
        qc = QuantumCircuit(qr, cr, name=f"ZKP_range_{lower}_{upper}")
        
        # Circuit IQP pour la range proof
        angles = self._derive_angles(commitment, n_qubits)
        
        for q in path:
            qc.h(q)
        
        for i, q in enumerate(path):
            qc.rz(angles[i], q)
        
        # Pattern CZ basÃ© sur les bits de value normalisÃ©
        normalized = (value - lower) / (upper - lower) if upper > lower else 0.5
        n_cz = int(normalized * (len(path) - 1))
        for i in range(n_cz):
            qc.cz(path[i], path[i + 1])
        
        for q in path:
            qc.h(q)
        
        for i, q in enumerate(path):
            qc.measure(q, i)
        
        self._metadata['proof_type'] = 'range'
        self._metadata['range'] = f"[{lower}, {upper}]"
        self._log(f"Built Range Proof circuit: {n_qubits}Q, range=[{lower},{upper}]")
        
        return qc
    
    def _derive_angles(self, data: bytes, n: int) -> List[float]:
        """DÃ©rive n angles depuis des bytes"""
        extended = hashlib.shake_256(data).digest(n * 4)
        angles = []
        for i in range(n):
            val = struct.unpack('>I', extended[i*4:(i+1)*4])[0]
            angle = (val / (2**32)) * 2 * np.pi
            angles.append(angle)
        return angles


class TimeLockBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour chiffrement temporel.
    
    - Forward time-lock: DÃ©chiffrement impossible AVANT une date
    - Expiring time-lock: DÃ©chiffrement impossible APRÃˆS une date
    - Exploite la dÃ©rive de calibration du processeur quantique
    
    Principe: Les paramÃ¨tres du circuit sont liÃ©s aux caractÃ©ristiques
    de calibration qui Ã©voluent dans le temps, crÃ©ant une contrainte
    temporelle intrinsÃ¨que.
    """
    
    name = "timelock"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
        self._calibration_drift_rate = 0.001  # DÃ©rive typique par heure
    
    def build(self, n_qubits: int = 50, **params) -> 'CircuitType':
        """
        MÃ©thode build() par dÃ©faut - construit un forward time-lock.
        
        Pour un contrÃ´le plus fin, utiliser build_forward_lock(), 
        build_expiring_lock(), ou build_window_lock().
        """
        data = params.get('data', secrets.token_bytes(32))
        unlock_time = params.get('unlock_time', datetime.now() + timedelta(hours=24))
        return self.build_forward_lock(data, unlock_time, n_qubits)
    
    def build_forward_lock(self, data: bytes, unlock_time: datetime,
                           n_qubits: int = 50, calibration_ref: Dict = None,
                           add_measurements: bool = True) -> 'CircuitType':
        """
        Construit un circuit "forward time-lock".
        
        Le dÃ©chiffrement ne sera possible qu'APRÃˆS unlock_time car le
        circuit est paramÃ©trÃ© pour la calibration future estimÃ©e.
        
        Args:
            data: DonnÃ©es Ã  protÃ©ger
            unlock_time: Date Ã  partir de laquelle le dÃ©chiffrement est possible
            n_qubits: Nombre de qubits
            calibration_ref: Calibration de rÃ©fÃ©rence actuelle
            add_measurements: Ajouter les mesures
        
        Returns:
            Circuit time-locked
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        now = datetime.now()
        hours_until_unlock = max(0, (unlock_time - now).total_seconds() / 3600)
        
        # Estimer la calibration future
        future_drift = self._estimate_calibration_drift(hours_until_unlock)
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"TL_forward_{n_qubits}Q")
        else:
            qc = QuantumCircuit(qr, name=f"TL_forward_{n_qubits}Q")
        
        # Encoder le temps dans les paramÃ¨tres
        time_seed = struct.pack('>d', unlock_time.timestamp()) + data[:24]
        time_angles = self._derive_angles(time_seed, n_qubits)
        
        # Hadamard initial
        for q in path:
            qc.h(q)
        
        qc.barrier()
        
        # Rotations basÃ©es sur la calibration FUTURE estimÃ©e
        for i, q in enumerate(path):
            # L'angle inclut la dÃ©rive estimÃ©e
            adjusted_angle = time_angles[i] * (1 + future_drift[i % len(future_drift)])
            qc.rz(adjusted_angle, q)
        
        # Portes CZ
        for i in range(len(path) - 1):
            qc.cz(path[i], path[i + 1])
        
        qc.barrier()
        
        # Rotations de donnÃ©es
        data_hash = hashlib.sha256(data).digest()
        data_angles = self._derive_angles(data_hash, n_qubits)
        for i, q in enumerate(path):
            qc.rz(data_angles[i], q)
        
        qc.barrier()
        
        # Hadamard final
        for q in path:
            qc.h(q)
        
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['timelock_mode'] = 'forward'
        self._metadata['unlock_time'] = unlock_time.isoformat()
        self._metadata['hours_until_unlock'] = round(hours_until_unlock, 2)
        self._log(f"Built Forward TimeLock: unlocks at {unlock_time.isoformat()}")
        
        return qc
    
    def build_expiring_lock(self, data: bytes, expire_time: datetime,
                            n_qubits: int = 50, calibration_ref: Dict = None,
                            add_measurements: bool = True) -> 'CircuitType':
        """
        Construit un circuit "expiring time-lock".
        
        Le dÃ©chiffrement ne sera possible que jusqu'Ã  expire_time,
        aprÃ¨s quoi la dÃ©rive de calibration rendra le circuit inutilisable.
        
        Args:
            data: DonnÃ©es Ã  protÃ©ger
            expire_time: Date aprÃ¨s laquelle le dÃ©chiffrement devient impossible
            n_qubits: Nombre de qubits
            calibration_ref: Calibration de rÃ©fÃ©rence actuelle
            add_measurements: Ajouter les mesures
        
        Returns:
            Circuit avec expiration
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"TL_expire_{n_qubits}Q")
        else:
            qc = QuantumCircuit(qr, name=f"TL_expire_{n_qubits}Q")
        
        # Encoder le temps d'expiration
        expire_seed = struct.pack('>d', expire_time.timestamp()) + data[:24]
        
        # Utiliser la calibration ACTUELLE
        current_calib = self._get_current_calibration_signature()
        combined_seed = expire_seed + current_calib
        
        time_angles = self._derive_angles(combined_seed, n_qubits)
        
        # Construction du circuit
        for q in path:
            qc.h(q)
        
        qc.barrier()
        
        # Rotations Ã©troitement liÃ©es Ã  la calibration actuelle
        # AprÃ¨s expiration, la dÃ©rive causera des erreurs
        for i, q in enumerate(path):
            qc.rz(time_angles[i], q)
        
        # Pattern CZ dense pour sensibilitÃ© Ã  la dÃ©rive
        for i in range(len(path) - 1):
            qc.cz(path[i], path[i + 1])
        
        # Couche supplÃ©mentaire pour sensibilitÃ© accrue
        for q in path:
            qc.h(q)
        
        for i in range(0, len(path) - 1, 2):
            qc.cz(path[i], path[i + 1])
        
        for q in path:
            qc.h(q)
        
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['timelock_mode'] = 'expiring'
        self._metadata['expire_time'] = expire_time.isoformat()
        self._log(f"Built Expiring TimeLock: expires at {expire_time.isoformat()}")
        
        return qc
    
    def build_window_lock(self, data: bytes, open_time: datetime, 
                          close_time: datetime, n_qubits: int = 50,
                          add_measurements: bool = True) -> 'CircuitType':
        """
        Construit un circuit avec fenÃªtre de dÃ©chiffrement.
        
        Le dÃ©chiffrement n'est possible que dans [open_time, close_time].
        
        Args:
            data: DonnÃ©es Ã  protÃ©ger
            open_time: DÃ©but de la fenÃªtre
            close_time: Fin de la fenÃªtre
            n_qubits: Nombre de qubits
        
        Returns:
            Circuit avec fenÃªtre temporelle
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c') if add_measurements else None
        
        if cr:
            qc = QuantumCircuit(qr, cr, name=f"TL_window_{n_qubits}Q")
        else:
            qc = QuantumCircuit(qr, name=f"TL_window_{n_qubits}Q")
        
        # Centre de la fenÃªtre
        window_center = open_time + (close_time - open_time) / 2
        window_seed = struct.pack('>dd', open_time.timestamp(), close_time.timestamp())
        window_seed += data[:16]
        
        angles = self._derive_angles(window_seed, n_qubits)
        
        for q in path:
            qc.h(q)
        
        for i, q in enumerate(path):
            qc.rz(angles[i], q)
        
        for i in range(len(path) - 1):
            qc.cz(path[i], path[i + 1])
        
        for q in path:
            qc.h(q)
        
        if add_measurements:
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['timelock_mode'] = 'window'
        self._metadata['window'] = f"[{open_time.isoformat()}, {close_time.isoformat()}]"
        self._log(f"Built Window TimeLock: [{open_time} - {close_time}]")
        
        return qc
    
    def _estimate_calibration_drift(self, hours: float) -> List[float]:
        """Estime la dÃ©rive de calibration aprÃ¨s N heures"""
        # ModÃ¨le simplifiÃ© de dÃ©rive
        base_drift = self._calibration_drift_rate * hours
        # Variation par qubit
        n_estimates = 20
        drifts = [base_drift * (1 + 0.1 * np.sin(i * np.pi / n_estimates)) 
                  for i in range(n_estimates)]
        return drifts
    
    def _get_current_calibration_signature(self) -> bytes:
        """GÃ©nÃ¨re une signature de la calibration actuelle"""
        # En production: extraire depuis backend.properties()
        timestamp = datetime.now().timestamp()
        return struct.pack('>d', timestamp)
    
    def _derive_angles(self, data: bytes, n: int) -> List[float]:
        """DÃ©rive n angles depuis des bytes"""
        extended = hashlib.shake_256(data).digest(n * 4)
        angles = []
        for i in range(n):
            val = struct.unpack('>I', extended[i*4:(i+1)*4])[0]
            angle = (val / (2**32)) * 2 * np.pi
            angles.append(angle)
        return angles


class ObliviousTransferBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour Oblivious Transfer quantique.
    
    - 1-of-2 OT: Le receveur choisit 1 message parmi 2 sans rÃ©vÃ©ler son choix
    - 1-of-N OT: Extension Ã  N messages
    - Le sender ne sait pas quel message a Ã©tÃ© choisi
    
    Protocole:
    1. Sender prÃ©pare N circuits IQP (un par message)
    2. Receiver exÃ©cute le circuit correspondant Ã  son choix
    3. Seul le circuit choisi produit une distribution dÃ©codable
    """
    
    name = "oblivious_transfer"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 50, **params) -> 'CircuitType':
        """
        MÃ©thode build() par dÃ©faut - construit un circuit receiver.
        
        Pour un contrÃ´le plus fin, utiliser build_sender_circuits() 
        ou build_receiver_circuit().
        """
        choice = params.get('choice', 0)
        total_messages = params.get('total_messages', 2)
        shared_seed = params.get('shared_seed', secrets.token_bytes(32))
        return self.build_receiver_circuit(choice, total_messages, shared_seed, n_qubits)
    
    def build_sender_circuits(self, messages: List[bytes], 
                               shared_seed: bytes = None,
                               n_qubits: int = 50) -> List['CircuitType']:
        """
        Construit les circuits du sender pour OT 1-of-N.
        
        Args:
            messages: Liste de N messages
            shared_seed: Seed partagÃ©e pour le protocole
            n_qubits: Nombre de qubits par circuit
        
        Returns:
            Liste de N circuits (un par message)
        """
        if shared_seed is None:
            shared_seed = secrets.token_bytes(32)
        
        circuits = []
        
        for idx, message in enumerate(messages):
            circuit = self._build_ot_circuit(
                message=message,
                index=idx,
                total=len(messages),
                shared_seed=shared_seed,
                n_qubits=n_qubits,
                role='sender'
            )
            circuits.append(circuit)
        
        self._metadata['ot_type'] = f"1-of-{len(messages)}"
        self._metadata['sender_circuits'] = len(messages)
        self._log(f"Built {len(messages)} sender circuits for 1-of-{len(messages)} OT")
        
        return circuits
    
    def build_receiver_circuit(self, choice: int, total_messages: int,
                                shared_seed: bytes, n_qubits: int = 50) -> 'CircuitType':
        """
        Construit le circuit du receiver pour OT.
        
        Args:
            choice: Index du message choisi (0 Ã  N-1)
            total_messages: Nombre total de messages
            shared_seed: Seed partagÃ©e
            n_qubits: Nombre de qubits
        
        Returns:
            Circuit pour dÃ©coder le message choisi
        """
        circuit = self._build_ot_circuit(
            message=None,
            index=choice,
            total=total_messages,
            shared_seed=shared_seed,
            n_qubits=n_qubits,
            role='receiver'
        )
        
        self._metadata['receiver_choice'] = choice
        self._log(f"Built receiver circuit for choice {choice}/{total_messages}")
        
        return circuit
    
    def _build_ot_circuit(self, message: bytes, index: int, total: int,
                          shared_seed: bytes, n_qubits: int, 
                          role: str) -> 'CircuitType':
        """Construit un circuit OT interne"""
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c')
        
        qc = QuantumCircuit(qr, cr, name=f"OT_{role}_{index}of{total}")
        
        # DÃ©river les paramÃ¨tres depuis la seed et l'index
        index_seed = shared_seed + struct.pack('>II', index, total)
        angles = self._derive_angles(index_seed, n_qubits)
        
        # Hadamard
        for q in path:
            qc.h(q)
        
        qc.barrier()
        
        # Rotations spÃ©cifiques Ã  l'index
        for i, q in enumerate(path):
            qc.rz(angles[i], q)
        
        # Pattern CZ dÃ©pendant de l'index
        cz_offset = index % len(path)
        for i in range(cz_offset, len(path) - 1):
            qc.cz(path[i], path[(i + 1) % len(path)])
        
        qc.barrier()
        
        # Si sender: encoder le message
        if role == 'sender' and message is not None:
            msg_hash = hashlib.sha256(message).digest()
            msg_angles = self._derive_angles(msg_hash, n_qubits)
            for i, q in enumerate(path):
                qc.rz(msg_angles[i], q)
            qc.barrier()
        
        # Hadamard final
        for q in path:
            qc.h(q)
        
        # Mesures
        for i, q in enumerate(path):
            qc.measure(q, i)
        
        return qc
    
    def _derive_angles(self, data: bytes, n: int) -> List[float]:
        """DÃ©rive n angles depuis des bytes"""
        extended = hashlib.shake_256(data).digest(n * 4)
        angles = []
        for i in range(n):
            val = struct.unpack('>I', extended[i*4:(i+1)*4])[0]
            angle = (val / (2**32)) * 2 * np.pi
            angles.append(angle)
        return angles


# =============================================================================
# [v2.5.15] NOUVEAUX CIRCUIT BUILDERS
# =============================================================================

class GroverBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour l'algorithme de Grover.
    
    L'algorithme de Grover permet une recherche quadratiquement accÃ©lÃ©rÃ©e
    dans une base de donnÃ©es non structurÃ©e. UtilisÃ© dans QAEE pour 
    l'estimation d'amplitude.
    
    ParamÃ¨tres:
        n_qubits: Nombre de qubits (taille de l'espace de recherche = 2^n)
        marked_states: Liste des Ã©tats Ã  trouver (entiers ou bitstrings)
        iterations: Nombre d'itÃ©rations de Grover (optimal: Ï€/4 * âˆšN)
        oracle_type: 'phase' (standard) ou 'boolean'
    """
    
    name = "grover"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 5, **params) -> 'CircuitType':
        """
        Construit un circuit de Grover.
        
        Args:
            n_qubits: Nombre de qubits de recherche
            marked_states: Ã‰tats marquÃ©s (dÃ©faut: [0] = premier Ã©tat)
            iterations: Nombre d'itÃ©rations (dÃ©faut: optimal)
            with_ancilla: Utiliser un ancilla pour l'oracle (dÃ©faut: True)
        
        Returns:
            Circuit Grover complet
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        marked_states = params.get('marked_states', [0])
        iterations = params.get('iterations', None)
        with_ancilla = params.get('with_ancilla', True)
        seed = params.get('seed', None)
        
        # Calculer le nombre optimal d'itÃ©rations
        N = 2 ** n_qubits
        M = len(marked_states)
        if iterations is None:
            iterations = max(1, int(np.pi / 4 * np.sqrt(N / M)))
        
        # CrÃ©er le circuit
        if with_ancilla:
            qr = QuantumRegister(n_qubits + 1, 'q')
            cr = ClassicalRegister(n_qubits, 'c')
            qc = QuantumCircuit(qr, cr, name=f"Grover_{n_qubits}q_{iterations}iter")
            ancilla = n_qubits
        else:
            qr = QuantumRegister(n_qubits, 'q')
            cr = ClassicalRegister(n_qubits, 'c')
            qc = QuantumCircuit(qr, cr, name=f"Grover_{n_qubits}q_{iterations}iter")
            ancilla = None
        
        # 1. Superposition initiale
        for i in range(n_qubits):
            qc.h(i)
        
        # PrÃ©parer ancilla en |->
        if with_ancilla:
            qc.x(ancilla)
            qc.h(ancilla)
        
        qc.barrier()
        
        # 2. ItÃ©rations de Grover
        for _ in range(iterations):
            # Oracle
            self._add_oracle(qc, n_qubits, marked_states, ancilla)
            qc.barrier()
            
            # Diffuseur
            self._add_diffuser(qc, n_qubits)
            qc.barrier()
        
        # 3. Mesure
        for i in range(n_qubits):
            qc.measure(i, i)
        
        self._metadata['iterations'] = iterations
        self._metadata['marked_states'] = marked_states
        self._metadata['search_space'] = N
        self._metadata['theoretical_success'] = np.sin((2 * iterations + 1) * np.arcsin(np.sqrt(M / N))) ** 2
        
        self._log(f"Built Grover circuit: {n_qubits}q, {iterations} iterations, "
                  f"P(success) â‰ˆ {self._metadata['theoretical_success']:.2%}")
        
        return qc
    
    def _add_oracle(self, qc, n_qubits: int, marked_states: List[int], ancilla: int = None):
        """Ajoute l'oracle de marquage"""
        for state in marked_states:
            # Convertir l'Ã©tat en bits
            bits = format(state, f'0{n_qubits}b')
            
            # X sur les qubits Ã  0
            for i, bit in enumerate(reversed(bits)):
                if bit == '0':
                    qc.x(i)
            
            # Multi-controlled Z (ou X sur ancilla)
            if ancilla is not None:
                # MCX sur ancilla
                qc.mcx(list(range(n_qubits)), ancilla)
            else:
                # Multi-controlled Z via phase
                if n_qubits == 1:
                    qc.z(0)
                elif n_qubits == 2:
                    qc.cz(0, 1)
                else:
                    # DÃ©composition en CZ
                    qc.h(n_qubits - 1)
                    qc.mcx(list(range(n_qubits - 1)), n_qubits - 1)
                    qc.h(n_qubits - 1)
            
            # DÃ©faire les X
            for i, bit in enumerate(reversed(bits)):
                if bit == '0':
                    qc.x(i)
    
    def _add_diffuser(self, qc, n_qubits: int):
        """Ajoute le diffuseur (inversion autour de la moyenne)"""
        # H sur tous les qubits
        for i in range(n_qubits):
            qc.h(i)
        
        # X sur tous
        for i in range(n_qubits):
            qc.x(i)
        
        # Multi-controlled Z
        qc.h(n_qubits - 1)
        qc.mcx(list(range(n_qubits - 1)), n_qubits - 1)
        qc.h(n_qubits - 1)
        
        # X sur tous
        for i in range(n_qubits):
            qc.x(i)
        
        # H sur tous
        for i in range(n_qubits):
            qc.h(i)


class SwapTestBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour le SWAP Test.
    
    Le SWAP Test permet de mesurer la similaritÃ© (fidelitÃ©) entre deux 
    Ã©tats quantiques |ÏˆâŸ© et |Ï†âŸ©. La probabilitÃ© de mesurer 0 sur l'ancilla
    est P(0) = (1 + |âŸ¨Ïˆ|Ï†âŸ©|Â²) / 2.
    
    TrÃ¨s utile pour QMC Biometric (comparaison de templates quantiques).
    
    ParamÃ¨tres:
        n_qubits: Nombre de qubits par registre (total = 2n + 1)
        state_prep_1: Circuit de prÃ©paration de |ÏˆâŸ©
        state_prep_2: Circuit de prÃ©paration de |Ï†âŸ©
    """
    
    name = "swap_test"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 3, **params) -> 'CircuitType':
        """
        Construit un circuit SWAP Test.
        
        Args:
            n_qubits: Qubits par registre
            state_1: 'ghz', 'random', 'zero', ou circuit custom
            state_2: 'ghz', 'random', 'zero', ou circuit custom  
            seed: Seed pour Ã©tats alÃ©atoires
            full_measurement: Mesurer tous les qubits (pas juste ancilla)
        
        Returns:
            Circuit SWAP Test
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        state_1 = params.get('state_1', 'ghz')
        state_2 = params.get('state_2', 'ghz')
        seed = params.get('seed', None)
        full_measurement = params.get('full_measurement', False)
        
        # Registres: 1 ancilla + n qubits Ã©tat 1 + n qubits Ã©tat 2
        ancilla = QuantumRegister(1, 'anc')
        reg1 = QuantumRegister(n_qubits, 'psi')
        reg2 = QuantumRegister(n_qubits, 'phi')
        
        if full_measurement:
            cr = ClassicalRegister(1 + 2 * n_qubits, 'c')
        else:
            cr = ClassicalRegister(1, 'c')
        
        qc = QuantumCircuit(ancilla, reg1, reg2, cr, name=f"SwapTest_{n_qubits}q")
        
        # 1. PrÃ©parer les Ã©tats
        self._prepare_state(qc, reg1, state_1, seed)
        self._prepare_state(qc, reg2, state_2, seed + 1 if seed else None)
        
        qc.barrier()
        
        # 2. SWAP Test: H - CSWAP - H - Mesure
        qc.h(ancilla[0])
        
        # Controlled-SWAP pour chaque paire de qubits
        for i in range(n_qubits):
            qc.cswap(ancilla[0], reg1[i], reg2[i])
        
        qc.h(ancilla[0])
        
        qc.barrier()
        
        # 3. Mesure
        qc.measure(ancilla[0], 0)
        
        if full_measurement:
            for i in range(n_qubits):
                qc.measure(reg1[i], 1 + i)
                qc.measure(reg2[i], 1 + n_qubits + i)
        
        self._metadata['n_qubits_per_register'] = n_qubits
        self._metadata['total_qubits'] = 1 + 2 * n_qubits
        self._metadata['state_1'] = str(state_1)
        self._metadata['state_2'] = str(state_2)
        
        self._log(f"Built SWAP Test: {n_qubits}q per register, states: {state_1} vs {state_2}")
        
        return qc
    
    def _prepare_state(self, qc, register, state_type, seed=None):
        """PrÃ©pare un Ã©tat dans un registre"""
        n = len(register)
        
        if state_type == 'zero':
            pass  # DÃ©jÃ  en |0...0âŸ©
        
        elif state_type == 'ghz':
            qc.h(register[0])
            for i in range(1, n):
                qc.cx(register[0], register[i])
        
        elif state_type == 'random':
            rng = np.random.default_rng(seed)
            for i in range(n):
                theta = rng.uniform(0, np.pi)
                phi = rng.uniform(0, 2 * np.pi)
                qc.ry(theta, register[i])
                qc.rz(phi, register[i])
            # Ajouter de l'intrication
            for i in range(n - 1):
                qc.cx(register[i], register[i + 1])
        
        elif state_type == 'plus':
            for i in range(n):
                qc.h(register[i])
        
        elif hasattr(state_type, 'data'):
            # C'est un circuit custom
            qc.compose(state_type, qubits=register, inplace=True)
    
    @staticmethod
    def compute_fidelity(counts: Dict[str, int]) -> float:
        """
        Calcule la fidÃ©litÃ© Ã  partir des counts du SWAP Test.
        
        P(0) = (1 + |âŸ¨Ïˆ|Ï†âŸ©|Â²) / 2
        => |âŸ¨Ïˆ|Ï†âŸ©|Â² = 2*P(0) - 1
        
        Args:
            counts: RÃ©sultats de mesure (avec ancilla en position 0 ou derniÃ¨re)
        
        Returns:
            FidÃ©litÃ© estimÃ©e (0 Ã  1)
        """
        total = sum(counts.values())
        
        # Trouver les counts oÃ¹ ancilla = 0
        p_zero = 0
        for bitstring, count in counts.items():
            # L'ancilla peut Ãªtre en premiÃ¨re ou derniÃ¨re position
            if bitstring[-1] == '0' or bitstring[0] == '0':
                p_zero += count
        
        p_zero /= total
        fidelity = max(0, min(1, 2 * p_zero - 1))
        
        return fidelity


class QRNGBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour Quantum Random Number Generator.
    
    GÃ©nÃ¨re des nombres vÃ©ritablement alÃ©atoires en exploitant la 
    superposition quantique. Chaque qubit en superposition |+âŸ© 
    produit un bit parfaitement alÃ©atoire lors de la mesure.
    
    ParamÃ¨tres:
        n_qubits: Nombre de bits Ã  gÃ©nÃ©rer par exÃ©cution
        enhanced: Utiliser des rotations pour amÃ©liorer la qualitÃ©
        entangled: Utiliser de l'intrication (augmente la complexitÃ©)
    """
    
    name = "qrng"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 32, **params) -> 'CircuitType':
        """
        Construit un circuit QRNG.
        
        Args:
            n_qubits: Nombre de bits alÃ©atoires Ã  gÃ©nÃ©rer
            enhanced: Mode amÃ©liorÃ© avec rotations alÃ©atoires (dÃ©faut: False)
            entangled: Ajouter de l'intrication (dÃ©faut: False)
            seed: Seed pour les rotations (mode enhanced)
            depth: Profondeur des couches (mode enhanced, dÃ©faut: 1)
        
        Returns:
            Circuit QRNG
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        enhanced = params.get('enhanced', False)
        entangled = params.get('entangled', False)
        seed = params.get('seed', None)
        depth = params.get('depth', 1)
        
        # Utiliser la topologie optimale si disponible
        path = self.get_optimal_path(n_qubits)[:n_qubits]
        max_qubit = max(path) + 1 if path else n_qubits
        
        qr = QuantumRegister(max_qubit, 'q')
        cr = ClassicalRegister(n_qubits, 'c')
        
        mode_name = "enhanced" if enhanced else ("entangled" if entangled else "basic")
        qc = QuantumCircuit(qr, cr, name=f"QRNG_{n_qubits}b_{mode_name}")
        
        if enhanced:
            # Mode amÃ©liorÃ©: rotations pseudo-alÃ©atoires + Hadamard
            rng = np.random.default_rng(seed)
            
            for layer in range(depth):
                # Rotations alÃ©atoires
                for i, q in enumerate(path):
                    theta = rng.uniform(0, np.pi)
                    phi = rng.uniform(0, 2 * np.pi)
                    qc.ry(theta, q)
                    qc.rz(phi, q)
                
                # Hadamard
                for q in path:
                    qc.h(q)
                
                if layer < depth - 1:
                    qc.barrier()
        
        elif entangled:
            # Mode intriquÃ©: GHZ-like puis Hadamard
            for q in path:
                qc.h(q)
            
            # Couche d'intrication
            for i in range(len(path) - 1):
                qc.cx(path[i], path[i + 1])
            
            qc.barrier()
            
            # Hadamard final
            for q in path:
                qc.h(q)
        
        else:
            # Mode basique: juste Hadamard
            for q in path:
                qc.h(q)
        
        qc.barrier()
        
        # Mesure
        for i, q in enumerate(path):
            qc.measure(q, i)
        
        self._metadata['n_bits'] = n_qubits
        self._metadata['mode'] = mode_name
        self._metadata['depth'] = depth if enhanced else 1
        self._metadata['bits_per_shot'] = n_qubits
        
        self._log(f"Built QRNG circuit: {n_qubits} bits, mode={mode_name}")
        
        return qc
    
    @staticmethod
    def extract_random_bytes(counts: Dict[str, int], n_bytes: int = None) -> bytes:
        """
        Extrait des bytes alÃ©atoires Ã  partir des rÃ©sultats.
        
        Args:
            counts: RÃ©sultats de mesure
            n_bytes: Nombre de bytes Ã  extraire (dÃ©faut: tous)
        
        Returns:
            Bytes alÃ©atoires
        """
        # Collecter tous les bits
        all_bits = []
        for bitstring, count in counts.items():
            # RÃ©pÃ©ter selon le count pour pondÃ©rer
            for _ in range(count):
                all_bits.extend(bitstring)
        
        # Convertir en bytes
        result = []
        for i in range(0, len(all_bits) - 7, 8):
            byte_str = ''.join(all_bits[i:i+8])
            result.append(int(byte_str, 2))
        
        result = bytes(result)
        
        if n_bytes is not None:
            result = result[:n_bytes]
        
        return result


class AmplitudeEncodingBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour l'encodage d'amplitude.
    
    Encode un vecteur de donnÃ©es classiques dans les amplitudes d'un 
    Ã©tat quantique. Un vecteur de dimension N nÃ©cessite log2(N) qubits.
    
    Exemple: [0.5, 0.5, 0.5, 0.5] â†’ |ÏˆâŸ© = 0.5|00âŸ© + 0.5|01âŸ© + 0.5|10âŸ© + 0.5|11âŸ©
    
    UtilisÃ© pour encoder des donnÃ©es biomÃ©triques, financiÃ¨res, etc.
    dans des Ã©tats quantiques pour traitement QML.
    """
    
    name = "amplitude_encoding"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 4, **params) -> 'CircuitType':
        """
        Construit un circuit d'encodage d'amplitude.
        
        Args:
            n_qubits: Nombre de qubits (encode 2^n amplitudes)
            data: Vecteur de donnÃ©es Ã  encoder (sera normalisÃ©)
            normalize: Normaliser automatiquement (dÃ©faut: True)
            method: 'mottonen' (exact) ou 'approx' (approximatif)
        
        Returns:
            Circuit d'encodage
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        data = params.get('data', None)
        normalize = params.get('normalize', True)
        method = params.get('method', 'mottonen')
        add_measurement = params.get('add_measurement', True)
        
        # Si pas de donnÃ©es, crÃ©er un vecteur uniforme
        N = 2 ** n_qubits
        if data is None:
            data = np.ones(N) / np.sqrt(N)
        else:
            data = np.array(data, dtype=float)
        
        # Padding si nÃ©cessaire
        if len(data) < N:
            data = np.pad(data, (0, N - len(data)))
        elif len(data) > N:
            data = data[:N]
        
        # Normalisation
        if normalize:
            norm = np.linalg.norm(data)
            if norm > 0:
                data = data / norm
        
        # CrÃ©er le circuit
        qr = QuantumRegister(n_qubits, 'q')
        
        if add_measurement:
            cr = ClassicalRegister(n_qubits, 'c')
            qc = QuantumCircuit(qr, cr, name=f"AmpEnc_{n_qubits}q")
        else:
            qc = QuantumCircuit(qr, name=f"AmpEnc_{n_qubits}q")
        
        if method == 'mottonen':
            # MÃ©thode de MÃ¶ttÃ¶nen et al. (exacte)
            self._mottonen_encoding(qc, data, n_qubits)
        else:
            # MÃ©thode approximative (plus simple, moins de portes)
            self._approx_encoding(qc, data, n_qubits)
        
        if add_measurement:
            qc.barrier()
            for i in range(n_qubits):
                qc.measure(i, i)
        
        self._metadata['n_qubits'] = n_qubits
        self._metadata['data_dim'] = len(data)
        self._metadata['method'] = method
        self._metadata['data_norm'] = float(np.linalg.norm(data))
        
        self._log(f"Built amplitude encoding: {n_qubits}q, dim={N}, method={method}")
        
        return qc
    
    def _mottonen_encoding(self, qc, data: np.ndarray, n_qubits: int):
        """
        Encodage exact par la mÃ©thode de MÃ¶ttÃ¶nen.
        Utilise initialize() de Qiskit qui implÃ©mente cette mÃ©thode.
        """
        # Qiskit's initialize fait exactement Ã§a
        qc.initialize(data, range(n_qubits))
        
        # DÃ©composer pour hardware (Ã©vite les portes unitaires gÃ©nÃ©riques)
        # Note: La transpilation fera Ã§a automatiquement
    
    def _approx_encoding(self, qc, data: np.ndarray, n_qubits: int):
        """
        Encodage approximatif avec rotations RY.
        Plus simple mais moins prÃ©cis pour des donnÃ©es complexes.
        """
        # Calculer les angles pour chaque qubit
        # MÃ©thode: RY rotations basÃ©es sur les probabilitÃ©s marginales
        
        for qubit in range(n_qubits):
            # Calculer la probabilitÃ© marginale pour ce qubit
            step = 2 ** (n_qubits - qubit - 1)
            prob_1 = 0
            prob_0 = 0
            
            for i in range(len(data)):
                bit = (i >> (n_qubits - qubit - 1)) & 1
                if bit == 1:
                    prob_1 += data[i] ** 2
                else:
                    prob_0 += data[i] ** 2
            
            total = prob_0 + prob_1
            if total > 0:
                theta = 2 * np.arcsin(np.sqrt(prob_1 / total))
                qc.ry(theta, qubit)
        
        # Ajouter des portes d'intrication pour amÃ©liorer l'approximation
        for i in range(n_qubits - 1):
            qc.cx(i, i + 1)
    
    @staticmethod
    def decode_amplitudes(counts: Dict[str, int], n_qubits: int) -> np.ndarray:
        """
        Reconstruit les amplitudes (approximatives) Ã  partir des mesures.
        
        Args:
            counts: RÃ©sultats de mesure
            n_qubits: Nombre de qubits
        
        Returns:
            Vecteur d'amplitudes estimÃ©es
        """
        N = 2 ** n_qubits
        total = sum(counts.values())
        
        amplitudes = np.zeros(N)
        for bitstring, count in counts.items():
            # Convertir bitstring en index
            idx = int(bitstring, 2)
            amplitudes[idx] = np.sqrt(count / total)
        
        return amplitudes


class QPEBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour Quantum Phase Estimation.
    
    Estime la phase Ï† d'un eigenvalue e^(2Ï€iÏ†) d'un opÃ©rateur unitaire U.
    Base de nombreux algorithmes quantiques dont Shor et l'estimation d'amplitude.
    
    ParamÃ¨tres:
        n_precision: Nombre de qubits de prÃ©cision (dÃ©termine la prÃ©cision: 2^-n)
        unitary: OpÃ©rateur unitaire U (circuit ou matrice)
        n_target: Qubits cibles pour U
    """
    
    name = "qpe"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 4, **params) -> 'CircuitType':
        """
        Construit un circuit QPE.
        
        Args:
            n_qubits: Qubits de prÃ©cision
            n_target: Qubits cibles (dÃ©faut: 1)
            unitary: Circuit unitaire ou 'T', 'S', 'Z', 'custom'
            phase: Phase Ã  encoder si unitary='custom' (pour tests)
        
        Returns:
            Circuit QPE
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        n_precision = n_qubits
        n_target = params.get('n_target', 1)
        unitary = params.get('unitary', 'T')
        phase = params.get('phase', None)
        
        # Registres
        precision_reg = QuantumRegister(n_precision, 'prec')
        target_reg = QuantumRegister(n_target, 'tgt')
        cr = ClassicalRegister(n_precision, 'c')
        
        qc = QuantumCircuit(precision_reg, target_reg, cr, 
                           name=f"QPE_{n_precision}p_{n_target}t")
        
        # 1. PrÃ©parer l'Ã©tat propre dans target
        # Pour T gate: |1âŸ© est un Ã©tat propre
        qc.x(target_reg[0])
        
        # 2. Hadamard sur tous les qubits de prÃ©cision
        for i in range(n_precision):
            qc.h(precision_reg[i])
        
        qc.barrier()
        
        # 3. Controlled-U^(2^k) applications
        for k in range(n_precision):
            power = 2 ** (n_precision - 1 - k)
            
            if unitary == 'T':
                # T gate: phase = 1/8
                angle = np.pi / 4 * power
                qc.cp(angle, precision_reg[k], target_reg[0])
            
            elif unitary == 'S':
                # S gate: phase = 1/4
                angle = np.pi / 2 * power
                qc.cp(angle, precision_reg[k], target_reg[0])
            
            elif unitary == 'Z':
                # Z gate: phase = 1/2
                angle = np.pi * power
                qc.cp(angle, precision_reg[k], target_reg[0])
            
            elif unitary == 'custom' and phase is not None:
                # Phase personnalisÃ©e
                angle = 2 * np.pi * phase * power
                qc.cp(angle, precision_reg[k], target_reg[0])
            
            elif hasattr(unitary, 'data'):
                # Circuit custom
                controlled_u = unitary.control(1)
                for _ in range(power):
                    qc.compose(controlled_u, 
                              qubits=[precision_reg[k]] + list(range(n_precision, n_precision + n_target)),
                              inplace=True)
        
        qc.barrier()
        
        # 4. QFT inverse sur les qubits de prÃ©cision
        self._add_inverse_qft(qc, precision_reg, n_precision)
        
        qc.barrier()
        
        # 5. Mesure
        for i in range(n_precision):
            qc.measure(precision_reg[i], i)
        
        self._metadata['n_precision'] = n_precision
        self._metadata['n_target'] = n_target
        self._metadata['unitary'] = str(unitary)
        self._metadata['precision'] = 1 / (2 ** n_precision)
        
        self._log(f"Built QPE: {n_precision} precision qubits, precision=1/{2**n_precision}")
        
        return qc
    
    def _add_inverse_qft(self, qc, register, n: int):
        """Ajoute la QFT inverse"""
        # Swap qubits
        for i in range(n // 2):
            qc.swap(register[i], register[n - 1 - i])
        
        # QFT inverse gates
        for i in range(n):
            for j in range(i):
                angle = -np.pi / (2 ** (i - j))
                qc.cp(angle, register[j], register[i])
            qc.h(register[i])
    
    @staticmethod
    def extract_phase(counts: Dict[str, int], n_precision: int) -> float:
        """
        Extrait la phase estimÃ©e Ã  partir des mesures.
        
        Args:
            counts: RÃ©sultats de mesure
            n_precision: Nombre de qubits de prÃ©cision
        
        Returns:
            Phase estimÃ©e (entre 0 et 1)
        """
        # Trouver le bitstring le plus frÃ©quent
        max_count = 0
        best_bitstring = None
        
        for bitstring, count in counts.items():
            if count > max_count:
                max_count = count
                best_bitstring = bitstring
        
        if best_bitstring is None:
            return 0.0
        
        # Convertir en phase
        # Le bitstring reprÃ©sente la fraction binaire de la phase
        phase_int = int(best_bitstring, 2)
        phase = phase_int / (2 ** n_precision)
        
        return phase


class HardwareEfficientBuilder(CircuitBuilder):
    """
    Constructeur d'ansatz Hardware-Efficient pour VQE/QAOA.
    
    GÃ©nÃ¨re des circuits variationnels optimisÃ©s pour l'exÃ©cution sur 
    hardware NISQ, en utilisant uniquement des portes natives et 
    respectant la topologie du processeur.
    
    Structure typique:
    - Couches de rotations RY-RZ
    - Couches d'intrication (CZ ou CX selon topologie)
    """
    
    name = "hardware_efficient"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 4, **params) -> 'CircuitType':
        """
        Construit un ansatz hardware-efficient.
        
        Args:
            n_qubits: Nombre de qubits
            depth: Nombre de couches (dÃ©faut: 3)
            rotation_gates: Liste de portes ['ry', 'rz'] ou ['rx', 'ry', 'rz']
            entanglement: 'linear', 'full', 'circular', 'topology'
            parameter_prefix: PrÃ©fixe des paramÃ¨tres (dÃ©faut: 'Î¸')
            barriers: Ajouter des barriÃ¨res entre couches (dÃ©faut: True)
        
        Returns:
            Circuit paramÃ©trÃ©
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        from qiskit.circuit import Parameter
        
        depth = params.get('depth', 3)
        rotation_gates = params.get('rotation_gates', ['ry', 'rz'])
        entanglement = params.get('entanglement', 'linear')
        parameter_prefix = params.get('parameter_prefix', 'Î¸')
        barriers = params.get('barriers', True)
        add_measurement = params.get('add_measurement', True)
        
        # Utiliser la topologie si disponible
        if entanglement == 'topology':
            path = self.get_optimal_path(n_qubits)[:n_qubits]
            max_qubit = max(path) + 1 if path else n_qubits
        else:
            path = list(range(n_qubits))
            max_qubit = n_qubits
        
        qr = QuantumRegister(max_qubit, 'q')
        
        if add_measurement:
            cr = ClassicalRegister(n_qubits, 'c')
            qc = QuantumCircuit(qr, cr, name=f"HWEff_{n_qubits}q_d{depth}")
        else:
            qc = QuantumCircuit(qr, name=f"HWEff_{n_qubits}q_d{depth}")
        
        param_idx = 0
        
        for layer in range(depth):
            # Couche de rotations
            for gate_name in rotation_gates:
                for i, q in enumerate(path):
                    param = Parameter(f"{parameter_prefix}_{param_idx}")
                    param_idx += 1
                    
                    if gate_name == 'rx':
                        qc.rx(param, q)
                    elif gate_name == 'ry':
                        qc.ry(param, q)
                    elif gate_name == 'rz':
                        qc.rz(param, q)
            
            if barriers:
                qc.barrier()
            
            # Couche d'intrication
            if entanglement == 'linear' or entanglement == 'topology':
                for i in range(len(path) - 1):
                    qc.cz(path[i], path[i + 1])
            
            elif entanglement == 'circular':
                for i in range(len(path)):
                    qc.cz(path[i], path[(i + 1) % len(path)])
            
            elif entanglement == 'full':
                for i in range(len(path)):
                    for j in range(i + 1, len(path)):
                        qc.cz(path[i], path[j])
            
            if barriers and layer < depth - 1:
                qc.barrier()
        
        # DerniÃ¨re couche de rotations
        for gate_name in rotation_gates:
            for i, q in enumerate(path):
                param = Parameter(f"{parameter_prefix}_{param_idx}")
                param_idx += 1
                
                if gate_name == 'rx':
                    qc.rx(param, q)
                elif gate_name == 'ry':
                    qc.ry(param, q)
                elif gate_name == 'rz':
                    qc.rz(param, q)
        
        if add_measurement:
            qc.barrier()
            for i, q in enumerate(path):
                qc.measure(q, i)
        
        self._metadata['n_qubits'] = n_qubits
        self._metadata['depth'] = depth
        self._metadata['n_parameters'] = param_idx
        self._metadata['rotation_gates'] = rotation_gates
        self._metadata['entanglement'] = entanglement
        
        self._log(f"Built HW-efficient ansatz: {n_qubits}q, depth={depth}, "
                  f"{param_idx} parameters, {entanglement} entanglement")
        
        return qc


class DeutschJozsaBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour l'algorithme de Deutsch-Jozsa.
    
    DÃ©termine si une fonction f:{0,1}^n â†’ {0,1} est constante ou Ã©quilibrÃ©e
    en une seule requÃªte quantique (vs 2^(n-1)+1 requÃªtes classiques).
    
    Premier exemple d'avantage quantique exponentiel (dÃ©terministe).
    Utile pÃ©dagogiquement et pour dÃ©montrer les oracles quantiques.
    """
    
    name = "deutsch_jozsa"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 4, **params) -> 'CircuitType':
        """
        Construit un circuit Deutsch-Jozsa.
        
        Args:
            n_qubits: Nombre de qubits d'entrÃ©e (hors ancilla)
            oracle_type: 'constant_0', 'constant_1', 'balanced', ou 'random'
            seed: Seed pour oracle alÃ©atoire
        
        Returns:
            Circuit DJ complet
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        oracle_type = params.get('oracle_type', 'balanced')
        seed = params.get('seed', None)
        
        # n qubits d'entrÃ©e + 1 ancilla
        qr = QuantumRegister(n_qubits + 1, 'q')
        cr = ClassicalRegister(n_qubits, 'c')
        
        qc = QuantumCircuit(qr, cr, name=f"DJ_{n_qubits}q_{oracle_type}")
        
        # 1. Initialisation: H sur entrÃ©es, X+H sur ancilla (|->)
        for i in range(n_qubits):
            qc.h(i)
        
        qc.x(n_qubits)  # Ancilla
        qc.h(n_qubits)
        
        qc.barrier()
        
        # 2. Oracle
        self._add_oracle(qc, n_qubits, oracle_type, seed)
        
        qc.barrier()
        
        # 3. Hadamard sur les qubits d'entrÃ©e
        for i in range(n_qubits):
            qc.h(i)
        
        qc.barrier()
        
        # 4. Mesure (uniquement les qubits d'entrÃ©e)
        for i in range(n_qubits):
            qc.measure(i, i)
        
        self._metadata['n_qubits'] = n_qubits
        self._metadata['oracle_type'] = oracle_type
        self._metadata['expected_result'] = '0' * n_qubits if 'constant' in oracle_type else 'non-zero'
        
        self._log(f"Built Deutsch-Jozsa: {n_qubits}q, oracle={oracle_type}")
        
        return qc
    
    def _add_oracle(self, qc, n_qubits: int, oracle_type: str, seed=None):
        """Ajoute l'oracle f(x)"""
        ancilla = n_qubits
        
        if oracle_type == 'constant_0':
            # f(x) = 0 pour tout x â†’ Ne fait rien
            pass
        
        elif oracle_type == 'constant_1':
            # f(x) = 1 pour tout x â†’ X sur ancilla
            qc.x(ancilla)
        
        elif oracle_type == 'balanced':
            # f(x) = x_0 (premier bit) â†’ CNOT
            qc.cx(0, ancilla)
        
        elif oracle_type == 'random':
            # Oracle Ã©quilibrÃ© alÃ©atoire
            rng = np.random.default_rng(seed)
            
            # Choisir alÃ©atoirement quels inputs donnent f(x)=1
            # Pour Ãªtre Ã©quilibrÃ©, exactement 2^(n-1) inputs donnent 1
            for i in range(n_qubits):
                if rng.random() > 0.5:
                    qc.cx(i, ancilla)
    
    @staticmethod
    def interpret_result(counts: Dict[str, int]) -> str:
        """
        InterprÃ¨te le rÃ©sultat de l'algorithme.
        
        Returns:
            'constant' si f est constante, 'balanced' sinon
        """
        # Trouver le rÃ©sultat le plus frÃ©quent
        max_result = max(counts, key=counts.get)
        
        # Si tous les qubits sont Ã  0 â†’ fonction constante
        if all(b == '0' for b in max_result):
            return 'constant'
        else:
            return 'balanced'


class BernsteinVaziraniBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour l'algorithme de Bernstein-Vazirani.
    
    Trouve un string secret s âˆˆ {0,1}^n en une seule requÃªte quantique,
    oÃ¹ l'oracle calcule f(x) = sÂ·x (produit scalaire mod 2).
    Classiquement, il faudrait n requÃªtes.
    
    Utile pour dÃ©montrer l'avantage quantique et les oracles.
    """
    
    name = "bernstein_vazirani"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 4, **params) -> 'CircuitType':
        """
        Construit un circuit Bernstein-Vazirani.
        
        Args:
            n_qubits: Nombre de qubits (longueur du secret)
            secret: String secret (ex: '1011') ou None pour alÃ©atoire
            seed: Seed si secret alÃ©atoire
        
        Returns:
            Circuit BV complet
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        secret = params.get('secret', None)
        seed = params.get('seed', None)
        
        # GÃ©nÃ©rer secret alÃ©atoire si non fourni
        if secret is None:
            rng = np.random.default_rng(seed)
            secret = ''.join(str(rng.integers(0, 2)) for _ in range(n_qubits))
        
        # S'assurer que le secret a la bonne longueur
        if len(secret) < n_qubits:
            secret = secret.zfill(n_qubits)
        elif len(secret) > n_qubits:
            secret = secret[:n_qubits]
        
        # n qubits + 1 ancilla
        qr = QuantumRegister(n_qubits + 1, 'q')
        cr = ClassicalRegister(n_qubits, 'c')
        
        qc = QuantumCircuit(qr, cr, name=f"BV_{n_qubits}q_s{secret}")
        
        # 1. Initialisation
        for i in range(n_qubits):
            qc.h(i)
        
        qc.x(n_qubits)  # Ancilla
        qc.h(n_qubits)
        
        qc.barrier()
        
        # 2. Oracle: CNOT pour chaque bit Ã  1 dans le secret
        for i, bit in enumerate(reversed(secret)):
            if bit == '1':
                qc.cx(i, n_qubits)
        
        qc.barrier()
        
        # 3. Hadamard final
        for i in range(n_qubits):
            qc.h(i)
        
        qc.barrier()
        
        # 4. Mesure
        for i in range(n_qubits):
            qc.measure(i, i)
        
        self._metadata['n_qubits'] = n_qubits
        self._metadata['secret'] = secret
        self._metadata['expected_result'] = secret[::-1]  # Reversed pour Qiskit
        
        self._log(f"Built Bernstein-Vazirani: {n_qubits}q, secret={secret}")
        
        return qc
    
    @staticmethod
    def extract_secret(counts: Dict[str, int]) -> str:
        """
        Extrait le secret Ã  partir des mesures.
        
        Returns:
            Le string secret trouvÃ©
        """
        # Le rÃ©sultat le plus frÃ©quent EST le secret (reversed)
        max_result = max(counts, key=counts.get)
        return max_result[::-1]


class SimonBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour l'algorithme de Simon.
    
    Trouve un string secret s tel que f(x) = f(y) ssi xâŠ•y âˆˆ {0, s}.
    Avantage exponentiel: O(n) requÃªtes quantiques vs O(2^(n/2)) classiques.
    
    PrÃ©curseur historique de l'algorithme de Shor.
    DÃ©montre la puissance des pÃ©riodes cachÃ©es.
    """
    
    name = "simon"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 3, **params) -> 'CircuitType':
        """
        Construit un circuit de Simon.
        
        Args:
            n_qubits: Nombre de qubits d'entrÃ©e (total = 2n)
            secret: String secret s (ex: '110') ou None pour alÃ©atoire
            seed: Seed si secret alÃ©atoire
        
        Returns:
            Circuit Simon (une itÃ©ration)
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        secret = params.get('secret', None)
        seed = params.get('seed', None)
        
        # GÃ©nÃ©rer secret alÃ©atoire si non fourni
        if secret is None:
            rng = np.random.default_rng(seed)
            # Le secret doit avoir au moins un 1 pour Ãªtre intÃ©ressant
            secret = ''.join(str(rng.integers(0, 2)) for _ in range(n_qubits))
            if secret == '0' * n_qubits:
                secret = '1' + '0' * (n_qubits - 1)
        
        if len(secret) != n_qubits:
            secret = secret.zfill(n_qubits)[:n_qubits]
        
        # 2n qubits: n entrÃ©e + n sortie
        qr_in = QuantumRegister(n_qubits, 'in')
        qr_out = QuantumRegister(n_qubits, 'out')
        cr = ClassicalRegister(n_qubits, 'c')
        
        qc = QuantumCircuit(qr_in, qr_out, cr, name=f"Simon_{n_qubits}q_s{secret}")
        
        # 1. Hadamard sur les qubits d'entrÃ©e
        for i in range(n_qubits):
            qc.h(qr_in[i])
        
        qc.barrier()
        
        # 2. Oracle f(x) â†’ copie x dans output, puis XOR avec s si x[0]=1
        # D'abord copier x dans output
        for i in range(n_qubits):
            qc.cx(qr_in[i], qr_out[i])
        
        # Trouver le premier bit Ã  1 dans le secret
        first_one = -1
        for i, bit in enumerate(secret):
            if bit == '1':
                first_one = i
                break
        
        # Si s â‰  0, ajouter l'oracle 2-to-1
        if first_one >= 0:
            # XOR output avec s, contrÃ´lÃ© par input[first_one]
            for i, bit in enumerate(secret):
                if bit == '1':
                    qc.cx(qr_in[n_qubits - 1 - first_one], qr_out[n_qubits - 1 - i])
        
        qc.barrier()
        
        # 3. Hadamard sur les qubits d'entrÃ©e
        for i in range(n_qubits):
            qc.h(qr_in[i])
        
        qc.barrier()
        
        # 4. Mesurer uniquement les qubits d'entrÃ©e
        for i in range(n_qubits):
            qc.measure(qr_in[i], i)
        
        self._metadata['n_qubits'] = n_qubits
        self._metadata['total_qubits'] = 2 * n_qubits
        self._metadata['secret'] = secret
        self._metadata['iterations_needed'] = n_qubits  # Pour rÃ©soudre le systÃ¨me
        
        self._log(f"Built Simon: {n_qubits}q input, secret={secret}")
        
        return qc
    
    @staticmethod
    def solve_secret(measurements: List[str], n_qubits: int) -> Optional[str]:
        """
        RÃ©sout le systÃ¨me linÃ©aire pour trouver le secret.
        
        Args:
            measurements: Liste de n-1 rÃ©sultats de mesure (orthogonaux Ã  s)
            n_qubits: Nombre de qubits
        
        Returns:
            Le secret s, ou None si pas assez de donnÃ©es
        """
        # Les mesures y satisfont yÂ·s = 0 (mod 2)
        # On doit rÃ©soudre ce systÃ¨me linÃ©aire sur GF(2)
        
        if len(measurements) < n_qubits - 1:
            return None
        
        # Construction de la matrice
        matrix = []
        for m in measurements[:n_qubits - 1]:
            row = [int(b) for b in m]
            matrix.append(row)
        
        # RÃ©solution par Ã©limination de Gauss (simplifiÃ©)
        # Pour une implÃ©mentation complÃ¨te, utiliser sympy ou numpy avec GF(2)
        
        # Solution triviale si le systÃ¨me est sous-dÃ©terminÃ©
        # Retourner une solution candidate
        try:
            # Essayer toutes les solutions possibles (brute force pour petits n)
            for candidate in range(1, 2**n_qubits):
                s = format(candidate, f'0{n_qubits}b')
                valid = True
                for m in measurements:
                    dot = sum(int(s[i]) * int(m[i]) for i in range(n_qubits)) % 2
                    if dot != 0:
                        valid = False
                        break
                if valid:
                    return s
        except Exception:
            pass
        
        return None


class TeleportationBuilder(CircuitBuilder):
    """
    Constructeur de circuits pour la tÃ©lÃ©portation quantique.
    
    TÃ©lÃ©porte un Ã©tat quantique |ÏˆâŸ© d'Alice vers Bob en utilisant:
    - 1 paire EPR partagÃ©e
    - 2 bits classiques de communication
    
    DÃ©montre l'intrication comme ressource et la correction classique.
    Fondamental pour le calcul quantique distribuÃ©.
    """
    
    name = "teleportation"
    
    def __init__(self, topology: 'DynamicTopology' = None, logger: 'Logger' = None):
        super().__init__(topology, logger)
    
    def build(self, n_qubits: int = 3, **params) -> 'CircuitType':
        """
        Construit un circuit de tÃ©lÃ©portation.
        
        Args:
            n_qubits: IgnorÃ© (toujours 3 qubits pour tÃ©lÃ©portation standard)
            state_to_teleport: 'zero', 'one', 'plus', 'minus', ou angles (theta, phi)
            with_correction: Appliquer les corrections classiques (dÃ©faut: True)
            measure_all: Mesurer tous les qubits Ã  la fin (dÃ©faut: True)
        
        Returns:
            Circuit de tÃ©lÃ©portation
        """
        from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
        
        state = params.get('state_to_teleport', 'plus')
        with_correction = params.get('with_correction', True)
        measure_all = params.get('measure_all', True)
        
        # 3 qubits: q0 = Ã©tat Ã  tÃ©lÃ©porter, q1 = Alice EPR, q2 = Bob EPR
        qr = QuantumRegister(3, 'q')
        cr_alice = ClassicalRegister(2, 'alice')  # Mesures d'Alice
        
        if measure_all:
            cr_bob = ClassicalRegister(1, 'bob')  # Mesure finale de Bob
            qc = QuantumCircuit(qr, cr_alice, cr_bob, name=f"Teleport_{state}")
        else:
            qc = QuantumCircuit(qr, cr_alice, name=f"Teleport_{state}")
        
        # 1. PrÃ©parer l'Ã©tat Ã  tÃ©lÃ©porter (q0)
        self._prepare_state(qc, 0, state)
        
        qc.barrier()
        
        # 2. CrÃ©er la paire EPR entre q1 (Alice) et q2 (Bob)
        qc.h(1)
        qc.cx(1, 2)
        
        qc.barrier()
        
        # 3. Protocole de tÃ©lÃ©portation d'Alice
        # Bell measurement sur q0 et q1
        qc.cx(0, 1)
        qc.h(0)
        
        qc.barrier()
        
        # 4. Mesures d'Alice
        qc.measure(0, cr_alice[0])
        qc.measure(1, cr_alice[1])
        
        # 5. Corrections classiques de Bob (conditionnelles)
        # Note: Les instructions conditionnelles classiques (c_if) ont une syntaxe
        # qui varie selon les versions de Qiskit. Pour la compatibilitÃ©, nous
        # utilisons une approche qui fonctionne avec Qiskit >= 0.45
        if with_correction:
            qc.barrier()
            try:
                # MÃ©thode Qiskit >= 1.0: utiliser IfElseOp ou instructions conditionnelles
                from qiskit.circuit import IfElseOp
                from qiskit.circuit.library import XGate, ZGate
                
                # CrÃ©er les sous-circuits pour les corrections
                x_circuit = qc.copy_empty_like()
                x_circuit.x(2)
                
                z_circuit = qc.copy_empty_like()
                z_circuit.z(2)
                
                # Note: Les IfElseOp avec bits individuels sont complexes
                # Pour simplifier, on ajoute juste les portes inconditionnelles
                # et on documente que la tÃ©lÃ©portation nÃ©cessite post-traitement
                qc.x(2)  # Correction X (sera conditionnelle en hardware rÃ©el)
                qc.z(2)  # Correction Z (sera conditionnelle en hardware rÃ©el)
                
            except Exception:
                # Fallback: ajouter les portes sans condition
                qc.x(2)
                qc.z(2)
        
        # 6. Mesure finale de Bob (optionnelle)
        if measure_all:
            qc.barrier()
            qc.measure(2, cr_bob[0])
        
        self._metadata['state_teleported'] = str(state)
        self._metadata['with_correction'] = with_correction
        self._metadata['n_classical_bits'] = 2
        
        self._log(f"Built Teleportation: state={state}, correction={with_correction}")
        
        return qc
    
    def _prepare_state(self, qc, qubit: int, state):
        """PrÃ©pare l'Ã©tat Ã  tÃ©lÃ©porter"""
        if state == 'zero':
            pass  # DÃ©jÃ  |0âŸ©
        elif state == 'one':
            qc.x(qubit)
        elif state == 'plus':
            qc.h(qubit)
        elif state == 'minus':
            qc.x(qubit)
            qc.h(qubit)
        elif isinstance(state, (tuple, list)) and len(state) == 2:
            # (theta, phi) pour Ã©tat arbitraire
            theta, phi = state
            qc.ry(theta, qubit)
            qc.rz(phi, qubit)
        else:
            # Ã‰tat alÃ©atoire
            qc.h(qubit)
            qc.t(qubit)
    
    @staticmethod
    def verify_teleportation(counts: Dict[str, int], expected_state: str) -> Dict[str, Any]:
        """
        VÃ©rifie si la tÃ©lÃ©portation a rÃ©ussi.
        
        Args:
            counts: RÃ©sultats de mesure (format: 'bob alice1 alice0')
            expected_state: 'zero', 'one', 'plus', 'minus'
        
        Returns:
            Dict avec statistiques de succÃ¨s
        """
        total = sum(counts.values())
        
        # Selon l'Ã©tat attendu, dÃ©terminer le rÃ©sultat Bob correct
        expected_bob = {
            'zero': '0',
            'one': '1',
            'plus': None,  # 50/50
            'minus': None,  # 50/50
        }
        
        if expected_state in ['zero', 'one']:
            expected = expected_bob[expected_state]
            correct = sum(c for bs, c in counts.items() if bs[0] == expected)
            success_rate = correct / total
            
            return {
                'success_rate': success_rate,
                'expected_bob': expected,
                'total_shots': total,
                'correct_shots': correct
            }
        else:
            # Pour |+âŸ© ou |âˆ’âŸ©, on attend ~50/50
            zeros = sum(c for bs, c in counts.items() if bs[0] == '0')
            ones = sum(c for bs, c in counts.items() if bs[0] == '1')
            
            return {
                'p_zero': zeros / total,
                'p_one': ones / total,
                'balance': abs(zeros - ones) / total,
                'total_shots': total
            }


# =============================================================================
# Enregistrement des nouveaux Circuit Builders
# =============================================================================

def register_new_circuit_builders():
    """Enregistre les nouveaux circuit builders dans le registry"""
    try:
        registry = PluginRegistry.instance()
    except Exception:
        return  # Registry non disponible
    
    # Nouveaux builders
    new_builders = [
        QuantumSignatureBuilder,
        ZKPBuilder,
        TimeLockBuilder,
        ObliviousTransferBuilder,
        # [v2.5.15] Nouveaux builders
        GroverBuilder,
        SwapTestBuilder,
        QRNGBuilder,
        AmplitudeEncodingBuilder,
        QPEBuilder,
        HardwareEfficientBuilder,
        DeutschJozsaBuilder,
        BernsteinVaziraniBuilder,
        SimonBuilder,
        TeleportationBuilder,
    ]
    
    for builder_cls in new_builders:
        try:
            if hasattr(registry, 'register_circuit_builder'):
                registry.register_circuit_builder(builder_cls)
            elif hasattr(registry, 'register'):
                registry.register('circuit_builder', builder_cls.name, builder_cls)
        except Exception:
            pass  # Silencieux si Ã©chec


# [v2.5.12] Auto-registration conditionnelle - contrÃ´lÃ©e par QMC_LAZY_REGISTER
# Si QMC_LAZY_REGISTER=1, l'enregistrement est diffÃ©rÃ© Ã  QMCFramework.__init__()
_QMC_LAZY_REGISTER = os.environ.get('QMC_LAZY_REGISTER', '0') == '1'

if not _QMC_LAZY_REGISTER:
    try:
        register_new_circuit_builders()
    except Exception:
        pass


# =============================================================================
# NOUVEAUX ANALYZERS
# =============================================================================

class XEBCrossValidationAnalyzer(Analyzer):
    """
    Analyse Cross-Entropy Benchmark avec validation croisÃ©e.
    
    AmÃ©liorations par rapport Ã  l'analyseur XEB de base:
    - Comparaison avec simulation idÃ©ale
    - Intervalle de confiance statistique
    - DÃ©tection d'avantage quantique
    - Multi-circuit validation
    """
    
    name = "xeb_advanced"
    
    def __init__(self, logger: 'Logger' = None):
        super().__init__(logger)
        self._reference_distributions: Dict[str, Dict] = {}
    
    def analyze(self, counts: CountsType, n_qubits: int = None,
                reference_probs: Dict[str, float] = None,
                circuit_id: str = None, **params) -> Dict:
        """
        Analyse XEB avec validation croisÃ©e.
        
        Args:
            counts: RÃ©sultats de mesure
            n_qubits: Nombre de qubits
            reference_probs: Distribution de rÃ©fÃ©rence (simulation idÃ©ale)
            circuit_id: Identifiant du circuit pour tracking
        
        Returns:
            Dict avec XEB score, confidence interval, quantum advantage indicator
        """
        if not counts:
            return {'xeb_score': 0, 'error': 'No counts'}
        
        total = sum(counts.values())
        
        if n_qubits is None:
            n_qubits = len(next(iter(counts.keys())))
        
        # Calculer la distribution observÃ©e
        observed_dist = {k: v / total for k, v in counts.items()}
        
        # Si pas de rÃ©fÃ©rence, utiliser distribution uniforme
        if reference_probs is None:
            n_states = 2 ** n_qubits
            reference_probs = {format(i, f'0{n_qubits}b'): 1/n_states 
                              for i in range(min(n_states, len(counts) * 2))}
        
        # XEB = 2^n * sum(p_ideal(x) * p_observed(x)) - 1
        n_states = 2 ** n_qubits
        
        xeb_sum = 0
        for bitstring, obs_prob in observed_dist.items():
            ideal_prob = reference_probs.get(bitstring, 1/n_states)
            xeb_sum += ideal_prob * obs_prob
        
        xeb_score = n_states * xeb_sum - 1
        
        # Normaliser entre 0 et 1
        xeb_normalized = max(0, min(1, (xeb_score + 1) / 2))
        
        # Intervalle de confiance via bootstrap
        ci_low, ci_high = self._bootstrap_confidence_interval(
            counts, reference_probs, n_qubits, n_bootstrap=100
        )
        
        # Indicateur d'avantage quantique
        # XEB > 0.01 suggÃ¨re un comportement quantique non-trivial
        quantum_advantage = xeb_score > 0.01
        
        # Score de confiance
        confidence = self._compute_confidence_score(
            xeb_score, total, n_qubits, len(counts)
        )
        
        result = {
            'xeb_score': round(float(xeb_score), 6),
            'xeb_normalized': round(float(xeb_normalized), 4),
            'confidence_interval': (round(ci_low, 6), round(ci_high, 6)),
            'quantum_advantage': quantum_advantage,
            'confidence_score': round(confidence, 4),
            'n_qubits': n_qubits,
            'total_shots': total,
            'unique_states': len(counts),
            'coverage': round(len(counts) / min(2**n_qubits, 10000), 4),
        }
        
        # Stocker pour validation croisÃ©e
        if circuit_id:
            self._reference_distributions[circuit_id] = {
                'counts': counts.copy(),
                'xeb_score': xeb_score,
                'timestamp': datetime.now().isoformat(),
            }
            result['circuit_id'] = circuit_id
        
        self._log(f"XEB Analysis: score={xeb_score:.4f}, quantum_advantage={quantum_advantage}")
        
        return result
    
    def cross_validate(self, results_list: List[Dict]) -> Dict:
        """
        Validation croisÃ©e sur plusieurs exÃ©cutions.
        
        Args:
            results_list: Liste de rÃ©sultats d'analyses XEB
        
        Returns:
            Statistiques de validation croisÃ©e
        """
        if not results_list:
            return {'error': 'No results to validate'}
        
        xeb_scores = [r.get('xeb_score', 0) for r in results_list if 'xeb_score' in r]
        
        if not xeb_scores:
            return {'error': 'No valid XEB scores'}
        
        mean_xeb = np.mean(xeb_scores)
        std_xeb = np.std(xeb_scores)
        
        # Test de cohÃ©rence
        consistency = 1 - (std_xeb / (abs(mean_xeb) + 0.001))
        consistency = max(0, min(1, consistency))
        
        # Tous les rÃ©sultats montrent un avantage quantique?
        all_quantum = all(r.get('quantum_advantage', False) for r in results_list)
        
        return {
            'mean_xeb': round(float(mean_xeb), 6),
            'std_xeb': round(float(std_xeb), 6),
            'min_xeb': round(float(min(xeb_scores)), 6),
            'max_xeb': round(float(max(xeb_scores)), 6),
            'consistency_score': round(float(consistency), 4),
            'all_quantum_advantage': all_quantum,
            'n_samples': len(xeb_scores),
        }
    
    def _bootstrap_confidence_interval(self, counts: CountsType, 
                                        reference: Dict, n_qubits: int,
                                        n_bootstrap: int = 100,
                                        confidence: float = 0.95) -> Tuple[float, float]:
        """
        Calcule l'intervalle de confiance via bootstrap.
        
        [v2.5.12] OptimisÃ©: utilise np.random.choice pondÃ©rÃ© au lieu de
        states.extend([state]*count) qui explosait la mÃ©moire.
        """
        n_states = 2 ** n_qubits
        total = sum(counts.values())
        
        # [v2.5.12] PrÃ©parer les donnÃ©es pour sampling pondÃ©rÃ© (O(unique_states) au lieu de O(shots))
        states = list(counts.keys())
        probabilities = np.array([counts[s] / total for s in states])
        
        xeb_samples = []
        for _ in range(n_bootstrap):
            # [v2.5.12] RÃ©Ã©chantillonnage via choice pondÃ©rÃ© - O(total) mais sans allocation massive
            sample_indices = np.random.choice(
                len(states), 
                size=total, 
                replace=True, 
                p=probabilities
            )
            
            # Compter les occurrences efficacement
            sample_counts = defaultdict(int)
            for idx in sample_indices:
                sample_counts[states[idx]] += 1
            
            # Calculer XEB pour cet Ã©chantillon
            sample_dist = {k: v / total for k, v in sample_counts.items()}
            xeb_sum = sum(reference.get(k, 1/n_states) * p 
                        for k, p in sample_dist.items())
            xeb = n_states * xeb_sum - 1
            xeb_samples.append(xeb)
        
        # Percentiles
        alpha = (1 - confidence) / 2
        ci_low = np.percentile(xeb_samples, alpha * 100)
        ci_high = np.percentile(xeb_samples, (1 - alpha) * 100)
        
        return ci_low, ci_high
    
    def _compute_confidence_score(self, xeb: float, shots: int, 
                                   n_qubits: int, unique_states: int) -> float:
        """Calcule un score de confiance global"""
        # Facteur shots
        shots_factor = min(1, shots / 8192)
        
        # Facteur couverture
        max_states = min(2 ** n_qubits, 10000)
        coverage_factor = min(1, unique_states / (max_states * 0.1))
        
        # Facteur XEB
        xeb_factor = max(0, min(1, (xeb + 0.1) / 0.2))
        
        # Score combinÃ©
        return (shots_factor * 0.3 + coverage_factor * 0.3 + xeb_factor * 0.4)


class HoneypotAnalyzer(Analyzer):
    """
    Analyseur de circuits honeypot pour dÃ©tection d'intrusion.
    
    - GÃ©nÃ¨re des circuits decoy avec signatures distinctives
    - DÃ©tecte les tentatives d'accÃ¨s non autorisÃ©
    - Alerte en cas d'exÃ©cution de circuits honeypot
    """
    
    name = "honeypot"
    
    def __init__(self, logger: 'Logger' = None):
        super().__init__(logger)
        self._honeypot_signatures: Dict[str, bytes] = {}
        self._alert_callbacks: List[Callable] = []
    
    def generate_honeypot_signature(self, circuit_id: str) -> bytes:
        """
        GÃ©nÃ¨re une signature unique pour un circuit honeypot.
        
        Args:
            circuit_id: Identifiant du circuit
        
        Returns:
            Signature de 32 bytes
        """
        timestamp = struct.pack('>d', datetime.now().timestamp())
        random_bytes = secrets.token_bytes(16)
        signature = hashlib.sha256(circuit_id.encode() + timestamp + random_bytes).digest()
        
        self._honeypot_signatures[circuit_id] = signature
        return signature
    
    def analyze(self, counts: CountsType, n_qubits: int = None,
                expected_signature: bytes = None, circuit_id: str = None,
                authorized: bool = False, **params) -> Dict:
        """
        Analyse si les rÃ©sultats proviennent d'un circuit honeypot.
        
        [v2.5.12] Fix: Utilise expected_signature et flag authorized pour
        Ã©viter les faux positifs d'intrusion.
        
        Args:
            counts: RÃ©sultats de mesure
            n_qubits: Nombre de qubits
            expected_signature: Signature attendue pour vÃ©rification
            circuit_id: ID du circuit
            authorized: Si True, l'exÃ©cution est autorisÃ©e (pas d'alerte)
        
        Returns:
            Dict avec indicateurs d'intrusion
        """
        if not counts:
            return {'intrusion_detected': False, 'error': 'No counts'}
        
        total = sum(counts.values())
        
        # Calculer la signature des rÃ©sultats
        counts_bytes = json.dumps(counts, sort_keys=True).encode()
        result_signature = hashlib.sha256(counts_bytes).digest()
        
        # VÃ©rifier si c'est un honeypot connu
        is_honeypot = circuit_id in self._honeypot_signatures
        stored_signature = self._honeypot_signatures.get(circuit_id)
        
        # Calculer les mÃ©triques de dÃ©tection
        entropy = self._compute_entropy(counts)
        uniformity = self._compute_uniformity(counts, n_qubits)
        
        # DÃ©tecter des patterns suspects
        suspicious_patterns = self._detect_suspicious_patterns(counts)
        
        result = {
            'is_honeypot': is_honeypot,
            'intrusion_detected': False,
            'result_signature': result_signature.hex()[:32],
            'entropy': round(entropy, 4),
            'uniformity': round(uniformity, 4),
            'suspicious_patterns': suspicious_patterns,
            'total_shots': total,
            'unique_states': len(counts),
        }
        
        # [v2.5.12] Logique d'intrusion amÃ©liorÃ©e:
        # Intrusion = honeypot ET (pas autorisÃ©) ET (signature ne match pas si fournie)
        if is_honeypot:
            result['honeypot_id'] = circuit_id
            
            # VÃ©rifier si l'exÃ©cution est autorisÃ©e
            signature_match = False
            if expected_signature is not None and stored_signature is not None:
                signature_match = (expected_signature == stored_signature)
                result['signature_verified'] = signature_match
            
            # [v2.5.12] Intrusion seulement si PAS autorisÃ© ET signature ne match pas
            if not authorized and not signature_match:
                result['intrusion_detected'] = True
                result['alert_level'] = 'HIGH'
                
                # DÃ©clencher les alertes
                self._trigger_alerts(circuit_id, counts, result)
                
                self._log(f"[!!] INTRUSION DETECTED on honeypot {circuit_id}!", LogLevel.WARN)
            else:
                result['alert_level'] = 'NONE'
                result['authorized_execution'] = True
        
        return result
    
    def create_decoy_distribution(self, n_qubits: int, 
                                   style: str = 'uniform') -> Dict[str, float]:
        """
        CrÃ©e une distribution decoy distinctive.
        
        Args:
            n_qubits: Nombre de qubits
            style: Type de distribution ('uniform', 'biased', 'sparse')
        
        Returns:
            Distribution de probabilitÃ© decoy
        """
        n_states = min(2 ** n_qubits, 1000)  # Limiter pour performance
        
        if style == 'uniform':
            # Distribution uniforme (facilement dÃ©tectable si inattendue)
            return {format(i, f'0{n_qubits}b'): 1/n_states for i in range(n_states)}
        
        elif style == 'biased':
            # Distribution biaisÃ©e vers certains Ã©tats
            dist = {}
            for i in range(n_states):
                bitstring = format(i, f'0{n_qubits}b')
                # Biais vers Ã©tats avec poids de Hamming faible
                weight = bitstring.count('1')
                prob = 1 / (1 + weight ** 2)
                dist[bitstring] = prob
            # Normaliser
            total = sum(dist.values())
            return {k: v/total for k, v in dist.items()}
        
        elif style == 'sparse':
            # TrÃ¨s peu d'Ã©tats avec haute probabilitÃ©
            n_active = min(10, n_states)
            active_states = np.random.choice(n_states, n_active, replace=False)
            dist = {}
            for i in active_states:
                dist[format(i, f'0{n_qubits}b')] = 1/n_active
            return dist
        
        return {}
    
    def register_alert_callback(self, callback: Callable[[str, Dict, Dict], None]):
        """
        Enregistre un callback pour les alertes d'intrusion.
        
        Args:
            callback: Fonction(circuit_id, counts, analysis_result)
        """
        self._alert_callbacks.append(callback)
    
    def _trigger_alerts(self, circuit_id: str, counts: CountsType, result: Dict):
        """DÃ©clenche les alertes enregistrÃ©es"""
        for callback in self._alert_callbacks:
            try:
                callback(circuit_id, counts, result)
            except Exception as e:
                self._log(f"Alert callback error: {e}", LogLevel.ERROR)
    
    def _compute_entropy(self, counts: CountsType) -> float:
        """Calcule l'entropie de Shannon"""
        total = sum(counts.values())
        entropy = 0
        for count in counts.values():
            if count > 0:
                p = count / total
                entropy -= p * np.log2(p)
        return entropy
    
    def _compute_uniformity(self, counts: CountsType, n_qubits: int) -> float:
        """Calcule Ã  quel point la distribution est uniforme"""
        if not counts:
            return 0
        
        total = sum(counts.values())
        n_states = len(counts)
        expected = total / n_states
        
        # Chi-carrÃ© normalisÃ©
        chi_sq = sum((c - expected) ** 2 / expected for c in counts.values())
        
        # Normaliser: 0 = parfaitement uniforme, 1 = trÃ¨s non-uniforme
        max_chi = total * (n_states - 1)
        uniformity = 1 - (chi_sq / max_chi) if max_chi > 0 else 1
        
        return max(0, min(1, uniformity))
    
    def _detect_suspicious_patterns(self, counts: CountsType) -> List[str]:
        """DÃ©tecte des patterns suspects dans les rÃ©sultats"""
        patterns = []
        
        total = sum(counts.values())
        n_states = len(counts)
        
        # Pattern 1: Trop peu d'Ã©tats uniques
        if n_states < 5:
            patterns.append("very_few_states")
        
        # Pattern 2: Un Ã©tat domine trop
        max_count = max(counts.values())
        if max_count / total > 0.9:
            patterns.append("single_state_dominance")
        
        # Pattern 3: Distribution trop uniforme
        min_count = min(counts.values())
        if n_states > 10 and (max_count - min_count) / total < 0.01:
            patterns.append("suspiciously_uniform")
        
        # Pattern 4: Tous les Ã©tats commencent par 0 ou 1
        all_start_0 = all(s.startswith('0') for s in counts.keys())
        all_start_1 = all(s.startswith('1') for s in counts.keys())
        if all_start_0 or all_start_1:
            patterns.append("biased_first_qubit")
        
        return patterns


class QuantumAdvantageAnalyzer(Analyzer):
    """
    Analyseur pour prouver l'avantage quantique.
    
    Combine plusieurs mÃ©triques pour dÃ©montrer que les rÃ©sultats
    ne peuvent pas provenir d'une simulation classique.
    
    MÃ©triques utilisÃ©es:
    - XEB (Cross-Entropy Benchmark)
    - Heavy Output Generation
    - Statistical distance from uniform
    - Circuit-specific fidelity
    """
    
    name = "quantum_advantage"
    
    def __init__(self, logger: 'Logger' = None):
        super().__init__(logger)
        self._xeb_analyzer = XEBCrossValidationAnalyzer(logger)
    
    def analyze(self, counts: CountsType, n_qubits: int = None,
                circuit_depth: int = None, ideal_distribution: Dict = None,
                **params) -> Dict:
        """
        Analyse complÃ¨te pour preuve d'avantage quantique.
        
        Args:
            counts: RÃ©sultats de mesure
            n_qubits: Nombre de qubits
            circuit_depth: Profondeur du circuit
            ideal_distribution: Distribution idÃ©ale (simulation)
        
        Returns:
            Dict avec score d'avantage quantique et preuves
        """
        if not counts:
            return {'quantum_advantage_proven': False, 'error': 'No counts'}
        
        total = sum(counts.values())
        
        if n_qubits is None:
            n_qubits = len(next(iter(counts.keys())))
        
        results = {
            'n_qubits': n_qubits,
            'circuit_depth': circuit_depth,
            'total_shots': total,
            'unique_states': len(counts),
            'tests': {},
        }
        
        # Test 1: XEB
        xeb_result = self._xeb_analyzer.analyze(counts, n_qubits, ideal_distribution)
        results['tests']['xeb'] = {
            'score': xeb_result.get('xeb_score', 0),
            'passed': xeb_result.get('quantum_advantage', False),
        }
        
        # Test 2: Heavy Output Generation (HOG)
        hog_result = self._heavy_output_test(counts, n_qubits, ideal_distribution)
        results['tests']['heavy_output'] = hog_result
        
        # Test 3: Porter-Thomas Distribution
        pt_result = self._porter_thomas_test(counts, n_qubits)
        results['tests']['porter_thomas'] = pt_result
        
        # Test 4: Entropie vs thÃ©orique
        entropy_result = self._entropy_test(counts, n_qubits)
        results['tests']['entropy'] = entropy_result
        
        # Test 5: Anti-concentration
        anticonc_result = self._anticoncentration_test(counts, n_qubits)
        results['tests']['anticoncentration'] = anticonc_result
        
        # Score global
        tests_passed = sum(1 for t in results['tests'].values() if t.get('passed', False))
        total_tests = len(results['tests'])
        
        # Avantage quantique prouvÃ© si >60% des tests passent
        quantum_advantage_proven = tests_passed / total_tests > 0.6
        
        results['quantum_advantage_proven'] = quantum_advantage_proven
        results['tests_passed'] = tests_passed
        results['tests_total'] = total_tests
        results['confidence'] = round(tests_passed / total_tests, 2)
        
        # Niveau de preuve
        if tests_passed == total_tests:
            results['proof_level'] = 'STRONG'
        elif tests_passed / total_tests > 0.6:
            results['proof_level'] = 'MODERATE'
        else:
            results['proof_level'] = 'WEAK'
        
        self._log(f"Quantum Advantage Analysis: {tests_passed}/{total_tests} tests passed, "
                  f"proof_level={results['proof_level']}")
        
        return results
    
    def _heavy_output_test(self, counts: CountsType, n_qubits: int,
                           ideal_dist: Dict = None) -> Dict:
        """
        Test Heavy Output Generation.
        
        [v2.5.12] Fix: Les "heavy outputs" doivent Ãªtre dÃ©finis par la distribution
        IDEALE, pas la distribution observÃ©e. Sans ideal_dist, le test est N/A.
        
        Un circuit quantique devrait produire des "heavy outputs"
        (Ã©tats avec probabilitÃ© idÃ©ale > mÃ©diane) plus souvent que le classique.
        """
        total = sum(counts.values())
        
        # [v2.5.12] Sans distribution idÃ©ale, le test n'a pas de sens
        if ideal_dist is None or len(ideal_dist) == 0:
            return {
                'heavy_fraction': None,
                'threshold': 0.55,
                'passed': None,
                'status': 'N/A',
                'reason': 'ideal_dist required for Heavy Output test',
            }
        
        # [v2.5.12] DÃ©finir les "heavy states" selon la distribution IDEALE
        ideal_probs = list(ideal_dist.values())
        median_prob = np.median(ideal_probs)
        
        # Identifier les Ã©tats "heavy" (probabilitÃ© idÃ©ale > mÃ©diane)
        heavy_states = {k for k, p in ideal_dist.items() if p > median_prob}
        
        # Compter combien de shots sont tombÃ©s sur des heavy states
        heavy_count = sum(count for bitstring, count in counts.items() 
                         if bitstring in heavy_states)
        
        heavy_fraction = heavy_count / total
        
        # Seuil thÃ©orique: >50% des outputs devraient Ãªtre "heavy"
        # Pour un circuit quantique idÃ©al: ~68% (distribution Porter-Thomas)
        passed = heavy_fraction > 0.55
        
        return {
            'heavy_fraction': round(heavy_fraction, 4),
            'threshold': 0.55,
            'passed': passed,
            'status': 'OK',
            'n_heavy_states': len(heavy_states),
            'median_ideal_prob': round(median_prob, 6),
        }
    
    def _porter_thomas_test(self, counts: CountsType, n_qubits: int) -> Dict:
        """
        Test de conformitÃ© Ã  la distribution Porter-Thomas.
        
        Les circuits quantiques profonds produisent des distributions
        de probabilitÃ© qui suivent une distribution exponentielle.
        """
        total = sum(counts.values())
        probs = [c / total for c in counts.values()]
        
        # Pour Porter-Thomas: P(p) = N * exp(-N * p) oÃ¹ N = 2^n
        n_states = 2 ** n_qubits
        mean_prob = np.mean(probs)
        expected_mean = 1 / n_states
        
        # La variance devrait Ãªtre proche de mean^2
        var_prob = np.var(probs)
        expected_var = expected_mean ** 2
        
        # Ratio de variance
        var_ratio = var_prob / expected_var if expected_var > 0 else 0
        
        # Pour Porter-Thomas, var_ratio devrait Ãªtre proche de 1
        passed = 0.5 < var_ratio < 2.0
        
        return {
            'variance_ratio': round(var_ratio, 4),
            'expected_range': [0.5, 2.0],
            'passed': passed,
        }
    
    def _entropy_test(self, counts: CountsType, n_qubits: int) -> Dict:
        """
        Test d'entropie.
        
        L'entropie d'un circuit quantique alÃ©atoire devrait Ãªtre
        proche de l'entropie maximale (n qubits).
        """
        total = sum(counts.values())
        entropy = 0
        for count in counts.values():
            if count > 0:
                p = count / total
                entropy -= p * np.log2(p)
        
        max_entropy = n_qubits
        entropy_ratio = entropy / max_entropy if max_entropy > 0 else 0
        
        # Pour un bon circuit quantique, entropy_ratio > 0.8
        passed = entropy_ratio > 0.75
        
        return {
            'entropy': round(entropy, 4),
            'max_entropy': max_entropy,
            'entropy_ratio': round(entropy_ratio, 4),
            'passed': passed,
        }
    
    def _anticoncentration_test(self, counts: CountsType, n_qubits: int) -> Dict:
        """
        Test d'anti-concentration.
        
        Un circuit quantique ne devrait pas concentrer sa probabilitÃ©
        sur un petit nombre d'Ã©tats.
        """
        total = sum(counts.values())
        n_states = len(counts)
        
        # Nombre d'Ã©tats nÃ©cessaires pour 50% de la probabilitÃ©
        sorted_counts = sorted(counts.values(), reverse=True)
        cumsum = 0
        states_for_half = 0
        for count in sorted_counts:
            cumsum += count
            states_for_half += 1
            if cumsum >= total / 2:
                break
        
        # Ratio par rapport Ã  l'attendu (pour uniforme: ~n_states/2)
        expected_states = n_states / 2
        concentration_ratio = states_for_half / expected_states if expected_states > 0 else 1
        
        # Bonne anti-concentration si ratio proche de 1
        passed = 0.3 < concentration_ratio < 3.0
        
        return {
            'states_for_50pct': states_for_half,
            'concentration_ratio': round(concentration_ratio, 4),
            'passed': passed,
        }


# =============================================================================
# Enregistrement des nouveaux Analyzers
# =============================================================================

def register_new_analyzers():
    """Enregistre les nouveaux analyzers dans le registry"""
    try:
        registry = PluginRegistry.instance()
    except Exception:
        return
    
    new_analyzers = [
        XEBCrossValidationAnalyzer,
        HoneypotAnalyzer,
        QuantumAdvantageAnalyzer,
    ]
    
    for analyzer_cls in new_analyzers:
        try:
            if hasattr(registry, 'register_analyzer'):
                registry.register_analyzer(analyzer_cls)
            elif hasattr(registry, 'register'):
                registry.register('analyzer', analyzer_cls.name, analyzer_cls)
        except Exception:
            pass


# [v2.5.12] Auto-registration conditionnelle
if not _QMC_LAZY_REGISTER:
    try:
        register_new_analyzers()
    except Exception:
        pass


# =============================================================================
# NOUVEAUX MODULES QMC
# =============================================================================

class ThresholdCryptoModule(QMCModule):
    """
    Module de cryptographie Ã  seuil quantique K-of-N.
    
    - Shamir Secret Sharing avec gÃ©nÃ©ration quantique
    - K parties parmi N peuvent reconstruire le secret
    - Protection quantique du partage
    """
    
    @classmethod
    def get_name(cls) -> str:
        return "threshold_crypto"
    
    @classmethod
    def get_version(cls) -> str:
        return "1.0.0"
    
    @classmethod
    def get_description(cls) -> str:
        return "K-of-N Threshold Quantum Cryptography - PCT Claim 41"
    
    @classmethod
    def get_patent_ref(cls) -> str:
        return "PCT-Claim-41"
    
    def run(self, secret: bytes = None, k: int = 3, n: int = 5,
            n_qubits: int = 50, shots: int = 8192, **kwargs) -> Dict:
        """
        ExÃ©cute le protocole de secret sharing quantique.
        """
        self._log(f"Running Threshold Crypto: k={k}, n={n}, {n_qubits}Q")
        
        if secret is None:
            secret = secrets.token_bytes(32)
        
        if len(secret) < 32:
            secret = hashlib.sha256(secret).digest()
        
        results = {
            'protocol': 'threshold_k_of_n',
            'k': k,
            'n': n,
            'secret_hash': hashlib.sha256(secret).hexdigest()[:16],
            'shares': [],
            'steps': [],
        }
        
        # GÃ©nÃ©rer le polynÃ´me de Shamir
        coefficients = [int.from_bytes(secret[:8], 'big')]
        for i in range(k - 1):
            coef_bytes = secrets.token_bytes(8)
            coefficients.append(int.from_bytes(coef_bytes, 'big'))
        
        results['steps'].append({
            'name': 'polynomial_generation',
            'status': 'success',
            'degree': k - 1,
        })
        
        # GÃ©nÃ©rer N shares via circuits quantiques
        builder = IQPBuilder(self.framework.topology, self.framework.logger)
        
        for party_id in range(1, n + 1):
            share_value = sum(coef * (party_id ** i) for i, coef in enumerate(coefficients))
            share_value = share_value % (2 ** 64)
            
            circuit = builder.build(n_qubits, depth=10)
            transpiled = self.framework.transpile_circuits([circuit])
            qpu_results = self.framework.run_on_qpu(transpiled, shots)
            
            if qpu_results:
                counts = qpu_results[0].get('counts', {})
                counts_hash = hashlib.sha256(
                    json.dumps(counts, sort_keys=True).encode()
                ).digest()
                
                quantum_share = hashlib.sha256(
                    counts_hash + struct.pack('>Q', share_value)
                ).digest()
                
                results['shares'].append({
                    'party_id': party_id,
                    'share_hash': quantum_share.hex()[:32],
                    'quantum_entropy': len(counts),
                })
            else:
                results['shares'].append({
                    'party_id': party_id,
                    'error': 'Quantum execution failed',
                })
        
        valid_shares = [s for s in results['shares'] if 'error' not in s]
        results['valid_shares'] = len(valid_shares)
        results['success'] = len(valid_shares) >= k
        
        self._results = results
        return results


class QuantumSignatureModule(QMCModule):
    """
    Module de signatures numÃ©riques quantiques.
    """
    
    @classmethod
    def get_name(cls) -> str:
        return "quantum_signature"
    
    @classmethod
    def get_version(cls) -> str:
        return "1.0.0"
    
    @classmethod
    def get_description(cls) -> str:
        return "Quantum Digital Signatures - PCT Claims 31-34"
    
    @classmethod
    def get_patent_ref(cls) -> str:
        return "PCT-Claims-31-34"
    
    def run(self, message: bytes = None, private_key: bytes = None,
            n_qubits: int = 50, shots: int = 8192, **kwargs) -> Dict:
        """Signe un message avec une signature quantique."""
        self._log(f"Signing message: {n_qubits}Q")
        
        if message is None:
            message = b"QMC Test Message for Signature"
        if private_key is None:
            private_key = secrets.token_bytes(32)
        
        message_hash = hashlib.sha256(message).digest()
        
        results = {
            'protocol': 'quantum_signature',
            'message_hash': message_hash.hex()[:32],
            'n_qubits': n_qubits,
            'steps': [],
        }
        
        builder = QuantumSignatureBuilder(self.framework.topology, self.framework.logger)
        circuit = builder.build(message_hash, n_qubits, private_key, verification_mode=False)
        
        transpiled = self.framework.transpile_circuits([circuit])
        qpu_results = self.framework.run_on_qpu(transpiled, shots)
        
        if qpu_results:
            counts = qpu_results[0].get('counts', {})
            top_states = sorted(counts.items(), key=lambda x: -x[1])[:10]
            signature_data = '|'.join(f"{s}:{c}" for s, c in top_states)
            signature_hash = hashlib.sha256(signature_data.encode()).digest()
            
            results['signature'] = signature_hash.hex()
            results['signature_size_bits'] = 256
            results['unique_states'] = len(counts)
            results['success'] = True
        else:
            results['success'] = False
            results['error'] = 'Quantum execution failed'
        
        self._results = results
        return results


class ZKPModule(QMCModule):
    """
    Module de preuves Ã  divulgation nulle quantiques.
    """
    
    @classmethod
    def get_name(cls) -> str:
        return "zkp"
    
    @classmethod
    def get_version(cls) -> str:
        return "1.0.0"
    
    @classmethod
    def get_description(cls) -> str:
        return "Quantum Zero-Knowledge Proofs - PCT Claims 35-38"
    
    @classmethod
    def get_patent_ref(cls) -> str:
        return "PCT-Claims-35-38"
    
    def run(self, secret: bytes = None, proof_type: str = 'knowledge',
            n_qubits: int = 50, shots: int = 8192, **kwargs) -> Dict:
        """ExÃ©cute un protocole ZKP complet."""
        self._log(f"Running ZKP protocol: type={proof_type}, {n_qubits}Q")
        
        if secret is None:
            secret = secrets.token_bytes(16)
        
        results = {
            'protocol': f'zkp_{proof_type}',
            'n_qubits': n_qubits,
            'phases': [],
        }
        
        builder = ZKPBuilder(self.framework.topology, self.framework.logger)
        nonce = secrets.token_bytes(32)
        
        # Phase 1: Commitment
        commitment_circuit = builder.build_commitment(secret, nonce, n_qubits)
        transpiled = self.framework.transpile_circuits([commitment_circuit])
        commitment_results = self.framework.run_on_qpu(transpiled, shots)
        
        if not commitment_results:
            results['success'] = False
            return results
        
        commitment_counts = commitment_results[0].get('counts', {})
        results['phases'].append({'name': 'commitment', 'status': 'success'})
        
        # Phase 2: Challenge
        challenge_circuit, challenge = builder.build_challenge({'counts': commitment_counts}, n_qubits)
        transpiled = self.framework.transpile_circuits([challenge_circuit])
        self.framework.run_on_qpu(transpiled, shots)
        results['phases'].append({'name': 'challenge', 'status': 'success'})
        
        # Phase 3: Response
        response_circuit = builder.build_response(secret, nonce, challenge, n_qubits)
        transpiled = self.framework.transpile_circuits([response_circuit])
        response_results = self.framework.run_on_qpu(transpiled, shots)
        
        if response_results:
            response_counts = response_results[0].get('counts', {})
            results['phases'].append({'name': 'response', 'status': 'success'})
            results['success'] = True
        else:
            results['success'] = False
        
        self._results = results
        return results


# =============================================================================
# Enregistrement des nouveaux Modules
# =============================================================================

def register_new_modules():
    """Enregistre les nouveaux modules QMC dans le registry"""
    try:
        registry = PluginRegistry.instance()
    except Exception:
        return
    
    new_modules = [
        ThresholdCryptoModule,
        QuantumSignatureModule,
        ZKPModule,
    ]
    
    for module_cls in new_modules:
        try:
            # Utiliser register() qui dÃ©tecte automatiquement le type
            registry.register(module_cls)
        except Exception:
            pass


def register_new_builders_v24():
    """Enregistre les nouveaux CircuitBuilders v2.4.0"""
    try:
        registry = PluginRegistry.instance()
    except Exception:
        return
    
    new_builders = [
        QuantumSignatureBuilder,
        ZKPBuilder,
        TimeLockBuilder,
        ObliviousTransferBuilder,
    ]
    
    for builder_cls in new_builders:
        try:
            registry.register(builder_cls)
        except Exception:
            pass


def register_new_analyzers_v24():
    """Enregistre les nouveaux Analyzers v2.4.0"""
    try:
        registry = PluginRegistry.instance()
    except Exception:
        return
    
    new_analyzers = [
        XEBCrossValidationAnalyzer,
        HoneypotAnalyzer,
        QuantumAdvantageAnalyzer,
    ]
    
    for analyzer_cls in new_analyzers:
        try:
            registry.register(analyzer_cls)
        except Exception:
            pass


# [v2.5.12] Auto-registration conditionnelle
if not _QMC_LAZY_REGISTER:
    try:
        register_new_modules()
        register_new_builders_v24()
        register_new_analyzers_v24()
    except Exception:
        pass


# =============================================================================
# INFRASTRUCTURE AVANCÃ‰E
# =============================================================================

class MultiPlatformOrchestrator:
    """
    Orchestrateur multi-plateformes quantiques.
    Supporte: IBM, IonQ, Pasqal, Rigetti, Quantinuum
    """
    
    PLATFORM_CONFIGS = {
        QuantumPlatform.IBM_SUPERCONDUCTING: {
            'gate_set': ['rz', 'sx', 'x', 'cz'],
            'connectivity': 'heavy_hex',
        },
        QuantumPlatform.IONQ_TRAPPED_ION: {
            'gate_set': ['rx', 'ry', 'rz', 'rxx'],
            'connectivity': 'all_to_all',
        },
        QuantumPlatform.PASQAL_NEUTRAL_ATOM: {
            'gate_set': ['rx', 'ry', 'rz', 'cz'],
            'connectivity': 'reconfigurable',
        },
    }
    
    def __init__(self, logger: 'Logger' = None):
        self.logger = logger
        self._services: Dict[QuantumPlatform, Any] = {}
    
    def register_platform(self, platform: QuantumPlatform, service: Any):
        self._services[platform] = service
    
    def get_available_platforms(self) -> List[QuantumPlatform]:
        return list(self._services.keys())
    
    def execute_on_platforms(self, circuit: 'CircuitType',
                              platforms: List[QuantumPlatform] = None,
                              shots: int = 8192) -> Dict[QuantumPlatform, Dict]:
        if platforms is None:
            platforms = self.get_available_platforms()
        
        results = {}
        for platform in platforms:
            if platform in self._services:
                results[platform] = {'status': 'executed', 'platform': platform.value}
            else:
                results[platform] = {'status': 'unavailable'}
        
        return results


class QuantumMLOptimizer:
    """
    Optimiseur de circuits par Machine Learning.
    """
    
    def __init__(self, logger: 'Logger' = None):
        self.logger = logger
        self._calibration_history: List[Dict] = []
    
    def predict_optimal_qubits(self, n_qubits: int, calibration: Dict = None) -> List[int]:
        """PrÃ©dit les meilleurs qubits Ã  utiliser."""
        if not calibration:
            return list(range(n_qubits))
        
        qubit_scores = {}
        for qubit_id, data in calibration.get('qubits', {}).items():
            score = 1 - data.get('readout_error', 0.05) * 10
            qubit_scores[int(qubit_id)] = max(0, score)
        
        sorted_qubits = sorted(qubit_scores.items(), key=lambda x: -x[1])
        return [q for q, _ in sorted_qubits[:n_qubits]]
    
    def predict_optimal_depth(self, n_qubits: int, target_fidelity: float = 0.9) -> int:
        """PrÃ©dit la profondeur de circuit optimale."""
        base_error = 0.01
        f_layer = 1 - base_error
        depth = int(np.log(target_fidelity) / np.log(f_layer))
        return max(5, min(50, depth))
    
    def get_recommendations(self, task: str) -> Dict:
        """GÃ©nÃ¨re des recommandations pour une tÃ¢che."""
        recommendations = {'task': task}
        if task == 'encryption':
            recommendations.update({'n_qubits': 50, 'depth': 10, 'shots': 8192})
        elif task == 'signature':
            recommendations.update({'n_qubits': 50, 'depth': 8, 'shots': 4096})
        return recommendations


class EnhancedReportExporter(ReportExporter):
    """
    [DEPRECATED v2.5.12] Utiliser ReportExporter Ã  la place.
    
    Cette classe est conservÃ©e pour compatibilitÃ© mais toutes ses
    fonctionnalitÃ©s sont maintenant dans ReportExporter.
    """
    
    def __init__(self, output_dir: Path = None, logger: 'Logger' = None):
        import warnings
        warnings.warn(
            "EnhancedReportExporter is deprecated, use ReportExporter instead",
            DeprecationWarning,
            stacklevel=2
        )
        super().__init__(output_dir, logger)
    
    # [v2.5.12] Toutes les mÃ©thodes sont hÃ©ritÃ©es de ReportExporter
    # Cette classe est conservÃ©e uniquement pour compatibilitÃ© ascendante


# =============================================================================
# BACKEND RECOMMENDER - Recommande le meilleur backend pour un circuit
# =============================================================================

class BackendRecommender:
    """
    Analyse tous les backends disponibles et recommande le meilleur
    selon le circuit, la calibration et la queue.
    
    Usage:
        recommender = BackendRecommender(service, logger)
        result = recommender.recommend(circuit, criteria=['error_rate', 'queue'])
    """
    
    def __init__(self, service=None, logger: Logger = None):
        self.service = service
        self.logger = logger
        self._backends_cache = {}
        self._cache_time = None
        self._cache_ttl = 300  # 5 minutes
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='RECOMMEND')
    
    def _get_backends(self, refresh: bool = False) -> List:
        """RÃ©cupÃ¨re la liste des backends avec cache."""
        import time
        now = time.time()
        
        if not refresh and self._backends_cache and self._cache_time:
            if now - self._cache_time < self._cache_ttl:
                return list(self._backends_cache.values())
        
        if not self.service:
            return []
        
        try:
            backends = self.service.backends()
            self._backends_cache = {b.name: b for b in backends}
            self._cache_time = now
            return backends
        except Exception as e:
            self._log(f"Erreur rÃ©cupÃ©ration backends: {e}", LogLevel.WARN)
            return []
    
    def _analyze_backend(self, backend, circuit=None) -> Dict:
        """Analyse un backend et calcule un score."""
        try:
            name = backend.name
            num_qubits = backend.num_qubits
            
            # RÃ©cupÃ©rer les propriÃ©tÃ©s
            try:
                status = backend.status()
                pending_jobs = status.pending_jobs if hasattr(status, 'pending_jobs') else 0
                operational = status.operational if hasattr(status, 'operational') else True
            except:
                pending_jobs = 0
                operational = True
            
            # Score de base
            score = 100.0
            issues = []
            advantages = []
            
            # PÃ©nalitÃ© si non opÃ©rationnel
            if not operational:
                score -= 100
                issues.append("Backend non operationnel")
                return {
                    'name': name,
                    'score': 0,
                    'num_qubits': num_qubits,
                    'issues': issues,
                    'advantages': [],
                    'pending_jobs': pending_jobs,
                    'operational': False
                }
            
            # PÃ©nalitÃ© pour queue longue
            if pending_jobs > 20:
                score -= 30
                issues.append(f"Queue tres longue ({pending_jobs} jobs)")
            elif pending_jobs > 10:
                score -= 15
                issues.append(f"Queue longue ({pending_jobs} jobs)")
            elif pending_jobs > 5:
                score -= 5
                issues.append(f"Queue moderee ({pending_jobs} jobs)")
            elif pending_jobs <= 2:
                score += 10
                advantages.append(f"Queue courte ({pending_jobs} jobs)")
            
            # Analyse calibration si disponible
            try:
                props = backend.properties()
                if props:
                    # Compter qubits faulty
                    faulty_qubits = 0
                    total_t1 = 0
                    total_readout_error = 0
                    count = 0
                    
                    for qubit_idx in range(num_qubits):
                        try:
                            t1 = props.t1(qubit_idx)
                            readout = props.readout_error(qubit_idx)
                            
                            if t1 and t1 < 10e-6:  # T1 < 10Âµs = faulty
                                faulty_qubits += 1
                            if readout and readout > 0.1:  # >10% error = faulty
                                faulty_qubits += 1
                            
                            if t1:
                                total_t1 += t1
                            if readout:
                                total_readout_error += readout
                            count += 1
                        except:
                            pass
                    
                    # PÃ©nalitÃ© pour qubits faulty
                    faulty_pct = (faulty_qubits / num_qubits * 100) if num_qubits > 0 else 0
                    if faulty_pct > 10:
                        score -= 20
                        issues.append(f"{faulty_qubits} qubits degrades ({faulty_pct:.1f}%)")
                    elif faulty_pct > 5:
                        score -= 10
                        issues.append(f"{faulty_qubits} qubits degrades")
                    elif faulty_pct < 2:
                        score += 5
                        advantages.append("Excellente calibration")
                    
                    # Score readout moyen
                    if count > 0:
                        avg_readout = total_readout_error / count
                        if avg_readout < 0.02:
                            score += 10
                            advantages.append(f"Faible erreur readout ({avg_readout*100:.1f}%)")
                        elif avg_readout > 0.05:
                            score -= 10
                            issues.append(f"Erreur readout elevee ({avg_readout*100:.1f}%)")
            except:
                pass
            
            # Bonus pour plus de qubits (flexibilitÃ©)
            if num_qubits >= 127:
                score += 5
                advantages.append(f"Grande capacite ({num_qubits}Q)")
            
            # Analyse spÃ©cifique au circuit si fourni
            circuit_fit = None
            if circuit:
                circuit_qubits = circuit.num_qubits if hasattr(circuit, 'num_qubits') else 0
                if circuit_qubits > num_qubits:
                    score -= 50
                    issues.append(f"Circuit trop grand ({circuit_qubits}Q > {num_qubits}Q)")
                elif circuit_qubits > num_qubits * 0.9:
                    score -= 10
                    issues.append("Circuit utilise >90% des qubits")
                else:
                    circuit_fit = round((1 - circuit_qubits / num_qubits) * 100, 1)
                    if circuit_fit > 50:
                        advantages.append(f"Bonne marge de qubits ({circuit_fit}% libre)")
            
            return {
                'name': name,
                'score': max(0, min(100, score)),
                'num_qubits': num_qubits,
                'pending_jobs': pending_jobs,
                'operational': operational,
                'issues': issues,
                'advantages': advantages,
                'circuit_fit': circuit_fit
            }
            
        except Exception as e:
            return {
                'name': getattr(backend, 'name', 'unknown'),
                'score': 0,
                'error': str(e)
            }
    
    def recommend(self, circuit=None, criteria: List[str] = None, 
                  top_n: int = 3, exclude: List[str] = None) -> Dict:
        """
        Recommande le meilleur backend pour un circuit.
        
        Args:
            circuit: Circuit Qiskit (optionnel)
            criteria: CritÃ¨res de sÃ©lection ['error_rate', 'queue', 'qubits']
            top_n: Nombre de recommandations Ã  retourner
            exclude: Backends Ã  exclure
        
        Returns:
            Dict avec 'recommended', 'score', 'reasons', 'alternatives'
        """
        backends = self._get_backends()
        
        if not backends:
            return {'error': 'Aucun backend disponible', 'recommended': None}
        
        exclude = exclude or []
        
        # Analyser tous les backends
        analyses = []
        for backend in backends:
            if backend.name in exclude:
                continue
            analysis = self._analyze_backend(backend, circuit)
            if analysis.get('score', 0) > 0:
                analyses.append(analysis)
        
        if not analyses:
            return {'error': 'Aucun backend compatible', 'recommended': None}
        
        # Trier par score
        analyses.sort(key=lambda x: x.get('score', 0), reverse=True)
        
        # Meilleur backend
        best = analyses[0]
        
        # Construire les raisons
        reasons = best.get('advantages', [])
        if not reasons:
            reasons = [f"Score: {best['score']}/100"]
        
        # Alternatives
        alternatives = []
        for alt in analyses[1:top_n]:
            alt_info = {
                'backend': alt['name'],
                'score': alt['score'],
                'issue': alt['issues'][0] if alt.get('issues') else 'Score inferieur'
            }
            alternatives.append(alt_info)
        
        result = {
            'recommended': best['name'],
            'score': best['score'],
            'num_qubits': best['num_qubits'],
            'pending_jobs': best.get('pending_jobs', 0),
            'reasons': reasons,
            'issues': best.get('issues', []),
            'alternatives': alternatives,
            'all_analyses': analyses[:top_n]
        }
        
        self._log(f"Recommandation: {best['name']} (score: {best['score']}/100)")
        
        return result
    
    def compare_backends(self, backend_names: List[str], circuit=None) -> Dict:
        """Compare plusieurs backends spÃ©cifiques."""
        backends = self._get_backends()
        
        results = {}
        for name in backend_names:
            backend = self._backends_cache.get(name)
            if backend:
                results[name] = self._analyze_backend(backend, circuit)
            else:
                results[name] = {'error': 'Backend non trouve', 'score': 0}
        
        # Trouver le meilleur
        best_name = max(results.keys(), key=lambda k: results[k].get('score', 0))
        
        return {
            'comparison': results,
            'best': best_name,
            'best_score': results[best_name].get('score', 0)
        }
    
    def display_recommendation(self, result: Dict):
        """Affiche la recommandation de maniÃ¨re visuelle."""
        if result.get('error'):
            print(f"\n  [XX] {result['error']}\n")
            return
        
        W = 60
        print()
        print("  +" + "=" * W + "+")
        print("  |" + " RECOMMANDATION BACKEND ".center(W) + "|")
        print("  +" + "=" * W + "+")
        print("  |" + " " * W + "|")
        
        rec = result['recommended']
        score = result['score']
        qubits = result.get('num_qubits', '?')
        queue = result.get('pending_jobs', '?')
        
        print("  |  " + f"[>>] Backend: {rec}".ljust(W - 4) + "  |")
        print("  |  " + f"     Score: {score}/100  |  Qubits: {qubits}  |  Queue: {queue}".ljust(W - 4) + "  |")
        print("  |" + " " * W + "|")
        
        # Raisons
        if result.get('reasons'):
            print("  |  " + "[+] Avantages:".ljust(W - 4) + "  |")
            for reason in result['reasons'][:3]:
                print("  |  " + f"    - {reason}".ljust(W - 4) + "  |")
        
        # Issues
        if result.get('issues'):
            print("  |  " + "[-] Attention:".ljust(W - 4) + "  |")
            for issue in result['issues'][:2]:
                print("  |  " + f"    - {issue}".ljust(W - 4) + "  |")
        
        # Alternatives
        if result.get('alternatives'):
            print("  |" + " " * W + "|")
            print("  |  " + "Alternatives:".ljust(W - 4) + "  |")
            for alt in result['alternatives']:
                line = f"    {alt['backend']}: {alt['score']}/100 ({alt['issue']})"
                print("  |  " + line[:W-4].ljust(W - 4) + "  |")
        
        print("  |" + " " * W + "|")
        print("  +" + "=" * W + "+")
        print()


# =============================================================================
# RESULT CACHE - Cache local des rÃ©sultats QPU
# =============================================================================

class ResultCache:
    """
    Cache local des rÃ©sultats QPU pour Ã©viter de refaire les mÃªmes jobs.
    
    Usage:
        cache = ResultCache(cache_dir='.qmc_cache')
        
        # VÃ©rifier si en cache
        cached = cache.get(circuit_hash, shots)
        if cached:
            return cached
        
        # Sinon exÃ©cuter et sauvegarder
        results = run_on_qpu(...)
        cache.save(circuit_hash, shots, results, metadata)
    """
    
    def __init__(self, cache_dir: str = '.qmc_cache', max_size_mb: int = 500,
                 default_ttl_days: int = 30, logger: Logger = None):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.max_size_mb = max_size_mb
        self.default_ttl_days = default_ttl_days
        self.logger = logger
        self._index_file = self.cache_dir / '_index.json'
        self._index = self._load_index()
        self._stats = {'hits': 0, 'misses': 0, 'saves': 0}
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='CACHE')
    
    def _load_index(self) -> Dict:
        """Charge l'index du cache."""
        if self._index_file.exists():
            try:
                with open(self._index_file, 'r') as f:
                    return json.load(f)
            except:
                pass
        return {'entries': {}, 'stats': {'total_hits': 0, 'total_saves': 0, 'qpu_saved_s': 0}}
    
    def _save_index(self):
        """Sauvegarde l'index du cache."""
        try:
            with open(self._index_file, 'w') as f:
                json.dump(self._index, f, indent=2, default=str)
        except Exception as e:
            self._log(f"Erreur sauvegarde index: {e}", LogLevel.WARN)
    
    def _compute_hash(self, circuit, shots: int, backend: str = None, 
                      extra: Dict = None) -> str:
        """
        Calcule un hash unique pour identifier un rÃ©sultat.
        
        [v2.5.12] Fix: Utilise json.dumps(sort_keys=True) pour stabilitÃ©,
        et tente QPY serialization pour le circuit si disponible.
        """
        import hashlib
        
        # [v2.5.12] CrÃ©er une reprÃ©sentation STABLE du circuit
        circuit_repr = None
        
        # Option 1: QPY serialization (le plus stable)
        try:
            from qiskit import qpy
            import io
            buf = io.BytesIO()
            qpy.dump(circuit, buf)
            circuit_repr = buf.getvalue().hex()
        except Exception:
            pass
        
        # Option 2: QASM (assez stable)
        if circuit_repr is None and hasattr(circuit, 'qasm'):
            try:
                circuit_repr = circuit.qasm()
            except Exception:
                pass
        
        # Option 3: Fallback sur attributs stables
        if circuit_repr is None:
            try:
                circuit_repr = f"{circuit.num_qubits}q_{circuit.depth()}d_{circuit.size()}ops"
            except Exception:
                circuit_repr = str(id(circuit))  # Dernier recours
        
        # [v2.5.12] Combiner tous les paramÃ¨tres avec JSON stable
        key_parts = [
            circuit_repr,
            str(shots),
            str(backend or 'any'),
            json.dumps(extra or {}, sort_keys=True, default=str)  # [v2.5.12] Stable!
        ]
        key_string = '||'.join(key_parts)
        
        return hashlib.sha256(key_string.encode()).hexdigest()[:16]
    
    def get(self, circuit_or_hash, shots: int = None, backend: str = None) -> Optional[Dict]:
        """
        RÃ©cupÃ¨re un rÃ©sultat du cache.
        
        Args:
            circuit_or_hash: Circuit Qiskit ou hash direct
            shots: Nombre de shots
            backend: Nom du backend
        
        Returns:
            Dict avec les rÃ©sultats ou None si pas en cache
        """
        # Calculer ou utiliser le hash
        if isinstance(circuit_or_hash, str) and len(circuit_or_hash) == 16:
            cache_key = circuit_or_hash
        else:
            cache_key = self._compute_hash(circuit_or_hash, shots, backend)
        
        # VÃ©rifier l'index
        entry = self._index['entries'].get(cache_key)
        if not entry:
            self._stats['misses'] += 1
            return None
        
        # VÃ©rifier l'expiration
        from datetime import datetime
        created = datetime.fromisoformat(entry['created'])
        ttl_days = entry.get('ttl_days', self.default_ttl_days)
        if (datetime.now() - created).days > ttl_days:
            self._log(f"Cache expire: {cache_key}")
            self._stats['misses'] += 1
            return None
        
        # Charger le fichier
        cache_file = self.cache_dir / f"{cache_key}.json"
        if not cache_file.exists():
            self._stats['misses'] += 1
            return None
        
        try:
            with open(cache_file, 'r') as f:
                data = json.load(f)
            
            self._stats['hits'] += 1
            self._index['stats']['total_hits'] += 1
            self._save_index()
            
            self._log(f"Cache HIT: {cache_key} (QPU saved: {entry.get('qpu_time_s', 0):.1f}s)")
            
            return {
                'results': data.get('results'),
                'metadata': data.get('metadata'),
                'from_cache': True,
                'cache_key': cache_key,
                'original_job_id': entry.get('job_id'),
                'original_backend': entry.get('backend'),
                'qpu_time_saved': entry.get('qpu_time_s', 0)
            }
            
        except Exception as e:
            self._log(f"Erreur lecture cache: {e}", LogLevel.WARN)
            self._stats['misses'] += 1
            return None
    
    def save(self, circuit, shots: int, results: Any, 
             backend: str = None, job_id: str = None,
             qpu_time_s: float = 0, metadata: Dict = None,
             ttl_days: int = None) -> str:
        """
        Sauvegarde un rÃ©sultat dans le cache.
        
        Returns:
            cache_key: ClÃ© du cache
        """
        cache_key = self._compute_hash(circuit, shots, backend)
        
        # DonnÃ©es Ã  sauvegarder
        data = {
            'results': results,
            'metadata': metadata or {},
            'shots': shots,
            'backend': backend,
            'job_id': job_id,
        }
        
        # Sauvegarder le fichier
        cache_file = self.cache_dir / f"{cache_key}.json"
        try:
            with open(cache_file, 'w') as f:
                json.dump(data, f, indent=2, default=str)
        except Exception as e:
            self._log(f"Erreur sauvegarde cache: {e}", LogLevel.WARN)
            return None
        
        # Mettre Ã  jour l'index
        self._index['entries'][cache_key] = {
            'created': datetime.now().isoformat(),
            'shots': shots,
            'backend': backend,
            'job_id': job_id,
            'qpu_time_s': qpu_time_s,
            'ttl_days': ttl_days or self.default_ttl_days,
            'file_size': cache_file.stat().st_size
        }
        self._index['stats']['total_saves'] += 1
        self._index['stats']['qpu_saved_s'] += qpu_time_s
        self._save_index()
        
        self._stats['saves'] += 1
        self._log(f"Cache SAVE: {cache_key}")
        
        # Nettoyage si nÃ©cessaire
        self._cleanup_if_needed()
        
        return cache_key
    
    def _cleanup_if_needed(self):
        """Nettoie le cache si trop gros."""
        total_size = sum(
            entry.get('file_size', 0) 
            for entry in self._index['entries'].values()
        )
        
        if total_size > self.max_size_mb * 1024 * 1024:
            self._log("Cache plein, nettoyage des anciens...")
            self.clear(older_than_days=self.default_ttl_days // 2)
    
    def clear(self, older_than_days: int = None, all_cache: bool = False):
        """
        Nettoie le cache.
        
        Args:
            older_than_days: Supprime les entrÃ©es plus vieilles que X jours
            all_cache: Supprime tout le cache
        """
        if all_cache:
            for f in self.cache_dir.glob('*.json'):
                if f.name != '_index.json':
                    f.unlink()
            self._index['entries'] = {}
            self._save_index()
            self._log("Cache entierement vide")
            return
        
        if older_than_days:
            from datetime import datetime
            cutoff = datetime.now()
            removed = 0
            
            for key, entry in list(self._index['entries'].items()):
                created = datetime.fromisoformat(entry['created'])
                if (cutoff - created).days > older_than_days:
                    cache_file = self.cache_dir / f"{key}.json"
                    if cache_file.exists():
                        cache_file.unlink()
                    del self._index['entries'][key]
                    removed += 1
            
            self._save_index()
            self._log(f"Nettoyage: {removed} entrees supprimees")
    
    def stats(self) -> Dict:
        """Retourne les statistiques du cache."""
        entries = self._index['entries']
        total_size = sum(e.get('file_size', 0) for e in entries.values())
        qpu_saved = self._index['stats'].get('qpu_saved_s', 0)
        
        return {
            'entries': len(entries),
            'size_mb': round(total_size / 1024 / 1024, 2),
            'max_size_mb': self.max_size_mb,
            'session_hits': self._stats['hits'],
            'session_misses': self._stats['misses'],
            'session_saves': self._stats['saves'],
            'total_hits': self._index['stats'].get('total_hits', 0),
            'total_saves': self._index['stats'].get('total_saves', 0),
            'qpu_time_saved_s': qpu_saved,
            'qpu_time_saved_min': round(qpu_saved / 60, 2),
            'hit_rate': f"{self._stats['hits'] / max(1, self._stats['hits'] + self._stats['misses']) * 100:.1f}%"
        }
    
    def list(self, limit: int = 20) -> List[Dict]:
        """Liste les entrÃ©es du cache."""
        entries = []
        for key, entry in list(self._index['entries'].items())[:limit]:
            entries.append({
                'key': key,
                'backend': entry.get('backend'),
                'shots': entry.get('shots'),
                'created': entry.get('created'),
                'qpu_time_s': entry.get('qpu_time_s'),
                'job_id': entry.get('job_id')
            })
        return entries
    
    def display_stats(self):
        """Affiche les statistiques de maniÃ¨re visuelle."""
        stats = self.stats()
        
        W = 50
        print()
        print("  +" + "=" * W + "+")
        print("  |" + " CACHE STATISTICS ".center(W) + "|")
        print("  +" + "=" * W + "+")
        print("  |" + " " * W + "|")
        print("  |  " + f"Entrees:     {stats['entries']}".ljust(W - 4) + "  |")
        print("  |  " + f"Taille:      {stats['size_mb']} / {stats['max_size_mb']} MB".ljust(W - 4) + "  |")
        print("  |  " + f"Hit Rate:    {stats['hit_rate']}".ljust(W - 4) + "  |")
        print("  |" + " " * W + "|")
        print("  |  " + f"QPU Economise: {stats['qpu_time_saved_min']} min".ljust(W - 4) + "  |")
        print("  |" + " " * W + "|")
        print("  +" + "=" * W + "+")
        print()


# =============================================================================
# JOB QUEUE MANAGER - Gestion de file d'attente de jobs
# =============================================================================

class JobQueueManager:
    """
    Gestionnaire de file d'attente pour soumettre et gÃ©rer plusieurs jobs.
    
    Usage:
        queue = JobQueueManager(framework)
        queue.add(circuits1, shots=4096, name='exp1')
        queue.add(circuits2, shots=8192, name='exp2')
        queue.submit_all()
        results = queue.get_results(wait=True)
    """
    
    def __init__(self, framework=None, logger: Logger = None):
        self.framework = framework
        self.logger = logger
        self._queue: List[Dict] = []
        self._submitted: Dict[str, Dict] = {}  # job_id -> info
        self._results: Dict[str, Any] = {}  # job_id -> results
        self._queue_id = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='QUEUE')
    
    def add(self, circuits, shots: int = 4096, name: str = None,
            priority: int = 1, backend: str = None, metadata: Dict = None) -> str:
        """
        Ajoute des circuits Ã  la queue.
        
        Args:
            circuits: Circuit(s) Ã  exÃ©cuter
            shots: Nombre de shots
            name: Nom de l'expÃ©rience
            priority: PrioritÃ© (1=haute, 5=basse)
            backend: Backend spÃ©cifique (optionnel)
            metadata: MÃ©tadonnÃ©es additionnelles
        
        Returns:
            queue_item_id: Identifiant dans la queue
        """
        if not isinstance(circuits, list):
            circuits = [circuits]
        
        item_id = f"q_{len(self._queue):03d}_{name or 'exp'}"
        
        item = {
            'id': item_id,
            'circuits': circuits,
            'shots': shots,
            'name': name or f"experiment_{len(self._queue)}",
            'priority': priority,
            'backend': backend,
            'metadata': metadata or {},
            'status': 'pending',
            'added_at': datetime.now().isoformat()
        }
        
        self._queue.append(item)
        self._log(f"Added: {item_id} ({len(circuits)} circuits, {shots} shots)")
        
        return item_id
    
    def remove(self, item_id: str) -> bool:
        """Supprime un item de la queue."""
        for i, item in enumerate(self._queue):
            if item['id'] == item_id and item['status'] == 'pending':
                del self._queue[i]
                self._log(f"Removed: {item_id}")
                return True
        return False
    
    def clear(self):
        """Vide la queue (items non soumis uniquement)."""
        self._queue = [item for item in self._queue if item['status'] != 'pending']
        self._log("Queue cleared")
    
    def status(self) -> Dict:
        """Retourne le statut de la queue."""
        pending = len([i for i in self._queue if i['status'] == 'pending'])
        submitted = len([i for i in self._queue if i['status'] == 'submitted'])
        completed = len([i for i in self._queue if i['status'] == 'completed'])
        failed = len([i for i in self._queue if i['status'] == 'failed'])
        
        return {
            'total': len(self._queue),
            'pending': pending,
            'submitted': submitted,
            'completed': completed,
            'failed': failed,
            'results_ready': len(self._results)
        }
    
    def submit_next(self) -> Optional[str]:
        """
        Soumet le prochain item de la queue.
        
        [v2.5.12] Fix: Utilise le backend spÃ©cifiÃ© pour chaque item.
        """
        if not self.framework:
            self._log("Framework non configure!", LogLevel.ERROR)
            return None
        
        # Trouver le prochain item pending (par prioritÃ©)
        pending_items = [i for i in self._queue if i['status'] == 'pending']
        if not pending_items:
            return None
        
        pending_items.sort(key=lambda x: x['priority'])
        item = pending_items[0]
        
        try:
            # [v2.5.12] GÃ©rer le backend spÃ©cifiÃ©
            item_backend = item.get('backend')
            current_backend = getattr(self.framework, 'backend_name', None)
            backend_switched = False
            original_backend = current_backend
            
            if item_backend and item_backend != current_backend:
                # Tenter de changer de backend si le framework le supporte
                if hasattr(self.framework, 'connect'):
                    self._log(f"Switching backend: {current_backend} -> {item_backend}")
                    try:
                        self.framework.connect(backend_name=item_backend)
                        backend_switched = True
                    except Exception as e:
                        self._log(f"Cannot switch to backend {item_backend}: {e}", LogLevel.WARN)
                        self._log(f"Using current backend: {current_backend}", LogLevel.WARN)
                else:
                    self._log(f"Backend {item_backend} requested but framework doesn't support switching", 
                             LogLevel.WARN)
            
            # Soumettre au framework
            self._log(f"Submitting: {item['id']} on {self.framework.backend_name if hasattr(self.framework, 'backend_name') else 'unknown'}")
            item['status'] = 'submitted'
            item['submitted_at'] = datetime.now().isoformat()
            item['actual_backend'] = getattr(self.framework, 'backend_name', None)  # [v2.5.12]
            
            # Utiliser le framework pour soumettre
            if hasattr(self.framework, 'submit_job'):
                job = self.framework.submit_job(item['circuits'], item['shots'])
                job_id = job.job_id() if hasattr(job, 'job_id') else str(job)
            else:
                # Fallback: exÃ©cution directe
                results = self.framework.run_on_qpu(item['circuits'], item['shots'])
                job_id = f"direct_{item['id']}"
                item['status'] = 'completed'
                self._results[item['id']] = results
            
            item['job_id'] = job_id
            self._submitted[job_id] = item
            
            # [v2.5.12] Restaurer le backend original si on a switchÃ©
            if backend_switched and original_backend:
                try:
                    self.framework.connect(backend_name=original_backend)
                except Exception:
                    pass  # Best effort
            
            return job_id
            
        except Exception as e:
            self._log(f"Submit failed: {e}", LogLevel.ERROR)
            item['status'] = 'failed'
            item['error'] = str(e)
            return None
    
    def submit_all(self, max_concurrent: int = 3, wait: bool = False) -> List[str]:
        """
        Soumet tous les items de la queue.
        
        Args:
            max_concurrent: Nombre max de jobs en parallÃ¨le
            wait: Attendre la fin de tous les jobs
        
        Returns:
            Liste des job_ids soumis
        """
        job_ids = []
        
        while True:
            # Compter les jobs en cours
            running = len([i for i in self._queue if i['status'] == 'submitted'])
            
            if running >= max_concurrent:
                if wait:
                    time.sleep(5)
                    self._update_statuses()
                    continue
                else:
                    break
            
            # Soumettre le suivant
            job_id = self.submit_next()
            if job_id:
                job_ids.append(job_id)
            else:
                break
        
        if wait:
            self.wait_all()
        
        return job_ids
    
    def _update_statuses(self):
        """Met Ã  jour les statuts des jobs soumis."""
        if not self.framework or not hasattr(self.framework, 'service'):
            return
        
        for item in self._queue:
            if item['status'] == 'submitted' and 'job_id' in item:
                try:
                    job = self.framework.service.job(item['job_id'])
                    status = str(job.status())
                    
                    if status == 'DONE':
                        item['status'] = 'completed'
                        self._results[item['id']] = job.result()
                        
                        # [v2.5.14] Auto-delete si activÃ© dans le framework
                        if getattr(self.framework, 'auto_delete_job', False):
                            try:
                                self.framework._secure_delete_job(job, item['job_id'])
                            except Exception as e:
                                self._log(f"Auto-delete failed for {item['job_id']}: {e}", LogLevel.WARN)
                        
                    elif status in ['ERROR', 'CANCELLED']:
                        item['status'] = 'failed'
                except:
                    pass
    
    def wait_all(self, timeout: float = None) -> bool:
        """Attend que tous les jobs soient terminÃ©s."""
        start = time.time()
        
        while True:
            self._update_statuses()
            
            status = self.status()
            if status['submitted'] == 0:
                return True
            
            if timeout and (time.time() - start) > timeout:
                self._log("Timeout waiting for jobs", LogLevel.WARN)
                return False
            
            time.sleep(5)
    
    def get_results(self, item_id: str = None, wait: bool = False) -> Any:
        """
        RÃ©cupÃ¨re les rÃ©sultats.
        
        Args:
            item_id: ID spÃ©cifique ou None pour tous
            wait: Attendre si pas encore prÃªt
        """
        if wait:
            self.wait_all()
        
        if item_id:
            return self._results.get(item_id)
        
        return dict(self._results)
    
    def display_status(self):
        """Affiche le statut de la queue."""
        status = self.status()
        
        W = 55
        print()
        print("  +" + "=" * W + "+")
        print("  |" + " JOB QUEUE STATUS ".center(W) + "|")
        print("  +" + "=" * W + "+")
        print("  |" + " " * W + "|")
        print("  |  " + f"Total:     {status['total']:>4}".ljust(W - 4) + "  |")
        print("  |  " + f"Pending:   {status['pending']:>4}".ljust(W - 4) + "  |")
        print("  |  " + f"Submitted: {status['submitted']:>4}".ljust(W - 4) + "  |")
        print("  |  " + f"Completed: {status['completed']:>4}".ljust(W - 4) + "  |")
        print("  |  " + f"Failed:    {status['failed']:>4}".ljust(W - 4) + "  |")
        print("  |" + " " * W + "|")
        
        # DÃ©tail des items
        if self._queue:
            print("  |  " + "-" * (W - 4) + "  |")
            for item in self._queue[:10]:
                status_icon = {
                    'pending': '[..]',
                    'submitted': '[>>]',
                    'completed': '[OK]',
                    'failed': '[XX]'
                }.get(item['status'], '[??]')
                line = f"{status_icon} {item['name'][:20]:<20} {item['shots']} shots"
                print("  |  " + line.ljust(W - 4) + "  |")
        
        print("  |" + " " * W + "|")
        print("  +" + "=" * W + "+")
        print()


# =============================================================================
# NOTIFICATION MANAGER - SystÃ¨me de notifications
# =============================================================================

class NotificationManager:
    """
    Gestionnaire de notifications (Email, Slack, Discord, Webhook).
    
    Usage:
        notifier = NotificationManager()
        notifier.configure(
            email='user@example.com',
            slack_webhook='https://hooks.slack.com/...'
        )
        notifier.send('job_complete', {'job_id': 'xxx', 'status': 'DONE'})
    """
    
    def __init__(self, logger: Logger = None):
        self.logger = logger
        self._config = {
            'email': None,
            'smtp_server': 'smtp.gmail.com',
            'smtp_port': 587,
            'smtp_user': None,
            'smtp_password': None,
            'slack_webhook': None,
            'discord_webhook': None,
            'custom_webhook': None,
            'notify_on': ['job_complete', 'job_failed', 'queue_empty']
        }
        self._enabled = False
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='NOTIFY')
    
    def configure(self, **kwargs):
        """
        Configure les notifications.
        
        Args:
            email: Adresse email destinataire
            smtp_server: Serveur SMTP
            smtp_port: Port SMTP
            smtp_user: Utilisateur SMTP
            smtp_password: Mot de passe SMTP
            slack_webhook: URL webhook Slack
            discord_webhook: URL webhook Discord
            custom_webhook: URL webhook personnalisÃ©
            notify_on: Liste des Ã©vÃ©nements ['job_complete', 'job_failed', 'queue_empty']
        """
        for key, value in kwargs.items():
            if key in self._config:
                self._config[key] = value
        
        # Activer si au moins un canal configurÃ©
        self._enabled = any([
            self._config['email'] and self._config['smtp_user'],
            self._config['slack_webhook'],
            self._config['discord_webhook'],
            self._config['custom_webhook']
        ])
        
        if self._enabled:
            self._log("Notifications configurees")
        else:
            self._log("Aucun canal de notification configure", LogLevel.WARN)
    
    def is_enabled(self) -> bool:
        return self._enabled
    
    def should_notify(self, event_type: str) -> bool:
        """VÃ©rifie si on doit notifier pour cet Ã©vÃ©nement."""
        return event_type in self._config.get('notify_on', [])
    
    def send(self, event_type: str, data: Dict) -> bool:
        """
        Envoie une notification.
        
        Args:
            event_type: Type d'Ã©vÃ©nement ('job_complete', 'job_failed', etc.)
            data: DonnÃ©es de l'Ã©vÃ©nement
        
        Returns:
            True si envoyÃ© avec succÃ¨s
        """
        if not self._enabled:
            return False
        
        if not self.should_notify(event_type):
            return False
        
        # Construire le message
        message = self._format_message(event_type, data)
        
        success = False
        
        # Envoyer sur tous les canaux configurÃ©s
        if self._config['slack_webhook']:
            success |= self._send_slack(message)
        
        if self._config['discord_webhook']:
            success |= self._send_discord(message)
        
        if self._config['custom_webhook']:
            success |= self._send_webhook(message, data)
        
        if self._config['email'] and self._config['smtp_user']:
            success |= self._send_email(event_type, message)
        
        return success
    
    def _format_message(self, event_type: str, data: Dict) -> str:
        """Formate le message de notification."""
        templates = {
            'job_complete': (
                "[OK] QMC Job Complete\n"
                "Job ID: {job_id}\n"
                "Status: {status}\n"
                "Backend: {backend}\n"
                "QPU Time: {qpu_time:.1f}s"
            ),
            'job_failed': (
                "[XX] QMC Job Failed\n"
                "Job ID: {job_id}\n"
                "Error: {error}\n"
                "Backend: {backend}"
            ),
            'queue_empty': (
                "[OK] QMC Queue Complete\n"
                "All jobs finished\n"
                "Total: {total}\n"
                "Completed: {completed}\n"
                "Failed: {failed}"
            ),
            'long_queue': (
                "[!!] QMC Long Queue Warning\n"
                "Backend: {backend}\n"
                "Queue length: {queue_length} jobs\n"
                "Estimated wait: {wait_time}"
            )
        }
        
        template = templates.get(event_type, "QMC Notification: {event_type}\n{data}")
        
        try:
            # Ajouter event_type et data au contexte
            context = {'event_type': event_type, 'data': str(data)}
            context.update(data)
            return template.format(**context)
        except:
            return f"QMC {event_type}: {data}"
    
    def _send_slack(self, message: str) -> bool:
        """Envoie via Slack webhook."""
        try:
            import urllib.request
            
            payload = json.dumps({'text': message}).encode()
            req = urllib.request.Request(
                self._config['slack_webhook'],
                data=payload,
                headers={'Content-Type': 'application/json'}
            )
            
            with urllib.request.urlopen(req, timeout=10) as resp:
                if resp.status == 200:
                    self._log("Slack notification sent")
                    return True
        except Exception as e:
            self._log(f"Slack error: {e}", LogLevel.WARN)
        return False
    
    def _send_discord(self, message: str) -> bool:
        """Envoie via Discord webhook."""
        try:
            import urllib.request
            
            payload = json.dumps({'content': message}).encode()
            req = urllib.request.Request(
                self._config['discord_webhook'],
                data=payload,
                headers={'Content-Type': 'application/json'}
            )
            
            with urllib.request.urlopen(req, timeout=10) as resp:
                if resp.status in [200, 204]:
                    self._log("Discord notification sent")
                    return True
        except Exception as e:
            self._log(f"Discord error: {e}", LogLevel.WARN)
        return False
    
    def _send_webhook(self, message: str, data: Dict) -> bool:
        """Envoie via webhook personnalisÃ©."""
        try:
            import urllib.request
            
            payload = json.dumps({
                'message': message,
                'data': data,
                'timestamp': datetime.now().isoformat()
            }).encode()
            
            req = urllib.request.Request(
                self._config['custom_webhook'],
                data=payload,
                headers={'Content-Type': 'application/json'}
            )
            
            with urllib.request.urlopen(req, timeout=10) as resp:
                if resp.status in [200, 201, 204]:
                    self._log("Webhook notification sent")
                    return True
        except Exception as e:
            self._log(f"Webhook error: {e}", LogLevel.WARN)
        return False
    
    def _send_email(self, subject: str, message: str) -> bool:
        """Envoie par email."""
        try:
            import smtplib
            from email.mime.text import MIMEText
            from email.mime.multipart import MIMEMultipart
            
            msg = MIMEMultipart()
            msg['From'] = self._config['smtp_user']
            msg['To'] = self._config['email']
            msg['Subject'] = f"QMC Notification: {subject}"
            
            msg.attach(MIMEText(message, 'plain'))
            
            server = smtplib.SMTP(
                self._config['smtp_server'],
                self._config['smtp_port']
            )
            server.starttls()
            server.login(
                self._config['smtp_user'],
                self._config['smtp_password']
            )
            server.send_message(msg)
            server.quit()
            
            self._log("Email notification sent")
            return True
            
        except Exception as e:
            self._log(f"Email error: {e}", LogLevel.WARN)
        return False
    
    def notify_job_complete(self, job_id: str, status: str, 
                           backend: str = None, qpu_time: float = 0):
        """Raccourci pour notifier la fin d'un job."""
        self.send('job_complete', {
            'job_id': job_id,
            'status': status,
            'backend': backend or 'unknown',
            'qpu_time': qpu_time
        })
    
    def notify_job_failed(self, job_id: str, error: str, backend: str = None):
        """Raccourci pour notifier l'Ã©chec d'un job."""
        self.send('job_failed', {
            'job_id': job_id,
            'error': error,
            'backend': backend or 'unknown'
        })
    
    def test(self) -> bool:
        """Envoie une notification de test."""
        return self.send('job_complete', {
            'job_id': 'TEST_123',
            'status': 'DONE',
            'backend': 'test_backend',
            'qpu_time': 0.0
        })


# =============================================================================
# CIRCUIT COST ESTIMATOR - Estimation du coÃ»t avant exÃ©cution
# =============================================================================

class CircuitCostEstimator:
    """
    Estime le temps QPU et le coÃ»t avant soumission.
    
    Usage:
        estimator = CircuitCostEstimator(framework)
        estimate = estimator.estimate(circuits, shots=4096)
        estimator.display_estimate(estimate)
    """
    
    # Coefficients empiriques (basÃ©s sur IBM Heron)
    COEF_BASE_TIME = 0.5  # secondes par circuit
    COEF_SHOT = 0.00002   # secondes par shot
    COEF_DEPTH = 0.001    # secondes par niveau de profondeur
    COEF_2Q_GATE = 0.0005 # secondes par porte 2Q
    COEF_QUBIT = 0.002    # secondes par qubit utilisÃ©
    
    def __init__(self, framework=None, logger: Logger = None):
        self.framework = framework
        self.logger = logger
        self._history = []  # Historique pour calibrer les estimations
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='ESTIMATE')
    
    def _analyze_circuit(self, circuit) -> Dict:
        """Analyse un circuit pour extraire ses caractÃ©ristiques."""
        try:
            num_qubits = circuit.num_qubits
            depth = circuit.depth()
            
            # Compter les portes 2Q
            two_q_gates = 0
            total_gates = 0
            
            for instruction in circuit.data:
                total_gates += 1
                if len(instruction.qubits) >= 2:
                    two_q_gates += 1
            
            return {
                'num_qubits': num_qubits,
                'depth': depth,
                'two_q_gates': two_q_gates,
                'total_gates': total_gates
            }
        except Exception as e:
            return {
                'num_qubits': 0,
                'depth': 0,
                'two_q_gates': 0,
                'total_gates': 0,
                'error': str(e)
            }
    
    def estimate(self, circuits, shots: int = 4096, 
                 backend: str = None) -> Dict:
        """
        Estime le temps et le coÃ»t d'exÃ©cution.
        
        Args:
            circuits: Circuit(s) Ã  estimer
            shots: Nombre de shots
            backend: Backend cible (optionnel)
        
        Returns:
            Dict avec estimations dÃ©taillÃ©es
        """
        if not isinstance(circuits, list):
            circuits = [circuits]
        
        # Analyser chaque circuit
        analyses = []
        total_depth = 0
        total_2q = 0
        total_qubits = 0
        
        for circuit in circuits:
            analysis = self._analyze_circuit(circuit)
            analyses.append(analysis)
            total_depth += analysis.get('depth', 0)
            total_2q += analysis.get('two_q_gates', 0)
            total_qubits = max(total_qubits, analysis.get('num_qubits', 0))
        
        n_circuits = len(circuits)
        total_shots = n_circuits * shots
        
        # Estimation du temps QPU
        base_time = n_circuits * self.COEF_BASE_TIME
        shot_time = total_shots * self.COEF_SHOT
        depth_time = total_depth * self.COEF_DEPTH
        gate_time = total_2q * self.COEF_2Q_GATE
        qubit_time = total_qubits * self.COEF_QUBIT * n_circuits
        
        estimated_time = base_time + shot_time + depth_time + gate_time + qubit_time
        
        # Marges d'erreur
        time_min = estimated_time * 0.7
        time_max = estimated_time * 1.5
        
        # Estimation du temps de queue
        queue_estimates = {}
        if self.framework and hasattr(self.framework, 'service'):
            try:
                for b in self.framework.service.backends():
                    try:
                        status = b.status()
                        pending = status.pending_jobs if hasattr(status, 'pending_jobs') else 0
                        # Estimation: 2min par job en queue
                        wait_min = pending * 2
                        queue_estimates[b.name] = {
                            'pending_jobs': pending,
                            'estimated_wait_min': wait_min,
                            'estimated_wait_str': f"~{wait_min}min" if wait_min < 60 else f"~{wait_min//60}h{wait_min%60}min"
                        }
                    except:
                        pass
            except:
                pass
        
        # Impact sur le budget mensuel
        budget_impact = {}
        if self.framework:
            try:
                current_usage = self.framework.get_monthly_usage(days=30, animate=False)
                current_used = current_usage.get('total_time_s', 0) / 60  # en minutes
                
                # Budget mensuel typique: 10 min
                monthly_budget = 10.0
                after_job = current_used + (estimated_time / 60)
                remaining = monthly_budget - after_job
                
                budget_impact = {
                    'current_used_min': round(current_used, 2),
                    'estimated_job_min': round(estimated_time / 60, 2),
                    'after_job_min': round(after_job, 2),
                    'remaining_min': round(max(0, remaining), 2),
                    'monthly_budget_min': monthly_budget,
                    'within_budget': remaining > 0
                }
            except:
                pass
        
        result = {
            'circuits': n_circuits,
            'total_shots': total_shots,
            'max_qubits': total_qubits,
            'total_depth': total_depth,
            'total_2q_gates': total_2q,
            'circuit_analyses': analyses,
            'estimated_qpu_time': {
                'expected_s': round(estimated_time, 2),
                'min_s': round(time_min, 2),
                'max_s': round(time_max, 2),
                'expected_str': f"{estimated_time:.1f}s" if estimated_time < 60 else f"{estimated_time/60:.1f}min"
            },
            'queue_estimates': queue_estimates,
            'budget_impact': budget_impact,
            'recommendation': self._get_recommendation(estimated_time, budget_impact)
        }
        
        return result
    
    def _get_recommendation(self, estimated_time: float, budget: Dict) -> str:
        """GÃ©nÃ¨re une recommandation basÃ©e sur l'estimation."""
        if budget.get('within_budget') == False:
            return "[!!] ATTENTION: Depasse le budget mensuel!"
        
        if estimated_time > 300:  # > 5 min
            return "[!!] Job long (>5min) - Verifiez les parametres"
        
        if estimated_time > 60:
            return "[OK] Job moyen - Execution recommandee"
        
        return "[OK] Job court - OK pour execution"
    
    def display_estimate(self, estimate: Dict, confirm: bool = False) -> bool:
        """
        Affiche l'estimation de maniÃ¨re visuelle.
        
        Args:
            estimate: RÃ©sultat de estimate()
            confirm: Demander confirmation avant de continuer
        
        Returns:
            True si confirmÃ© ou pas de confirmation demandÃ©e
        """
        W = 62
        print()
        print("  +" + "=" * W + "+")
        print("  |" + " ESTIMATION COUT QPU ".center(W) + "|")
        print("  +" + "=" * W + "+")
        print("  |" + " " * W + "|")
        
        # Circuits
        print("  |  " + "CIRCUITS".ljust(W - 4) + "  |")
        print("  |  " + "-" * (W - 4) + "  |")
        print("  |  " + f"Nombre:        {estimate['circuits']}".ljust(W - 4) + "  |")
        print("  |  " + f"Total shots:   {estimate['total_shots']:,}".ljust(W - 4) + "  |")
        print("  |  " + f"Max qubits:    {estimate['max_qubits']}".ljust(W - 4) + "  |")
        print("  |  " + f"Profondeur:    {estimate['total_depth']}".ljust(W - 4) + "  |")
        print("  |  " + f"Portes 2Q:     {estimate['total_2q_gates']}".ljust(W - 4) + "  |")
        print("  |" + " " * W + "|")
        
        # Temps estimÃ©
        qpu = estimate['estimated_qpu_time']
        print("  |  " + "TEMPS QPU ESTIME".ljust(W - 4) + "  |")
        print("  |  " + "-" * (W - 4) + "  |")
        print("  |  " + f"Attendu:       {qpu['expected_str']}".ljust(W - 4) + "  |")
        print("  |  " + f"Fourchette:    {qpu['min_s']:.1f}s - {qpu['max_s']:.1f}s".ljust(W - 4) + "  |")
        print("  |" + " " * W + "|")
        
        # Queue
        if estimate.get('queue_estimates'):
            print("  |  " + "TEMPS D'ATTENTE ESTIME".ljust(W - 4) + "  |")
            print("  |  " + "-" * (W - 4) + "  |")
            for backend, info in list(estimate['queue_estimates'].items())[:3]:
                line = f"{backend}: {info['estimated_wait_str']} ({info['pending_jobs']} jobs)"
                print("  |  " + f"  {line}".ljust(W - 4) + "  |")
            print("  |" + " " * W + "|")
        
        # Budget
        if estimate.get('budget_impact'):
            budget = estimate['budget_impact']
            print("  |  " + "IMPACT BUDGET MENSUEL".ljust(W - 4) + "  |")
            print("  |  " + "-" * (W - 4) + "  |")
            print("  |  " + f"Utilise:       {budget['current_used_min']:.1f} min".ljust(W - 4) + "  |")
            print("  |  " + f"Ce job:       +{budget['estimated_job_min']:.1f} min".ljust(W - 4) + "  |")
            print("  |  " + f"Apres:         {budget['after_job_min']:.1f} / {budget['monthly_budget_min']} min".ljust(W - 4) + "  |")
            print("  |  " + f"Restant:       {budget['remaining_min']:.1f} min".ljust(W - 4) + "  |")
            print("  |" + " " * W + "|")
        
        # Recommandation
        print("  |  " + estimate.get('recommendation', '').ljust(W - 4) + "  |")
        print("  |" + " " * W + "|")
        print("  +" + "=" * W + "+")
        print()
        
        if confirm:
            response = input("  Confirmer l'execution? (y/n): ").strip().lower()
            return response in ['y', 'yes', 'o', 'oui']
        
        return True
    
    def calibrate(self, actual_time: float, estimated_time: float):
        """
        Calibre les coefficients basÃ© sur les rÃ©sultats rÃ©els.
        
        Args:
            actual_time: Temps rÃ©el mesurÃ©
            estimated_time: Temps estimÃ©
        """
        self._history.append({
            'actual': actual_time,
            'estimated': estimated_time,
            'ratio': actual_time / estimated_time if estimated_time > 0 else 1
        })
        
        # Ajuster les coefficients si assez d'historique
        if len(self._history) >= 10:
            avg_ratio = sum(h['ratio'] for h in self._history[-10:]) / 10
            
            # Ajuster tous les coefficients
            if avg_ratio > 1.1:  # Sous-estimation
                self.COEF_BASE_TIME *= avg_ratio
                self.COEF_SHOT *= avg_ratio
                self.COEF_DEPTH *= avg_ratio
                self._log(f"Coefficients ajustes (x{avg_ratio:.2f})")
            elif avg_ratio < 0.9:  # Sur-estimation
                self.COEF_BASE_TIME *= avg_ratio
                self.COEF_SHOT *= avg_ratio
                self.COEF_DEPTH *= avg_ratio
                self._log(f"Coefficients ajustes (x{avg_ratio:.2f})")


# =============================================================================
# v2.5.16 - BATCH MANAGER INTELLIGENT
# =============================================================================

class BatchManager:
    """
    [v2.5.16] Gestionnaire intelligent de batches pour gros jobs.
    
    DÃ©coupe automatiquement les gros jobs en batches optimaux,
    gÃ¨re les erreurs par batch, et permet la reprise automatique.
    
    Usage:
        batch_mgr = BatchManager(framework, max_circuits_per_batch=30)
        results = batch_mgr.submit_all(circuits, shots=4096)
        
        # Ou avec callback de progression
        results = batch_mgr.submit_all(circuits, shots=4096, 
                                       on_batch_complete=lambda i, r: print(f"Batch {i} done"))
    """
    
    def __init__(self, framework: 'QMCFramework', 
                 max_circuits_per_batch: int = 30,
                 max_shots_per_batch: int = 100000,
                 retry_failed_batches: bool = True,
                 save_intermediate: bool = True,
                 logger: Logger = None):
        """
        Args:
            framework: Instance QMCFramework connectÃ©e
            max_circuits_per_batch: Max circuits par batch (dÃ©faut: 30)
            max_shots_per_batch: Max shots totaux par batch (dÃ©faut: 100k)
            retry_failed_batches: RÃ©essayer les batches en erreur (dÃ©faut: True)
            save_intermediate: Sauvegarder les rÃ©sultats intermÃ©diaires (dÃ©faut: True)
            logger: Logger pour les messages
        """
        self.framework = framework
        self.max_circuits = max_circuits_per_batch
        self.max_shots = max_shots_per_batch
        self.retry_failed = retry_failed_batches
        self.save_intermediate = save_intermediate
        self.logger = logger or (framework.logger if framework else None)
        
        # Ã‰tat
        self._batches: List[Dict] = []
        self._results: List[Dict] = []
        self._failed_batches: List[int] = []
        self._checkpoint_file: Optional[Path] = None
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='BATCH')
        else:
            print(f"[BATCH] {msg}")
    
    def calculate_optimal_batch_size(self, circuits: List, shots: int) -> int:
        """
        Calcule la taille optimale de batch selon les circuits et shots.
        
        Returns:
            Nombre optimal de circuits par batch
        """
        # Contrainte 1: Max circuits
        max_by_circuits = self.max_circuits
        
        # Contrainte 2: Max shots totaux
        max_by_shots = self.max_shots // shots if shots > 0 else self.max_circuits
        
        # Contrainte 3: ComplexitÃ© des circuits (profondeur moyenne)
        avg_depth = sum(c.depth() for c in circuits) / len(circuits) if circuits else 10
        
        # Si circuits trÃ¨s profonds, rÃ©duire la taille du batch
        if avg_depth > 100:
            depth_factor = 0.5
        elif avg_depth > 50:
            depth_factor = 0.75
        else:
            depth_factor = 1.0
        
        optimal = int(min(max_by_circuits, max_by_shots) * depth_factor)
        return max(1, optimal)  # Au moins 1
    
    def split_into_batches(self, circuits: List, shots: int) -> List[List]:
        """
        DÃ©coupe une liste de circuits en batches optimaux.
        
        Returns:
            Liste de batches (chaque batch est une liste de circuits)
        """
        batch_size = self.calculate_optimal_batch_size(circuits, shots)
        
        batches = []
        for i in range(0, len(circuits), batch_size):
            batches.append(circuits[i:i + batch_size])
        
        self._log(f"DÃ©coupage: {len(circuits)} circuits â†’ {len(batches)} batches de ~{batch_size} circuits")
        
        return batches
    
    def submit_all(self, circuits: List, shots: int = 4096,
                   on_batch_complete: Callable = None,
                   on_batch_error: Callable = None,
                   **kwargs) -> Dict[str, Any]:
        """
        Soumet tous les circuits en batches avec gestion d'erreurs.
        
        Args:
            circuits: Liste de circuits Ã  exÃ©cuter
            shots: Nombre de shots par circuit
            on_batch_complete: Callback(batch_index, results) appelÃ© aprÃ¨s chaque batch
            on_batch_error: Callback(batch_index, error) appelÃ© si erreur
            **kwargs: Arguments additionnels pour run_on_qpu
            
        Returns:
            Dict avec tous les rÃ©sultats consolidÃ©s
        """
        if not circuits:
            return {'status': 'empty', 'results': [], 'batches': 0}
        
        batches = self.split_into_batches(circuits, shots)
        n_batches = len(batches)
        
        all_results = []
        batch_info = []
        failed_indices = []
        
        # Afficher le plan
        print()
        print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("  â•‘  ğŸ“¦ BATCH MANAGER - EXÃ‰CUTION PAR LOTS                                     â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  ğŸ“Š Total circuits:  {len(circuits):<52} â•‘")
        print(f"  â•‘  ğŸ“¦ Nombre de batches: {n_batches:<51} â•‘")
        print(f"  â•‘  ğŸ¯ Circuits/batch:   ~{len(batches[0]) if batches else 0:<50} â•‘")
        print(f"  â•‘  ğŸ”« Shots/circuit:    {shots:<52} â•‘")
        print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
        
        start_time = time.time()
        
        for i, batch in enumerate(batches):
            batch_start = time.time()
            
            print(f"  â”Œâ”€ Batch {i+1}/{n_batches} ({len(batch)} circuits) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            
            try:
                # Soumettre le batch
                results = self.framework.run_on_qpu(batch, shots=shots, **kwargs)
                
                if results:
                    all_results.extend(results)
                    batch_info.append({
                        'index': i,
                        'circuits': len(batch),
                        'status': 'success',
                        'duration_s': time.time() - batch_start
                    })
                    
                    print(f"  â””â”€ âœ… Batch {i+1} terminÃ© ({time.time() - batch_start:.1f}s)")
                    
                    if on_batch_complete:
                        on_batch_complete(i, results)
                    
                    # Sauvegarder checkpoint intermÃ©diaire
                    if self.save_intermediate:
                        self._save_checkpoint(i, all_results, batch_info)
                else:
                    raise Exception("RÃ©sultats vides")
                    
            except Exception as e:
                failed_indices.append(i)
                batch_info.append({
                    'index': i,
                    'circuits': len(batch),
                    'status': 'error',
                    'error': str(e),
                    'duration_s': time.time() - batch_start
                })
                
                print(f"  â””â”€ âŒ Batch {i+1} ERREUR: {str(e)[:50]}")
                self._log(f"Batch {i+1} failed: {e}", LogLevel.ERROR)
                
                if on_batch_error:
                    on_batch_error(i, e)
        
        # Retry des batches en erreur si demandÃ©
        if self.retry_failed and failed_indices:
            print()
            print(f"  â³ Retry des {len(failed_indices)} batches en erreur...")
            
            for idx in failed_indices[:]:  # Copie pour modifier pendant itÃ©ration
                batch = batches[idx]
                try:
                    results = self.framework.run_on_qpu(batch, shots=shots, **kwargs)
                    if results:
                        all_results.extend(results)
                        batch_info[idx]['status'] = 'success_retry'
                        failed_indices.remove(idx)
                        print(f"  âœ… Batch {idx+1} rÃ©cupÃ©rÃ© au retry")
                except Exception as e:
                    print(f"  âŒ Batch {idx+1} Ã©chec dÃ©finitif: {e}")
        
        total_time = time.time() - start_time
        
        # RÃ©sumÃ© final
        success_count = sum(1 for b in batch_info if 'success' in b['status'])
        
        print()
        print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("  â•‘  ğŸ“Š RÃ‰SUMÃ‰ BATCH MANAGER                                                   â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  âœ… Batches rÃ©ussis:  {success_count}/{n_batches:<47} â•‘")
        print(f"  â•‘  âŒ Batches Ã©chouÃ©s:  {len(failed_indices):<52} â•‘")
        print(f"  â•‘  ğŸ“ˆ RÃ©sultats totaux: {len(all_results):<52} â•‘")
        print(f"  â•‘  â±ï¸  Temps total:     {total_time:.1f}s                                            â•‘")
        print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        return {
            'status': 'complete' if not failed_indices else 'partial',
            'results': all_results,
            'batches': batch_info,
            'total_circuits': len(circuits),
            'successful_circuits': len(all_results),
            'failed_batches': failed_indices,
            'total_time_s': total_time
        }
    
    def _save_checkpoint(self, batch_index: int, results: List, batch_info: List):
        """Sauvegarde un checkpoint intermÃ©diaire."""
        if not self.framework or not hasattr(self.framework, 'dir_manager'):
            return
        
        try:
            checkpoint = {
                'batch_index': batch_index,
                'results_count': len(results),
                'batch_info': batch_info,
                'timestamp': datetime.now().isoformat()
            }
            
            self._checkpoint_file = self.framework.dir_manager.get_file(
                f'batch_checkpoint_{batch_index}.json'
            )
            
            with open(self._checkpoint_file, 'w') as f:
                json.dump(checkpoint, f, indent=2, default=str)
                
        except Exception as e:
            self._log(f"Checkpoint save failed: {e}", LogLevel.WARN)
    
    def resume_from_checkpoint(self, checkpoint_file: str) -> Optional[Dict]:
        """
        Reprend une exÃ©cution depuis un checkpoint.
        
        Args:
            checkpoint_file: Chemin vers le fichier checkpoint
            
        Returns:
            Dict avec les informations de reprise ou None
        """
        try:
            with open(checkpoint_file, 'r') as f:
                checkpoint = json.load(f)
            
            self._log(f"Reprise depuis batch {checkpoint['batch_index'] + 1}")
            return checkpoint
            
        except Exception as e:
            self._log(f"Cannot load checkpoint: {e}", LogLevel.ERROR)
            return None


# =============================================================================
# v2.5.16 - BUDGET MANAGER
# =============================================================================

class BudgetManager:
    """
    [v2.5.16] Gestionnaire de budget QPU mensuel.
    
    Permet de:
    - DÃ©finir un budget mensuel en minutes QPU
    - Suivre l'utilisation en temps rÃ©el
    - Alerter quand on approche de la limite
    - Bloquer les exÃ©cutions si dÃ©passement
    
    Usage:
        budget = BudgetManager(framework, monthly_budget_minutes=100)
        budget.set_alert_threshold(80)  # Alerte Ã  80%
        
        # VÃ©rifier avant exÃ©cution
        if budget.can_execute(estimated_minutes=2.5):
            results = fw.run_on_qpu(circuits)
            budget.record_usage(results)
    """
    
    def __init__(self, framework: 'QMCFramework' = None,
                 monthly_budget_minutes: float = 100.0,
                 alert_threshold_percent: float = 80.0,
                 block_on_exceed: bool = False,
                 logger: Logger = None):
        """
        Args:
            framework: Instance QMCFramework pour rÃ©cupÃ©rer l'usage rÃ©el
            monthly_budget_minutes: Budget mensuel en minutes (dÃ©faut: 100)
            alert_threshold_percent: Seuil d'alerte en % (dÃ©faut: 80%)
            block_on_exceed: Bloquer les exÃ©cutions si budget dÃ©passÃ© (dÃ©faut: False)
            logger: Logger pour les messages
        """
        self.framework = framework
        self.monthly_budget = monthly_budget_minutes
        self.alert_threshold = alert_threshold_percent
        self.block_on_exceed = block_on_exceed
        self.logger = logger or (framework.logger if framework else None)
        
        # Tracking
        self._usage_records: List[Dict] = []
        self._alerts_sent: Set[int] = set()  # Thresholds dÃ©jÃ  alertÃ©s
        self._storage_file: Optional[Path] = None
        
        # Charger l'historique si disponible
        self._load_history()
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='BUDGET')
        else:
            print(f"[BUDGET] {msg}")
    
    def _load_history(self):
        """Charge l'historique d'usage depuis le fichier."""
        try:
            home = Path.home()
            self._storage_file = home / '.qmc_budget_history.json'
            
            if self._storage_file.exists():
                with open(self._storage_file, 'r') as f:
                    data = json.load(f)
                    self._usage_records = data.get('records', [])
                    self._log(f"Historique chargÃ©: {len(self._usage_records)} enregistrements")
        except Exception as e:
            self._log(f"Cannot load history: {e}", LogLevel.WARN)
    
    def _save_history(self):
        """Sauvegarde l'historique d'usage."""
        try:
            if self._storage_file:
                with open(self._storage_file, 'w') as f:
                    json.dump({
                        'records': self._usage_records,
                        'monthly_budget': self.monthly_budget,
                        'last_updated': datetime.now().isoformat()
                    }, f, indent=2)
        except Exception as e:
            self._log(f"Cannot save history: {e}", LogLevel.WARN)
    
    def get_current_month_usage(self) -> float:
        """
        Retourne l'usage du mois en cours en minutes.
        
        Returns:
            Usage en minutes
        """
        now = datetime.now()
        current_month = now.strftime('%Y-%m')
        
        monthly_usage = sum(
            r.get('minutes', 0)
            for r in self._usage_records
            if r.get('month') == current_month
        )
        
        return monthly_usage
    
    def get_remaining_budget(self) -> float:
        """
        Retourne le budget restant pour le mois.
        
        Returns:
            Minutes restantes
        """
        return max(0, self.monthly_budget - self.get_current_month_usage())
    
    def get_usage_percent(self) -> float:
        """
        Retourne le pourcentage du budget utilisÃ©.
        
        Returns:
            Pourcentage (0-100+)
        """
        if self.monthly_budget <= 0:
            return 0
        return (self.get_current_month_usage() / self.monthly_budget) * 100
    
    def can_execute(self, estimated_minutes: float) -> bool:
        """
        VÃ©rifie si une exÃ©cution peut Ãªtre faite dans le budget.
        
        Args:
            estimated_minutes: Estimation du temps QPU nÃ©cessaire
            
        Returns:
            True si OK, False si dÃ©passerait le budget
        """
        remaining = self.get_remaining_budget()
        
        if estimated_minutes > remaining:
            self._log(f"âš ï¸ Budget insuffisant! EstimÃ©: {estimated_minutes:.2f}min, "
                     f"Restant: {remaining:.2f}min", LogLevel.WARN)
            
            if self.block_on_exceed:
                return False
        
        # VÃ©rifier les alertes
        self._check_alerts()
        
        return True
    
    def _check_alerts(self):
        """VÃ©rifie et envoie les alertes de seuil."""
        usage_pct = self.get_usage_percent()
        
        # Alertes Ã  50%, 75%, 90%, 100%
        thresholds = [50, 75, 90, 100]
        
        for threshold in thresholds:
            if usage_pct >= threshold and threshold not in self._alerts_sent:
                self._alerts_sent.add(threshold)
                
                if threshold >= 100:
                    self._log(f"ğŸ”´ BUDGET DÃ‰PASSÃ‰! Usage: {usage_pct:.1f}%", LogLevel.ERROR)
                elif threshold >= 90:
                    self._log(f"ğŸŸ  ATTENTION: Budget Ã  {usage_pct:.1f}%", LogLevel.WARN)
                else:
                    self._log(f"ğŸŸ¡ Info: Budget Ã  {usage_pct:.1f}%", LogLevel.INFO)
    
    def record_usage(self, job_result: Dict = None, minutes: float = None, 
                     job_id: str = None):
        """
        Enregistre une utilisation QPU.
        
        Args:
            job_result: RÃ©sultat de run_on_qpu (extrait le temps automatiquement)
            minutes: Temps en minutes (si pas de job_result)
            job_id: ID du job pour rÃ©fÃ©rence
        """
        now = datetime.now()
        
        # Extraire le temps du rÃ©sultat si fourni
        if job_result and isinstance(job_result, dict):
            qpu_time = job_result.get('qpu_time_s', 0) or 0
            minutes = qpu_time / 60.0
            job_id = job_result.get('job_id', job_id)
        elif job_result and isinstance(job_result, list) and job_result:
            # Liste de rÃ©sultats
            total_qpu = sum(r.get('qpu_time_s', 0) or 0 for r in job_result if isinstance(r, dict))
            minutes = total_qpu / 60.0
        
        if minutes is None or minutes <= 0:
            return
        
        record = {
            'timestamp': now.isoformat(),
            'month': now.strftime('%Y-%m'),
            'minutes': minutes,
            'job_id': job_id
        }
        
        self._usage_records.append(record)
        self._save_history()
        
        self._log(f"ğŸ“ Usage enregistrÃ©: {minutes:.3f} min (Job: {job_id or 'N/A'})")
        self._check_alerts()
    
    def fetch_real_usage(self, days: int = 30) -> float:
        """
        RÃ©cupÃ¨re l'usage rÃ©el depuis IBM Quantum.
        
        Args:
            days: Nombre de jours Ã  analyser
            
        Returns:
            Usage total en minutes
        """
        if not self.framework or not hasattr(self.framework, 'get_monthly_usage'):
            self._log("Framework non connectÃ©, impossible de rÃ©cupÃ©rer l'usage rÃ©el", LogLevel.WARN)
            return self.get_current_month_usage()
        
        try:
            usage = self.framework.get_monthly_usage(days=days, animate=False)
            if usage and 'total_time_s' in usage:
                return usage['total_time_s'] / 60.0
        except Exception as e:
            self._log(f"Erreur rÃ©cupÃ©ration usage: {e}", LogLevel.WARN)
        
        return self.get_current_month_usage()
    
    def display_status(self):
        """Affiche le statut du budget."""
        usage = self.get_current_month_usage()
        remaining = self.get_remaining_budget()
        pct = self.get_usage_percent()
        
        # Barre de progression
        bar_width = 40
        filled = int(bar_width * min(pct, 100) / 100)
        bar = 'â–ˆ' * filled + 'â–‘' * (bar_width - filled)
        
        # Couleur selon le niveau
        if pct >= 100:
            status_emoji = "ğŸ”´"
            status_text = "DÃ‰PASSÃ‰"
        elif pct >= 90:
            status_emoji = "ğŸŸ "
            status_text = "CRITIQUE"
        elif pct >= 75:
            status_emoji = "ğŸŸ¡"
            status_text = "ATTENTION"
        else:
            status_emoji = "ğŸŸ¢"
            status_text = "OK"
        
        print()
        print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("  â•‘  ğŸ’° STATUT BUDGET QPU                                                      â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  ğŸ“… Mois:        {datetime.now().strftime('%B %Y'):<55} â•‘")
        print(f"  â•‘  ğŸ“Š Budget:      {self.monthly_budget:.1f} minutes                                         â•‘")
        print(f"  â•‘  ğŸ“ˆ UtilisÃ©:     {usage:.2f} minutes ({pct:.1f}%)                               â•‘")
        print(f"  â•‘  ğŸ“‰ Restant:     {remaining:.2f} minutes                                       â•‘")
        print(f"  â•‘  {status_emoji} Statut:      {status_text:<56} â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  [{bar}] {pct:5.1f}%  â•‘")
        print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
    
    def reset_month(self):
        """RÃ©initialise le compteur pour le nouveau mois."""
        self._alerts_sent.clear()
        self._log("ğŸ”„ Compteur mensuel rÃ©initialisÃ©")


# =============================================================================
# v2.5.16 - CIRCUIT PROFILER
# =============================================================================

class CircuitProfiler:
    """
    [v2.5.16] Analyseur de circuits quantiques AVANT transpilation.
    
    Fournit:
    - Analyse de complexitÃ© (profondeur, portes, qubits)
    - Estimation du temps d'exÃ©cution
    - Identification des goulots d'Ã©tranglement
    - Suggestions d'optimisation
    - Score de "transpilabilitÃ©"
    
    Usage:
        profiler = CircuitProfiler(framework)
        report = profiler.profile(circuit)
        profiler.display_report(report)
        
        # Ou profiler plusieurs circuits
        reports = profiler.profile_batch(circuits)
    """
    
    def __init__(self, framework: 'QMCFramework' = None, logger: Logger = None):
        """
        Args:
            framework: Instance QMCFramework pour accÃ¨s backend
            logger: Logger pour les messages
        """
        self.framework = framework
        self.logger = logger or (framework.logger if framework else None)
        
        # MÃ©triques de rÃ©fÃ©rence pour IBM Heron
        self.reference_metrics = {
            'gate_times_ns': {
                'rz': 0,      # Virtual (instantanÃ©)
                'sx': 25,     # ~25ns
                'x': 25,
                'cz': 68,     # ~68ns pour CZ
                'ecr': 68,    # ~68ns pour ECR
                'cx': 300,    # ~300ns (dÃ©composÃ©)
                'swap': 900,  # ~3x CZ
            },
            'max_depth_recommended': 100,
            'max_2q_gates_recommended': 50,
            't1_typical_us': 200,   # T1 typique
            't2_typical_us': 150,   # T2 typique
        }
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='PROFILER')
    
    def profile(self, circuit) -> Dict[str, Any]:
        """
        Profile un circuit quantique.
        
        Args:
            circuit: QuantumCircuit Ã  analyser
            
        Returns:
            Dict avec le profil complet
        """
        profile = {
            'basic_metrics': {},
            'gate_analysis': {},
            'complexity_score': 0,
            'estimated_time': {},
            'bottlenecks': [],
            'suggestions': [],
            'transpile_prediction': {},
        }
        
        # 1. MÃ©triques de base
        profile['basic_metrics'] = {
            'num_qubits': circuit.num_qubits,
            'num_clbits': circuit.num_clbits,
            'depth': circuit.depth(),
            'size': circuit.size(),  # Nombre total d'opÃ©rations
            'width': circuit.width(),  # Qubits + clbits
        }
        
        # 2. Analyse des portes
        gate_counts = dict(circuit.count_ops())
        
        # Classifier les portes
        single_qubit_gates = 0
        two_qubit_gates = 0
        multi_qubit_gates = 0
        measurements = 0
        barriers = 0
        
        two_q_gate_names = {'cx', 'cz', 'ecr', 'swap', 'iswap', 'cp', 'crx', 'cry', 'crz', 'rzz', 'rxx', 'ryy'}
        
        for gate, count in gate_counts.items():
            gate_lower = gate.lower()
            if gate_lower == 'measure':
                measurements += count
            elif gate_lower == 'barrier':
                barriers += count
            elif gate_lower in two_q_gate_names:
                two_qubit_gates += count
            elif any(x in gate_lower for x in ['ccx', 'cswap', 'mcx', 'mct']):
                multi_qubit_gates += count
            else:
                single_qubit_gates += count
        
        profile['gate_analysis'] = {
            'gate_counts': gate_counts,
            'single_qubit_gates': single_qubit_gates,
            'two_qubit_gates': two_qubit_gates,
            'multi_qubit_gates': multi_qubit_gates,
            'measurements': measurements,
            'barriers': barriers,
            'total_gates': sum(gate_counts.values()) - barriers,
        }
        
        # 3. Estimation du temps d'exÃ©cution
        estimated_ns = 0
        for gate, count in gate_counts.items():
            gate_time = self.reference_metrics['gate_times_ns'].get(gate.lower(), 50)  # 50ns par dÃ©faut
            estimated_ns += gate_time * count
        
        # Ajouter le temps de mesure (~1us par qubit mesurÃ©)
        estimated_ns += measurements * 1000
        
        profile['estimated_time'] = {
            'circuit_time_ns': estimated_ns,
            'circuit_time_us': estimated_ns / 1000,
            'circuit_time_ms': estimated_ns / 1_000_000,
            # Estimation avec shots
            'per_1000_shots_ms': (estimated_ns / 1_000_000) * 1000,
            'per_4096_shots_s': (estimated_ns / 1_000_000_000) * 4096,
        }
        
        # 4. Score de complexitÃ© (0-100)
        depth = profile['basic_metrics']['depth']
        n_2q = two_qubit_gates
        n_qubits = profile['basic_metrics']['num_qubits']
        
        # PÃ©nalitÃ©s
        depth_penalty = min(50, depth / 2)  # Max 50 points pour la profondeur
        gate_penalty = min(30, n_2q / 2)    # Max 30 points pour les portes 2Q
        qubit_penalty = min(20, n_qubits / 8)  # Max 20 points pour les qubits
        
        complexity_score = depth_penalty + gate_penalty + qubit_penalty
        profile['complexity_score'] = min(100, complexity_score)
        
        # 5. Identification des goulots d'Ã©tranglement
        bottlenecks = []
        
        if depth > self.reference_metrics['max_depth_recommended']:
            bottlenecks.append({
                'type': 'depth',
                'severity': 'high' if depth > 200 else 'medium',
                'message': f"Profondeur Ã©levÃ©e ({depth}) - risque de dÃ©cohÃ©rence",
                'value': depth,
                'threshold': self.reference_metrics['max_depth_recommended']
            })
        
        if n_2q > self.reference_metrics['max_2q_gates_recommended']:
            bottlenecks.append({
                'type': 'two_qubit_gates',
                'severity': 'high' if n_2q > 100 else 'medium',
                'message': f"Nombreuses portes 2Q ({n_2q}) - forte accumulation d'erreurs",
                'value': n_2q,
                'threshold': self.reference_metrics['max_2q_gates_recommended']
            })
        
        if multi_qubit_gates > 0:
            bottlenecks.append({
                'type': 'multi_qubit_gates',
                'severity': 'high',
                'message': f"Portes multi-qubits ({multi_qubit_gates}) - dÃ©composition coÃ»teuse",
                'value': multi_qubit_gates,
                'threshold': 0
            })
        
        # Estimation du temps de cohÃ©rence
        t2_us = self.reference_metrics['t2_typical_us']
        circuit_time_us = estimated_ns / 1000
        if circuit_time_us > t2_us * 0.5:
            bottlenecks.append({
                'type': 'coherence',
                'severity': 'critical' if circuit_time_us > t2_us else 'high',
                'message': f"Circuit approche T2 ({circuit_time_us:.1f}Âµs vs T2={t2_us}Âµs)",
                'value': circuit_time_us,
                'threshold': t2_us
            })
        
        profile['bottlenecks'] = bottlenecks
        
        # 6. Suggestions d'optimisation
        suggestions = []
        
        if depth > 50:
            suggestions.append("ğŸ’¡ Augmenter optimization_level Ã  3 pour rÃ©duire la profondeur")
        
        if n_2q > 30:
            suggestions.append("ğŸ’¡ Utiliser VF2PostLayout pour meilleur mapping des portes 2Q")
        
        if multi_qubit_gates > 0:
            suggestions.append("ğŸ’¡ DÃ©composer les portes multi-qubits manuellement avant transpilation")
        
        if 'swap' in gate_counts and gate_counts['swap'] > 5:
            suggestions.append("ğŸ’¡ RÃ©organiser le circuit pour rÃ©duire les SWAPs")
        
        if n_qubits > 50:
            suggestions.append("ğŸ’¡ ConsidÃ©rer le dÃ©coupage en sous-circuits plus petits")
        
        if not suggestions:
            suggestions.append("âœ… Circuit bien optimisÃ© pour l'exÃ©cution NISQ")
        
        profile['suggestions'] = suggestions
        
        # 7. PrÃ©diction de transpilation
        # Estimer l'augmentation de profondeur aprÃ¨s transpilation
        if self.framework and self.framework.backend:
            # Estimation basÃ©e sur la connectivitÃ©
            estimated_depth_increase = 1.5 if n_2q > 20 else 1.2
        else:
            estimated_depth_increase = 1.5
        
        profile['transpile_prediction'] = {
            'estimated_depth_after': int(depth * estimated_depth_increase),
            'estimated_2q_gates_after': int(n_2q * 1.3),  # +30% typique
            'success_probability': 'high' if complexity_score < 30 else ('medium' if complexity_score < 60 else 'low'),
        }
        
        return profile
    
    def profile_batch(self, circuits: List) -> List[Dict]:
        """Profile plusieurs circuits."""
        return [self.profile(c) for c in circuits]
    
    def display_report(self, profile: Dict, show_gates: bool = True):
        """
        Affiche un rapport de profil formatÃ©.
        
        Args:
            profile: Profil gÃ©nÃ©rÃ© par profile()
            show_gates: Afficher le dÃ©tail des portes
        """
        basic = profile['basic_metrics']
        gates = profile['gate_analysis']
        time_est = profile['estimated_time']
        score = profile['complexity_score']
        
        # Couleur du score
        if score < 30:
            score_emoji = "ğŸŸ¢"
            score_label = "SIMPLE"
        elif score < 60:
            score_emoji = "ğŸŸ¡"
            score_label = "MODÃ‰RÃ‰"
        else:
            score_emoji = "ğŸ”´"
            score_label = "COMPLEXE"
        
        print()
        print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("  â•‘  ğŸ”¬ PROFIL DE CIRCUIT QUANTIQUE                                            â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  ğŸ“Š Qubits:       {basic['num_qubits']:<55} â•‘")
        print(f"  â•‘  ğŸ“ Profondeur:   {basic['depth']:<55} â•‘")
        print(f"  â•‘  ğŸ”¢ OpÃ©rations:   {basic['size']:<55} â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  {score_emoji} Score complexitÃ©: {score:.0f}/100 ({score_label})                            â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  âš™ï¸  ANALYSE DES PORTES                                                    â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘     1-qubit gates:  {gates['single_qubit_gates']:<52} â•‘")
        print(f"  â•‘     2-qubit gates:  {gates['two_qubit_gates']:<52} â•‘")
        if gates['multi_qubit_gates'] > 0:
            print(f"  â•‘     Multi-Q gates:  {gates['multi_qubit_gates']:<52} â•‘")
        print(f"  â•‘     Mesures:        {gates['measurements']:<52} â•‘")
        
        if show_gates and gates['gate_counts']:
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            print("  â•‘  ğŸ“‹ DÃ‰TAIL DES PORTES                                                      â•‘")
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            
            # Top 8 portes
            sorted_gates = sorted(gates['gate_counts'].items(), key=lambda x: x[1], reverse=True)[:8]
            for gate, count in sorted_gates:
                if gate.lower() != 'barrier':
                    print(f"  â•‘     {gate:<15}: {count:<51} â•‘")
        
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  â±ï¸  ESTIMATION TEMPS                                                       â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘     Circuit seul:    {time_est['circuit_time_us']:.2f} Âµs                                   â•‘")
        print(f"  â•‘     4096 shots:      {time_est['per_4096_shots_s']:.3f} s                                    â•‘")
        
        if profile['bottlenecks']:
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            print("  â•‘  âš ï¸  GOULOTS D'Ã‰TRANGLEMENT                                                â•‘")
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            for bn in profile['bottlenecks'][:4]:
                severity_emoji = {'critical': 'ğŸ”´', 'high': 'ğŸŸ ', 'medium': 'ğŸŸ¡'}.get(bn['severity'], 'âšª')
                msg = bn['message'][:60]
                print(f"  â•‘  {severity_emoji} {msg:<68} â•‘")
        
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  ğŸ’¡ SUGGESTIONS                                                            â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        for sugg in profile['suggestions'][:4]:
            sugg_text = sugg[:68]
            print(f"  â•‘     {sugg_text:<67} â•‘")
        
        # PrÃ©diction transpilation
        pred = profile['transpile_prediction']
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  ğŸ”® PRÃ‰DICTION POST-TRANSPILATION                                          â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘     Profondeur estimÃ©e:  {pred['estimated_depth_after']:<47} â•‘")
        print(f"  â•‘     Portes 2Q estimÃ©es:  {pred['estimated_2q_gates_after']:<47} â•‘")
        success_emoji = {'high': 'ğŸŸ¢', 'medium': 'ğŸŸ¡', 'low': 'ğŸ”´'}.get(pred['success_probability'], 'âšª')
        print(f"  â•‘     ProbabilitÃ© succÃ¨s:  {success_emoji} {pred['success_probability'].upper():<44} â•‘")
        
        print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()


# =============================================================================
# v2.5.16 - RESULT COMPARATOR
# =============================================================================

class ResultComparator:
    """
    [v2.5.21] Comparateur de rÃ©sultats quantiques avec Qiskit native.
    
    Compare deux ensembles de rÃ©sultats (ex: simulateur vs QPU, deux backends)
    et fournit des mÃ©triques de divergence dÃ©taillÃ©es.
    
    v2.5.21: IntÃ¨gre qiskit.quantum_info.hellinger_fidelity native.
    
    Usage:
        comparator = ResultComparator()
        
        # Comparer deux distributions
        comparison = comparator.compare(counts_a, counts_b)
        comparator.display_comparison(comparison)
        
        # Ou comparer des rÃ©sultats de run_on_qpu
        comparison = comparator.compare_results(results_sim, results_qpu)
    """
    
    def __init__(self, logger: Logger = None):
        self.logger = logger
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='COMPARE')
    
    def compare(self, counts_a: Dict[str, int], counts_b: Dict[str, int],
                label_a: str = "A", label_b: str = "B") -> Dict[str, Any]:
        """
        Compare deux distributions de counts.
        
        Args:
            counts_a: Premier dict de counts {bitstring: count}
            counts_b: Second dict de counts
            label_a: Label pour A
            label_b: Label pour B
            
        Returns:
            Dict avec les mÃ©triques de comparaison
        """
        comparison = {
            'labels': (label_a, label_b),
            'metrics': {},
            'divergence': {},
            'top_differences': [],
            'summary': {}
        }
        
        # Normaliser en distributions de probabilitÃ©
        total_a = sum(counts_a.values())
        total_b = sum(counts_b.values())
        
        all_keys = set(counts_a.keys()) | set(counts_b.keys())
        
        prob_a = {k: counts_a.get(k, 0) / total_a for k in all_keys}
        prob_b = {k: counts_b.get(k, 0) / total_b for k in all_keys}
        
        # MÃ©triques de base
        comparison['metrics'] = {
            'total_shots_a': total_a,
            'total_shots_b': total_b,
            'unique_outcomes_a': len(counts_a),
            'unique_outcomes_b': len(counts_b),
            'common_outcomes': len(set(counts_a.keys()) & set(counts_b.keys())),
            'total_outcomes': len(all_keys),
        }
        
        # 1. Total Variation Distance (TVD)
        tvd = 0.5 * sum(abs(prob_a[k] - prob_b[k]) for k in all_keys)
        
        # 2. Fidelity - v2.5.21: Utiliser Qiskit hellinger_fidelity
        hellinger_fid = QiskitQuantumInfoWrapper.hellinger_fidelity(counts_a, counts_b)
        
        # Fallback si Qiskit non disponible
        if hellinger_fid < 0:
            # Calcul manuel (overlap classique)
            hellinger_fid = sum(math.sqrt(prob_a[k] * prob_b[k]) for k in all_keys) ** 2
        
        # 3. KL Divergence (avec lissage pour Ã©viter log(0))
        epsilon = 1e-10
        kl_div = sum(
            prob_a[k] * math.log((prob_a[k] + epsilon) / (prob_b[k] + epsilon))
            for k in all_keys if prob_a[k] > 0
        )
        
        # 4. Jensen-Shannon Divergence
        m = {k: (prob_a[k] + prob_b[k]) / 2 for k in all_keys}
        js_div = 0.5 * sum(
            prob_a[k] * math.log((prob_a[k] + epsilon) / (m[k] + epsilon))
            for k in all_keys if prob_a[k] > 0
        ) + 0.5 * sum(
            prob_b[k] * math.log((prob_b[k] + epsilon) / (m[k] + epsilon))
            for k in all_keys if prob_b[k] > 0
        )
        
        # 5. Chi-squared statistic
        chi_sq = sum(
            ((counts_a.get(k, 0) - counts_b.get(k, 0) * total_a / total_b) ** 2) / 
            max(1, counts_b.get(k, 0) * total_a / total_b)
            for k in all_keys
        )
        
        comparison['divergence'] = {
            'tvd': tvd,
            'hellinger_fidelity': hellinger_fid,  # v2.5.21: Renamed from 'fidelity'
            'fidelity': hellinger_fid,  # Keep for backward compatibility
            'kl_divergence': kl_div,
            'js_divergence': js_div,
            'chi_squared': chi_sq,
            'qiskit_native': True,  # v2.5.21 marker
        }
        
        # 6. Top diffÃ©rences
        differences = []
        for k in all_keys:
            diff = abs(prob_a[k] - prob_b[k])
            if diff > 0.001:  # Seuil de 0.1%
                differences.append({
                    'bitstring': k,
                    'prob_a': prob_a[k],
                    'prob_b': prob_b[k],
                    'difference': diff,
                    'percent_diff': diff * 100
                })
        
        differences.sort(key=lambda x: x['difference'], reverse=True)
        comparison['top_differences'] = differences[:10]
        
        # 7. RÃ©sumÃ© qualitatif
        if tvd < 0.05:
            quality = "EXCELLENT"
            color = "green"
        elif tvd < 0.10:
            quality = "GOOD"
            color = "green"
        elif tvd < 0.20:
            quality = "ACCEPTABLE"
            color = "yellow"
        elif tvd < 0.35:
            quality = "MEDIOCRE"
            color = "orange"
        else:
            quality = "POOR"
            color = "red"
        
        comparison['summary'] = {
            'quality': quality,
            'color': color,
            'interpretation': self._interpret_results(tvd, hellinger_fid, comparison['metrics'])
        }
        
        return comparison
    
    # v2.5.21: Nouvelle mÃ©thode pour analyse complÃ¨te avec Qiskit
    def analyze_with_qiskit(self, counts_a: Dict[str, int], 
                            counts_b: Dict[str, int]) -> Dict[str, Any]:
        """
        Analyse complÃ¨te des counts avec QiskitQuantumInfoWrapper (v2.5.21).
        
        Args:
            counts_a: Premiers counts
            counts_b: Seconds counts
            
        Returns:
            Dict avec toutes les mÃ©triques Qiskit
        """
        analysis_a = QiskitQuantumInfoWrapper.analyze_counts(counts_a, counts_b)
        analysis_b = QiskitQuantumInfoWrapper.analyze_counts(counts_b, counts_a)
        
        return {
            'analysis_a': analysis_a,
            'analysis_b': analysis_b,
            'hellinger_fidelity': QiskitQuantumInfoWrapper.hellinger_fidelity(counts_a, counts_b),
            'comparison': self.compare(counts_a, counts_b),
        }
    
    def _interpret_results(self, tvd: float, fidelity: float, metrics: Dict) -> str:
        """GÃ©nÃ¨re une interprÃ©tation textuelle."""
        if tvd < 0.05:
            return "Distributions are nearly identical. Excellent reproducibility."
        elif tvd < 0.10:
            return "Low divergence. Results consistent with expected quantum noise."
        elif tvd < 0.20:
            return "Moderate divergence. Possible noise effects or calibration differences."
        elif tvd < 0.35:
            return "Significant divergence. Check execution parameters and calibration."
        else:
            return "High divergence. Results are not comparable - likely problem."
    
    def compare_results(self, results_a: List[Dict], results_b: List[Dict],
                        label_a: str = "A", label_b: str = "B") -> Dict[str, Any]:
        """
        Compare deux listes de rÃ©sultats de run_on_qpu.
        
        Args:
            results_a: PremiÃ¨re liste de rÃ©sultats
            results_b: Seconde liste de rÃ©sultats
            
        Returns:
            Dict avec comparaisons circuit par circuit
        """
        if not results_a or not results_b:
            return {'error': 'RÃ©sultats vides'}
        
        # Aligner par nombre de circuits
        n_circuits = min(len(results_a), len(results_b))
        
        comparisons = []
        aggregate_tvd = []
        aggregate_fidelity = []
        
        for i in range(n_circuits):
            counts_a = results_a[i].get('counts', {})
            counts_b = results_b[i].get('counts', {})
            
            if counts_a and counts_b:
                comp = self.compare(counts_a, counts_b, label_a, label_b)
                comp['circuit_index'] = i
                comparisons.append(comp)
                
                aggregate_tvd.append(comp['divergence']['tvd'])
                aggregate_fidelity.append(comp['divergence']['fidelity'])
        
        # Statistiques agrÃ©gÃ©es
        return {
            'per_circuit': comparisons,
            'aggregate': {
                'mean_tvd': sum(aggregate_tvd) / len(aggregate_tvd) if aggregate_tvd else 0,
                'mean_fidelity': sum(aggregate_fidelity) / len(aggregate_fidelity) if aggregate_fidelity else 0,
                'max_tvd': max(aggregate_tvd) if aggregate_tvd else 0,
                'min_fidelity': min(aggregate_fidelity) if aggregate_fidelity else 0,
                'circuits_compared': len(comparisons),
            },
            'labels': (label_a, label_b)
        }
    
    def display_comparison(self, comparison: Dict, show_details: bool = True):
        """
        Affiche un rapport de comparaison formatÃ©.
        
        Args:
            comparison: RÃ©sultat de compare() ou compare_results()
            show_details: Afficher les dÃ©tails par bitstring
        """
        # VÃ©rifier si c'est une comparaison simple ou agrÃ©gÃ©e
        if 'per_circuit' in comparison:
            self._display_aggregate_comparison(comparison)
        else:
            self._display_single_comparison(comparison, show_details)
    
    def _display_single_comparison(self, comparison: Dict, show_details: bool):
        """Affiche une comparaison simple."""
        labels = comparison['labels']
        metrics = comparison['metrics']
        div = comparison['divergence']
        summary = comparison['summary']
        
        print()
        print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("  â•‘  ğŸ“Š COMPARAISON DE RÃ‰SULTATS                                               â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  ğŸ“ {labels[0]} vs {labels[1]:<62} â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  {summary['emoji']} QualitÃ©: {summary['quality']:<60} â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  ğŸ“ˆ MÃ‰TRIQUES DE DIVERGENCE                                                â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘     TVD (Total Variation):    {div['tvd']:.4f}                                   â•‘")
        print(f"  â•‘     FidelitÃ©:                 {div['fidelity']:.4f}                                   â•‘")
        print(f"  â•‘     JS Divergence:            {div['js_divergence']:.4f}                                   â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  ğŸ“‹ STATISTIQUES                                                           â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘     Shots {labels[0]}:  {metrics['total_shots_a']:<54} â•‘")
        print(f"  â•‘     Shots {labels[1]}:  {metrics['total_shots_b']:<54} â•‘")
        print(f"  â•‘     Outcomes communs:         {metrics['common_outcomes']}/{metrics['total_outcomes']:<40} â•‘")
        
        if show_details and comparison['top_differences']:
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            print("  â•‘  ğŸ” TOP DIFFÃ‰RENCES                                                        â•‘")
            print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
            print(f"  â•‘  {'Bitstring':<20} {labels[0]:>10} {labels[1]:>10} {'Diff':>10}      â•‘")
            print("  â•‘  " + "-" * 52 + "                  â•‘")
            
            for diff in comparison['top_differences'][:5]:
                bs = diff['bitstring'][:18]
                pa = f"{diff['prob_a']:.3f}"
                pb = f"{diff['prob_b']:.3f}"
                d = f"{diff['percent_diff']:.1f}%"
                print(f"  â•‘  {bs:<20} {pa:>10} {pb:>10} {d:>10}      â•‘")
        
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        interp = summary['interpretation'][:68]
        print(f"  â•‘  ğŸ’¬ {interp:<67} â•‘")
        print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
    
    def _display_aggregate_comparison(self, comparison: Dict):
        """Affiche une comparaison agrÃ©gÃ©e (plusieurs circuits)."""
        agg = comparison['aggregate']
        labels = comparison['labels']
        
        # QualitÃ© globale basÃ©e sur TVD moyenne
        mean_tvd = agg['mean_tvd']
        if mean_tvd < 0.10:
            quality = "EXCELLENT"
            emoji = "ğŸŸ¢"
        elif mean_tvd < 0.20:
            quality = "BON"
            emoji = "ğŸŸ¢"
        elif mean_tvd < 0.35:
            quality = "ACCEPTABLE"
            emoji = "ğŸŸ¡"
        else:
            quality = "MÃ‰DIOCRE"
            emoji = "ğŸŸ "
        
        print()
        print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("  â•‘  ğŸ“Š COMPARAISON AGRÃ‰GÃ‰E DE RÃ‰SULTATS                                       â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  ğŸ“ {labels[0]} vs {labels[1]:<62} â•‘")
        print(f"  â•‘  ğŸ“‹ Circuits comparÃ©s: {agg['circuits_compared']:<50} â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘  {emoji} QualitÃ© globale: {quality:<54} â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("  â•‘  ğŸ“ˆ STATISTIQUES AGRÃ‰GÃ‰ES                                                  â•‘")
        print("  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"  â•‘     TVD moyenne:              {agg['mean_tvd']:.4f}                                   â•‘")
        print(f"  â•‘     TVD max:                  {agg['max_tvd']:.4f}                                   â•‘")
        print(f"  â•‘     FidÃ©litÃ© moyenne:         {agg['mean_fidelity']:.4f}                                   â•‘")
        print(f"  â•‘     FidÃ©litÃ© min:             {agg['min_fidelity']:.4f}                                   â•‘")
        print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()


# =============================================================================
# v2.5.17 - EXECUTION ARCHIVE (MEGA JSON COMPLET)
# =============================================================================

class ExecutionArchive:
    """
    [v2.5.17] GÃ©nÃ©rateur d'archives JSON COMPLÃˆTES pour analyse externe.
    
    CrÃ©e un fichier JSON contenant ABSOLUMENT TOUT aprÃ¨s chaque run_on_qpu():
    
    ğŸ“¦ CONTENU DE L'ARCHIVE:
    â”œâ”€â”€ metadata          # Timestamp, version, projet, machine
    â”œâ”€â”€ backend           # Nom, version, num_qubits, basis_gates
    â”œâ”€â”€ calibration       # Ã‰tat COMPLET du QPU (156 qubits, gates, erreurs)
    â”œâ”€â”€ circuits          # QASM, depth, gates, qubits utilisÃ©s
    â”œâ”€â”€ transpilation     # Avant/aprÃ¨s, layout, optimizations
    â”œâ”€â”€ mitigation        # Twirling, DD, ZNE config
    â”œâ”€â”€ execution         # Job ID, timing dÃ©taillÃ©, queue, QPU time
    â”œâ”€â”€ results           # Counts complets, statistiques, entropie
    â”œâ”€â”€ analysis          # XEB, fidelity, randomness scores
    â””â”€â”€ error             # Traceback complet si erreur
    
    ACTIVATION AUTOMATIQUE:
        Par dÃ©faut, run_on_qpu() gÃ©nÃ¨re l'archive. Pour dÃ©sactiver:
        results = fw.run_on_qpu(circuits, generate_archive=False)
    
    USAGE EXTERNE:
        # Charger l'archive pour analyse
        with open('archive_xxx.json') as f:
            data = json.load(f)
        
        # Envoyer Ã  un serveur
        requests.post('https://analysis.server/upload', json=data)
    
    TAILLE TYPIQUE:
        - 10 circuits IQP 50q: ~2-5 MB
        - 100 circuits: ~20-50 MB
        - Compression gzip recommandÃ©e pour stockage
    """
    
    def __init__(self, framework: 'QMCFramework' = None,
                 output_dir: str = None,
                 logger: Logger = None,
                 compress: bool = False):
        """
        Args:
            framework: Instance QMCFramework
            output_dir: RÃ©pertoire de sortie
            logger: Logger pour les messages
            compress: Compresser en .json.gz (dÃ©faut: False)
        """
        self.framework = framework
        self.output_dir = Path(output_dir) if output_dir else None
        self.logger = logger or (framework.logger if framework else None)
        self.compress = compress
        self._last_archive_path = None
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='ARCHIVE')
        else:
            print(f"[ARCHIVE] {msg}")
    
    def _get_output_dir(self) -> Path:
        """Retourne le rÃ©pertoire de sortie."""
        if self.output_dir:
            return self.output_dir
        if self.framework and hasattr(self.framework, 'dir_manager') and self.framework.dir_manager:
            return self.framework.dir_manager.run_dir
        return Path('qmc_archives')
    
    def generate(self,
                 results: List[Dict] = None,
                 circuits = None,
                 transpiled_circuits = None,
                 run_context: Dict = None,
                 error: Exception = None) -> Path:
        """
        GÃ©nÃ¨re une archive JSON COMPLÃˆTE.
        
        Args:
            results: RÃ©sultats de l'exÃ©cution
            circuits: Circuits originaux (avant transpilation)
            transpiled_circuits: Circuits aprÃ¨s transpilation
            run_context: Contexte d'exÃ©cution
            error: Exception si erreur
            
        Returns:
            Path vers le fichier JSON gÃ©nÃ©rÃ©
        """
        # Collecter TOUTES les donnÃ©es
        archive = self._build_complete_archive(
            results=results,
            circuits=circuits,
            transpiled_circuits=transpiled_circuits,
            run_context=run_context,
            error=error
        )
        
        # DÃ©terminer le chemin de sortie
        output_dir = self._get_output_dir()
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Nom du fichier
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        job_id = run_context.get('job_id', 'local')[:12] if run_context else 'local'
        status = 'ERROR' if error else 'OK'
        
        if self.compress:
            filename = f"archive_{timestamp}_{job_id}_{status}.json.gz"
            filepath = output_dir / filename
            import gzip
            with gzip.open(filepath, 'wt', encoding='utf-8') as f:
                json.dump(archive, f, indent=2, default=str, ensure_ascii=False)
        else:
            filename = f"archive_{timestamp}_{job_id}_{status}.json"
            filepath = output_dir / filename
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(archive, f, indent=2, default=str, ensure_ascii=False)
        
        self._last_archive_path = filepath
        size_kb = filepath.stat().st_size / 1024
        size_mb = size_kb / 1024
        
        if size_mb > 1:
            self._log(f"ğŸ“¦ Archive gÃ©nÃ©rÃ©e: {filepath} ({size_mb:.1f} MB)")
        else:
            self._log(f"ğŸ“¦ Archive gÃ©nÃ©rÃ©e: {filepath} ({size_kb:.1f} KB)")
        
        return filepath
    
    def _build_complete_archive(self,
                                results: List[Dict],
                                circuits,
                                transpiled_circuits,
                                run_context: Dict,
                                error: Exception) -> Dict:
        """
        Construit l'archive ULTRA-COMPLÃˆTE avec ABSOLUMENT TOUTES les donnÃ©es.
        
        Cette archive est le support DÃ‰FINITIF pour l'analyse future.
        Elle contient TOUT ce qui s'est passÃ© pendant l'exÃ©cution.
        """
        
        archive = {
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 1: MÃ‰TADONNÃ‰ES SYSTÃˆME
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'metadata': {
                'archive_version': '2.0',  # Version 2.0 = ultra-complÃ¨te
                'archive_format': 'QMC_EXECUTION_ARCHIVE',
                'framework_version': __version__,
                'generated_at': datetime.now().isoformat(),
                'generated_at_unix': time.time(),
                'generated_at_utc': datetime.utcnow().isoformat() + 'Z',
                'python_version': sys.version,
                'python_version_info': list(sys.version_info[:3]),
                'platform': sys.platform,
                'platform_details': self._get_platform_details(),
                'hostname': self._get_hostname(),
                'project': getattr(self.framework, 'project', 'QMC') if self.framework else 'QMC',
                'status': 'ERROR' if error else 'SUCCESS',
            },
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 2: VERSIONS DES DÃ‰PENDANCES
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'dependencies': self._collect_dependencies_versions(),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 3: CONFIGURATION COMPLÃˆTE DU FRAMEWORK
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'framework_config': self._collect_framework_config(),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 4: BACKEND COMPLET
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'backend': self._collect_backend_info(),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 5: CALIBRATION COMPLÃˆTE DU QPU (156 qubits)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'calibration': self._collect_full_calibration(),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 6: CIRCUITS ORIGINAUX (avant transpilation)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'circuits_original': self._collect_circuits_info(circuits, prefix='original'),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 7: CIRCUITS TRANSPILÃ‰S (aprÃ¨s optimisation)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'circuits_transpiled': self._collect_circuits_info(transpiled_circuits, prefix='transpiled'),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 8: MAPPING LAYOUT (virtual â†’ physical qubits)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'layout_mapping': self._collect_layout_mapping(transpiled_circuits),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 9: CONFIGURATION TRANSPILATION
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'transpilation_config': self._collect_transpilation_config(run_context),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 10: CONFIGURATION MITIGATION D'ERREURS
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'mitigation_config': self._collect_mitigation_config(),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 11: OPTIONS SAMPLER IBM
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'sampler_options': self._collect_sampler_options(),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 12: EXÃ‰CUTION DÃ‰TAILLÃ‰E
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'execution': self._collect_execution_info(run_context),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 13: METADATA JOB IBM (si disponible)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'job_metadata': self._collect_job_metadata(run_context),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 14: RÃ‰SULTATS COMPLETS (counts + memory)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'results': self._collect_results(results),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 15: RAW MEMORY (shots individuels si disponible)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'raw_memory': self._collect_raw_memory(results),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 16: STATISTIQUES & ANALYSES AVANCÃ‰ES
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'statistics': self._compute_statistics(results),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 17: LOGS DE LA SESSION
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'session_logs': self._collect_session_logs(),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 18: WARNINGS & ERREURS RENCONTRÃ‰ES
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'warnings': self._collect_warnings(),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 19: ESTIMATIONS PRÃ‰-EXÃ‰CUTION
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'pre_execution_estimates': self._collect_estimates(circuits, run_context),
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 20: ERREUR COMPLÃˆTE (si prÃ©sente)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'error': self._collect_error_info(error) if error else None,
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # SECTION 21: CHECKSUMS & INTÃ‰GRITÃ‰
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            'integrity': {
                'results_hash': None,
                'circuits_hash': None,
                'archive_hash': None,
            }
        }
        
        # Calculer les checksums pour validation
        try:
            if results:
                results_str = json.dumps(results, sort_keys=True, default=str)
                archive['integrity']['results_hash'] = hashlib.sha256(results_str.encode()).hexdigest()
            if circuits:
                circuits_repr = str([str(c) for c in circuits[:20]])
                archive['integrity']['circuits_hash'] = hashlib.sha256(circuits_repr.encode()).hexdigest()
        except:
            pass
        
        return archive
    
    def _get_platform_details(self) -> Dict:
        """RÃ©cupÃ¨re les dÃ©tails de la plateforme."""
        import platform
        try:
            return {
                'system': platform.system(),
                'release': platform.release(),
                'version': platform.version(),
                'machine': platform.machine(),
                'processor': platform.processor(),
                'architecture': platform.architecture()[0],
            }
        except:
            return {}
    
    def _collect_dependencies_versions(self) -> Dict:
        """Collecte les versions de TOUTES les dÃ©pendances."""
        deps = {
            'qiskit': None,
            'qiskit_ibm_runtime': None,
            'qiskit_aer': None,
            'numpy': None,
            'scipy': None,
            'matplotlib': None,
        }
        
        try:
            import qiskit
            deps['qiskit'] = qiskit.__version__
        except:
            pass
        
        try:
            import qiskit_ibm_runtime
            deps['qiskit_ibm_runtime'] = qiskit_ibm_runtime.__version__
        except:
            pass
        
        try:
            import qiskit_aer
            deps['qiskit_aer'] = qiskit_aer.__version__
        except:
            pass
        
        try:
            import numpy
            deps['numpy'] = numpy.__version__
        except:
            pass
        
        try:
            import scipy
            deps['scipy'] = scipy.__version__
        except:
            pass
        
        try:
            import matplotlib
            deps['matplotlib'] = matplotlib.__version__
        except:
            pass
        
        return deps
    
    def _collect_framework_config(self) -> Dict:
        """Collecte la configuration COMPLÃˆTE du framework."""
        config = {
            'project': None,
            'backend_name': None,
            'mode': None,
            'connected': False,
            
            # SÃ©curitÃ©
            'security': {
                'private': False,
                'redact_logs': False,
                'auto_delete_job': False,
                'production_mode': False,
                'auto_confirm': True,
            },
            
            # Budget
            'budget': {
                'configured': False,
                'monthly_minutes': None,
                'used_minutes': None,
                'remaining_minutes': None,
                'alert_threshold_pct': None,
            },
            
            # QualitÃ©
            'quality_thresholds': {},
            
            # Directories
            'directories': {
                'run_dir': None,
                'base_dir': None,
            },
        }
        
        if not self.framework:
            return config
        
        fw = self.framework
        
        try:
            config['project'] = getattr(fw, 'project', None)
            config['backend_name'] = getattr(fw, 'backend_name', None)
            config['mode'] = str(getattr(fw, '_mode', None))
            config['connected'] = getattr(fw, '_connected', False)
            
            # SÃ©curitÃ©
            config['security']['private'] = getattr(fw, 'private', False)
            config['security']['redact_logs'] = getattr(fw, 'redact_logs', False)
            config['security']['auto_delete_job'] = getattr(fw, 'auto_delete_job', False)
            config['security']['production_mode'] = getattr(fw, 'production_mode', False)
            config['security']['auto_confirm'] = getattr(fw, 'auto_confirm', True)
            
            # Budget
            if hasattr(fw, 'budget') and fw.budget:
                budget = fw.budget
                config['budget']['configured'] = True
                config['budget']['monthly_minutes'] = getattr(budget, 'monthly_budget_minutes', None)
                if hasattr(budget, 'get_remaining'):
                    config['budget']['remaining_minutes'] = budget.get_remaining()
                if hasattr(budget, 'get_usage'):
                    usage = budget.get_usage()
                    config['budget']['used_minutes'] = usage.get('current_month_minutes')
                config['budget']['alert_threshold_pct'] = getattr(budget, 'alert_threshold_pct', None)
            
            # QualitÃ©
            if hasattr(fw, 'quality_thresholds') and fw.quality_thresholds:
                qt = fw.quality_thresholds
                config['quality_thresholds'] = {
                    'min_entropy': qt.min_entropy,
                    'max_top_prob': qt.max_top_prob,
                    'min_fidelity': qt.min_fidelity,
                    'min_uniformity': qt.min_uniformity,
                }
            
            # Directories
            if hasattr(fw, 'dir_manager') and fw.dir_manager:
                dm = fw.dir_manager
                config['directories']['run_dir'] = str(getattr(dm, 'run_dir', None))
                config['directories']['base_dir'] = str(getattr(dm, 'base_dir', None))
                
        except Exception as e:
            config['error'] = str(e)
        
        return config
    
    def _collect_layout_mapping(self, transpiled_circuits) -> List[Dict]:
        """Collecte le mapping des qubits virtuels â†’ physiques."""
        if not transpiled_circuits:
            return []
        
        mappings = []
        
        for i, circuit in enumerate(transpiled_circuits):
            mapping = {
                'circuit_index': i,
                'initial_layout': None,
                'final_layout': None,
                'virtual_to_physical': {},
            }
            
            try:
                if hasattr(circuit, '_layout') and circuit._layout:
                    layout = circuit._layout
                    
                    if hasattr(layout, 'initial_layout') and layout.initial_layout:
                        mapping['initial_layout'] = str(layout.initial_layout)
                        
                        # Extraire le mapping vâ†’p
                        try:
                            for virt_qubit, phys_qubit in layout.initial_layout.get_virtual_bits().items():
                                if hasattr(virt_qubit, '_index'):
                                    mapping['virtual_to_physical'][virt_qubit._index] = phys_qubit
                        except:
                            pass
                    
                    if hasattr(layout, 'final_index_layout'):
                        mapping['final_layout'] = list(layout.final_index_layout())
                        
            except:
                pass
            
            mappings.append(mapping)
        
        return mappings
    
    def _collect_sampler_options(self) -> Dict:
        """Collecte les options du Sampler IBM."""
        options = {
            'available': False,
            'resilience_level': None,
            'optimization_level': None,
            'dynamical_decoupling': {},
            'twirling': {},
            'execution': {},
        }
        
        if not self.framework:
            return options
        
        try:
            if hasattr(self.framework, 'error_mitigation') and self.framework.error_mitigation:
                em = self.framework.error_mitigation
                options['available'] = True
                
                if hasattr(em, 'config'):
                    cfg = em.config
                    options['resilience_level'] = getattr(cfg, 'resilience_level', None)
                    options['optimization_level'] = getattr(cfg, 'optimization_level', None)
                    
                    if hasattr(cfg, 'dd_enabled'):
                        options['dynamical_decoupling'] = {
                            'enabled': cfg.dd_enabled,
                            'sequence': getattr(cfg, 'dd_sequence', None),
                        }
                    
                    if hasattr(cfg, 'twirling_enabled'):
                        options['twirling'] = {
                            'enabled': cfg.twirling_enabled,
                            'strategy': getattr(cfg, 'twirling_strategy', None),
                            'num_randomizations': getattr(cfg, 'twirling_num_randomizations', None),
                        }
        except:
            pass
        
        return options
    
    def _collect_job_metadata(self, run_context: Dict) -> Dict:
        """Collecte les mÃ©tadonnÃ©es du job IBM."""
        metadata = {
            'job_id': run_context.get('job_id') if run_context else None,
            'creation_date': None,
            'tags': [],
            'session_id': None,
            'backend_options': {},
            'header': {},
        }
        
        # Les mÃ©tadonnÃ©es complÃ¨tes seraient rÃ©cupÃ©rÃ©es du job IBM si disponible
        # Pour l'instant on stocke ce qui est dans run_context
        if run_context:
            metadata['submitted_at'] = run_context.get('submitted_at')
            metadata['completed_at'] = run_context.get('completed_at')
            metadata['status'] = run_context.get('status')
        
        return metadata
    
    def _collect_raw_memory(self, results: List[Dict]) -> List[Dict]:
        """
        Collecte la mÃ©moire brute (shots individuels).
        
        IMPORTANT: Cette section peut Ãªtre trÃ¨s volumineuse!
        Pour 4096 shots Ã— 50 qubits = ~200KB par circuit
        """
        if not results:
            return []
        
        raw_memory = []
        
        for i, r in enumerate(results):
            if not isinstance(r, dict):
                continue
            
            memory_data = {
                'circuit_index': i,
                'has_memory': False,
                'memory': None,
                'memory_size': 0,
            }
            
            # La mÃ©moire brute est parfois disponible dans les rÃ©sultats
            if 'memory' in r and r['memory']:
                memory_data['has_memory'] = True
                memory_data['memory'] = r['memory']
                memory_data['memory_size'] = len(r['memory'])
            
            raw_memory.append(memory_data)
        
        return raw_memory
    
    def _collect_session_logs(self) -> List[Dict]:
        """Collecte les logs de la session."""
        logs = []
        
        if not self.framework:
            return logs
        
        try:
            if hasattr(self.framework, 'logger') and self.framework.logger:
                logger = self.framework.logger
                
                # RÃ©cupÃ©rer les derniers logs si disponibles
                if hasattr(logger, '_log_buffer'):
                    for entry in logger._log_buffer[-100:]:  # Max 100 derniers
                        logs.append({
                            'timestamp': entry.get('timestamp'),
                            'level': entry.get('level'),
                            'section': entry.get('section'),
                            'message': entry.get('message'),
                        })
        except:
            pass
        
        return logs
    
    def _collect_warnings(self) -> List[Dict]:
        """Collecte les warnings rencontrÃ©s."""
        warnings_list = []
        
        if not self.framework:
            return warnings_list
        
        try:
            if hasattr(self.framework, '_warnings') and self.framework._warnings:
                for w in self.framework._warnings[-50:]:  # Max 50
                    warnings_list.append({
                        'timestamp': w.get('timestamp'),
                        'type': w.get('type'),
                        'message': w.get('message'),
                        'context': w.get('context'),
                    })
        except:
            pass
        
        return warnings_list
    
    def _collect_estimates(self, circuits, run_context: Dict) -> Dict:
        """Collecte les estimations prÃ©-exÃ©cution."""
        estimates = {
            'estimated_qpu_time_s': None,
            'estimated_queue_time_s': None,
            'estimated_cost_minutes': None,
            'circuit_complexity_scores': [],
        }
        
        if not self.framework or not circuits:
            return estimates
        
        try:
            # Estimations de coÃ»t si disponibles
            if hasattr(self.framework, 'circuit_cost_estimator') and self.framework.circuit_cost_estimator:
                est = self.framework.circuit_cost_estimator
                shots = run_context.get('shots', 4096) if run_context else 4096
                
                if hasattr(est, 'estimate'):
                    result = est.estimate(circuits, shots)
                    estimates['estimated_qpu_time_s'] = result.get('estimated_qpu_time_s')
                    estimates['estimated_cost_minutes'] = result.get('estimated_minutes')
            
            # Scores de complexitÃ© par circuit
            if hasattr(self.framework, 'circuit_profiler') and self.framework.circuit_profiler:
                profiler = self.framework.circuit_profiler
                for i, c in enumerate(circuits[:10]):  # Max 10
                    try:
                        profile = profiler.profile(c)
                        estimates['circuit_complexity_scores'].append({
                            'index': i,
                            'complexity_score': profile.get('complexity_score'),
                            'depth': profile.get('depth'),
                            'gate_count': profile.get('gate_count'),
                        })
                    except:
                        pass
        except:
            pass
        
        return estimates
    
    def _get_hostname(self) -> str:
        """RÃ©cupÃ¨re le nom de la machine."""
        try:
            import socket
            return socket.gethostname()
        except:
            return 'unknown'
    
    def _collect_backend_info(self) -> Dict:
        """Collecte les informations du backend."""
        info = {
            'name': None,
            'version': None,
            'num_qubits': None,
            'basis_gates': [],
            'max_circuits': None,
            'max_shots': None,
            'coupling_map_size': None,
            'processor_type': None,
            'online': None,
        }
        
        if not self.framework:
            return info
        
        backend = getattr(self.framework, 'backend', None)
        if not backend:
            info['name'] = getattr(self.framework, 'backend_name', 'N/A')
            return info
        
        try:
            info['name'] = getattr(backend, 'name', str(backend))
            info['version'] = getattr(backend, 'version', None)
            
            if hasattr(backend, 'target') and backend.target:
                target = backend.target
                info['num_qubits'] = target.num_qubits
                info['basis_gates'] = list(target.operation_names) if hasattr(target, 'operation_names') else []
                
                if hasattr(target, 'build_coupling_map'):
                    cm = target.build_coupling_map()
                    if cm:
                        info['coupling_map_size'] = len(cm.get_edges())
            
            if hasattr(backend, 'max_circuits'):
                info['max_circuits'] = backend.max_circuits
            
            if hasattr(backend, 'configuration'):
                config = backend.configuration()
                if config:
                    info['max_shots'] = getattr(config, 'max_shots', None)
                    info['processor_type'] = getattr(config, 'processor_type', None)
            
            if hasattr(backend, 'status'):
                try:
                    status = backend.status()
                    info['online'] = getattr(status, 'operational', None)
                except:
                    pass
                    
        except Exception as e:
            info['error'] = str(e)
        
        return info
    
    def _collect_full_calibration(self) -> Dict:
        """Collecte la calibration COMPLÃˆTE du QPU."""
        calib = {
            'available': False,
            'timestamp': None,
            'num_qubits': 0,
            'qubits': [],
            'gates_1q': [],
            'gates_2q': [],
            'coupling_map': [],
            'summary': {},
        }
        
        if not self.framework:
            return calib
        
        backend = getattr(self.framework, 'backend', None)
        if not backend:
            return calib
        
        try:
            calib['available'] = True
            
            # Via backend.target (Qiskit moderne)
            if hasattr(backend, 'target') and backend.target:
                target = backend.target
                calib['num_qubits'] = target.num_qubits
                
                t1_values, t2_values, readout_errors = [], [], []
                
                # Collecter TOUS les qubits
                for qubit in range(target.num_qubits):
                    q_data = {
                        'index': qubit,
                        't1_us': None,
                        't2_us': None,
                        'frequency_ghz': None,
                        'anharmonicity_ghz': None,
                        'readout_error_pct': None,
                        'readout_length_ns': None,
                        'prob_meas0_prep1': None,
                        'prob_meas1_prep0': None,
                    }
                    
                    try:
                        if hasattr(target, 'qubit_properties') and target.qubit_properties:
                            props = target.qubit_properties[qubit]
                            if props:
                                if hasattr(props, 't1') and props.t1:
                                    q_data['t1_us'] = round(props.t1 * 1e6, 2)
                                    t1_values.append(props.t1 * 1e6)
                                if hasattr(props, 't2') and props.t2:
                                    q_data['t2_us'] = round(props.t2 * 1e6, 2)
                                    t2_values.append(props.t2 * 1e6)
                                if hasattr(props, 'frequency') and props.frequency:
                                    q_data['frequency_ghz'] = round(props.frequency / 1e9, 4)
                    except:
                        pass
                    
                    # Erreur de mesure
                    try:
                        measure_props = target.get('measure', (qubit))
                        if measure_props:
                            if hasattr(measure_props, 'error') and measure_props.error:
                                q_data['readout_error_pct'] = round(measure_props.error * 100, 4)
                                readout_errors.append(measure_props.error * 100)
                            if hasattr(measure_props, 'duration') and measure_props.duration:
                                q_data['readout_length_ns'] = round(measure_props.duration * 1e9, 1)
                    except:
                        pass
                    
                    calib['qubits'].append(q_data)
                
                # Gates 1-qubit
                for gate_name in ['sx', 'x', 'rz', 'id']:
                    if gate_name in target.operation_names:
                        for qargs in target.qargs_for_operation_name(gate_name):
                            if len(qargs) == 1:
                                try:
                                    gate_props = target.get(gate_name, qargs)
                                    if gate_props:
                                        calib['gates_1q'].append({
                                            'gate': gate_name,
                                            'qubit': qargs[0],
                                            'error_pct': round(gate_props.error * 100, 4) if gate_props.error else None,
                                            'duration_ns': round(gate_props.duration * 1e9, 1) if gate_props.duration else None,
                                        })
                                except:
                                    pass
                
                # Gates 2-qubit
                cx_errors = []
                for gate_name in ['cx', 'ecr', 'cz', 'rzz']:
                    if gate_name in target.operation_names:
                        for qargs in target.qargs_for_operation_name(gate_name):
                            if len(qargs) == 2:
                                try:
                                    gate_props = target.get(gate_name, qargs)
                                    if gate_props:
                                        error_pct = round(gate_props.error * 100, 4) if gate_props.error else None
                                        if error_pct:
                                            cx_errors.append(error_pct)
                                        calib['gates_2q'].append({
                                            'gate': gate_name,
                                            'qubits': list(qargs),
                                            'error_pct': error_pct,
                                            'duration_ns': round(gate_props.duration * 1e9, 1) if gate_props.duration else None,
                                        })
                                except:
                                    pass
                
                # Coupling map
                if hasattr(target, 'build_coupling_map'):
                    cm = target.build_coupling_map()
                    if cm:
                        calib['coupling_map'] = [list(edge) for edge in cm.get_edges()]
                
                # Summary
                calib['summary'] = {
                    'total_qubits': target.num_qubits,
                    'avg_t1_us': round(sum(t1_values) / len(t1_values), 2) if t1_values else None,
                    'avg_t2_us': round(sum(t2_values) / len(t2_values), 2) if t2_values else None,
                    'min_t1_us': round(min(t1_values), 2) if t1_values else None,
                    'max_t1_us': round(max(t1_values), 2) if t1_values else None,
                    'avg_readout_error_pct': round(sum(readout_errors) / len(readout_errors), 4) if readout_errors else None,
                    'total_1q_gates': len(calib['gates_1q']),
                    'total_2q_gates': len(calib['gates_2q']),
                    'avg_2q_error_pct': round(sum(cx_errors) / len(cx_errors), 4) if cx_errors else None,
                    'min_2q_error_pct': round(min(cx_errors), 4) if cx_errors else None,
                    'max_2q_error_pct': round(max(cx_errors), 4) if cx_errors else None,
                    'coupling_map_edges': len(calib['coupling_map']),
                }
                
        except Exception as e:
            calib['error'] = str(e)
        
        return calib
    
    def _collect_circuits_info(self, circuits, prefix: str = '') -> List[Dict]:
        """Collecte les informations des circuits."""
        if not circuits:
            return []
        
        circuits_info = []
        
        for i, circuit in enumerate(circuits):
            try:
                c_info = {
                    'index': i,
                    'name': getattr(circuit, 'name', f'{prefix}_{i}'),
                    'num_qubits': circuit.num_qubits,
                    'num_clbits': circuit.num_clbits,
                    'depth': circuit.depth(),
                    'size': circuit.size(),
                    'width': circuit.width(),
                    'num_parameters': circuit.num_parameters,
                    'global_phase': str(circuit.global_phase),
                    
                    # Analyse des gates
                    'gate_counts': dict(circuit.count_ops()),
                    'num_1q_gates': sum(1 for inst in circuit.data if len(inst.qubits) == 1),
                    'num_2q_gates': sum(1 for inst in circuit.data if len(inst.qubits) == 2),
                    'num_3q_plus_gates': sum(1 for inst in circuit.data if len(inst.qubits) >= 3),
                    
                    # Qubits utilisÃ©s
                    'qubits_used': sorted(list(set(
                        q._index if hasattr(q, '_index') else i 
                        for inst in circuit.data 
                        for i, q in enumerate(inst.qubits)
                    ))),
                    
                    # Layout si disponible
                    'layout': None,
                    
                    # QASM (limitÃ© Ã  50KB par circuit)
                    'qasm': None,
                }
                
                # Layout aprÃ¨s transpilation
                if hasattr(circuit, '_layout') and circuit._layout:
                    try:
                        layout = circuit._layout
                        if hasattr(layout, 'final_index_layout'):
                            c_info['layout'] = {
                                'final_layout': list(layout.final_index_layout()),
                            }
                        if hasattr(layout, 'initial_layout'):
                            c_info['layout'] = c_info.get('layout', {})
                            c_info['layout']['initial_layout'] = str(layout.initial_layout)
                    except:
                        pass
                
                # QASM (limitÃ© pour Ã©viter fichiers trop gros)
                try:
                    from qiskit.qasm2 import dumps as qasm2_dumps
                    qasm_str = qasm2_dumps(circuit)
                    if len(qasm_str) < 50000:  # Max 50KB par circuit
                        c_info['qasm'] = qasm_str
                    else:
                        c_info['qasm'] = f"[TRUNCATED - {len(qasm_str)} bytes]"
                except:
                    try:
                        qasm_str = circuit.qasm()
                        if len(qasm_str) < 50000:
                            c_info['qasm'] = qasm_str
                    except:
                        pass
                
                circuits_info.append(c_info)
                
            except Exception as e:
                circuits_info.append({
                    'index': i,
                    'error': str(e)
                })
        
        return circuits_info
    
    def _collect_transpilation_config(self, run_context: Dict) -> Dict:
        """Collecte la configuration de transpilation."""
        config = {
            'optimization_level': run_context.get('optimization_level', 3) if run_context else 3,
            'layout_strategy': run_context.get('layout_strategy', 'none') if run_context else 'none',
            'routing_method': None,
            'translation_method': None,
            'scheduling_method': None,
            'approximation_degree': None,
            'seed_transpiler': None,
        }
        
        if self.framework:
            # RÃ©cupÃ©rer depuis le framework si disponible
            if hasattr(self.framework, 'transpile_options'):
                opts = self.framework.transpile_options
                if isinstance(opts, dict):
                    config.update({
                        'routing_method': opts.get('routing_method'),
                        'translation_method': opts.get('translation_method'),
                        'scheduling_method': opts.get('scheduling_method'),
                        'approximation_degree': opts.get('approximation_degree'),
                        'seed_transpiler': opts.get('seed_transpiler'),
                    })
        
        return config
    
    def _collect_mitigation_config(self) -> Dict:
        """Collecte la configuration de mitigation d'erreurs."""
        config = {
            'enabled': False,
            'twirling': {'enabled': False},
            'dynamical_decoupling': {'enabled': False},
            'zne': {'enabled': False},
            'measurement_error_mitigation': {'enabled': False},
        }
        
        if not self.framework:
            return config
        
        if hasattr(self.framework, 'error_mitigation') and self.framework.error_mitigation:
            em = self.framework.error_mitigation
            config['enabled'] = True
            
            try:
                summary = em.get_summary() if hasattr(em, 'get_summary') else {}
                
                if 'twirling' in summary:
                    config['twirling'] = {
                        'enabled': summary['twirling'].get('enabled', False),
                        'strategy': summary['twirling'].get('strategy'),
                        'num_randomizations': summary['twirling'].get('num_randomizations'),
                    }
                
                if 'dynamical_decoupling' in summary:
                    config['dynamical_decoupling'] = {
                        'enabled': summary['dynamical_decoupling'].get('enabled', False),
                        'sequence': summary['dynamical_decoupling'].get('sequence'),
                    }
                    
            except:
                pass
        
        return config
    
    def _collect_execution_info(self, run_context: Dict) -> Dict:
        """Collecte les informations d'exÃ©cution."""
        ctx = run_context or {}
        
        return {
            'job_id': ctx.get('job_id'),
            'shots': ctx.get('shots', 0),
            'circuits_count': ctx.get('circuits_count', 0),
            
            # Timing dÃ©taillÃ©
            'timing': {
                'total_time_s': ctx.get('total_time_s', 0),
                'queue_time_s': ctx.get('queue_time_s', 0),
                'execution_time_s': ctx.get('execution_time_s', 0),
                'qpu_time_s': ctx.get('qpu_time_s', 0),
                'transpile_time_s': ctx.get('transpile_time_s', 0),
            },
            
            # Timestamps
            'submitted_at': ctx.get('submitted_at'),
            'completed_at': ctx.get('completed_at'),
            
            # Status
            'status': ctx.get('status', 'UNKNOWN'),
        }
    
    def _collect_results(self, results: List[Dict]) -> List[Dict]:
        """Collecte les rÃ©sultats COMPLETS."""
        if not results:
            return []
        
        collected = []
        
        for i, r in enumerate(results):
            if not isinstance(r, dict):
                collected.append({'index': i, 'error': 'Invalid result format'})
                continue
            
            counts = r.get('counts', {})
            total_shots = sum(counts.values()) if counts else 0
            
            result_data = {
                'index': i,
                'shots': r.get('shots', total_shots),
                'num_outcomes': len(counts),
                
                # Counts complets (tous les bitstrings)
                'counts': counts,
                
                # ProbabilitÃ©s
                'probabilities': {k: v / total_shots for k, v in counts.items()} if total_shots > 0 else {},
                
                # Top 10 bitstrings
                'top_10': sorted(
                    [{'bitstring': k, 'count': v, 'probability': v / total_shots if total_shots > 0 else 0}
                     for k, v in counts.items()],
                    key=lambda x: x['count'],
                    reverse=True
                )[:10],
                
                # MÃ©tadonnÃ©es du circuit si prÃ©sentes
                'circuit_depth': r.get('depth'),
                'circuit_name': r.get('name'),
                'fidelity': r.get('fidelity'),
                
                # MÃ©moire brute si disponible
                'memory': r.get('memory'),  # Liste des shots individuels
            }
            
            collected.append(result_data)
        
        return collected
    
    def _compute_statistics(self, results: List[Dict]) -> Dict:
        """Calcule les statistiques avancÃ©es."""
        stats = {
            'global': {},
            'per_circuit': [],
        }
        
        if not results:
            return stats
        
        entropies = []
        uniformities = []
        top_probs = []
        
        for i, r in enumerate(results):
            if not isinstance(r, dict):
                continue
            
            counts = r.get('counts', {})
            if not counts:
                continue
            
            total = sum(counts.values())
            n_outcomes = len(counts)
            n_qubits = len(list(counts.keys())[0]) if counts else 0
            max_possible_outcomes = 2 ** n_qubits if n_qubits > 0 else 1
            
            # Entropie de Shannon
            entropy = 0
            for count in counts.values():
                if count > 0:
                    p = count / total
                    entropy -= p * math.log2(p)
            
            max_entropy = math.log2(n_outcomes) if n_outcomes > 1 else 1
            uniformity = (entropy / max_entropy * 100) if max_entropy > 0 else 0
            
            # Distribution
            sorted_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)
            top_prob = (sorted_counts[0][1] / total * 100) if sorted_counts else 0
            
            # Statistiques par circuit
            circuit_stats = {
                'index': i,
                'shots': total,
                'unique_outcomes': n_outcomes,
                'max_possible_outcomes': max_possible_outcomes,
                'outcome_ratio': n_outcomes / max_possible_outcomes if max_possible_outcomes > 0 else 0,
                
                # Entropie
                'entropy_bits': round(entropy, 4),
                'max_entropy_bits': round(max_entropy, 4),
                'uniformity_pct': round(uniformity, 2),
                
                # Distribution
                'top_bitstring': sorted_counts[0][0] if sorted_counts else None,
                'top_probability_pct': round(top_prob, 2),
                'bottom_probability_pct': round(sorted_counts[-1][1] / total * 100, 4) if sorted_counts else 0,
                
                # Moments statistiques
                'mean_count': round(total / n_outcomes, 2) if n_outcomes > 0 else 0,
                'std_count': round(
                    math.sqrt(sum((c - total/n_outcomes)**2 for c in counts.values()) / n_outcomes), 2
                ) if n_outcomes > 1 else 0,
            }
            
            stats['per_circuit'].append(circuit_stats)
            entropies.append(entropy)
            uniformities.append(uniformity)
            top_probs.append(top_prob)
        
        # Statistiques globales
        if entropies:
            stats['global'] = {
                'total_circuits': len(results),
                'total_shots': sum(sum(r.get('counts', {}).values()) for r in results if isinstance(r, dict)),
                'avg_entropy_bits': round(sum(entropies) / len(entropies), 4),
                'min_entropy_bits': round(min(entropies), 4),
                'max_entropy_bits': round(max(entropies), 4),
                'avg_uniformity_pct': round(sum(uniformities) / len(uniformities), 2),
                'avg_top_probability_pct': round(sum(top_probs) / len(top_probs), 2),
            }
        
        return stats
    
    def _collect_error_info(self, error: Exception) -> Dict:
        """Collecte les informations d'erreur."""
        return {
            'type': type(error).__name__,
            'message': str(error),
            'traceback': traceback.format_exc(),
            'args': [str(arg) for arg in error.args] if hasattr(error, 'args') else [],
        }


# =============================================================================
# v2.5.17 - AUTO REPORT GENERATOR (ULTRA-COMPLET)
# =============================================================================

class AutoReportGenerator:
    """
    [v2.5.21] GÃ©nÃ©rateur de rapports HTML ULTRA-COMPLETS automatique.
    
    GÃ©nÃ¨re automatiquement aprÃ¨s chaque run_on_qpu() un rapport contenant:
    - RÃ©sumÃ© exÃ©cutif avec statut SUCCESS/ERROR
    - Configuration complÃ¨te (shots, circuits, backend, options)
    - Calibration du backend (T1, T2, erreurs, qubits utilisÃ©s)
    - RÃ©sultats dÃ©taillÃ©s par circuit avec distributions
    - Statistiques avancÃ©es (entropie, uniformitÃ©, top bitstrings)
    - Graphiques interactifs (Chart.js)
    - Timeline d'exÃ©cution (QUEUED â†’ RUNNING â†’ DONE)
    - Erreurs rencontrÃ©es avec diagnostic
    - Export JSON des donnÃ©es brutes
    - [v2.5.21] Visualisations Qiskit natives (histogrammes, gate_map, error_map)
    
    ACTIVATION AUTOMATIQUE:
        Par dÃ©faut, run_on_qpu() gÃ©nÃ¨re le rapport. Pour dÃ©sactiver:
        results = fw.run_on_qpu(circuits, generate_report=False)
    
    Usage manuel:
        report_path = fw.report_generator.generate(results, run_context)
    """
    
    def __init__(self, framework: 'QMCFramework' = None, 
                 output_dir: str = None,
                 logger: Logger = None):
        """
        Args:
            framework: Instance QMCFramework pour mÃ©tadonnÃ©es et calibration
            output_dir: RÃ©pertoire de sortie (optionnel, dÃ©faut: rÃ©pertoire du framework)
            logger: Logger pour les messages
        """
        self.framework = framework
        self.output_dir = Path(output_dir) if output_dir else None
        self.logger = logger or (framework.logger if framework else None)
        self._last_report_path = None
        
        # v2.5.21: IntÃ©gration QiskitVisualizationWrapper
        self._qiskit_viz = None  # InitialisÃ© paresseusement
    
    def _get_qiskit_viz(self) -> QiskitVisualizationWrapper:
        """Retourne le wrapper de visualisation Qiskit (lazy init)."""
        if self._qiskit_viz is None:
            out_dir = self._get_output_dir()
            self._qiskit_viz = QiskitVisualizationWrapper(output_dir=out_dir)
        return self._qiskit_viz
    
    def _log(self, msg: str, level: LogLevel = LogLevel.INFO):
        if self.logger:
            self.logger.log(msg, level, section='REPORT')
        else:
            print(f"[REPORT] {msg}")
    
    # v2.5.21: Nouvelle mÃ©thode pour gÃ©nÃ©rer des visualisations Qiskit
    def generate_qiskit_visualizations(self, results: List[Dict] = None,
                                        backend = None,
                                        output_dir: Path = None) -> Dict[str, Path]:
        """
        GÃ©nÃ¨re des visualisations Qiskit pour le rapport (v2.5.21).
        
        Args:
            results: RÃ©sultats avec counts
            backend: Backend IBM pour gate_map/error_map
            output_dir: RÃ©pertoire de sortie
            
        Returns:
            Dict avec les paths des fichiers gÃ©nÃ©rÃ©s
        """
        out_dir = Path(output_dir) if output_dir else self._get_output_dir()
        out_dir.mkdir(parents=True, exist_ok=True)
        
        viz = QiskitVisualizationWrapper(output_dir=out_dir)
        generated = {}
        
        # Histogrammes des counts - [v2.5.21] Limiter Ã  10 circuits max pour performance
        if results:
            max_histograms = min(10, len(results))  # Max 10 histogrammes
            for i, result in enumerate(results[:max_histograms]):
                counts = result.get('counts', {})
                if counts:
                    try:
                        filename = f"histogram_circuit_{i}.png"
                        # v2.5.21: Ajouter info sur le filtrage dans le titre
                        n_states = len(counts)
                        total_shots = sum(counts.values())
                        title = f"Circuit {i} Results (Top 25/{n_states} states, {total_shots} shots)"
                        
                        fig = viz.plot_histogram(
                            counts, 
                            title=title,
                            filename=filename,
                            max_bars=25,        # Limiter Ã  25 barres
                            show_others=True    # Montrer "Others" pour le reste
                        )
                        if fig:
                            generated[f'histogram_{i}'] = out_dir / filename
                            try:
                                import matplotlib.pyplot as plt
                                plt.close(fig)
                            except:
                                pass
                    except Exception as e:
                        self._log(f"Histogram {i} generation failed: {e}", LogLevel.WARN)
        
        # Gate map et error map du backend
        if backend:
            try:
                fig = viz.plot_gate_map(backend, filename="backend_gate_map.png")
                if fig:
                    generated['gate_map'] = out_dir / "backend_gate_map.png"
                    try:
                        import matplotlib.pyplot as plt
                        plt.close(fig)
                    except:
                        pass
            except Exception as e:
                self._log(f"Gate map generation failed: {e}", LogLevel.WARN)
            
            try:
                fig = viz.plot_error_map(backend, filename="backend_error_map.png")
                if fig:
                    generated['error_map'] = out_dir / "backend_error_map.png"
                    try:
                        import matplotlib.pyplot as plt
                        plt.close(fig)
                    except:
                        pass
            except Exception as e:
                self._log(f"Error map generation failed: {e}", LogLevel.WARN)
        
        if generated:
            self._log(f"Generated {len(generated)} Qiskit visualizations")
        
        return generated
    
    def generate(self, 
                 results: List[Dict] = None,
                 run_context: Dict = None,
                 error: Exception = None,
                 title: str = None,
                 transpiled_circuits: List = None,
                 include_qiskit_viz: bool = True) -> Path:
        """
        GÃ©nÃ¨re un rapport HTML ultra-complet.
        
        Args:
            results: Liste des rÃ©sultats de run_on_qpu
            run_context: Contexte d'exÃ©cution (shots, backend, timing, etc.)
            error: Exception si erreur pendant l'exÃ©cution
            title: Titre personnalisÃ© (optionnel)
            transpiled_circuits: [v2.5.18] Circuits transpilÃ©s pour visualisation
            include_qiskit_viz: [v2.5.21] GÃ©nÃ©rer visualisations Qiskit (dÃ©faut: True)
            
        Returns:
            Path vers le fichier HTML gÃ©nÃ©rÃ©
        """
        # [v2.5.18] Stocker les circuits pour _collect_all_data
        self._transpiled_circuits = transpiled_circuits
        
        # Collecter toutes les donnÃ©es
        data = self._collect_all_data(results, run_context, error)
        
        # [v2.5.21] GÃ©nÃ©rer visualisations Qiskit si demandÃ©
        if include_qiskit_viz and results:
            try:
                backend = getattr(self.framework, 'backend', None) if self.framework else None
                qiskit_viz_files = self.generate_qiskit_visualizations(results, backend)
                data['qiskit_visualizations'] = {k: str(v) for k, v in qiskit_viz_files.items()}
            except Exception as e:
                self._log(f"Qiskit visualizations failed: {e}", LogLevel.WARN)
                data['qiskit_visualizations'] = {}
        
        # GÃ©nÃ©rer le titre
        if not title:
            status = "ERROR" if error else "SUCCESS"
            project = data.get('project', 'QMC')
            title = f"QMC Report - {project} - {status}"
        
        # GÃ©nÃ©rer le HTML (template professionnel v2.0)
        html = self._generate_professional_html(data, title)
        
        # DÃ©terminer le rÃ©pertoire de sortie
        output_dir = self._get_output_dir()
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Nom du fichier
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        status_tag = "ERROR" if error else "OK"
        filename = f"report_{timestamp}_{status_tag}.html"
        filepath = output_dir / filename
        
        # Sauvegarder
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(html)
        
        self._last_report_path = filepath
        self._log(f"Report generated: {filepath}")
        
        # Sauvegarder aussi les donnÃ©es JSON (sans les images base64 pour Ã©viter fichier Ã©norme)
        json_path = output_dir / f"report_{timestamp}_{status_tag}_data.json"
        try:
            # CrÃ©er une copie sans les images base64
            data_for_json = {k: v for k, v in data.items() if k != 'circuit_images'}
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(data_for_json, f, indent=2, default=str)
        except Exception as e:
            self._log(f"Warning: JSON export failed: {e}", LogLevel.WARN)
        
        # Nettoyer
        self._transpiled_circuits = None
        
        return filepath
    
    def _get_output_dir(self) -> Path:
        """Retourne le rÃ©pertoire de sortie."""
        # PrioritÃ©: output_dir explicite > framework.dir_manager > dÃ©faut
        if self.output_dir:
            return self.output_dir
        if self.framework and hasattr(self.framework, 'dir_manager') and self.framework.dir_manager:
            return self.framework.dir_manager.run_dir
        return Path('qmc_reports')
    
    def _collect_all_data(self, results: List[Dict], run_context: Dict, error: Exception) -> Dict:
        """Collecte TOUTES les donnÃ©es pour le rapport."""
        data = {
            # MÃ©tadonnÃ©es
            'generated_at': datetime.now().isoformat(),
            'framework_version': __version__,
            'python_version': sys.version.split()[0],
            'status': 'ERROR' if error else 'SUCCESS',
            
            # Projet
            'project': getattr(self.framework, 'project', 'QMC') if self.framework else 'QMC',
            'backend_name': getattr(self.framework, 'backend_name', 'N/A') if self.framework else 'N/A',
            
            # Contexte d'exÃ©cution
            'run_context': run_context or {},
            
            # RÃ©sultats
            'results': results or [],
            'results_count': len(results) if results else 0,
            
            # Erreur si prÃ©sente
            'error': None,
            
            # Sections Ã  remplir
            'summary': {},
            'calibration': {},
            'statistics': {},
            'timing': {},
            'charts_data': {},
        }
        
        # Extraire les infos d'erreur
        if error:
            data['error'] = {
                'type': type(error).__name__,
                'message': str(error),
                'traceback': traceback.format_exc() if error else None
            }
        
        # Extraire du run_context
        ctx = run_context or {}
        data['timing'] = {
            'total_time_s': ctx.get('total_time_s', 0),
            'queue_time_s': ctx.get('queue_time_s', 0),
            'execution_time_s': ctx.get('execution_time_s', 0),
            'qpu_time_s': ctx.get('qpu_time_s', 0),
            'transpile_time_s': ctx.get('transpile_time_s', 0),
        }
        
        data['run_context'] = {
            'shots': ctx.get('shots', 0),
            'circuits_count': ctx.get('circuits_count', len(results) if results else 0),
            'optimization_level': ctx.get('optimization_level', 3),
            'layout_strategy': ctx.get('layout_strategy', 'auto'),
            'job_id': ctx.get('job_id', 'N/A'),
            'submitted_at': ctx.get('submitted_at', 'N/A'),
            'completed_at': ctx.get('completed_at', 'N/A'),
        }
        
        # [v2.5.18] Collecter les infos de transpilation
        data['transpilation'] = self._collect_transpilation_data()
        
        # [v2.5.18] Collecter la liste des fichiers gÃ©nÃ©rÃ©s
        data['files'] = self._collect_generated_files()
        
        # [v2.5.18] Collecter les dÃ©tails des circuits
        data['circuits_details'] = self._collect_circuits_details()
        
        # [v2.5.21] GÃ©nÃ©rer les visualisations des circuits (images base64)
        # GÃ©nÃ©rer TOUTES les images (pas de limite)
        n_circuits = len(data['circuits_details']) if data['circuits_details'] else 0
        data['circuit_images'] = self._generate_circuit_images(max_circuits=n_circuits)
        
        # [v2.5.18] GÃ©nÃ©rer les visualisations Qiskit professionnelles
        data['qiskit_visualizations'] = self._generate_qiskit_visualizations(results)
        
        # Collecter la calibration du backend
        data['calibration'] = self._collect_calibration_data()
        
        # Calculer les statistiques des rÃ©sultats
        if results:
            data['summary'] = self._calculate_summary(results)
            data['statistics'] = self._calculate_statistics(results)
            data['charts_data'] = self._prepare_charts_data(results)
        
        return data
    
    def _collect_transpilation_data(self) -> Dict:
        """[v2.5.18] Collecte les donnÃ©es de transpilation."""
        trans = {
            'available': False,
            'score': None,
            'recommendation': None,
            'overhead_2q_percent': None,
            'swaps_estimated': None,
            'depth_expansion': None,
            'before': {},
            'after': {},
        }
        
        if not self.framework:
            return trans
        
        # RÃ©cupÃ©rer les stats de transpilation du framework
        stats = getattr(self.framework, '_last_transpilation_stats', None)
        if stats:
            trans['available'] = True
            trans['score'] = stats.get('score')
            trans['recommendation'] = stats.get('recommendation')
            trans['overhead_2q_percent'] = stats.get('overhead_2q_percent')
            trans['swaps_estimated'] = stats.get('swaps_estimated')
            trans['depth_expansion'] = stats.get('depth_expansion')
            trans['before'] = stats.get('before', {})
            trans['after'] = stats.get('after', {})
        
        return trans
    
    def _collect_generated_files(self) -> List[Dict]:
        """[v2.5.18] Collecte la liste des fichiers gÃ©nÃ©rÃ©s dans le rÃ©pertoire."""
        files = []
        
        if not self.framework:
            return files
        
        # RÃ©cupÃ©rer le rÃ©pertoire de sortie
        run_dir = self._get_output_dir()
        if not run_dir or not run_dir.exists():
            return files
        
        try:
            for filepath in run_dir.iterdir():
                if filepath.is_file():
                    stat = filepath.stat()
                    files.append({
                        'name': filepath.name,
                        'path': str(filepath),
                        'size_kb': round(stat.st_size / 1024, 1),
                        'extension': filepath.suffix.lower(),
                        'modified': datetime.fromtimestamp(stat.st_mtime).strftime('%H:%M:%S'),
                        'type': self._get_file_type(filepath.suffix.lower()),
                    })
        except Exception:
            pass
        
        # Trier par type puis par nom
        files.sort(key=lambda x: (x['type'], x['name']))
        return files
    
    def _get_file_type(self, extension: str) -> str:
        """Retourne le type de fichier basÃ© sur l'extension."""
        types = {
            '.html': 'report',
            '.json': 'data',
            '.log': 'log',
            '.txt': 'text',
            '.csv': 'data',
            '.png': 'image',
            '.pdf': 'document',
            '.qasm': 'circuit',
            '.qpy': 'circuit',
        }
        return types.get(extension, 'other')
    
    def _collect_circuits_details(self) -> List[Dict]:
        """[v2.5.18] Collecte les dÃ©tails de tous les circuits transpilÃ©s."""
        circuits = []
        
        if not self.framework:
            return circuits
        
        # RÃ©cupÃ©rer les infos depuis le rapport interne du framework
        report = getattr(self.framework, 'report', None)
        if report:
            transpiled_info = report.get('circuits_transpiled', section='transpilation')
            if transpiled_info:
                return transpiled_info
        
        # Fallback: lire depuis le fichier circuits.json si disponible
        run_dir = self._get_output_dir()
        circuits_file = run_dir / 'circuits.json' if run_dir else None
        if circuits_file and circuits_file.exists():
            try:
                with open(circuits_file) as f:
                    data = json.load(f)
                    return data.get('circuits', [])
            except Exception:
                pass
        
        return circuits

    def _generate_circuit_images(self, max_circuits: int = None, max_depth: int = 50) -> List[Dict]:
        """
        [v2.5.21] GÃ©nÃ¨re les visualisations des circuits en base64.
        
        Utilise Qiskit draw('mpl') pour crÃ©er des images PNG des circuits,
        puis les encode en base64 pour intÃ©gration directe dans le HTML.
        
        Args:
            max_circuits: Nombre max de circuits Ã  visualiser (None = tous)
            max_depth: Profondeur max pour affichage complet (circuits plus profonds tronquÃ©s)
            
        Returns:
            Liste de dict avec {index, name, image_base64, width, depth, truncated}
        """
        images = []
        
        # [v2.5.21] RÃ©cupÃ©rer les circuits depuis plusieurs sources (ordre de prioritÃ©)
        circuits = None
        source = None
        
        # Source 1: Circuits passÃ©s directement Ã  generate()
        circuits = getattr(self, '_transpiled_circuits', None)
        if circuits:
            source = "self._transpiled_circuits (passÃ© Ã  generate)"
        
        # Fallback 2: Circuits stockÃ©s dans le framework
        if not circuits and self.framework:
            circuits = getattr(self.framework, '_last_transpiled_circuits', None)
            if circuits:
                source = "framework._last_transpiled_circuits"
        
        # Fallback 3: Circuits originaux (non transpilÃ©s)
        if not circuits and self.framework:
            circuits = getattr(self.framework, '_last_circuits', None)
            if circuits:
                source = "framework._last_circuits (non transpilÃ©s)"
        
        if not circuits:
            self._log("[CIRCUIT_VIZ] âš ï¸ Aucun circuit disponible pour visualisation", LogLevel.WARN)
            self._log("[CIRCUIT_VIZ]    VÃ©rifiez que transpiled_circuits est passÃ© Ã  generate()", LogLevel.DEBUG)
            return images
        
        total_circuits = len(circuits)
        
        # [v2.5.21] Pas de limite par dÃ©faut - gÃ©nÃ©rer tous les circuits
        n_to_generate = total_circuits if max_circuits is None else min(total_circuits, max_circuits)
        
        self._log(f"[CIRCUIT_VIZ] Source: {source}", LogLevel.DEBUG)
        self._log(f"[CIRCUIT_VIZ] GÃ©nÃ©ration de {n_to_generate}/{total_circuits} visualisations", LogLevel.INFO)
        
        if max_circuits is not None and total_circuits > max_circuits:
            self._log(f"[CIRCUIT_VIZ] âš ï¸ {total_circuits - max_circuits} circuits omis (limite: {max_circuits})", LogLevel.WARN)
        
        try:
            import matplotlib
            matplotlib.use('Agg')  # Backend non-interactif
            import matplotlib.pyplot as plt
            from io import BytesIO
            import base64
        except ImportError:
            self._log("Warning: matplotlib non disponible, pas de visualisation circuits", LogLevel.WARN)
            return images
        
        # [v2.5.21] Pas de limite - dessiner tous les circuits demandÃ©s
        circuits_to_draw = circuits if max_circuits is None else circuits[:max_circuits]
        
        for i, circuit in enumerate(circuits_to_draw):
            try:
                # Obtenir les infos du circuit
                name = getattr(circuit, 'name', f'circuit_{i}')
                depth = circuit.depth()
                n_qubits = circuit.num_qubits
                
                # VÃ©rifier si le circuit est trop profond
                truncated = False
                circuit_to_draw = circuit
                
                if depth > max_depth:
                    # Pour les circuits trÃ¨s profonds, on dessine seulement les premiÃ¨res gates
                    truncated = True
                    # On ne peut pas facilement tronquer, donc on note juste que c'est tronquÃ©
                
                # CrÃ©er la figure avec Qiskit
                fig = circuit_to_draw.draw(
                    output='mpl',
                    fold=-1 if depth <= 30 else 80,  # Fold pour circuits larges
                    scale=0.6 if depth > 20 else 0.8,
                    style={
                        'backgroundcolor': '#1a1f2e',
                        'textcolor': '#e2e8f0',
                        'subtextcolor': '#a0aec0',
                        'linecolor': '#4a5568',
                        'creglinecolor': '#718096',
                        'gatetextcolor': '#1a1f2e',
                        'gatefacecolor': '#667eea',
                        'barrierfacecolor': '#ed8936',
                        'displaycolor': {
                            'cx': ('#48bb78', '#1a1f2e'),
                            'cz': ('#4299e1', '#1a1f2e'),
                            'h': ('#f6ad55', '#1a1f2e'),
                            'x': ('#fc8181', '#1a1f2e'),
                            'measure': ('#b794f4', '#1a1f2e'),
                        }
                    },
                    plot_barriers=True,
                    idle_wires=False if n_qubits > 10 else True)
                
                # Convertir en base64
                buf = BytesIO()
                fig.savefig(buf, format='png', dpi=100, bbox_inches='tight',
                           facecolor='#1a1f2e', edgecolor='none')
                plt.close(fig)
                buf.seek(0)
                
                image_base64 = base64.b64encode(buf.read()).decode('utf-8')
                
                images.append({
                    'index': i,
                    'name': name[:40] + '...' if len(name) > 40 else name,
                    'full_name': name,
                    'image_base64': image_base64,
                    'n_qubits': n_qubits,
                    'depth': depth,
                    'truncated': truncated,
                })
                
            except Exception as e:
                # En cas d'erreur, continuer avec les autres circuits
                self._log(f"Warning: Impossible de dessiner circuit {i}: {e}", LogLevel.WARN)
                continue
        
        # Fermer toutes les figures matplotlib pour libÃ©rer la mÃ©moire
        plt.close('all')
        
        self._log(f"[CIRCUIT_VIZ] {len(images)} visualisations gÃ©nÃ©rÃ©es", LogLevel.DEBUG)
        
        return images
    
    def _generate_qiskit_visualizations(self, results: List[Dict]) -> Dict:
        """
        [v2.5.18] GÃ©nÃ¨re des visualisations professionnelles avec Qiskit.
        
        CrÃ©e plusieurs types de graphiques:
        - Histogrammes des rÃ©sultats (plot_histogram)
        - Carte d'erreurs du backend (plot_error_map)
        - Graphiques de comparaison multi-circuits
        - Heatmap de qualitÃ© des qubits
        
        Returns:
            Dict avec les images base64 par type
        """
        viz = {
            'histograms': [],      # Histogrammes par circuit
            'error_map': None,     # Carte d'erreurs du backend
            'comparison_charts': [],  # Graphiques de comparaison
            'qubit_heatmap': None,    # Heatmap des qubits
        }
        
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            from io import BytesIO
            import base64
            import numpy as np
        except ImportError:
            return viz
        
        # IBM Carbon Design System Colors
        # Remove dark background, use light theme
        plt.style.use('default')
        plt.rcParams.update({
            'figure.facecolor': 'white',
            'axes.facecolor': 'white',
            'axes.edgecolor': '#c6c6c6',
            'axes.labelcolor': '#161616',
            'xtick.color': '#525252',
            'ytick.color': '#525252',
            'text.color': '#161616',
            'grid.color': '#e0e0e0',
        })
        
        IBM = {
            'blue_60': '#0f62fe', 'blue_50': '#4589ff', 'blue_40': '#78a9ff',
            'blue_70': '#0043ce', 'blue_80': '#002d9c',
            'gray_100': '#161616', 'gray_70': '#525252', 'gray_30': '#c6c6c6',
            'gray_20': '#e0e0e0', 'gray_10': '#f4f4f4',
            'green_60': '#198038', 'red_60': '#da1e28', 'yellow_30': '#f1c21b',
            'orange_40': '#ff832b', 'purple_60': '#8a3ffc', 'teal_50': '#009d9a',
            'cyan_50': '#1192e8', 'magenta_50': '#ee5396',
        }
        
        # === 1. HISTOGRAMMES DES RÃ‰SULTATS (IBM Style) ===
        if results:
            try:
                from qiskit.visualization import plot_histogram
                
                # GÃ©nÃ©rer histogrammes pour les 5 premiers circuits
                for i, result in enumerate(results[:5]):
                    counts = result.get('counts', {})
                    if not counts:
                        continue
                    
                    # Limiter Ã  top 20 bitstrings
                    sorted_counts = dict(sorted(counts.items(), key=lambda x: x[1], reverse=True)[:20])
                    
                    try:
                        fig = plot_histogram(
                            sorted_counts,
                            title=f"Circuit {i}: Distribution ({sum(counts.values())} shots)",
                            figsize=(10, 4),
                            color=IBM['blue_60'],
                            bar_labels=False)
                        fig.patch.set_facecolor('white')
                        for ax in fig.axes:
                            ax.set_facecolor('white')
                            ax.tick_params(colors=IBM['gray_70'], labelsize=9)
                            ax.xaxis.label.set_color(IBM['gray_100'])
                            ax.yaxis.label.set_color(IBM['gray_100'])
                            ax.title.set_color(IBM['gray_100'])
                            ax.title.set_fontweight('normal')
                            for spine in ax.spines.values():
                                spine.set_color(IBM['gray_30'])
                        
                        buf = BytesIO()
                        fig.savefig(buf, format='png', dpi=120, bbox_inches='tight',
                                   facecolor='white', edgecolor='none')
                        plt.close(fig)
                        buf.seek(0)
                        
                        viz['histograms'].append({
                            'index': i,
                            'name': result.get('circuit_name', f'circuit_{i}'),
                            'image_base64': base64.b64encode(buf.read()).decode('utf-8'),
                            'total_shots': sum(counts.values()),
                            'unique_outcomes': len(counts),
                        })
                    except Exception as e:
                        self._log(f"Warning: Histogram {i} failed: {e}", LogLevel.WARN)
                        
            except ImportError:
                pass
        
        # === 2. GRAPHIQUE DE COMPARAISON MULTI-CIRCUITS (IBM Style) ===
        if results and len(results) > 1:
            try:
                # Graphique entropie vs uniformitÃ© - IBM Carbon Light Theme
                fig, axes = plt.subplots(1, 2, figsize=(14, 5))
                fig.patch.set_facecolor('white')
                
                circuit_indices = list(range(len(results[:20])))
                entropies = []
                uniformities = []
                top_probs = []
                
                for r in results[:20]:
                    stats = r.get('statistics', {})
                    entropies.append(stats.get('entropy_bits', 0))
                    uniformities.append(stats.get('uniformity_percent', 0))
                    top_probs.append(stats.get('top_probability', 0))
                
                # Graphique 1: Entropie par circuit
                ax1 = axes[0]
                ax1.set_facecolor('white')
                bars1 = ax1.bar(circuit_indices, entropies, color=IBM['blue_60'], width=0.7)
                mean_ent = np.mean(entropies) if entropies else 0
                ax1.axhline(y=mean_ent, color=IBM['orange_40'], linestyle='--', 
                           linewidth=1.5, label=f'Mean: {mean_ent:.2f}')
                ax1.set_xlabel('Circuit Index', color=IBM['gray_100'], fontsize=10)
                ax1.set_ylabel('Entropy (bits)', color=IBM['gray_100'], fontsize=10)
                ax1.set_title('Entropy per Circuit', color=IBM['gray_100'], fontsize=12, fontweight='normal')
                ax1.tick_params(colors=IBM['gray_70'], labelsize=9)
                ax1.legend(facecolor='white', edgecolor=IBM['gray_30'], labelcolor=IBM['gray_100'], fontsize=9)
                ax1.grid(axis='y', linestyle='-', alpha=0.3, color=IBM['gray_30'])
                for spine in ax1.spines.values():
                    spine.set_color(IBM['gray_30'])
                
                # Graphique 2: UniformitÃ© et Top Prob
                ax2 = axes[1]
                ax2.set_facecolor('white')
                x = np.arange(len(circuit_indices))
                width = 0.35
                bars2 = ax2.bar(x - width/2, uniformities, width, label='Uniformity %', color=IBM['teal_50'])
                bars3 = ax2.bar(x + width/2, top_probs, width, label='Top Prob %', color=IBM['purple_60'])
                ax2.set_xlabel('Circuit Index', color=IBM['gray_100'], fontsize=10)
                ax2.set_ylabel('Percentage', color=IBM['gray_100'], fontsize=10)
                ax2.set_title('Uniformity vs Top Probability', color=IBM['gray_100'], fontsize=12, fontweight='normal')
                ax2.tick_params(colors=IBM['gray_70'], labelsize=9)
                ax2.legend(facecolor='white', edgecolor=IBM['gray_30'], labelcolor=IBM['gray_100'], fontsize=9)
                ax2.grid(axis='y', linestyle='-', alpha=0.3, color=IBM['gray_30'])
                for spine in ax2.spines.values():
                    spine.set_color(IBM['gray_30'])
                
                plt.tight_layout()
                
                buf = BytesIO()
                fig.savefig(buf, format='png', dpi=120, bbox_inches='tight',
                           facecolor='white', edgecolor='none')
                plt.close(fig)
                buf.seek(0)
                
                viz['comparison_charts'].append({
                    'name': 'Circuit Quality Metrics',
                    'image_base64': base64.b64encode(buf.read()).decode('utf-8'),
                })
                
            except Exception as e:
                self._log(f"Warning: Comparison chart failed: {e}", LogLevel.WARN)
        
        # === 3. HEATMAP QUALITÃ‰ DES QUBITS (IBM Style) ===
        if self.framework:
            try:
                backend = getattr(self.framework, 'backend', None)
                if backend and hasattr(backend, 'target'):
                    target = backend.target
                    n_qubits = target.num_qubits
                    
                    # Collecter les erreurs de readout par qubit
                    readout_errors = []
                    for q in range(min(n_qubits, 156)):  # Limiter Ã  156 qubits max
                        try:
                            measure_props = target.get('measure', (q))
                            if measure_props and hasattr(measure_props, 'error') and measure_props.error:
                                readout_errors.append(measure_props.error * 100)
                            else:
                                readout_errors.append(np.nan)
                        except:
                            readout_errors.append(np.nan)
                    
                    if readout_errors and not all(np.isnan(readout_errors)):
                        # CrÃ©er une grille pour la heatmap
                        grid_size = int(np.ceil(np.sqrt(len(readout_errors))))
                        grid = np.full((grid_size, grid_size), np.nan)
                        
                        for i, err in enumerate(readout_errors):
                            row = i // grid_size
                            col = i % grid_size
                            if row < grid_size and col < grid_size:
                                grid[row, col] = err
                        
                        fig, ax = plt.subplots(figsize=(10, 8))
                        fig.patch.set_facecolor('white')
                        ax.set_facecolor('white')
                        
                        # IBM-style colormap: Blue (good) to Red (bad)
                        from matplotlib.colors import LinearSegmentedColormap
                        ibm_cmap = LinearSegmentedColormap.from_list('ibm_quality',
                            [IBM['blue_60'], IBM['blue_40'], IBM['yellow_30'], IBM['orange_40'], IBM['red_60']])
                        
                        im = ax.imshow(grid, cmap=ibm_cmap, aspect='equal', vmin=0, vmax=10)
                        
                        # Colorbar
                        cbar = plt.colorbar(im, ax=ax, label='Readout Error (%)')
                        cbar.ax.yaxis.label.set_color(IBM['gray_100'])
                        cbar.ax.tick_params(colors=IBM['gray_70'])
                        
                        ax.set_title(f'Qubit Quality Heatmap ({len(readout_errors)} qubits)', 
                                    color=IBM['gray_100'], fontsize=12, fontweight='normal')
                        ax.set_xlabel('Position X', color=IBM['gray_100'], fontsize=10)
                        ax.set_ylabel('Position Y', color=IBM['gray_100'], fontsize=10)
                        ax.tick_params(colors=IBM['gray_70'])
                        
                        # Ajouter les numÃ©ros de qubits
                        for i in range(min(len(readout_errors), grid_size * grid_size)):
                            row = i // grid_size
                            col = i % grid_size
                            if row < grid_size and col < grid_size:
                                ax.text(col, row, str(i), ha='center', va='center', 
                                       fontsize=6, color='white' if grid[row, col] > 5 else IBM['gray_100'])
                        
                        plt.tight_layout()
                        
                        buf = BytesIO()
                        fig.savefig(buf, format='png', dpi=120, bbox_inches='tight',
                                   facecolor='white', edgecolor='none')
                        plt.close(fig)
                        buf.seek(0)
                        
                        viz['qubit_heatmap'] = {
                            'image_base64': base64.b64encode(buf.read()).decode('utf-8'),
                            'n_qubits': len(readout_errors),
                            'avg_error': np.nanmean(readout_errors),
                            'max_error': np.nanmax(readout_errors),
                        }
                        
            except Exception as e:
                self._log(f"Warning: Qubit heatmap failed: {e}", LogLevel.WARN)
        
        # === 4. ERROR MAP DU BACKEND (plot_error_map) - IBM Style ===
        if self.framework:
            try:
                backend = getattr(self.framework, 'backend', None)
                if backend:
                    from qiskit.visualization import plot_error_map
                    
                    fig = plot_error_map(backend, figsize=(12, 10), show_title=True)
                    fig.patch.set_facecolor('white')
                    
                    buf = BytesIO()
                    fig.savefig(buf, format='png', dpi=120, bbox_inches='tight',
                               facecolor='white', edgecolor='none')
                    plt.close(fig)
                    buf.seek(0)
                    
                    viz['error_map'] = {
                        'image_base64': base64.b64encode(buf.read()).decode('utf-8'),
                        'backend_name': getattr(backend, 'name', 'Unknown'),
                    }
                    
            except Exception as e:
                # plot_error_map peut ne pas Ãªtre disponible pour tous les backends
                self._log(f"Info: Error map not available: {e}", LogLevel.DEBUG)
        
        # Fermer toutes les figures
        plt.close('all')
        
        return viz

    def _collect_calibration_data(self) -> Dict:
        """
        Collecte les donnÃ©es de calibration COMPLÃˆTES du backend.
        
        RÃ©cupÃ¨re directement depuis le backend IBM :
        - Tous les qubits avec T1, T2, erreur readout, frÃ©quence
        - Toutes les gates 2-qubit avec erreurs
        - Topologie (coupling map)
        - Date de derniÃ¨re calibration
        - Statistiques globales
        """
        calib = {
            'available': False,
            'backend_name': None,
            'backend_version': None,
            'num_qubits': 0,
            'calibration_time': None,
            'basis_gates': [],
            
            # Qubits
            'qubits_info': [],
            'qubits_summary': {
                'total': 0,
                'operational': 0,
                'faulty': 0,
                'avg_t1_us': None,
                'avg_t2_us': None,
                'min_t1_us': None,
                'max_t1_us': None,
                'avg_readout_error': None,
                'worst_readout_error': None,
            },
            'faulty_qubits': [],
            
            # Gates 2-qubit
            'two_qubit_gates': [],
            'gates_summary': {
                'total_connections': 0,
                'avg_cx_error': None,
                'worst_cx_error': None,
                'best_cx_error': None,
            },
            
            # Topologie
            'coupling_map': [],
            
            # Erreur Ã©ventuelle
            'error': None,
        }
        
        if not self.framework:
            calib['error'] = "No framework available"
            return calib
        
        # Essayer d'obtenir le backend
        backend = getattr(self.framework, 'backend', None)
        if not backend:
            calib['error'] = "No backend connected"
            return calib
        
        try:
            calib['available'] = True
            calib['backend_name'] = getattr(backend, 'name', str(backend))
            calib['backend_version'] = getattr(backend, 'version', 'N/A')
            
            # === MÃ‰THODE 1: Via backend.target (Qiskit moderne) ===
            if hasattr(backend, 'target') and backend.target:
                target = backend.target
                calib['num_qubits'] = target.num_qubits
                calib['basis_gates'] = list(target.operation_names) if hasattr(target, 'operation_names') else []
                
                # Collecter infos qubits
                t1_values, t2_values, readout_errors = [], [], []
                faulty = []
                
                for qubit in range(target.num_qubits):
                    q_info = {'index': qubit, 't1_us': None, 't2_us': None, 
                              'readout_error': None, 'frequency_ghz': None, 'status': 'OK'}
                    
                    # T1, T2 via les propriÃ©tÃ©s du qubit
                    try:
                        if hasattr(target, 'qubit_properties') and target.qubit_properties:
                            props = target.qubit_properties[qubit]
                            if props:
                                if hasattr(props, 't1') and props.t1:
                                    q_info['t1_us'] = round(props.t1 * 1e6, 1)
                                    t1_values.append(props.t1 * 1e6)
                                if hasattr(props, 't2') and props.t2:
                                    q_info['t2_us'] = round(props.t2 * 1e6, 1)
                                    t2_values.append(props.t2 * 1e6)
                                if hasattr(props, 'frequency') and props.frequency:
                                    q_info['frequency_ghz'] = round(props.frequency / 1e9, 3)
                    except:
                        pass
                    
                    # Erreur de mesure
                    try:
                        measure_props = target.get('measure', (qubit))
                        if measure_props and hasattr(measure_props, 'error') and measure_props.error:
                            q_info['readout_error'] = round(measure_props.error * 100, 3)
                            readout_errors.append(measure_props.error * 100)
                            if measure_props.error > 0.10:  # >10% = faulty
                                q_info['status'] = 'FAULTY'
                                faulty.append(qubit)
                    except:
                        pass
                    
                    calib['qubits_info'].append(q_info)
                
                calib['faulty_qubits'] = faulty
                calib['qubits_summary']['total'] = target.num_qubits
                calib['qubits_summary']['operational'] = target.num_qubits - len(faulty)
                calib['qubits_summary']['faulty'] = len(faulty)
                
                if t1_values:
                    calib['qubits_summary']['avg_t1_us'] = round(sum(t1_values) / len(t1_values), 1)
                    calib['qubits_summary']['min_t1_us'] = round(min(t1_values), 1)
                    calib['qubits_summary']['max_t1_us'] = round(max(t1_values), 1)
                if t2_values:
                    calib['qubits_summary']['avg_t2_us'] = round(sum(t2_values) / len(t2_values), 1)
                if readout_errors:
                    calib['qubits_summary']['avg_readout_error'] = round(sum(readout_errors) / len(readout_errors), 3)
                    calib['qubits_summary']['worst_readout_error'] = round(max(readout_errors), 3)
                
                # Gates 2-qubit (CX, ECR, CZ)
                cx_errors = []
                two_q_gates = ['cx', 'ecr', 'cz']
                for gate_name in two_q_gates:
                    if gate_name in target.operation_names:
                        for qargs in target.qargs_for_operation_name(gate_name):
                            if len(qargs) == 2:
                                try:
                                    gate_props = target.get(gate_name, qargs)
                                    if gate_props and hasattr(gate_props, 'error') and gate_props.error:
                                        error_pct = gate_props.error * 100
                                        cx_errors.append(error_pct)
                                        calib['two_qubit_gates'].append({
                                            'gate': gate_name.upper(),
                                            'qubits': list(qargs),
                                            'error_pct': round(error_pct, 3),
                                            'duration_ns': round(gate_props.duration * 1e9, 1) if gate_props.duration else None
                                        })
                                except:
                                    pass
                
                if cx_errors:
                    calib['gates_summary']['total_connections'] = len(cx_errors)
                    calib['gates_summary']['avg_cx_error'] = round(sum(cx_errors) / len(cx_errors), 3)
                    calib['gates_summary']['best_cx_error'] = round(min(cx_errors), 3)
                    calib['gates_summary']['worst_cx_error'] = round(max(cx_errors), 3)
                
                # Coupling map
                if hasattr(target, 'build_coupling_map'):
                    cm = target.build_coupling_map()
                    if cm:
                        calib['coupling_map'] = [list(edge) for edge in cm.get_edges()]
            
            # === MÃ‰THODE 2: Via backend.properties() (ancienne API) ===
            elif hasattr(backend, 'properties') and callable(backend.properties):
                props = backend.properties()
                if props:
                    calib['calibration_time'] = str(props.last_update_date) if hasattr(props, 'last_update_date') else None
                    
                    t1_values, t2_values, readout_errors = [], [], []
                    faulty = []
                    
                    for qubit in range(props.num_qubits if hasattr(props, 'num_qubits') else 0):
                        q_info = {'index': qubit, 't1_us': None, 't2_us': None, 
                                  'readout_error': None, 'frequency_ghz': None, 'status': 'OK'}
                        
                        try:
                            t1 = props.t1(qubit)
                            if t1:
                                q_info['t1_us'] = round(t1 * 1e6, 1)
                                t1_values.append(t1 * 1e6)
                        except:
                            pass
                        
                        try:
                            t2 = props.t2(qubit)
                            if t2:
                                q_info['t2_us'] = round(t2 * 1e6, 1)
                                t2_values.append(t2 * 1e6)
                        except:
                            pass
                        
                        try:
                            freq = props.frequency(qubit)
                            if freq:
                                q_info['frequency_ghz'] = round(freq / 1e9, 3)
                        except:
                            pass
                        
                        try:
                            re = props.readout_error(qubit)
                            if re:
                                q_info['readout_error'] = round(re * 100, 3)
                                readout_errors.append(re * 100)
                                if re > 0.10:
                                    q_info['status'] = 'FAULTY'
                                    faulty.append(qubit)
                        except:
                            pass
                        
                        calib['qubits_info'].append(q_info)
                    
                    calib['num_qubits'] = len(calib['qubits_info'])
                    calib['faulty_qubits'] = faulty
                    calib['qubits_summary']['total'] = calib['num_qubits']
                    calib['qubits_summary']['operational'] = calib['num_qubits'] - len(faulty)
                    calib['qubits_summary']['faulty'] = len(faulty)
                    
                    if t1_values:
                        calib['qubits_summary']['avg_t1_us'] = round(sum(t1_values) / len(t1_values), 1)
                        calib['qubits_summary']['min_t1_us'] = round(min(t1_values), 1)
                        calib['qubits_summary']['max_t1_us'] = round(max(t1_values), 1)
                    if t2_values:
                        calib['qubits_summary']['avg_t2_us'] = round(sum(t2_values) / len(t2_values), 1)
                    if readout_errors:
                        calib['qubits_summary']['avg_readout_error'] = round(sum(readout_errors) / len(readout_errors), 3)
                        calib['qubits_summary']['worst_readout_error'] = round(max(readout_errors), 3)
            
            # === MÃ‰THODE 3: Via circuit_optimizer (fallback) ===
            elif hasattr(self.framework, 'circuit_optimizer') and self.framework.circuit_optimizer:
                opt = self.framework.circuit_optimizer
                
                if hasattr(opt, 'qubits') and opt.qubits:
                    t1_values, t2_values, readout_errors = [], [], []
                    
                    for q in opt.qubits:
                        q_info = {
                            'index': q.index,
                            't1_us': round(q.t1 * 1e6, 1) if q.t1 else None,
                            't2_us': round(q.t2 * 1e6, 1) if q.t2 else None,
                            'readout_error': round(q.readout_error * 100, 3) if q.readout_error else None,
                            'frequency_ghz': round(q.frequency / 1e9, 3) if q.frequency else None,
                            'status': 'FAULTY' if q.readout_error and q.readout_error > 0.10 else 'OK'
                        }
                        calib['qubits_info'].append(q_info)
                        
                        if q.t1:
                            t1_values.append(q.t1 * 1e6)
                        if q.t2:
                            t2_values.append(q.t2 * 1e6)
                        if q.readout_error:
                            readout_errors.append(q.readout_error * 100)
                    
                    calib['num_qubits'] = len(calib['qubits_info'])
                    calib['qubits_summary']['total'] = calib['num_qubits']
                    
                    if t1_values:
                        calib['qubits_summary']['avg_t1_us'] = round(sum(t1_values) / len(t1_values), 1)
                    if t2_values:
                        calib['qubits_summary']['avg_t2_us'] = round(sum(t2_values) / len(t2_values), 1)
                    if readout_errors:
                        calib['qubits_summary']['avg_readout_error'] = round(sum(readout_errors) / len(readout_errors), 3)
                
                if hasattr(opt, 'get_faulty_qubits'):
                    calib['faulty_qubits'] = list(opt.get_faulty_qubits())
                    calib['qubits_summary']['faulty'] = len(calib['faulty_qubits'])
                    calib['qubits_summary']['operational'] = calib['num_qubits'] - len(calib['faulty_qubits'])
            
            else:
                calib['error'] = "No calibration source available (target, properties, or optimizer)"
            
            # [v2.5.21] FALLBACK FINAL: Essayer framework.noise._calibration_data 
            # qui est rempli par analyze_calibration()
            if not calib['qubits_info'] and self.framework:
                noise = getattr(self.framework, 'noise', None)
                if noise:
                    cached_calib = getattr(noise, '_calibration_data', None)
                    if cached_calib and isinstance(cached_calib, dict):
                        summary_data = cached_calib.get('summary', {})
                        qubits_data = cached_calib.get('qubits', {})
                        
                        # RÃ©cupÃ©rer T1/T2/readout depuis summary
                        if summary_data:
                            t1_info = summary_data.get('t1_us', {})
                            t2_info = summary_data.get('t2_us', {})
                            re_info = summary_data.get('readout_error', {})
                            
                            if t1_info.get('mean'):
                                calib['qubits_summary']['avg_t1_us'] = t1_info['mean']
                            if t2_info.get('mean'):
                                calib['qubits_summary']['avg_t2_us'] = t2_info['mean']
                            if re_info.get('mean'):
                                calib['qubits_summary']['avg_readout_error'] = round(re_info['mean'] * 100, 3)
                            if re_info.get('max'):
                                calib['qubits_summary']['worst_readout_error'] = round(re_info['max'] * 100, 3)
                        
                        # RÃ©cupÃ©rer les infos des qubits individuels
                        if qubits_data:
                            for idx, q_data in qubits_data.items():
                                q_info = {
                                    'index': int(idx),
                                    't1_us': round(q_data.get('t1', 0) * 1e6, 1) if q_data.get('t1') else None,
                                    't2_us': round(q_data.get('t2', 0) * 1e6, 1) if q_data.get('t2') else None,
                                    'readout_error': round(q_data.get('readout_error', 0) * 100, 3) if q_data.get('readout_error') else None,
                                    'status': 'FAULTY' if q_data.get('readout_error') and q_data.get('readout_error') > 0.10 else 'OK'
                                }
                                calib['qubits_info'].append(q_info)
                            
                            calib['num_qubits'] = len(calib['qubits_info'])
                            calib['qubits_summary']['total'] = calib['num_qubits']
                            calib['available'] = True
                            calib['error'] = None
        
        except Exception as e:
            calib['error'] = f"Error collecting calibration: {str(e)}"
            import traceback
            calib['traceback'] = traceback.format_exc()
        
        return calib
    
    def _calculate_summary(self, results: List[Dict]) -> Dict:
        """Calcule le rÃ©sumÃ© global des rÃ©sultats."""
        summary = {
            'total_circuits': len(results),
            'total_shots': 0,
            'total_outcomes': 0,
            'avg_outcomes_per_circuit': 0,
            'circuits_with_errors': 0,
        }
        
        all_outcomes = 0
        for r in results:
            if isinstance(r, dict):
                counts = r.get('counts', {})
                summary['total_shots'] += sum(counts.values())
                all_outcomes += len(counts)
                
                if r.get('error'):
                    summary['circuits_with_errors'] += 1
        
        summary['total_outcomes'] = all_outcomes
        if results:
            summary['avg_outcomes_per_circuit'] = round(all_outcomes / len(results), 1)
        
        return summary
    
    def _calculate_statistics(self, results: List[Dict]) -> Dict:
        """Calcule les statistiques avancÃ©es."""
        stats = {
            'per_circuit': [],
            'global': {
                'avg_entropy': 0,
                'avg_uniformity': 0,
                'avg_top_prob': 0,
            }
        }
        
        entropies = []
        uniformities = []
        top_probs = []
        
        for i, r in enumerate(results):
            if not isinstance(r, dict):
                continue
            
            counts = r.get('counts', {})
            if not counts:
                continue
            
            total = sum(counts.values())
            n_outcomes = len(counts)
            
            # Calculer l'entropie
            entropy = 0
            for count in counts.values():
                if count > 0:
                    p = count / total
                    entropy -= p * math.log2(p)
            
            # Entropie maximale possible
            max_entropy = math.log2(n_outcomes) if n_outcomes > 1 else 1
            uniformity = (entropy / max_entropy * 100) if max_entropy > 0 else 0
            
            # Top bitstrings
            sorted_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)
            top_5 = sorted_counts[:5]
            top_prob = (sorted_counts[0][1] / total * 100) if sorted_counts else 0
            
            circuit_stats = {
                'index': i,
                'shots': total,
                'unique_outcomes': n_outcomes,
                'entropy_bits': round(entropy, 3),
                'max_entropy_bits': round(max_entropy, 3),
                'uniformity_percent': round(uniformity, 1),
                'top_bitstring': sorted_counts[0][0] if sorted_counts else 'N/A',
                'top_probability': round(top_prob, 2),
                'top_5': [{'bitstring': bs, 'count': c, 'prob': round(c/total*100, 2)} 
                         for bs, c in top_5],
                'depth': r.get('depth', 'N/A'),
                'fidelity': r.get('fidelity', 'N/A'),
            }
            
            stats['per_circuit'].append(circuit_stats)
            entropies.append(entropy)
            uniformities.append(uniformity)
            top_probs.append(top_prob)
        
        # Moyennes globales
        if entropies:
            stats['global']['avg_entropy'] = round(sum(entropies) / len(entropies), 3)
            stats['global']['avg_uniformity'] = round(sum(uniformities) / len(uniformities), 1)
            stats['global']['avg_top_prob'] = round(sum(top_probs) / len(top_probs), 2)
        
        return stats
    
    def _prepare_charts_data(self, results: List[Dict]) -> Dict:
        """PrÃ©pare les donnÃ©es pour les graphiques Chart.js."""
        charts = {
            'distributions': [],
            'entropy_by_circuit': [],
            'uniformity_by_circuit': [],
            'labels': [],      # Pour Chart.js - bitstrings du premier circuit
            'values': [],      # Pour Chart.js - counts du premier circuit
        }
        
        first_circuit_done = False
        
        for i, r in enumerate(results):
            if not isinstance(r, dict):
                continue
            
            counts = r.get('counts', {})
            if not counts:
                continue
            
            total = sum(counts.values())
            sorted_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)[:10]
            
            # DonnÃ©es dÃ©taillÃ©es pour chaque circuit
            charts['distributions'].append({
                'circuit': i,
                'data': [{'bitstring': k[:12], 'probability': round(v/total*100, 2)} 
                        for k, v in sorted_counts]
            })
            
            # Pour le graphique principal (premier circuit avec donnÃ©es)
            if not first_circuit_done and sorted_counts:
                charts['labels'] = [k[:12] + ('...' if len(k) > 12 else '') for k, v in sorted_counts]
                charts['values'] = [v for k, v in sorted_counts]
                first_circuit_done = True
        
        return charts
    
    def _generate_professional_html(self, data: Dict, title: str) -> str:
        """
        [v2.5.19] GÃ©nÃ¨re un rapport HTML professionnel style IBM/Nature.
        
        Design:
        - Palette sobre (bleu marine, gris, blanc)
        - Typographie scientifique (Inter, JetBrains Mono)
        - Pas d'emojis
        - Sections numÃ©rotÃ©es
        - Layout publication scientifique
        """
        from datetime import datetime
        
        status = data.get('status', 'UNKNOWN')
        status_class = 'success' if status == 'SUCCESS' else 'error'
        
        # DonnÃ©es
        timing = data.get('timing', {})
        run_ctx = data.get('run_context', {})
        stats = data.get('statistics', {}).get('global', {})
        calib = data.get('calibration', {})
        trans = data.get('transpilation', {})
        summary = data.get('summary', {})
        
        # Valeurs extraites pour Ã©viter les problÃ¨mes de f-string
        total_shots = summary.get('total_shots', 0)
        trans_after = trans.get('after', {})
        trans_final_depth = trans_after.get('depth', 'N/A')
        
        # JSON pour charts
        charts_data = json.dumps(data.get('charts_data', {}), indent=2)
        full_data = json.dumps({k: v for k, v in data.items() 
                               if k not in ['circuit_images', 'qiskit_visualizations']}, 
                              indent=2, default=str)
        
        # CSS Professionnel - IBM Carbon Design System
        css = '''
/* IBM Carbon Design System Color Palette */
:root {
    /* Core Blue Family */
    --ibm-blue-100: #001141;
    --ibm-blue-90: #001d6c;
    --ibm-blue-80: #002d9c;
    --ibm-blue-70: #0043ce;
    --ibm-blue-60: #0f62fe;
    --ibm-blue-50: #4589ff;
    --ibm-blue-40: #78a9ff;
    --ibm-blue-30: #a6c8ff;
    --ibm-blue-20: #d0e2ff;
    --ibm-blue-10: #edf5ff;
    
    /* Neutral Gray */
    --ibm-gray-100: #161616;
    --ibm-gray-90: #262626;
    --ibm-gray-80: #393939;
    --ibm-gray-70: #525252;
    --ibm-gray-60: #6f6f6f;
    --ibm-gray-50: #8d8d8d;
    --ibm-gray-40: #a8a8a8;
    --ibm-gray-30: #c6c6c6;
    --ibm-gray-20: #e0e0e0;
    --ibm-gray-10: #f4f4f4;
    
    /* Support Colors */
    --ibm-green-60: #198038;
    --ibm-green-50: #24a148;
    --ibm-red-60: #da1e28;
    --ibm-red-50: #fa4d56;
    --ibm-yellow-30: #f1c21b;
    --ibm-orange-40: #ff832b;
    --ibm-purple-60: #8a3ffc;
    --ibm-teal-50: #009d9a;
    --ibm-cyan-50: #1192e8;
    --ibm-magenta-50: #ee5396;
    
    /* Semantic Aliases */
    --primary: var(--ibm-blue-60);
    --primary-hover: var(--ibm-blue-70);
    --primary-light: var(--ibm-blue-50);
    --success: var(--ibm-green-60);
    --warning: var(--ibm-yellow-30);
    --danger: var(--ibm-red-60);
    --info: var(--ibm-cyan-50);
    
    /* Background */
    --bg: #ffffff;
    --bg-secondary: var(--ibm-gray-10);
    --bg-tertiary: var(--ibm-gray-20);
    --bg-inverse: var(--ibm-gray-100);
    
    /* Text */
    --text-primary: var(--ibm-gray-100);
    --text-secondary: var(--ibm-gray-70);
    --text-muted: var(--ibm-gray-50);
    --text-on-color: #ffffff;
    
    /* Border */
    --border-subtle: var(--ibm-gray-20);
    --border-strong: var(--ibm-gray-50);
    
    /* Spacing (IBM 2x Grid) */
    --spacing-01: 0.125rem;
    --spacing-02: 0.25rem;
    --spacing-03: 0.5rem;
    --spacing-04: 0.75rem;
    --spacing-05: 1rem;
    --spacing-06: 1.5rem;
    --spacing-07: 2rem;
    --spacing-08: 2.5rem;
    --spacing-09: 3rem;
}

* { box-sizing: border-box; margin: 0; padding: 0; }

body {
    font-family: 'IBM Plex Sans', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
    background: var(--bg);
    color: var(--text-primary);
    line-height: 1.5;
    font-size: 14px;
    -webkit-font-smoothing: antialiased;
}

/* Typography - IBM Plex */
h1, h2, h3, h4, h5, h6 { 
    font-family: 'IBM Plex Sans', sans-serif;
    font-weight: 600; 
    line-height: 1.25; 
    color: var(--text-primary);
    letter-spacing: 0;
}
h1 { font-size: 2rem; font-weight: 300; }
h2 { font-size: 1.25rem; font-weight: 600; margin: var(--spacing-07) 0 var(--spacing-05); }
h3 { font-size: 1rem; font-weight: 600; }

code, pre, .mono {
    font-family: 'IBM Plex Mono', 'Consolas', monospace;
}

/* Layout */
.report-container { max-width: 1584px; margin: 0 auto; }

/* Header - IBM Style */
.report-header {
    background: var(--ibm-gray-100);
    color: var(--text-on-color);
    padding: var(--spacing-07) var(--spacing-09);
    position: relative;
}
.report-header::after {
    content: '';
    position: absolute;
    bottom: 0;
    left: 0;
    right: 0;
    height: 3px;
    background: var(--primary);
}
.header-content { display: flex; justify-content: space-between; align-items: flex-start; }
.header-title h1 { color: var(--text-on-color); font-weight: 400; letter-spacing: 0; }
.header-subtitle { color: var(--ibm-gray-30); font-size: 0.875rem; margin-top: var(--spacing-03); }
.header-meta { text-align: right; font-size: 0.75rem; }
.status-indicator {
    display: inline-flex;
    align-items: center;
    padding: var(--spacing-02) var(--spacing-04);
    font-weight: 400;
    font-size: 0.75rem;
    text-transform: uppercase;
    letter-spacing: 0.32px;
}
.status-indicator.success { background: var(--success); color: white; }
.status-indicator.error { background: var(--danger); color: white; }
.header-details { color: var(--ibm-gray-40); margin-top: var(--spacing-04); line-height: 1.6; }

/* Body */
.report-body { padding: var(--spacing-07) var(--spacing-09); }

/* Section Headers - IBM Style */
.section-header {
    display: flex;
    align-items: center;
    gap: var(--spacing-04);
    margin: var(--spacing-08) 0 var(--spacing-05);
    padding-bottom: var(--spacing-04);
    border-bottom: 1px solid var(--border-subtle);
}
.section-header h2 { 
    margin: 0; 
    font-size: 0.875rem; 
    font-weight: 600;
    text-transform: uppercase; 
    letter-spacing: 0.32px;
    color: var(--text-primary);
}
.section-number {
    background: var(--primary);
    color: white;
    min-width: 24px;
    height: 24px;
    border-radius: 0;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 0.75rem;
    font-weight: 600;
}

/* Summary Cards - IBM Tile Style */
.summary-grid { 
    display: grid; 
    grid-template-columns: repeat(5, 1fr); 
    gap: 1px;
    background: var(--border-subtle);
    margin-bottom: var(--spacing-07);
}
.summary-card {
    background: var(--bg);
    padding: var(--spacing-05);
    text-align: left;
}
.summary-card.highlight { 
    background: var(--primary); 
    color: white;
}
.summary-value { 
    font-size: 2rem; 
    font-weight: 300; 
    color: var(--text-primary); 
    line-height: 1.2;
    font-family: 'IBM Plex Sans', sans-serif;
}
.summary-card.highlight .summary-value { color: white; }
.summary-label {
    font-size: 0.75rem;
    color: var(--text-secondary);
    text-transform: uppercase;
    letter-spacing: 0.32px;
    margin-top: var(--spacing-03);
}
.summary-card.highlight .summary-label { color: rgba(255,255,255,0.85); }

/* Data Tables - IBM Carbon Style */
.data-table { width: 100%; border-collapse: collapse; font-size: 0.875rem; margin: var(--spacing-05) 0; }
.data-table th {
    background: var(--ibm-gray-10);
    padding: var(--spacing-04) var(--spacing-05);
    text-align: left;
    font-weight: 600;
    border-bottom: 1px solid var(--border-strong);
    font-size: 0.75rem;
    text-transform: uppercase;
    letter-spacing: 0.32px;
    color: var(--text-primary);
}
.data-table td { 
    padding: var(--spacing-04) var(--spacing-05); 
    border-bottom: 1px solid var(--border-subtle);
    vertical-align: top;
}
.data-table tbody tr:hover td { background: var(--ibm-blue-10); }
.data-table .numeric { font-family: 'IBM Plex Mono', monospace; text-align: right; }

/* Info Panels - IBM Tile */
.info-panel {
    background: var(--bg);
    border: 1px solid var(--border-subtle);
    padding: var(--spacing-05);
    margin: var(--spacing-05) 0;
}
.info-panel-header { 
    font-weight: 600; 
    color: var(--text-primary); 
    margin-bottom: var(--spacing-04);
    font-size: 0.875rem;
}
.info-grid { display: grid; grid-template-columns: repeat(2, 1fr); gap: var(--spacing-05); }
.info-item { display: flex; flex-direction: column; }
.info-label { 
    font-size: 0.75rem; 
    color: var(--text-secondary); 
    text-transform: uppercase; 
    letter-spacing: 0.32px; 
}
.info-value { 
    font-size: 0.875rem; 
    font-weight: 500; 
    margin-top: var(--spacing-02);
    color: var(--text-primary);
}

/* Timeline - IBM Progress Indicator Style */
.timeline { 
    display: flex; 
    justify-content: space-between; 
    position: relative; 
    padding: var(--spacing-05) 0;
    margin: var(--spacing-05) 0;
}
.timeline::before {
    content: '';
    position: absolute;
    top: calc(var(--spacing-05) + 6px);
    left: 24px;
    right: 24px;
    height: 1px;
    background: var(--ibm-gray-30);
}
.timeline-step { 
    background: var(--bg); 
    position: relative; 
    z-index: 1; 
    text-align: center; 
    padding: 0 var(--spacing-04);
}
.timeline-dot { 
    width: 12px; 
    height: 12px; 
    border-radius: 50%; 
    background: var(--primary); 
    margin: 0 auto var(--spacing-03);
    border: 2px solid var(--bg);
    box-shadow: 0 0 0 2px var(--primary);
}
.timeline-label { 
    font-size: 0.75rem; 
    color: var(--text-secondary); 
    text-transform: uppercase;
    letter-spacing: 0.32px;
}
.timeline-value { font-size: 0.875rem; font-weight: 600; color: var(--text-primary); margin-top: var(--spacing-02); }

/* Charts & Visualizations */
.chart-container { 
    background: var(--bg); 
    border: 1px solid var(--border-subtle); 
    padding: var(--spacing-05); 
    margin: var(--spacing-05) 0;
}
.viz-gallery { 
    display: grid; 
    grid-template-columns: repeat(auto-fill, minmax(400px, 1fr)); 
    gap: var(--spacing-05); 
    margin: var(--spacing-05) 0;
}
.viz-item { 
    background: var(--bg); 
    border: 1px solid var(--border-subtle);
    overflow: hidden;
}
.viz-item-header { 
    padding: var(--spacing-04) var(--spacing-05); 
    background: var(--ibm-gray-10); 
    border-bottom: 1px solid var(--border-subtle); 
    font-size: 0.75rem; 
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.32px;
}
.viz-item img { width: 100%; display: block; cursor: pointer; transition: opacity 0.15s; }
.viz-item img:hover { opacity: 0.85; }

/* Score Display - IBM Gauge Style */
.score-display { 
    display: flex; 
    align-items: center; 
    gap: var(--spacing-06); 
    padding: var(--spacing-05); 
    background: var(--ibm-gray-10);
    margin: var(--spacing-05) 0;
}
.score-circle {
    width: 72px;
    height: 72px;
    border-radius: 0;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    font-weight: 600;
    color: white;
}
.score-circle.go { background: var(--success); }
.score-circle.warn { background: var(--warning); color: var(--ibm-gray-100); }
.score-circle.nogo { background: var(--danger); }
.score-value { font-size: 1.5rem; font-weight: 300; line-height: 1; font-family: 'IBM Plex Sans', sans-serif; }
.score-label { font-size: 0.625rem; text-transform: uppercase; margin-top: var(--spacing-02); letter-spacing: 0.32px; }
.score-details { flex: 1; }

/* Collapsible - IBM Accordion */
.collapsible-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    cursor: pointer;
    padding: var(--spacing-04) var(--spacing-05);
    background: var(--bg);
    border: 1px solid var(--border-subtle);
    margin: var(--spacing-05) 0 0;
}
.collapsible-header:hover { background: var(--ibm-gray-10); }
.collapsible-content { 
    display: none; 
    padding: var(--spacing-05); 
    border: 1px solid var(--border-subtle); 
    border-top: none;
}
.collapsible-content.active { display: block; }

/* Code/JSON Viewer - IBM Plex Mono */
.json-viewer {
    background: var(--ibm-gray-100);
    color: var(--ibm-gray-10);
    font-family: 'IBM Plex Mono', monospace;
    font-size: 0.75rem;
    padding: var(--spacing-05);
    overflow-x: auto;
    max-height: 500px;
    overflow-y: auto;
}

/* Footer */
.report-footer {
    margin-top: var(--spacing-09);
    padding: var(--spacing-05) var(--spacing-09);
    background: var(--ibm-gray-10);
    border-top: 1px solid var(--border-subtle);
    font-size: 0.75rem;
    color: var(--text-secondary);
    display: flex;
    justify-content: space-between;
}
.modal {
    display: none;
    position: fixed;
    z-index: 1000;
    left: 0;
    top: 0;
    width: 100%;
    height: 100%;
    background: rgba(0,0,0,0.9);
    justify-content: center;
    align-items: center;
}
.modal.active { display: flex; }
.modal img { max-width: 95%; max-height: 90vh; border-radius: 8px; }
.modal-close { position: absolute; top: 20px; right: 30px; color: white; font-size: 2rem; cursor: pointer; }
@media (max-width: 1200px) { .summary-grid { grid-template-columns: repeat(3, 1fr); } .viz-gallery { grid-template-columns: 1fr; } }
@media (max-width: 768px) { .summary-grid { grid-template-columns: repeat(2, 1fr); } .info-grid { grid-template-columns: 1fr; } .report-body { padding: 1rem; } }
@media print { .report-header { background: var(--primary) !important; -webkit-print-color-adjust: exact; } .collapsible-content { display: block !important; } }
'''
        
        # GÃ©nÃ©rer les sections HTML
        transpilation_section = self._pro_transpilation_section(trans)
        circuits_section = self._pro_circuits_section(data.get('circuits_details', []))
        circuit_viz_section = self._pro_circuit_viz_section(data.get('circuit_images', []))
        calibration_section = self._pro_calibration_section(calib)
        stats_section = self._pro_statistics_section(stats, data.get('statistics', {}).get('per_circuit', []))
        qiskit_viz_section = self._pro_qiskit_viz_section(data.get('qiskit_visualizations', {}))
        files_section = self._pro_files_section(data.get('files', []))
        
        html = f'''<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@300;400;500;600;700&family=IBM+Plex+Mono:wght@400;500&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>{css}</style>
</head>
<body>
    <div class="report-container">
        <header class="report-header">
            <div class="header-content">
                <div class="header-title">
                    <h1>QMC Quantum Execution Report</h1>
                    <p class="header-subtitle">{data.get('project', 'QMC Research Lab')} | {data.get('backend_name', 'N/A')}</p>
                </div>
                <div class="header-meta">
                    <span class="status-indicator {status_class}">{status}</span>
                    <div class="header-details">
                        Framework v{data.get('framework_version', __version__)}<br>
                        {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                    </div>
                </div>
            </div>
        </header>
        
        <main class="report-body">
            <div class="summary-grid">
                <div class="summary-card highlight">
                    <div class="summary-value">{data.get('results_count', 0)}</div>
                    <div class="summary-label">Circuits</div>
                </div>
                <div class="summary-card">
                    <div class="summary-value">{run_ctx.get('shots', 0):,}</div>
                    <div class="summary-label">Shots/Circuit</div>
                </div>
                <div class="summary-card">
                    <div class="summary-value">{total_shots:,}</div>
                    <div class="summary-label">Total Shots</div>
                </div>
                <div class="summary-card">
                    <div class="summary-value">{timing.get('qpu_time_s', 0):.2f}s</div>
                    <div class="summary-label">QPU Time</div>
                </div>
                <div class="summary-card">
                    <div class="summary-value">{timing.get('total_time_s', 0):.1f}s</div>
                    <div class="summary-label">Total Time</div>
                </div>
            </div>
            
            <div class="section-header">
                <span class="section-number">1</span>
                <h2>Execution Timeline</h2>
            </div>
            <div class="timeline">
                <div class="timeline-step">
                    <div class="timeline-dot"></div>
                    <div class="timeline-label">Submitted</div>
                    <div class="timeline-value">{run_ctx.get('submitted_at', 'N/A')}</div>
                </div>
                <div class="timeline-step">
                    <div class="timeline-dot"></div>
                    <div class="timeline-label">Queue</div>
                    <div class="timeline-value">{timing.get('queue_time_s', 0):.1f}s</div>
                </div>
                <div class="timeline-step">
                    <div class="timeline-dot"></div>
                    <div class="timeline-label">Transpile</div>
                    <div class="timeline-value">{timing.get('transpile_time_s', 0):.1f}s</div>
                </div>
                <div class="timeline-step">
                    <div class="timeline-dot"></div>
                    <div class="timeline-label">QPU</div>
                    <div class="timeline-value">{timing.get('qpu_time_s', 0):.2f}s</div>
                </div>
                <div class="timeline-step">
                    <div class="timeline-dot"></div>
                    <div class="timeline-label">Completed</div>
                    <div class="timeline-value">{run_ctx.get('completed_at', 'N/A')}</div>
                </div>
            </div>
            
            <div class="section-header">
                <span class="section-number">2</span>
                <h2>Configuration</h2>
            </div>
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem;">
                <div class="info-panel">
                    <div class="info-panel-header">Backend</div>
                    <div class="info-grid">
                        <div class="info-item">
                            <span class="info-label">Name</span>
                            <span class="info-value">{data.get('backend_name', 'N/A')}</span>
                        </div>
                        <div class="info-item">
                            <span class="info-label">Qubits</span>
                            <span class="info-value">{calib.get('total_qubits', 'N/A')}</span>
                        </div>
                        <div class="info-item">
                            <span class="info-label">Version</span>
                            <span class="info-value">{calib.get('backend_version', 'N/A')}</span>
                        </div>
                        <div class="info-item">
                            <span class="info-label">Job ID</span>
                            <span class="info-value" style="font-family: monospace; font-size: 0.8rem;">{run_ctx.get('job_id', 'N/A')}</span>
                        </div>
                    </div>
                </div>
                <div class="info-panel">
                    <div class="info-panel-header">Execution Parameters</div>
                    <div class="info-grid">
                        <div class="info-item">
                            <span class="info-label">Optimization</span>
                            <span class="info-value">Level {run_ctx.get('optimization_level', 3)}</span>
                        </div>
                        <div class="info-item">
                            <span class="info-label">Layout</span>
                            <span class="info-value">{run_ctx.get('layout_strategy', 'auto')}</span>
                        </div>
                        <div class="info-item">
                            <span class="info-label">Shots</span>
                            <span class="info-value">{run_ctx.get('shots', 0):,}</span>
                        </div>
                        <div class="info-item">
                            <span class="info-label">Circuits</span>
                            <span class="info-value">{run_ctx.get('circuits_count', 0)}</span>
                        </div>
                    </div>
                </div>
            </div>
            
            {transpilation_section}
            {circuits_section}
            {circuit_viz_section}
            {calibration_section}
            {stats_section}
            {qiskit_viz_section}
            
            <div class="section-header">
                <span class="section-number">9</span>
                <h2>Results Distribution</h2>
            </div>
            <div class="chart-container">
                <canvas id="distributionChart" height="300"></canvas>
            </div>
            
            <div class="section-header">
                <span class="section-number">10</span>
                <h2>Raw Data Export</h2>
            </div>
            <div class="collapsible-header" onclick="toggleSection('jsonSection')">
                <span>Complete JSON Data</span>
                <span class="toggle-icon">+</span>
            </div>
            <div id="jsonSection" class="collapsible-content">
                <button onclick="copyJson()" style="margin-bottom: 1rem; padding: 0.5rem 1rem; cursor: pointer; border: 1px solid var(--border); border-radius: 4px; background: white;">Copy JSON</button>
                <div class="json-viewer">
                    <pre id="jsonData">{full_data}</pre>
                </div>
            </div>
            
            {files_section}
        </main>
        
        <footer class="report-footer">
            <div>QMC Research Lab | Quantum Mandatory Cryptography</div>
            <div>Generated by QMC Framework v{data.get('framework_version', __version__)}</div>
        </footer>
        
        <div id="imageModal" class="modal" onclick="closeModal()">
            <span class="modal-close">&times;</span>
            <img src="" alt="Enlarged view">
        </div>
    </div>
    
    <script>
        function toggleSection(id) {{
            const content = document.getElementById(id);
            const header = content.previousElementSibling;
            const icon = header.querySelector('.toggle-icon');
            content.classList.toggle('active');
            icon.textContent = content.classList.contains('active') ? 'âˆ’' : '+';
        }}
        function openModal(src) {{
            const modal = document.getElementById('imageModal');
            modal.querySelector('img').src = src;
            modal.classList.add('active');
        }}
        function closeModal() {{ document.getElementById('imageModal').classList.remove('active'); }}
        function copyJson() {{
            navigator.clipboard.writeText(document.getElementById('jsonData').textContent);
        }}
        document.addEventListener('keydown', (e) => {{ if (e.key === 'Escape') closeModal(); }});
        
        document.addEventListener('DOMContentLoaded', () => {{
            const chartsData = {charts_data};
            const ctx = document.getElementById('distributionChart');
            if (!ctx || !chartsData.labels) return;
            new Chart(ctx, {{
                type: 'bar',
                data: {{
                    labels: chartsData.labels || [],
                    datasets: [{{ label: 'Counts', data: chartsData.values || [], backgroundColor: '#1a365d', borderWidth: 0 }}]
                }},
                options: {{
                    responsive: true,
                    maintainAspectRatio: false,
                    plugins: {{ legend: {{ display: false }} }},
                    scales: {{
                        y: {{ beginAtZero: true, title: {{ display: true, text: 'Counts' }} }},
                        x: {{ title: {{ display: true, text: 'Bitstring' }}, ticks: {{ maxRotation: 45 }} }}
                    }}
                }}
            }});
        }});
    </script>
</body>
</html>'''
        
        return html
    
    def _pro_transpilation_section(self, trans: Dict) -> str:
        """GÃ©nÃ¨re la section transpilation (style pro)."""
        if not trans or not trans.get('available'):
            return ''
        
        score = trans.get('score', 0) or 0
        rec = trans.get('recommendation', 'N/A')
        score_class = 'go' if score >= 80 else ('warn' if score >= 50 else 'nogo')
        trans_after = trans.get('after', {})
        final_depth = trans_after.get('depth', 'N/A')
        
        return f'''
        <div class="section-header">
            <span class="section-number">3</span>
            <h2>Transpilation Quality</h2>
        </div>
        <div class="score-display">
            <div class="score-circle {score_class}">
                <span class="score-value">{score}</span>
                <span class="score-label">{rec}</span>
            </div>
            <div class="score-details">
                <div class="info-grid" style="grid-template-columns: repeat(4, 1fr);">
                    <div class="info-item">
                        <span class="info-label">2Q Overhead</span>
                        <span class="info-value">+{trans.get('overhead_2q_percent', 0):.1f}%</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Est. SWAPs</span>
                        <span class="info-value">~{trans.get('swaps_estimated', 0)}</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Depth Exp.</span>
                        <span class="info-value">{trans.get('depth_expansion', 1):.2f}x</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Final Depth</span>
                        <span class="info-value">{final_depth}</span>
                    </div>
                </div>
            </div>
        </div>
        '''
    
    def _pro_circuits_section(self, circuits: List[Dict]) -> str:
        """GÃ©nÃ¨re la section circuits (style pro)."""
        if not circuits:
            return ''
        
        rows = ''
        # [v2.5.21] Pas de limite - afficher tous les circuits
        for i, c in enumerate(circuits):
            # [v2.5.21] Extraction robuste du nombre de qubits
            # PrioritÃ©: n_qubits > len(physical_qubits) > num_qubits
            n_qubits = c.get('n_qubits')
            if n_qubits is None:
                phys_qubits = c.get('physical_qubits')
                if isinstance(phys_qubits, list) and phys_qubits:
                    n_qubits = len(phys_qubits)
                else:
                    n_qubits = c.get('num_qubits', 'N/A')
            
            # Depth: transpiled_depth ou depth
            depth = c.get('transpiled_depth') or c.get('depth') or 'N/A'
            
            # Gates 2Q
            gates_2q = c.get('gates_2q') or c.get('num_2q_gates') or 'N/A'
            
            rows += f'''
            <tr>
                <td class="numeric">{i}</td>
                <td>{c.get('name', f'circuit_{i}')[:35]}</td>
                <td class="numeric">{n_qubits}</td>
                <td class="numeric">{depth}</td>
                <td class="numeric">{gates_2q}</td>
            </tr>
            '''
        
        return f'''
        <div class="section-header">
            <span class="section-number">4</span>
            <h2>Transpiled Circuits ({len(circuits)})</h2>
        </div>
        <table class="data-table">
            <thead>
                <tr><th>#</th><th>Name</th><th>Qubits</th><th>Depth</th><th>2Q Gates</th></tr>
            </thead>
            <tbody>{rows}</tbody>
        </table>
        '''
    
    def _pro_circuit_viz_section(self, images: List[Dict]) -> str:
        """GÃ©nÃ¨re la section visualisation circuits (style pro)."""
        if not images:
            return ''
        
        items = ''
        for img in images:
            items += f'''
            <div class="viz-item">
                <div class="viz-item-header">{img.get('name', 'Circuit')} | {img.get('n_qubits', '?')}q, d={img.get('depth', '?')}</div>
                <img src="data:image/png;base64,{img.get('image_base64', '')}" onclick="openModal(this.src)" loading="lazy">
            </div>
            '''
        
        return f'''
        <div class="section-header">
            <span class="section-number">5</span>
            <h2>Circuit Diagrams ({len(images)})</h2>
        </div>
        <p style="color: var(--text-muted); margin-bottom: 1rem; font-size: 0.85rem;">Click to enlarge</p>
        <div class="viz-gallery">{items}</div>
        '''
    
    def _pro_calibration_section(self, calib: Dict) -> str:
        """GÃ©nÃ¨re la section calibration (style pro)."""
        if not calib or not calib.get('available'):
            return ''
        
        # [v2.5.21] Utiliser les bonnes clÃ©s depuis _collect_calibration_data
        qubits_summary = calib.get('qubits_summary', {})
        gates_summary = calib.get('gates_summary', {})
        
        # Fallback pour compatibilitÃ© avec ancienne structure
        total_qubits = calib.get('num_qubits') or qubits_summary.get('total', 0)
        faulty = qubits_summary.get('faulty', 0)
        avg_t1 = qubits_summary.get('avg_t1_us', 0) or 0
        avg_t2 = qubits_summary.get('avg_t2_us', 0) or 0
        avg_readout = qubits_summary.get('avg_readout_error', 0) or 0
        
        # Gates info
        total_2q_gates = gates_summary.get('total_connections', 0) or len(calib.get('two_qubit_gates', []))
        avg_2q_error = gates_summary.get('avg_cx_error', 0) or 0
        
        # Date de calibration
        calib_date = calib.get('calibration_time') or 'N/A'
        if calib_date and calib_date != 'N/A':
            calib_date = str(calib_date)[:10]
        
        return f'''
        <div class="section-header">
            <span class="section-number">6</span>
            <h2>Backend Calibration</h2>
        </div>
        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem;">
            <div class="info-panel">
                <div class="info-panel-header">Qubit Metrics</div>
                <div class="info-grid">
                    <div class="info-item">
                        <span class="info-label">Total Qubits</span>
                        <span class="info-value">{total_qubits}</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Faulty</span>
                        <span class="info-value">{faulty}</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Avg T1</span>
                        <span class="info-value">{avg_t1:.1f} Âµs</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Avg T2</span>
                        <span class="info-value">{avg_t2:.1f} Âµs</span>
                    </div>
                </div>
            </div>
            <div class="info-panel">
                <div class="info-panel-header">Gate Metrics</div>
                <div class="info-grid">
                    <div class="info-item">
                        <span class="info-label">2Q Gates</span>
                        <span class="info-value">{total_2q_gates}</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Avg 2Q Error</span>
                        <span class="info-value">{avg_2q_error:.2f}%</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Readout Error</span>
                        <span class="info-value">{avg_readout:.2f}%</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Calibration</span>
                        <span class="info-value">{calib_date}</span>
                    </div>
                </div>
            </div>
        </div>
        '''
    
    def _pro_statistics_section(self, global_stats: Dict, per_circuit: List[Dict]) -> str:
        """GÃ©nÃ¨re la section statistiques (style pro)."""
        rows = ''
        for i, c in enumerate(per_circuit[:20]):
            rows += f'''
            <tr>
                <td class="numeric">{i}</td>
                <td class="numeric">{c.get('shots', 0):,}</td>
                <td class="numeric">{c.get('unique_outcomes', 0)}</td>
                <td class="numeric">{c.get('entropy_bits', 0):.2f}</td>
                <td class="numeric">{c.get('uniformity_percent', 0):.1f}%</td>
                <td style="font-family: monospace;">{c.get('top_bitstring', 'N/A')}</td>
                <td class="numeric">{c.get('top_probability', 0):.1f}%</td>
            </tr>
            '''
        
        return f'''
        <div class="section-header">
            <span class="section-number">7</span>
            <h2>Results Statistics</h2>
        </div>
        <div class="summary-grid" style="grid-template-columns: repeat(3, 1fr); margin-bottom: 1.5rem;">
            <div class="summary-card">
                <div class="summary-value">{global_stats.get('avg_entropy', 0):.2f}</div>
                <div class="summary-label">Avg Entropy (bits)</div>
            </div>
            <div class="summary-card">
                <div class="summary-value">{global_stats.get('avg_uniformity', 0):.1f}%</div>
                <div class="summary-label">Avg Uniformity</div>
            </div>
            <div class="summary-card">
                <div class="summary-value">{global_stats.get('avg_top_prob', 0):.1f}%</div>
                <div class="summary-label">Avg Top Prob</div>
            </div>
        </div>
        <table class="data-table">
            <thead>
                <tr><th>#</th><th>Shots</th><th>Outcomes</th><th>Entropy</th><th>Uniformity</th><th>Top Bitstring</th><th>Prob</th></tr>
            </thead>
            <tbody>{rows}</tbody>
        </table>
        '''
    
    def _pro_qiskit_viz_section(self, viz: Dict) -> str:
        """GÃ©nÃ¨re la section visualisations Qiskit (style pro)."""
        if not viz:
            return ''
        
        sections = ''
        
        histograms = viz.get('histograms', [])
        if histograms:
            items = ''.join([f'''
            <div class="viz-item">
                <div class="viz-item-header">Circuit {h.get('index', '?')}: {h.get('name', 'Unknown')[:25]}</div>
                <img src="data:image/png;base64,{h.get('image_base64', '')}" onclick="openModal(this.src)" loading="lazy">
            </div>
            ''' for h in histograms])
            sections += f'<h3 style="margin: 1.5rem 0 1rem; font-size: 0.95rem;">Measurement Histograms</h3><div class="viz-gallery">{items}</div>'
        
        comparison = viz.get('comparison_charts', [])
        if comparison:
            items = ''.join([f'''
            <div class="viz-item" style="grid-column: 1 / -1;">
                <div class="viz-item-header">{c.get('name', 'Comparison')}</div>
                <img src="data:image/png;base64,{c.get('image_base64', '')}" onclick="openModal(this.src)" loading="lazy">
            </div>
            ''' for c in comparison])
            sections += f'<h3 style="margin: 1.5rem 0 1rem; font-size: 0.95rem;">Comparative Analysis</h3><div class="viz-gallery">{items}</div>'
        
        heatmap = viz.get('qubit_heatmap')
        if heatmap:
            sections += f'''
            <h3 style="margin: 1.5rem 0 1rem; font-size: 0.95rem;">Qubit Quality Heatmap ({heatmap.get('n_qubits', 0)} qubits)</h3>
            <div class="viz-item" style="max-width: 800px;">
                <img src="data:image/png;base64,{heatmap.get('image_base64', '')}" onclick="openModal(this.src)" loading="lazy">
            </div>
            '''
        
        if not sections:
            return ''
        
        return f'''
        <div class="section-header">
            <span class="section-number">8</span>
            <h2>Advanced Visualizations</h2>
        </div>
        {sections}
        '''
    
    def _pro_files_section(self, files: List[Dict]) -> str:
        """GÃ©nÃ¨re la section fichiers (style pro)."""
        if not files:
            return ''
        
        rows = ''.join([f'''
        <tr>
            <td>{f.get('name', 'unknown')}</td>
            <td class="numeric">{f.get('size_kb', 0):.1f} KB</td>
            <td>{f.get('type', 'other')}</td>
        </tr>
        ''' for f in files])
        
        return f'''
        <div class="section-header">
            <span class="section-number">11</span>
            <h2>Generated Files ({len(files)})</h2>
        </div>
        <table class="data-table">
            <thead><tr><th>Filename</th><th>Size</th><th>Type</th></tr></thead>
            <tbody>{rows}</tbody>
        </table>
        '''
    
    def _generate_complete_html(self, data: Dict, title: str) -> str:
        """GÃ©nÃ¨re le HTML complet du rapport."""
        
        status = data.get('status', 'UNKNOWN')
        status_color = '#48bb78' if status == 'SUCCESS' else '#f56565'
        status_emoji = 'âœ…' if status == 'SUCCESS' else 'âŒ'
        
        # PrÃ©parer les donnÃ©es JSON pour JavaScript
        charts_data_json = json.dumps(data.get('charts_data', {}), indent=2)
        stats_json = json.dumps(data.get('statistics', {}), indent=2)
        
        html = f'''<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {{
            --primary: #667eea;
            --secondary: #764ba2;
            --success: #48bb78;
            --warning: #ed8936;
            --danger: #f56565;
            --info: #4299e1;
            --bg: #0f1419;
            --card-bg: #1a1f2e;
            --card-bg-alt: #242d3d;
            --text: #e2e8f0;
            --text-muted: #a0aec0;
            --border: #2d3748;
        }}
        
        * {{ box-sizing: border-box; margin: 0; padding: 0; }}
        
        body {{
            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            padding: 20px;
            min-height: 100vh;
        }}
        
        .container {{ max-width: 1600px; margin: 0 auto; }}
        
        /* Header */
        header {{
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            padding: 30px 40px;
            border-radius: 16px;
            margin-bottom: 30px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3);
        }}
        
        header h1 {{
            font-size: 2em;
            font-weight: 700;
            display: flex;
            align-items: center;
            gap: 15px;
        }}
        
        .status-badge {{
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 8px 20px;
            border-radius: 30px;
            font-weight: 600;
            font-size: 1.1em;
            background: {status_color};
            color: white;
        }}
        
        .meta-info {{
            text-align: right;
            font-size: 0.9em;
            opacity: 0.9;
        }}
        
        /* Grid layouts */
        .grid-2 {{ display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px; margin-bottom: 20px; }}
        .grid-3 {{ display: grid; grid-template-columns: repeat(3, 1fr); gap: 20px; margin-bottom: 20px; }}
        .grid-4 {{ display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; margin-bottom: 20px; }}
        
        @media (max-width: 1200px) {{
            .grid-4 {{ grid-template-columns: repeat(2, 1fr); }}
            .grid-3 {{ grid-template-columns: repeat(2, 1fr); }}
        }}
        @media (max-width: 768px) {{
            .grid-2, .grid-3, .grid-4 {{ grid-template-columns: 1fr; }}
        }}
        
        /* Cards */
        .card {{
            background: var(--card-bg);
            border-radius: 12px;
            padding: 24px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.3);
            border: 1px solid var(--border);
        }}
        
        .card-header {{
            display: flex;
            align-items: center;
            gap: 12px;
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 2px solid var(--primary);
        }}
        
        .card-header h3 {{
            font-size: 1.2em;
            color: var(--text);
        }}
        
        .card-header .icon {{
            font-size: 1.5em;
        }}
        
        /* Metrics */
        .metric {{
            background: var(--card-bg-alt);
            border-radius: 10px;
            padding: 20px;
            text-align: center;
        }}
        
        .metric-value {{
            font-size: 2.2em;
            font-weight: 700;
            color: var(--primary);
            line-height: 1.2;
        }}
        
        .metric-label {{
            font-size: 0.85em;
            color: var(--text-muted);
            margin-top: 5px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }}
        
        .metric.success .metric-value {{ color: var(--success); }}
        .metric.warning .metric-value {{ color: var(--warning); }}
        .metric.danger .metric-value {{ color: var(--danger); }}
        .metric.info .metric-value {{ color: var(--info); }}
        
        /* Tables */
        table {{
            width: 100%;
            border-collapse: collapse;
            margin-top: 15px;
            font-size: 0.9em;
        }}
        
        th, td {{
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid var(--border);
        }}
        
        th {{
            background: var(--card-bg-alt);
            color: var(--primary);
            font-weight: 600;
            text-transform: uppercase;
            font-size: 0.8em;
            letter-spacing: 0.5px;
        }}
        
        tr:hover td {{ background: rgba(102, 126, 234, 0.1); }}
        
        /* Charts */
        .chart-container {{
            position: relative;
            height: 300px;
            margin-top: 15px;
        }}
        
        .chart-container.large {{ height: 400px; }}
        
        /* Progress bars */
        .progress-bar {{
            background: var(--card-bg-alt);
            border-radius: 10px;
            height: 24px;
            overflow: hidden;
            margin: 10px 0;
        }}
        
        .progress-fill {{
            height: 100%;
            border-radius: 10px;
            transition: width 0.5s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.75em;
            font-weight: 600;
        }}
        
        .progress-fill.success {{ background: linear-gradient(90deg, #48bb78, #38a169); }}
        .progress-fill.warning {{ background: linear-gradient(90deg, #ed8936, #dd6b20); }}
        .progress-fill.danger {{ background: linear-gradient(90deg, #f56565, #e53e3e); }}
        .progress-fill.info {{ background: linear-gradient(90deg, #4299e1, #3182ce); }}
        
        /* Code blocks */
        .code-block {{
            background: #0d1117;
            border-radius: 8px;
            padding: 15px;
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.85em;
            overflow-x: auto;
            border: 1px solid var(--border);
        }}
        
        /* JSON Viewer */
        .json-viewer {{
            background: #0d1117;
            border-radius: 8px;
            padding: 15px;
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.85em;
            overflow-x: auto;
            border: 1px solid var(--border);
            max-height: 600px;
            overflow-y: auto;
        }}
        .json-viewer .json-key {{ color: #7ee787; }}
        .json-viewer .json-string {{ color: #a5d6ff; }}
        .json-viewer .json-number {{ color: #79c0ff; }}
        .json-viewer .json-boolean {{ color: #ff7b72; }}
        .json-viewer .json-null {{ color: #8b949e; }}
        .json-viewer .json-bracket {{ color: #8b949e; }}
        .json-viewer .json-comma {{ color: #8b949e; }}
        .json-viewer .json-toggle {{ 
            cursor: pointer; 
            color: #58a6ff; 
            margin-left: 5px;
            user-select: none;
        }}
        .json-viewer .json-content {{ padding-left: 20px; }}
        .json-viewer .json-item {{ margin: 2px 0; }}
        
        /* File links */
        .file-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
            gap: 15px;
        }}
        .file-item {{
            background: var(--card-bg-alt);
            border-radius: 10px;
            padding: 15px;
            display: flex;
            align-items: center;
            gap: 12px;
            border: 1px solid var(--border);
            transition: all 0.2s;
        }}
        .file-item:hover {{
            border-color: var(--primary);
            transform: translateY(-2px);
        }}
        .file-icon {{
            font-size: 2em;
            width: 50px;
            height: 50px;
            display: flex;
            align-items: center;
            justify-content: center;
            background: var(--bg);
            border-radius: 8px;
        }}
        .file-info {{ flex: 1; }}
        .file-name {{ font-weight: 600; word-break: break-word; }}
        .file-meta {{ font-size: 0.8em; color: var(--text-muted); margin-top: 4px; }}
        .file-link {{
            color: var(--primary);
            text-decoration: none;
            font-size: 0.85em;
        }}
        .file-link:hover {{ text-decoration: underline; }}
        
        /* Transpilation score */
        .score-badge {{
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 60px;
            height: 60px;
            border-radius: 50%;
            font-size: 1.2em;
            font-weight: 700;
        }}
        .score-badge.go {{ background: rgba(72, 187, 120, 0.2); color: var(--success); border: 2px solid var(--success); }}
        .score-badge.warn {{ background: rgba(237, 137, 54, 0.2); color: var(--warning); border: 2px solid var(--warning); }}
        .score-badge.nogo {{ background: rgba(245, 101, 101, 0.2); color: var(--danger); border: 2px solid var(--danger); }}

        /* Error section */
        .error-section {{
            background: linear-gradient(135deg, rgba(245, 101, 101, 0.1), rgba(229, 62, 62, 0.1));
            border: 1px solid var(--danger);
            border-radius: 12px;
            padding: 24px;
            margin-bottom: 20px;
        }}
        
        .error-section h3 {{
            color: var(--danger);
            margin-bottom: 15px;
        }}
        
        /* Timeline */
        .timeline {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 20px 0;
        }}
        
        .timeline-item {{
            text-align: center;
            flex: 1;
            position: relative;
        }}
        
        .timeline-item::after {{
            content: '';
            position: absolute;
            top: 20px;
            right: -50%;
            width: 100%;
            height: 3px;
            background: var(--border);
            z-index: 0;
        }}
        
        .timeline-item:last-child::after {{ display: none; }}
        
        .timeline-dot {{
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: var(--primary);
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto 10px;
            position: relative;
            z-index: 1;
        }}
        
        .timeline-label {{ font-size: 0.85em; color: var(--text-muted); }}
        .timeline-value {{ font-weight: 600; margin-top: 5px; }}
        
        /* Section titles */
        .section-title {{
            font-size: 1.5em;
            font-weight: 700;
            margin: 40px 0 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid var(--primary);
            display: flex;
            align-items: center;
            gap: 10px;
        }}
        
        /* Footer */
        footer {{
            text-align: center;
            padding: 30px;
            color: var(--text-muted);
            margin-top: 40px;
            border-top: 1px solid var(--border);
        }}
        
        /* Collapsible */
        .collapsible {{
            cursor: pointer;
            user-select: none;
        }}
        
        .collapsible-content {{
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease;
        }}
        
        .collapsible-content.open {{ max-height: 2000px; }}
        
        /* Animations */
        @keyframes fadeIn {{
            from {{ opacity: 0; transform: translateY(20px); }}
            to {{ opacity: 1; transform: translateY(0); }}
        }}
        
        .card {{ animation: fadeIn 0.5s ease forwards; }}
        
        /* Print styles */
        @media print {{
            body {{ background: white; color: black; }}
            .card {{ box-shadow: none; border: 1px solid #ddd; page-break-inside: avoid; }}
            header {{ background: #667eea; -webkit-print-color-adjust: exact; }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <!-- HEADER -->
        <header>
            <div>
                <h1>
                    <span>ğŸ”¬</span>
                    QMC Quantum Report
                </h1>
                <p style="margin-top: 10px; opacity: 0.9;">
                    {data.get('project', 'QMC')} | {data.get('backend_name', 'N/A')}
                </p>
            </div>
            <div class="meta-info">
                <div class="status-badge">{status_emoji} {status}</div>
                <p style="margin-top: 10px;">Framework v{data.get('framework_version', __version__)}</p>
                <p>{datetime.now().strftime('%d/%m/%Y %H:%M:%S')}</p>
            </div>
        </header>
        
        <!-- RÃ‰SUMÃ‰ EXÃ‰CUTIF -->
        <div class="grid-4">
            <div class="metric {'success' if status == 'SUCCESS' else 'danger'}">
                <div class="metric-value">{data.get('results_count', 0)}</div>
                <div class="metric-label">Circuits ExÃ©cutÃ©s</div>
            </div>
            <div class="metric info">
                <div class="metric-value">{data.get('run_context', {}).get('shots', 0):,}</div>
                <div class="metric-label">Shots/Circuit</div>
            </div>
            <div class="metric">
                <div class="metric-value">{data.get('summary', {}).get('total_shots', 0):,}</div>
                <div class="metric-label">Shots Totaux</div>
            </div>
            <div class="metric info">
                <div class="metric-value">{data.get('timing', {}).get('total_time_s', 0):.1f}s</div>
                <div class="metric-label">Temps Total</div>
            </div>
        </div>
        
        {self._generate_error_section(data.get('error'))}
        
        <!-- TIMELINE D'EXÃ‰CUTION -->
        <div class="card">
            <div class="card-header">
                <span class="icon">â±ï¸</span>
                <h3>Timeline d'ExÃ©cution</h3>
            </div>
            <div class="timeline">
                <div class="timeline-item">
                    <div class="timeline-dot">ğŸ“¤</div>
                    <div class="timeline-label">Soumission</div>
                    <div class="timeline-value">{data.get('run_context', {}).get('submitted_at', 'N/A')}</div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-dot">â³</div>
                    <div class="timeline-label">Queue</div>
                    <div class="timeline-value">{data.get('timing', {}).get('queue_time_s', 0):.1f}s</div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-dot">âš¡</div>
                    <div class="timeline-label">ExÃ©cution QPU</div>
                    <div class="timeline-value">{data.get('timing', {}).get('qpu_time_s', 0):.2f}s</div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-dot">âœ…</div>
                    <div class="timeline-label">TerminÃ©</div>
                    <div class="timeline-value">{data.get('run_context', {}).get('completed_at', 'N/A')}</div>
                </div>
            </div>
        </div>
        
        <!-- CONFIGURATION -->
        <h2 class="section-title">âš™ï¸ Configuration</h2>
        <div class="grid-2">
            <div class="card">
                <div class="card-header">
                    <span class="icon">ğŸ–¥ï¸</span>
                    <h3>Backend & Environnement</h3>
                </div>
                <table>
                    <tr><td>Backend</td><td><strong>{data.get('backend_name', 'N/A')}</strong></td></tr>
                    <tr><td>Job ID</td><td><code>{data.get('run_context', {}).get('job_id', 'N/A')}</code></td></tr>
                    <tr><td>Framework</td><td>v{data.get('framework_version', __version__)}</td></tr>
                    <tr><td>Python</td><td>{data.get('python_version', 'N/A')}</td></tr>
                </table>
            </div>
            <div class="card">
                <div class="card-header">
                    <span class="icon">ğŸ›ï¸</span>
                    <h3>ParamÃ¨tres d'ExÃ©cution</h3>
                </div>
                <table>
                    <tr><td>Shots</td><td><strong>{data.get('run_context', {}).get('shots', 0):,}</strong></td></tr>
                    <tr><td>Circuits</td><td>{data.get('run_context', {}).get('circuits_count', 0)}</td></tr>
                    <tr><td>Optimization Level</td><td>{data.get('run_context', {}).get('optimization_level', 3)}</td></tr>
                    <tr><td>Layout Strategy</td><td>{data.get('run_context', {}).get('layout_strategy', 'auto')}</td></tr>
                </table>
            </div>
        </div>
        
        <!-- TRANSPILATION -->
        {self._generate_transpilation_section(data.get('transpilation', {}))}
        
        <!-- CIRCUITS DÃ‰TAILLÃ‰S -->
        {self._generate_circuits_details_section(data.get('circuits_details', []))}
        
        <!-- VISUALISATION DES CIRCUITS -->
        {self._generate_circuit_visualizations_section(data.get('circuit_images', []))}
        
        <!-- CALIBRATION DU BACKEND -->
        {self._generate_calibration_section(data.get('calibration', {}))}
        
        <!-- STATISTIQUES GLOBALES -->
        <h2 class="section-title">ğŸ“Š Statistiques Globales</h2>
        <div class="grid-3">
            <div class="metric">
                <div class="metric-value">{data.get('statistics', {}).get('global', {}).get('avg_entropy', 0):.2f}</div>
                <div class="metric-label">Entropie Moyenne (bits)</div>
            </div>
            <div class="metric">
                <div class="metric-value">{data.get('statistics', {}).get('global', {}).get('avg_uniformity', 0):.1f}%</div>
                <div class="metric-label">UniformitÃ© Moyenne</div>
            </div>
            <div class="metric">
                <div class="metric-value">{data.get('statistics', {}).get('global', {}).get('avg_top_prob', 0):.1f}%</div>
                <div class="metric-label">Prob. Top Bitstring Moy.</div>
            </div>
        </div>
        
        <!-- VISUALISATIONS QISKIT PROFESSIONNELLES -->
        {self._generate_qiskit_visualizations_section(data.get('qiskit_visualizations', {}))}
        
        <!-- GRAPHIQUE DISTRIBUTION -->
        <div class="card">
            <div class="card-header">
                <span class="icon">ğŸ“ˆ</span>
                <h3>Distribution des RÃ©sultats (Premier Circuit)</h3>
            </div>
            <div class="chart-container large">
                <canvas id="distributionChart"></canvas>
            </div>
        </div>
        
        <!-- DÃ‰TAILS PAR CIRCUIT -->
        <h2 class="section-title">ğŸ“‹ DÃ©tails par Circuit</h2>
        <div class="card">
            <table>
                <thead>
                    <tr>
                        <th>#</th>
                        <th>Shots</th>
                        <th>Outcomes</th>
                        <th>Entropie</th>
                        <th>UniformitÃ©</th>
                        <th>Top Bitstring</th>
                        <th>Prob.</th>
                    </tr>
                </thead>
                <tbody>
                    {self._generate_circuit_rows(data.get('statistics', {}).get('per_circuit', []))}
                </tbody>
            </table>
        </div>
        
        <!-- FICHIERS GÃ‰NÃ‰RÃ‰S -->
        {self._generate_files_section(data.get('files', []))}
        
        <!-- DONNÃ‰ES BRUTES COMPLÃˆTES -->
        <h2 class="section-title collapsible" onclick="toggleCollapsible('raw-data')">
            ğŸ“¦ DonnÃ©es JSON ComplÃ¨tes (cliquer pour afficher)
        </h2>
        <div id="raw-data" class="collapsible-content">
            <div class="card">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px;">
                    <span>ğŸ” Visualisation JSON interactive</span>
                    <button onclick="copyJsonToClipboard()" style="background: var(--primary); color: white; border: none; padding: 8px 16px; border-radius: 6px; cursor: pointer;">
                        ğŸ“‹ Copier JSON
                    </button>
                </div>
                <div id="json-viewer" class="json-viewer"></div>
            </div>
        </div>
        
        <!-- FOOTER -->
        <footer>
            <p><strong>QMC Quantum Framework v{__version__}</strong></p>
            <p>QMC Research Lab 2025 | Quantum Mandatory Cryptography</p>
            <p style="margin-top: 10px; font-size: 0.85em;">
                Rapport gÃ©nÃ©rÃ© automatiquement | {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
            </p>
        </footer>
    </div>
    
    <script>
        // DonnÃ©es complÃ¨tes pour export
        const fullData = {json.dumps(data, indent=2, default=str)};
        const chartsData = {charts_data_json};
        const statsData = {stats_json};
        
        // JSON Viewer interactif
        function renderJsonViewer(data, container, level = 0) {{
            const indent = '  '.repeat(level);
            let html = '';
            
            if (Array.isArray(data)) {{
                if (data.length === 0) {{
                    html = '<span class="json-bracket">[]</span>';
                }} else {{
                    html = '<span class="json-bracket">[</span>';
                    html += `<span class="json-toggle" onclick="toggleJson(this)">â–¼</span>`;
                    html += '<div class="json-content">';
                    data.forEach((item, i) => {{
                        html += '<div class="json-item">';
                        html += renderJsonViewer(item, null, level + 1);
                        if (i < data.length - 1) html += '<span class="json-comma">,</span>';
                        html += '</div>';
                    }});
                    html += '</div>';
                    html += '<span class="json-bracket">]</span>';
                }}
            }} else if (typeof data === 'object' && data !== null) {{
                const keys = Object.keys(data);
                if (keys.length === 0) {{
                    html = '<span class="json-bracket">{{}}</span>';
                }} else {{
                    html = '<span class="json-bracket">{{</span>';
                    html += `<span class="json-toggle" onclick="toggleJson(this)">â–¼</span>`;
                    html += '<div class="json-content">';
                    keys.forEach((key, i) => {{
                        html += '<div class="json-item">';
                        html += `<span class="json-key">"${{key}}"</span>: `;
                        html += renderJsonViewer(data[key], null, level + 1);
                        if (i < keys.length - 1) html += '<span class="json-comma">,</span>';
                        html += '</div>';
                    }});
                    html += '</div>';
                    html += '<span class="json-bracket">}}</span>';
                }}
            }} else if (typeof data === 'string') {{
                html = `<span class="json-string">"${{data}}"</span>`;
            }} else if (typeof data === 'number') {{
                html = `<span class="json-number">${{data}}</span>`;
            }} else if (typeof data === 'boolean') {{
                html = `<span class="json-boolean">${{data}}</span>`;
            }} else if (data === null) {{
                html = '<span class="json-null">null</span>';
            }}
            
            if (container) {{
                container.innerHTML = html;
            }}
            return html;
        }}
        
        function toggleJson(el) {{
            const content = el.nextElementSibling;
            if (content.style.display === 'none') {{
                content.style.display = 'block';
                el.textContent = 'â–¼';
            }} else {{
                content.style.display = 'none';
                el.textContent = 'â–¶';
            }}
        }}
        
        function copyJsonToClipboard() {{
            navigator.clipboard.writeText(JSON.stringify(fullData, null, 2));
            alert('JSON copiÃ© dans le presse-papier!');
        }}
        
        // Initialiser le JSON viewer
        document.addEventListener('DOMContentLoaded', () => {{
            const viewer = document.getElementById('json-viewer');
            if (viewer) {{
                renderJsonViewer(fullData, viewer);
            }}
        }});
        
        // Graphique de distribution
        if (chartsData.distributions && chartsData.distributions.length > 0) {{
            const dist = chartsData.distributions[0];
            const ctx = document.getElementById('distributionChart').getContext('2d');
            
            new Chart(ctx, {{
                type: 'bar',
                data: {{
                    labels: dist.data.map(d => d.bitstring),
                    datasets: [{{
                        label: 'ProbabilitÃ© (%)',
                        data: dist.data.map(d => d.probability),
                        backgroundColor: 'rgba(102, 126, 234, 0.7)',
                        borderColor: 'rgba(102, 126, 234, 1)',
                        borderWidth: 2,
                        borderRadius: 6,
                    }}]
                }},
                options: {{
                    responsive: true,
                    maintainAspectRatio: false,
                    plugins: {{
                        legend: {{ display: false }},
                        tooltip: {{
                            backgroundColor: '#1a1f2e',
                            titleColor: '#e2e8f0',
                            bodyColor: '#e2e8f0',
                            borderColor: '#667eea',
                            borderWidth: 1,
                        }}
                    }},
                    scales: {{
                        y: {{
                            beginAtZero: true,
                            title: {{ display: true, text: 'ProbabilitÃ© (%)', color: '#a0aec0' }},
                            grid: {{ color: '#2d3748' }},
                            ticks: {{ color: '#a0aec0' }}
                        }},
                        x: {{
                            title: {{ display: true, text: 'Bitstring', color: '#a0aec0' }},
                            grid: {{ display: false }},
                            ticks: {{ color: '#a0aec0', maxRotation: 45 }}
                        }}
                    }}
                }}
            }});
        }}
        
        // Fonction pour toggle les sections collapsibles
        function toggleCollapsible(id) {{
            const content = document.getElementById(id);
            content.classList.toggle('open');
        }}
    </script>
</body>
</html>'''
        
        return html
    
    def _generate_error_section(self, error: Dict) -> str:
        """GÃ©nÃ¨re la section d'erreur si prÃ©sente."""
        if not error:
            return ''
        
        return f'''
        <div class="error-section">
            <h3>âŒ Erreur RencontrÃ©e</h3>
            <p><strong>Type:</strong> {error.get('type', 'Unknown')}</p>
            <p><strong>Message:</strong> {error.get('message', 'No message')}</p>
            <details style="margin-top: 15px;">
                <summary style="cursor: pointer; color: var(--danger);">Voir le traceback complet</summary>
                <div class="code-block" style="margin-top: 10px;">
                    <pre>{error.get('traceback', 'No traceback available')}</pre>
                </div>
            </details>
        </div>
        '''
    
    def _generate_calibration_section(self, calib: Dict) -> str:
        """GÃ©nÃ¨re la section calibration COMPLÃˆTE du QPU."""
        
        # Message si non disponible
        if not calib.get('available'):
            error_msg = calib.get('error', 'DonnÃ©es non disponibles')
            return f'''
            <h2 class="section-title">ğŸ“¡ Ã‰tat du QPU</h2>
            <div class="card">
                <p style="color: var(--warning);">âš ï¸ {error_msg}</p>
                <p style="color: var(--text-muted); margin-top: 10px;">
                    Pour obtenir les donnÃ©es de calibration, assurez-vous que:
                    <br>â€¢ Le framework est connectÃ© Ã  un backend IBM rÃ©el
                    <br>â€¢ Le backend expose ses propriÃ©tÃ©s (target ou properties)
                </p>
            </div>
            '''
        
        # Extraire les donnÃ©es
        summary = calib.get('qubits_summary', {})
        gates_summary = calib.get('gates_summary', {})
        faulty = calib.get('faulty_qubits', [])
        qubits_info = calib.get('qubits_info', [])
        two_q_gates = calib.get('two_qubit_gates', [])
        
        # GÃ©nÃ©rer les lignes du tableau des qubits (top 20)
        qubits_rows = ''
        for q in qubits_info[:20]:
            status_class = 'danger' if q.get('status') == 'FAULTY' else ''
            status_icon = 'âŒ' if q.get('status') == 'FAULTY' else 'âœ…'
            qubits_rows += f'''
            <tr class="{status_class}">
                <td>{status_icon} Q{q.get('index', '?')}</td>
                <td>{q.get('t1_us', 'N/A') if q.get('t1_us') else 'N/A'}</td>
                <td>{q.get('t2_us', 'N/A') if q.get('t2_us') else 'N/A'}</td>
                <td style="color: {'var(--danger)' if q.get('readout_error') and q.get('readout_error') > 5 else 'inherit'}">{q.get('readout_error', 'N/A') if q.get('readout_error') else 'N/A'}%</td>
                <td>{q.get('frequency_ghz', 'N/A') if q.get('frequency_ghz') else 'N/A'}</td>
            </tr>
            '''
        
        # GÃ©nÃ©rer les lignes des gates 2-qubit (top 15 pires)
        gates_rows = ''
        sorted_gates = sorted(two_q_gates, key=lambda x: x.get('error_pct', 0), reverse=True)[:15]
        for g in sorted_gates:
            error_class = 'danger' if g.get('error_pct', 0) > 2 else ('warning' if g.get('error_pct', 0) > 1 else '')
            gates_rows += f'''
            <tr class="{error_class}">
                <td>{g.get('gate', 'CX')}</td>
                <td>Q{g['qubits'][0]} â†’ Q{g['qubits'][1]}</td>
                <td style="color: {'var(--danger)' if g.get('error_pct', 0) > 2 else 'inherit'}">{g.get('error_pct', 'N/A')}%</td>
                <td>{g.get('duration_ns', 'N/A')} ns</td>
            </tr>
            '''
        
        # Liste des qubits faulty
        faulty_str = ', '.join([f'Q{q}' for q in faulty[:20]]) if faulty else 'Aucun'
        if len(faulty) > 20:
            faulty_str += f' ... (+{len(faulty) - 20} autres)'
        
        # Nombre total de qubits Ã  afficher
        total_qubits = summary.get('total', calib.get('num_qubits', 0))
        remaining_qubits = total_qubits - 20 if total_qubits > 20 else 0
        
        return f'''
        <h2 class="section-title">ğŸ“¡ Ã‰tat Complet du QPU</h2>
        
        <!-- MÃ©triques principales -->
        <div class="grid-4">
            <div class="metric info">
                <div class="metric-value">{total_qubits}</div>
                <div class="metric-label">Qubits Totaux</div>
            </div>
            <div class="metric {'success' if summary.get('operational', 0) == total_qubits else 'warning'}">
                <div class="metric-value">{summary.get('operational', total_qubits)}</div>
                <div class="metric-label">OpÃ©rationnels</div>
            </div>
            <div class="metric {'danger' if faulty else 'success'}">
                <div class="metric-value">{len(faulty)}</div>
                <div class="metric-label">Faulty (>10% err)</div>
            </div>
            <div class="metric info">
                <div class="metric-value">{gates_summary.get('total_connections', len(two_q_gates))}</div>
                <div class="metric-label">Connexions 2Q</div>
            </div>
        </div>
        
        <!-- MÃ©triques T1/T2 et erreurs -->
        <div class="grid-2" style="margin-top: 20px;">
            <div class="card">
                <div class="card-header">
                    <span class="icon">â±ï¸</span>
                    <h3>Temps de CohÃ©rence</h3>
                </div>
                <div class="grid-2">
                    <div class="metric">
                        <div class="metric-value">{summary.get('avg_t1_us', 'N/A')}</div>
                        <div class="metric-label">T1 Moyen (Âµs)</div>
                    </div>
                    <div class="metric">
                        <div class="metric-value">{summary.get('avg_t2_us', 'N/A')}</div>
                        <div class="metric-label">T2 Moyen (Âµs)</div>
                    </div>
                </div>
                <p style="margin-top: 15px; color: var(--text-muted); font-size: 0.85em;">
                    T1 Range: {summary.get('min_t1_us', 'N/A')} - {summary.get('max_t1_us', 'N/A')} Âµs
                </p>
            </div>
            
            <div class="card">
                <div class="card-header">
                    <span class="icon">ğŸ“Š</span>
                    <h3>Erreurs</h3>
                </div>
                <div class="grid-2">
                    <div class="metric {'warning' if summary.get('avg_readout_error') and summary.get('avg_readout_error') > 2 else ''}">
                        <div class="metric-value">{summary.get('avg_readout_error', 'N/A')}%</div>
                        <div class="metric-label">Readout Moy.</div>
                    </div>
                    <div class="metric {'warning' if gates_summary.get('avg_cx_error') and gates_summary.get('avg_cx_error') > 1 else ''}">
                        <div class="metric-value">{gates_summary.get('avg_cx_error', 'N/A')}%</div>
                        <div class="metric-label">CX/ECR Moy.</div>
                    </div>
                </div>
                <p style="margin-top: 15px; color: var(--text-muted); font-size: 0.85em;">
                    Worst Readout: {summary.get('worst_readout_error', 'N/A')}% | 
                    Worst CX: {gates_summary.get('worst_cx_error', 'N/A')}%
                </p>
            </div>
        </div>
        
        <!-- Tableau des qubits -->
        <div class="card" style="margin-top: 20px;">
            <div class="card-header">
                <span class="icon">ğŸ”¬</span>
                <h3>DÃ©tails par Qubit (Top 20 sur {total_qubits})</h3>
            </div>
            <table>
                <thead>
                    <tr>
                        <th>Qubit</th>
                        <th>T1 (Âµs)</th>
                        <th>T2 (Âµs)</th>
                        <th>Readout Err</th>
                        <th>FrÃ©quence (GHz)</th>
                    </tr>
                </thead>
                <tbody>{qubits_rows}</tbody>
            </table>
            {f'<p style="margin-top: 10px; color: var(--text-muted);">... et {remaining_qubits} autres qubits</p>' if remaining_qubits > 0 else ''}
        </div>
        
        <!-- Tableau des gates 2-qubit -->
        {f"""
        <div class="card" style="margin-top: 20px;">
            <div class="card-header">
                <span class="icon">ğŸ”—</span>
                <h3>Gates 2-Qubit (Top 15 - Pires erreurs)</h3>
            </div>
            <table>
                <thead>
                    <tr>
                        <th>Gate</th>
                        <th>Qubits</th>
                        <th>Erreur</th>
                        <th>DurÃ©e</th>
                    </tr>
                </thead>
                <tbody>{gates_rows}</tbody>
            </table>
            <p style="margin-top: 10px; color: var(--text-muted);">
                Meilleure connexion: {gates_summary.get('best_cx_error', 'N/A')}% erreur
            </p>
        </div>
        """ if gates_rows else ''}
        
        <!-- Qubits Ã  Ã©viter -->
        <div class="card" style="margin-top: 20px; {'border-color: var(--danger);' if faulty else ''}">
            <div class="card-header">
                <span class="icon">{'âš ï¸' if faulty else 'âœ…'}</span>
                <h3>{'Qubits Ã  Ã‰viter' if faulty else 'Tous les Qubits OpÃ©rationnels'}</h3>
            </div>
            <p style="color: {'var(--danger)' if faulty else 'var(--success)'};">
                {faulty_str}
            </p>
            {f'<p style="margin-top: 10px; color: var(--text-muted); font-size: 0.85em;">Ces qubits ont une erreur de lecture > 10%</p>' if faulty else ''}
        </div>
        '''
    
    def _generate_transpilation_section(self, trans: Dict) -> str:
        """[v2.5.18] GÃ©nÃ¨re la section transpilation."""
        if not trans.get('available'):
            return ''
        
        score = trans.get('score', 0)
        recommendation = trans.get('recommendation', 'WARN')
        overhead = trans.get('overhead_2q_percent', 0)
        swaps = trans.get('swaps_estimated', 0)
        depth_exp = trans.get('depth_expansion', 1)
        
        # Couleurs selon recommandation
        if recommendation == 'GO':
            badge_class = 'go'
            rec_text = 'ğŸŸ¢ GO - ExÃ©cution recommandÃ©e'
            rec_color = 'var(--success)'
        elif recommendation == 'WARN':
            badge_class = 'warn'
            rec_text = 'ğŸŸ¡ WARN - Overhead modÃ©rÃ©'
            rec_color = 'var(--warning)'
        else:
            badge_class = 'nogo'
            rec_text = 'ğŸ”´ NO-GO - Overhead excessif'
            rec_color = 'var(--danger)'
        
        before = trans.get('before', {})
        after = trans.get('after', {})
        
        return f'''
        <h2 class="section-title">ğŸ”§ QualitÃ© de Transpilation</h2>
        <div class="grid-2">
            <div class="card" style="text-align: center;">
                <div class="card-header">
                    <span class="icon">ğŸ“</span>
                    <h3>Score Global</h3>
                </div>
                <div style="display: flex; align-items: center; justify-content: center; gap: 30px;">
                    <div class="score-badge {badge_class}">{score}</div>
                    <div style="text-align: left;">
                        <div style="font-size: 1.1em; font-weight: 600; color: {rec_color};">{rec_text}</div>
                        <div style="color: var(--text-muted); margin-top: 5px;">sur 100 points</div>
                    </div>
                </div>
            </div>
            <div class="card">
                <div class="card-header">
                    <span class="icon">ğŸ“Š</span>
                    <h3>MÃ©triques de Transpilation</h3>
                </div>
                <table>
                    <tr><td>Overhead 2Q</td><td style="color: {'var(--danger)' if overhead > 100 else ('var(--warning)' if overhead > 50 else 'inherit')}">{overhead:+.1f}%</td></tr>
                    <tr><td>SWAPs estimÃ©s</td><td>~{swaps}</td></tr>
                    <tr><td>Expansion profondeur</td><td>{depth_exp:.2f}x</td></tr>
                    <tr><td>Profondeur avant</td><td>{before.get('depth', 'N/A')}</td></tr>
                    <tr><td>Profondeur aprÃ¨s</td><td>{after.get('depth', 'N/A')}</td></tr>
                    <tr><td>Gates 2Q avant</td><td>{before.get('gates_2q', 'N/A')}</td></tr>
                    <tr><td>Gates 2Q aprÃ¨s</td><td>{after.get('gates_2q', 'N/A')}</td></tr>
                </table>
            </div>
        </div>
        '''
    
    def _generate_circuits_details_section(self, circuits: List[Dict]) -> str:
        """[v2.5.18] GÃ©nÃ¨re la section dÃ©tails des circuits."""
        if not circuits:
            return ''
        
        # Calculer les stats globales
        total_circuits = len(circuits)
        total_depth = sum(c.get('transpiled_depth', 0) for c in circuits)
        total_2q = sum(c.get('gates_2q', 0) for c in circuits)
        avg_depth = total_depth / total_circuits if total_circuits else 0
        avg_2q = total_2q / total_circuits if total_circuits else 0
        
        # [v2.5.21] GÃ©nÃ©rer les lignes du tableau (tous les circuits)
        rows = ''
        for c in circuits:
            name = c.get('name', f"circuit_{c.get('index', '?')}")
            if len(name) > 25:
                name = name[:22] + '...'
            
            depth = c.get('transpiled_depth', 0) or c.get('depth', 0)
            gates_2q = c.get('gates_2q', 0)
            
            # [v2.5.21] PrioritÃ©: n_qubits > len(physical_qubits)
            n_qubits = c.get('n_qubits')
            if n_qubits is None:
                phys_qubits = c.get('physical_qubits', [])
                n_qubits = len(phys_qubits) if phys_qubits else c.get('num_qubits', '?')
            
            # Indicateur de warning si profondeur Ã©levÃ©e
            depth_warning = 'âš ï¸' if depth and depth > 200 else ''
            
            rows += f'''
            <tr>
                <td>{c.get('index', '?')}</td>
                <td title="{c.get('name', '')}">{name}</td>
                <td>{n_qubits}</td>
                <td>{depth_warning} {depth}</td>
                <td>{gates_2q}</td>
                <td>{'âœ…' if c.get('vf2_applied') else 'âŒ'}</td>
            </tr>
            '''
        
        return f'''
        <h2 class="section-title">ğŸ”Œ Circuits TranspilÃ©s ({total_circuits})</h2>
        <div class="grid-4" style="margin-bottom: 20px;">
            <div class="metric">
                <div class="metric-value">{total_circuits}</div>
                <div class="metric-label">Circuits</div>
            </div>
            <div class="metric">
                <div class="metric-value">{avg_depth:.0f}</div>
                <div class="metric-label">Profondeur Moy.</div>
            </div>
            <div class="metric">
                <div class="metric-value">{avg_2q:.0f}</div>
                <div class="metric-label">Gates 2Q Moy.</div>
            </div>
            <div class="metric">
                <div class="metric-value">{total_2q:,}</div>
                <div class="metric-label">Gates 2Q Total</div>
            </div>
        </div>
        <div class="card">
            <table>
                <thead>
                    <tr>
                        <th>#</th>
                        <th>Nom</th>
                        <th>Qubits</th>
                        <th>Profondeur</th>
                        <th>Gates 2Q</th>
                        <th>VF2</th>
                    </tr>
                </thead>
                <tbody>
                    {rows}
                </tbody>
            </table>
        </div>
        '''
    
    def _generate_circuit_visualizations_section(self, circuit_images: List[Dict]) -> str:
        """
        [v2.5.18] GÃ©nÃ¨re la section de visualisation des circuits avec images.
        
        Affiche les images base64 des circuits dans une galerie interactive
        avec possibilitÃ© de zoom et navigation.
        """
        if not circuit_images:
            return ''
        
        n_circuits = len(circuit_images)
        
        # GÃ©nÃ©rer les cartes d'images
        image_cards = ''
        for img in circuit_images:
            name = img.get('name', f"Circuit {img.get('index', '?')}")
            n_qubits = img.get('n_qubits', '?')
            depth = img.get('depth', '?')
            truncated = img.get('truncated', False)
            image_base64 = img.get('image_base64', '')
            
            truncated_badge = '<span class="truncated-badge">âš ï¸ TronquÃ©</span>' if truncated else ''
            
            image_cards += f'''
            <div class="circuit-card">
                <div class="circuit-header">
                    <span class="circuit-name" title="{img.get('full_name', name)}">{name}</span>
                    {truncated_badge}
                </div>
                <div class="circuit-image-container" onclick="openCircuitModal(this)">
                    <img src="data:image/png;base64,{image_base64}" 
                         alt="Circuit {img.get('index', '?')}"
                         class="circuit-image"
                         loading="lazy" />
                    <div class="circuit-overlay">ğŸ” Cliquer pour agrandir</div>
                </div>
                <div class="circuit-meta">
                    <span>ğŸ“ {n_qubits} qubits</span>
                    <span>ğŸ“ Profondeur: {depth}</span>
                </div>
            </div>
            '''
        
        return f'''
        <h2 class="section-title">âš›ï¸ Visualisation des Circuits ({n_circuits})</h2>
        <p style="color: var(--text-muted); margin-bottom: 15px;">
            SchÃ©mas des circuits transpilÃ©s avec cÃ¢blage rÃ©el et portes quantiques.
            Cliquez sur une image pour l'agrandir.
        </p>
        <div class="circuit-gallery">
            {image_cards}
        </div>
        
        <!-- Modal pour zoom -->
        <div id="circuit-modal" class="circuit-modal" onclick="closeCircuitModal()">
            <div class="modal-content">
                <span class="modal-close">&times;</span>
                <img id="modal-image" src="" alt="Circuit agrandi" />
            </div>
        </div>
        
        <style>
            .circuit-gallery {{
                display: grid;
                grid-template-columns: repeat(auto-fill, minmax(400px, 1fr));
                gap: 20px;
                margin-top: 15px;
            }}
            
            .circuit-card {{
                background: var(--card-bg);
                border-radius: 12px;
                overflow: hidden;
                border: 1px solid var(--border);
                transition: transform 0.2s, box-shadow 0.2s;
            }}
            
            .circuit-card:hover {{
                transform: translateY(-3px);
                box-shadow: 0 8px 25px rgba(102, 126, 234, 0.2);
            }}
            
            .circuit-header {{
                padding: 12px 15px;
                background: var(--card-bg-alt);
                border-bottom: 1px solid var(--border);
                display: flex;
                justify-content: space-between;
                align-items: center;
            }}
            
            .circuit-name {{
                font-weight: 600;
                color: var(--primary);
                white-space: nowrap;
                overflow: hidden;
                text-overflow: ellipsis;
                max-width: 250px;
            }}
            
            .truncated-badge {{
                background: rgba(237, 137, 54, 0.2);
                color: var(--warning);
                padding: 2px 8px;
                border-radius: 10px;
                font-size: 0.75em;
            }}
            
            .circuit-image-container {{
                position: relative;
                cursor: pointer;
                overflow: hidden;
            }}
            
            .circuit-image {{
                width: 100%;
                height: auto;
                display: block;
                transition: transform 0.3s;
            }}
            
            .circuit-overlay {{
                position: absolute;
                bottom: 0;
                left: 0;
                right: 0;
                background: linear-gradient(transparent, rgba(0,0,0,0.8));
                color: white;
                padding: 20px 15px 10px;
                text-align: center;
                font-size: 0.85em;
                opacity: 0;
                transition: opacity 0.3s;
            }}
            
            .circuit-image-container:hover .circuit-overlay {{
                opacity: 1;
            }}
            
            .circuit-image-container:hover .circuit-image {{
                transform: scale(1.02);
            }}
            
            .circuit-meta {{
                padding: 10px 15px;
                display: flex;
                justify-content: space-between;
                font-size: 0.85em;
                color: var(--text-muted);
            }}
            
            /* Modal */
            .circuit-modal {{
                display: none;
                position: fixed;
                z-index: 1000;
                left: 0;
                top: 0;
                width: 100%;
                height: 100%;
                background: rgba(0, 0, 0, 0.9);
                justify-content: center;
                align-items: center;
            }}
            
            .circuit-modal.active {{
                display: flex;
            }}
            
            .modal-content {{
                position: relative;
                max-width: 95%;
                max-height: 95%;
            }}
            
            .modal-content img {{
                max-width: 100%;
                max-height: 90vh;
                border-radius: 8px;
                box-shadow: 0 10px 50px rgba(0, 0, 0, 0.5);
            }}
            
            .modal-close {{
                position: absolute;
                top: -40px;
                right: 0;
                color: white;
                font-size: 35px;
                font-weight: bold;
                cursor: pointer;
                transition: color 0.2s;
            }}
            
            .modal-close:hover {{
                color: var(--primary);
            }}
            
            @media (max-width: 768px) {{
                .circuit-gallery {{
                    grid-template-columns: 1fr;
                }}
            }}
        </style>
        
        <script>
            function openCircuitModal(container) {{
                const img = container.querySelector('img');
                const modal = document.getElementById('circuit-modal');
                const modalImg = document.getElementById('modal-image');
                modalImg.src = img.src;
                modal.classList.add('active');
            }}
            
            function closeCircuitModal() {{
                document.getElementById('circuit-modal').classList.remove('active');
            }}
            
            // Fermer avec Escape
            document.addEventListener('keydown', function(e) {{
                if (e.key === 'Escape') closeCircuitModal();
            }});
        </script>
        '''
    
    def _generate_qiskit_visualizations_section(self, viz: Dict) -> str:
        """
        [v2.5.18] GÃ©nÃ¨re la section des visualisations Qiskit professionnelles.
        
        Affiche:
        - Histogrammes des rÃ©sultats par circuit
        - Graphiques de comparaison multi-circuits
        - Heatmap qualitÃ© des qubits
        - Carte d'erreurs du backend
        """
        if not viz:
            return ''
        
        histograms = viz.get('histograms', [])
        comparison_charts = viz.get('comparison_charts', [])
        qubit_heatmap = viz.get('qubit_heatmap')
        error_map = viz.get('error_map')
        
        # VÃ©rifier s'il y a du contenu Ã  afficher
        has_content = histograms or comparison_charts or qubit_heatmap or error_map
        if not has_content:
            return ''
        
        sections_html = ''
        
        # === HISTOGRAMMES DES RÃ‰SULTATS ===
        if histograms:
            hist_cards = ''
            for h in histograms:
                hist_cards += f'''
                <div class="viz-card">
                    <div class="viz-header">
                        <span class="viz-title">Circuit {h.get('index', '?')}: {h.get('name', 'Unknown')[:30]}</span>
                        <span class="viz-meta">{h.get('total_shots', 0):,} shots â€¢ {h.get('unique_outcomes', 0)} outcomes</span>
                    </div>
                    <div class="viz-image" onclick="openVizModal(this)">
                        <img src="data:image/png;base64,{h.get('image_base64', '')}" alt="Histogram {h.get('index')}" loading="lazy" />
                    </div>
                </div>
                '''
            
            sections_html += f'''
            <div class="viz-section">
                <h3 class="viz-section-title">ğŸ“Š Histogrammes des RÃ©sultats</h3>
                <p class="viz-description">Distribution des bitstrings mesurÃ©s (Top 20) pour chaque circuit.</p>
                <div class="viz-grid">
                    {hist_cards}
                </div>
            </div>
            '''
        
        # === GRAPHIQUES DE COMPARAISON ===
        if comparison_charts:
            comp_cards = ''
            for c in comparison_charts:
                comp_cards += f'''
                <div class="viz-card wide">
                    <div class="viz-header">
                        <span class="viz-title">{c.get('name', 'Comparaison')}</span>
                    </div>
                    <div class="viz-image" onclick="openVizModal(this)">
                        <img src="data:image/png;base64,{c.get('image_base64', '')}" alt="{c.get('name')}" loading="lazy" />
                    </div>
                </div>
                '''
            
            sections_html += f'''
            <div class="viz-section">
                <h3 class="viz-section-title">ğŸ“ˆ Analyse Comparative</h3>
                <p class="viz-description">Comparaison des mÃ©triques entre circuits (entropie, uniformitÃ©, probabilitÃ©s).</p>
                <div class="viz-grid-wide">
                    {comp_cards}
                </div>
            </div>
            '''
        
        # === HEATMAP QUALITÃ‰ DES QUBITS ===
        if qubit_heatmap:
            sections_html += f'''
            <div class="viz-section">
                <h3 class="viz-section-title">ğŸ”¥ QualitÃ© des Qubits</h3>
                <p class="viz-description">
                    Heatmap des erreurs de readout pour {qubit_heatmap.get('n_qubits', '?')} qubits.
                    Erreur moyenne: {qubit_heatmap.get('avg_error', 0):.2f}% | Max: {qubit_heatmap.get('max_error', 0):.2f}%
                </p>
                <div class="viz-card wide">
                    <div class="viz-image" onclick="openVizModal(this)">
                        <img src="data:image/png;base64,{qubit_heatmap.get('image_base64', '')}" alt="Qubit Heatmap" loading="lazy" />
                    </div>
                </div>
            </div>
            '''
        
        # === CARTE D'ERREURS DU BACKEND ===
        if error_map:
            sections_html += f'''
            <div class="viz-section">
                <h3 class="viz-section-title">ğŸ—ºï¸ Carte d'Erreurs du Backend</h3>
                <p class="viz-description">
                    Visualisation Qiskit des erreurs pour {error_map.get('backend_name', 'Unknown')}.
                    Les couleurs indiquent les taux d'erreur des qubits et des connexions.
                </p>
                <div class="viz-card wide">
                    <div class="viz-image" onclick="openVizModal(this)">
                        <img src="data:image/png;base64,{error_map.get('image_base64', '')}" alt="Error Map" loading="lazy" />
                    </div>
                </div>
            </div>
            '''
        
        return f'''
        <h2 class="section-title">ğŸ¨ Visualisations Qiskit Professionnelles</h2>
        <div class="qiskit-viz-container">
            {sections_html}
        </div>
        
        <!-- Modal pour zoom visualisations -->
        <div id="viz-modal" class="viz-modal" onclick="closeVizModal()">
            <div class="viz-modal-content">
                <span class="viz-modal-close">&times;</span>
                <img id="viz-modal-image" src="" alt="Visualization agrandi" />
            </div>
        </div>
        
        <style>
            .qiskit-viz-container {{
                margin: 20px 0;
            }}
            
            .viz-section {{
                margin-bottom: 30px;
            }}
            
            .viz-section-title {{
                color: var(--primary);
                font-size: 1.1em;
                margin-bottom: 8px;
                display: flex;
                align-items: center;
                gap: 8px;
            }}
            
            .viz-description {{
                color: var(--text-muted);
                font-size: 0.9em;
                margin-bottom: 15px;
            }}
            
            .viz-grid {{
                display: grid;
                grid-template-columns: repeat(auto-fill, minmax(450px, 1fr));
                gap: 20px;
            }}
            
            .viz-grid-wide {{
                display: grid;
                grid-template-columns: 1fr;
                gap: 20px;
            }}
            
            .viz-card {{
                background: var(--card-bg);
                border-radius: 12px;
                overflow: hidden;
                border: 1px solid var(--border);
                transition: transform 0.2s, box-shadow 0.2s;
            }}
            
            .viz-card.wide {{
                max-width: 100%;
            }}
            
            .viz-card:hover {{
                transform: translateY(-3px);
                box-shadow: 0 8px 25px rgba(102, 126, 234, 0.2);
            }}
            
            .viz-header {{
                padding: 12px 15px;
                background: var(--card-bg-alt);
                border-bottom: 1px solid var(--border);
                display: flex;
                justify-content: space-between;
                align-items: center;
                flex-wrap: wrap;
                gap: 10px;
            }}
            
            .viz-title {{
                font-weight: 600;
                color: var(--text);
            }}
            
            .viz-meta {{
                font-size: 0.85em;
                color: var(--text-muted);
            }}
            
            .viz-image {{
                cursor: pointer;
                position: relative;
                overflow: hidden;
            }}
            
            .viz-image img {{
                width: 100%;
                height: auto;
                display: block;
                transition: transform 0.3s;
            }}
            
            .viz-image:hover img {{
                transform: scale(1.02);
            }}
            
            .viz-image::after {{
                content: 'ğŸ” Cliquer pour agrandir';
                position: absolute;
                bottom: 0;
                left: 0;
                right: 0;
                background: linear-gradient(transparent, rgba(0,0,0,0.8));
                color: white;
                padding: 20px 15px 10px;
                text-align: center;
                font-size: 0.85em;
                opacity: 0;
                transition: opacity 0.3s;
            }}
            
            .viz-image:hover::after {{
                opacity: 1;
            }}
            
            /* Modal pour visualisations */
            .viz-modal {{
                display: none;
                position: fixed;
                z-index: 1001;
                left: 0;
                top: 0;
                width: 100%;
                height: 100%;
                background: rgba(0, 0, 0, 0.95);
                justify-content: center;
                align-items: center;
            }}
            
            .viz-modal.active {{
                display: flex;
            }}
            
            .viz-modal-content {{
                position: relative;
                max-width: 95%;
                max-height: 95%;
            }}
            
            .viz-modal-content img {{
                max-width: 100%;
                max-height: 90vh;
                border-radius: 8px;
                box-shadow: 0 10px 50px rgba(0, 0, 0, 0.5);
            }}
            
            .viz-modal-close {{
                position: absolute;
                top: -40px;
                right: 0;
                color: white;
                font-size: 35px;
                font-weight: bold;
                cursor: pointer;
                transition: color 0.2s;
            }}
            
            .viz-modal-close:hover {{
                color: var(--primary);
            }}
            
            @media (max-width: 768px) {{
                .viz-grid {{
                    grid-template-columns: 1fr;
                }}
            }}
        </style>
        
        <script>
            function openVizModal(container) {{
                const img = container.querySelector('img');
                const modal = document.getElementById('viz-modal');
                const modalImg = document.getElementById('viz-modal-image');
                modalImg.src = img.src;
                modal.classList.add('active');
            }}
            
            function closeVizModal() {{
                document.getElementById('viz-modal').classList.remove('active');
            }}
            
            // Ajouter au gestionnaire d'Ã©vÃ©nements existant
            document.addEventListener('keydown', function(e) {{
                if (e.key === 'Escape') {{
                    closeVizModal();
                    closeCircuitModal();
                }}
            }});
        </script>
        '''
    
    def _generate_files_section(self, files: List[Dict]) -> str:
        """[v2.5.18] GÃ©nÃ¨re la section fichiers gÃ©nÃ©rÃ©s."""
        if not files:
            return ''
        
        # IcÃ´nes par type
        icons = {
            'report': 'ğŸ“Š',
            'data': 'ğŸ“',
            'log': 'ğŸ“',
            'text': 'ğŸ“„',
            'image': 'ğŸ–¼ï¸',
            'document': 'ğŸ“‘',
            'circuit': 'âš›ï¸',
            'other': 'ğŸ“',
        }
        
        # GÃ©nÃ©rer les cartes de fichiers
        file_cards = ''
        for f in files:
            icon = icons.get(f.get('type', 'other'), 'ğŸ“')
            name = f.get('name', 'unknown')
            size = f.get('size_kb', 0)
            modified = f.get('modified', '')
            path = f.get('path', '')
            
            # Tronquer le nom si trop long
            display_name = name if len(name) <= 35 else name[:32] + '...'
            
            file_cards += f'''
            <div class="file-item">
                <div class="file-icon">{icon}</div>
                <div class="file-info">
                    <div class="file-name" title="{name}">{display_name}</div>
                    <div class="file-meta">{size} KB â€¢ {modified}</div>
                </div>
            </div>
            '''
        
        total_size = sum(f.get('size_kb', 0) for f in files)
        
        return f'''
        <h2 class="section-title">ğŸ“‚ Fichiers GÃ©nÃ©rÃ©s ({len(files)})</h2>
        <p style="color: var(--text-muted); margin-bottom: 15px;">
            Total: {total_size:.1f} KB dans le rÃ©pertoire de sortie
        </p>
        <div class="file-grid">
            {file_cards}
        </div>
        '''

    def _generate_circuit_rows(self, per_circuit: List[Dict]) -> str:
        """GÃ©nÃ¨re les lignes du tableau de circuits."""
        rows = ''
        for c in per_circuit[:50]:  # Max 50 circuits
            rows += f'''
            <tr>
                <td>{c.get('index', '?')}</td>
                <td>{c.get('shots', 0):,}</td>
                <td>{c.get('unique_outcomes', 0)}</td>
                <td>{c.get('entropy_bits', 0):.2f} bits</td>
                <td>{c.get('uniformity_percent', 0):.1f}%</td>
                <td><code>{c.get('top_bitstring', 'N/A')[:16]}</code></td>
                <td>{c.get('top_probability', 0):.1f}%</td>
            </tr>
            '''
        return rows
    
    def open_in_browser(self, filepath: Path = None):
        """Ouvre le dernier rapport dans le navigateur."""
        path = filepath or self._last_report_path
        if path and path.exists():
            import webbrowser
            webbrowser.open(f'file://{path.absolute()}')
            self._log(f"ğŸ“Š Rapport ouvert dans le navigateur")


# Alias pour compatibilitÃ©
HTMLDashboard = AutoReportGenerator


# =============================================================================
# =============================================================================

class QMCFrameworkV2_4(QMCFramework):
    """
    QMC Framework v2.5.3 avec optimisation de circuit automatique.
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    NOUVEAUTÃ‰S v2.5.3 - CIRCUIT OPTIMIZER
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Moteur d'optimisation automatique utilisant TOUTES les mÃ©triques de 
    calibration IBM pour placer les circuits sur les meilleurs qubits.
    
    ACTIVÃ‰ PAR DÃ‰FAUT - Chaque appel Ã  run_on_qpu() :
    1. Charge la calibration du backend (T1, T2, readout, asymÃ©trie, etc.)
    2. Identifie les qubits faulty et biaisÃ©s Ã  Ã©viter
    3. Calcule le layout optimal pour minimiser le bruit
    4. Transpile le circuit avec ce layout
    5. ExÃ©cute sur le QPU
    
    Nouvelles mÃ©thodes:
    - load_calibration_csv(path): Charge depuis CSV IBM (plus prÃ©cis)
    - display_calibration_summary(): Affiche l'Ã©tat du QPU
    - get_optimal_layout(n): Retourne le meilleur placement
    - transpile_optimized(circuit): Transpile avec layout optimal
    - set_auto_optimize(bool): Active/dÃ©sactive l'optimisation
    - get_faulty_qubits(): Liste des qubits Ã  Ã©viter
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    FONCTIONNALITÃ‰S PRÃ‰CÃ‰DENTES
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    v2.5.2 - Pathfinding:
    - Algorithme DFS + backtracking pour trouver les chemins optimaux
    - +150% de qubits contigus trouvÃ©s vs greedy
    
    
    v2.5.0 - Composants avancÃ©s:
    - BackendRecommender: Recommandation de backend
    - ResultCache: Cache local des rÃ©sultats
    - JobQueueManager: File d'attente
    - NotificationManager: Alertes Email/Slack
    - CircuitCostEstimator: Estimation coÃ»t
    
    Usage:
        fw = QMCFrameworkV2_4(project='TEST', backend_name='ibm_fez')
        fw.connect()  # Charge automatiquement la calibration
        
        # Tout est optimisÃ© automatiquement
        results = fw.run_on_qpu(circuits, shots=4096)
        
        # Pour dÃ©sactiver l'optimisation:
        fw.set_auto_optimize(False)
        results = fw.run_on_qpu(circuits, shots=4096, optimize_layout=False)
    """
    
    VERSION = "2.5.3"
    
    def __init__(self, *args, enable_cache: bool = True, 
                 cache_dir: str = '.qmc_cache', **kwargs):
        super().__init__(*args, **kwargs)
        
        # Composants existants
        self.multi_platform = MultiPlatformOrchestrator(self.logger)
        self.ml_optimizer = QuantumMLOptimizer(self.logger)
        self.enhanced_exporter = EnhancedReportExporter(logger=self.logger)
        
        # Analyzers existants
        self.xeb_advanced = XEBCrossValidationAnalyzer(self.logger)
        self.honeypot_analyzer = HoneypotAnalyzer(self.logger)
        self.quantum_advantage = QuantumAdvantageAnalyzer(self.logger)
        
        # === COMPOSANTS v2.5 ===
        self.recommender = BackendRecommender(logger=self.logger)
        self.cache = ResultCache(cache_dir=cache_dir, logger=self.logger) if enable_cache else None
        self.job_queue = JobQueueManager(framework=self, logger=self.logger)
        self.notifications = NotificationManager(logger=self.logger)
        self.cost_estimator = CircuitCostEstimator(framework=self, logger=self.logger)
        
        
        # === CIRCUIT OPTIMIZER v2.5.3 ===
        self.circuit_optimizer = None  # ChargÃ© automatiquement aprÃ¨s connect()
        self._auto_optimize = True  # Optimisation activÃ©e par dÃ©faut
        
        # === COMPOSANTS v2.5.16 - PRODUCTIVITÃ‰ ===
        self._batch_manager = None  # Lazy init
        self._budget_manager = None  # Lazy init
        self._circuit_profiler = None  # Lazy init
        self._result_comparator = None  # Lazy init
        self._html_dashboard = None  # Lazy init
        
        self._enable_cache = enable_cache
    
    # =========================================================================
    # v2.5.16 - ACCÃˆS AUX NOUVEAUX OUTILS
    # =========================================================================
    
    @property
    def batch_manager(self) -> BatchManager:
        """[v2.5.16] Gestionnaire de batches intelligent."""
        if self._batch_manager is None:
            self._batch_manager = BatchManager(
                framework=self, 
                logger=self.logger
            )
        return self._batch_manager
    
    @property
    def budget(self) -> BudgetManager:
        """[v2.5.16] Gestionnaire de budget QPU."""
        if self._budget_manager is None:
            self._budget_manager = BudgetManager(
                framework=self,
                logger=self.logger
            )
        return self._budget_manager
    
    @property
    def profiler(self) -> CircuitProfiler:
        """[v2.5.16] Profileur de circuits."""
        if self._circuit_profiler is None:
            self._circuit_profiler = CircuitProfiler(
                framework=self,
                logger=self.logger
            )
        return self._circuit_profiler
    
    @property
    def comparator(self) -> ResultComparator:
        """[v2.5.16] Comparateur de rÃ©sultats."""
        if self._result_comparator is None:
            self._result_comparator = ResultComparator(logger=self.logger)
        return self._result_comparator
    
    @property
    def dashboard(self) -> HTMLDashboard:
        """[v2.5.16] GÃ©nÃ©rateur de dashboard HTML."""
        if self._html_dashboard is None:
            self._html_dashboard = HTMLDashboard(
                framework=self,
                logger=self.logger
            )
        return self._html_dashboard
    
    def set_budget(self, monthly_minutes: float, alert_at: float = 80.0, 
                   block_on_exceed: bool = False):
        """
        [v2.5.16] Configure le budget QPU mensuel.
        
        Args:
            monthly_minutes: Budget mensuel en minutes
            alert_at: Pourcentage pour alerte (dÃ©faut: 80%)
            block_on_exceed: Bloquer si budget dÃ©passÃ© (dÃ©faut: False)
            
        Usage:
            fw.set_budget(100, alert_at=80, block_on_exceed=True)
        """
        self._budget_manager = BudgetManager(
            framework=self,
            monthly_budget_minutes=monthly_minutes,
            alert_threshold_percent=alert_at,
            block_on_exceed=block_on_exceed,
            logger=self.logger
        )
        if self.logger:
            self.logger.info(f"ğŸ’° Budget configurÃ©: {monthly_minutes} min/mois, alerte Ã  {alert_at}%")
    
    def profile_circuit(self, circuit, display: bool = True) -> Dict:
        """
        [v2.5.16] Profile un circuit et affiche le rapport.
        
        Args:
            circuit: QuantumCircuit Ã  profiler
            display: Afficher le rapport (dÃ©faut: True)
            
        Returns:
            Dict avec le profil complet
        """
        profile = self.profiler.profile(circuit)
        if display:
            self.profiler.display_report(profile)
        return profile
    
    def compare_results(self, results_a, results_b, 
                       label_a: str = "A", label_b: str = "B",
                       display: bool = True) -> Dict:
        """
        [v2.5.16] Compare deux ensembles de rÃ©sultats.
        
        Args:
            results_a: Premiers rÃ©sultats (counts dict ou liste)
            results_b: Seconds rÃ©sultats
            label_a: Label pour A
            label_b: Label pour B
            display: Afficher le rapport (dÃ©faut: True)
            
        Returns:
            Dict avec la comparaison
        """
        # DÃ©terminer le type d'entrÃ©e
        if isinstance(results_a, dict) and isinstance(results_b, dict):
            # Deux dicts de counts simples
            comparison = self.comparator.compare(results_a, results_b, label_a, label_b)
        else:
            # Listes de rÃ©sultats
            comparison = self.comparator.compare_results(results_a, results_b, label_a, label_b)
        
        if display:
            self.comparator.display_comparison(comparison)
        
        return comparison
    
    def generate_dashboard(self, results: List[Dict] = None, 
                          title: str = "QMC Results",
                          open_browser: bool = True) -> Path:
        """
        [v2.5.16] GÃ©nÃ¨re un dashboard HTML.
        
        Args:
            results: RÃ©sultats Ã  inclure (ou utilise le dernier run)
            title: Titre du dashboard
            open_browser: Ouvrir dans le navigateur (dÃ©faut: True)
            
        Returns:
            Path vers le fichier HTML
        """
        filepath = self.dashboard.generate(results, title)
        if open_browser:
            self.dashboard.open_in_browser(filepath)
        return filepath
    
    def connect(self, *args, auto_load_calibration: bool = True, **kwargs) -> bool:
        """
        Connexion au backend avec chargement automatique de la calibration.
        
        [v2.5.3] Par dÃ©faut, charge automatiquement les donnÃ©es de calibration
        du backend pour optimiser le placement des circuits.
        
        Args:
            auto_load_calibration: Charger la calibration automatiquement (dÃ©faut: True)
            *args, **kwargs: Arguments passÃ©s Ã  la mÃ©thode parente
        
        Returns:
            True si connexion rÃ©ussie
        """
        result = super().connect(*args, **kwargs)
        
        if result and hasattr(self, 'service'):
            self.recommender.service = self.service
            self.cost_estimator.framework = self
            
            # === v2.5.3: CHARGER AUTOMATIQUEMENT LA CALIBRATION ===
            if auto_load_calibration:
                try:
                    self.circuit_optimizer = CircuitOptimizer.from_backend(
                        self.backend, self.logger
                    )
                    self.logger.info(f"[OPTIMIZER] Calibration chargÃ©e: "
                             f"{len(self.circuit_optimizer.qubits)} qubits, "
                             f"{len(self.circuit_optimizer.connections)} connexions")
                    
                    # Afficher les qubits problÃ©matiques
                    faulty = self.circuit_optimizer.get_faulty_qubits()
                    if faulty:
                        self.logger.info(f"[OPTIMIZER] Qubits Ã  Ã©viter: {sorted(faulty)}")
                    
                except Exception as e:
                    self.logger.warn(f"[OPTIMIZER] Calibration non disponible: {e}")
        
        return result
    
    def set_auto_optimize(self, enabled: bool = True):
        """
        Active ou dÃ©sactive l'optimisation automatique du layout.
        
        Args:
            enabled: True pour activer (dÃ©faut), False pour dÃ©sactiver
        
        Example:
            fw.set_auto_optimize(False)  # Je gÃ¨re mon layout manuellement
            fw.set_auto_optimize(True)   # Optimisation automatique
        """
        self._auto_optimize = enabled
        status = "ACTIVÃ‰E" if enabled else "DÃ‰SACTIVÃ‰E"
        if self.logger:
            self.logger.info(f"[OPTIMIZER] Optimisation automatique {status}")
        else:
            print(f"[OPTIMIZER] Optimisation automatique {status}")
    
    def set_vf2_trials(self, max_trials: int = 10000):
        """
        Configure le nombre de mappings que VF2PostLayout va essayer.
        
        Plus de trials = meilleur mapping mais plus de temps de calcul.
        
        Recommandations:
            - 1,000   : Rapide (~0.5s), qualitÃ© basique
            - 10,000  : Ã‰quilibrÃ© (~2-5s), bon pour la plupart des cas âœ“
            - 50,000  : Approfondi (~10-20s), pour circuits critiques
            - 100,000 : Maximum (~30-60s), qualitÃ© maximale
        
        Args:
            max_trials: Nombre de mappings Ã  essayer (dÃ©faut: 10000)
        
        Example:
            fw.set_vf2_trials(50000)  # Recherche approfondie
        """
        self._vf2_max_trials = max_trials
        if self.logger:
            self.logger.info(f"[OPTIMIZER] VF2 max_trials = {max_trials}")
        else:
            print(f"[OPTIMIZER] VF2 max_trials = {max_trials}")
    
    def create_fresh_error_map(self) -> 'ErrorMap':
        """
        CrÃ©e une ErrorMap avec les donnÃ©es de calibration FRAÃCHES.
        
        Utilise les donnÃ©es de notre CircuitOptimizer (chargÃ©es depuis CSV
        ou depuis le backend) pour crÃ©er une ErrorMap personnalisÃ©e.
        
        Cette ErrorMap peut Ãªtre injectÃ©e dans VF2PostLayout pour utiliser
        les donnÃ©es de calibration les plus rÃ©centes au lieu du target statique.
        
        Returns:
            ErrorMap avec erreurs 1Q et 2Q
        
        Example:
            error_map = fw.create_fresh_error_map()
            # Utiliser dans VF2PostLayout via property_set['vf2_avg_error_map']
        """
        try:
            from qiskit.transpiler.passes.layout.vf2_utils import ErrorMap
        except ImportError:
            self.logger.warn("[OPTIMIZER] ErrorMap non disponible")
            return None
        
        if not hasattr(self, 'circuit_optimizer') or not self.circuit_optimizer:
            self.logger.warn("[OPTIMIZER] Pas de donnÃ©es de calibration chargÃ©es")
            return None
        
        opt = self.circuit_optimizer
        n_qubits = len(opt.qubits)
        
        # CrÃ©er l'ErrorMap
        error_map = ErrorMap(n_qubits)
        
        # Ajouter les erreurs 1Q (readout + gate error)
        for q, cal in opt.qubits.items():
            if q < n_qubits and cal.operational:
                # Score inversÃ© = erreur (1 - score = erreur)
                error_1q = 1.0 - cal.quality_score()
                error_map.add_error((q, q), error_1q)
        
        # Ajouter les erreurs 2Q (CZ/ECR)
        for (q1, q2), conn in opt.connections.items():
            if q1 < n_qubits and q2 < n_qubits:
                error_2q = conn.error  # Erreur CZ/ECR directe
                error_map.add_error((q1, q2), error_2q)
                # Bidirectionnel
                error_map.add_error((q2, q1), error_2q)
        
        if self.logger:
            self.logger.info(f"[OPTIMIZER] ErrorMap crÃ©Ã©e: {n_qubits} qubits, {len(opt.connections)} connexions")
        
        return error_map
    
    def transpile_with_fresh_calibration(self, 
                                          circuits: List,
                                          optimization_level: int = 3,
                                          vf2_max_trials: int = 50000) -> List:
        """
        Transpile avec VF2PostLayout utilisant les donnÃ©es de calibration FRAÃCHES.
        
        Cette mÃ©thode injecte notre ErrorMap (basÃ©e sur nos donnÃ©es de calibration)
        dans VF2PostLayout au lieu d'utiliser le target statique du backend.
        
        Args:
            circuits: Circuits Ã  transpiler
            optimization_level: Niveau d'optimisation (0-3)
            vf2_max_trials: Nombre de trials VF2 (dÃ©faut: 50000)
        
        Returns:
            Circuits transpilÃ©s avec layout optimisÃ©
        
        Example:
            # Charger calibration fraÃ®che
            fw.load_calibration_csv('ibm_fez_calibrations_latest.csv')
            
            # Transpiler avec ces donnÃ©es
            optimized = fw.transpile_with_fresh_calibration(circuits, vf2_max_trials=100000)
        """
        from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager
        from qiskit.transpiler import PassManager, PropertySet
        
        if not self._connected:
            raise RuntimeError("Non connectÃ©!")
        
        # CrÃ©er l'ErrorMap avec nos donnÃ©es fraÃ®ches
        error_map = self.create_fresh_error_map()
        
        # Import VF2PostLayout
        try:
            from qiskit.transpiler.passes import VF2PostLayout
        except ImportError:
            self.logger.warn("[OPTIMIZER] VF2PostLayout non disponible")
            return self.transpile_circuits(circuits, optimization_level=optimization_level)
        
        self.logger.subsection(f"Transpilation avec calibration fraÃ®che ({len(circuits)} circuits)")
        
        transpiled = []
        
        for i, qc in enumerate(circuits):
            # Ã‰tape 1: Transpilation standard
            pm = generate_preset_pass_manager(
                optimization_level=optimization_level,
                backend=self.backend
            )
            t_qc = pm.run(qc)
            
            # Ã‰tape 2: VF2PostLayout avec notre ErrorMap
            if error_map:
                try:
                    # CrÃ©er un PassManager avec VF2PostLayout
                    vf2_pass = VF2PostLayout(
                        target=self.backend.target,
                        strict_direction=False,
                        max_trials=vf2_max_trials)
                    
                    # Injecter notre ErrorMap via property_set
                    vf2_pm = PassManager([vf2_pass])
                    
                    # CrÃ©er un PropertySet avec notre ErrorMap
                    prop_set = PropertySet()
                    prop_set['vf2_avg_error_map'] = error_map
                    
                    # ExÃ©cuter avec notre ErrorMap
                    t_qc = vf2_pm.run(t_qc)
                    
                    if i == 0:
                        self.logger.info(f"[OPTIMIZER] VF2 avec ErrorMap fraÃ®che ({vf2_max_trials} trials)")
                        
                except Exception as e:
                    if i == 0:
                        self.logger.warn(f"[OPTIMIZER] VF2 erreur: {e}")
            
            transpiled.append(t_qc)
            
            if i == 0:
                depth = t_qc.depth()
                ops = dict(t_qc.count_ops())
                n_2q = sum(v for k, v in ops.items() if k in ['cz', 'ecr', 'cx'])
                self.logger.info(f"Circuit: depth={depth}, 2Q_gates={n_2q}")
        
        return transpiled
    
    # =========================================================================
    # CIRCUIT OPTIMIZER v2.5.3 - Optimisation basÃ©e sur calibration
    # =========================================================================
    
    def load_calibration_csv(self, csv_path: str) -> 'CircuitOptimizer':
        """
        Charge un fichier CSV de calibration IBM pour l'optimisation.
        
        Le CSV peut Ãªtre tÃ©lÃ©chargÃ© depuis:
        IBM Quantum Dashboard â†’ Backend â†’ Download calibration data
        
        Args:
            csv_path: Chemin vers le fichier CSV de calibration
        
        Returns:
            CircuitOptimizer configurÃ© avec les donnÃ©es
        
        Example:
            optimizer = fw.load_calibration_csv('ibm_fez_calibration.csv')
            print(optimizer.display_summary())
        """
        self.circuit_optimizer = CircuitOptimizer.from_csv(csv_path, self.logger)
        return self.circuit_optimizer
    
    def load_calibration_from_backend(self) -> 'CircuitOptimizer':
        """
        Charge les donnÃ©es de calibration directement depuis le backend connectÃ©.
        
        Note: Cette mÃ©thode extrait moins de mÃ©triques que load_calibration_csv().
        Pour une optimisation complÃ¨te, utiliser le CSV.
        
        Returns:
            CircuitOptimizer configurÃ©
        """
        if not hasattr(self, 'backend') or not self.backend:
            self._log("Erreur: Connectez-vous d'abord avec connect()", LogLevel.ERROR)
            return None
        
        self.circuit_optimizer = CircuitOptimizer.from_backend(self.backend, self.logger)
        return self.circuit_optimizer
    
    def get_optimal_layout(self, n_qubits: int, 
                           strategy: str = 'contiguous') -> Dict[int, int]:
        """
        Trouve le meilleur placement pour un circuit de n qubits.
        
        Args:
            n_qubits: Nombre de qubits du circuit
            strategy: 'contiguous' (chemin optimal), 
                     'best_qubits' (meilleurs qubits isolÃ©s),
                     'topology_aware' (respecte les connexions)
        
        Returns:
            Dict {qubit_logique: qubit_physique}
        
        Example:
            layout = fw.get_optimal_layout(20)
            # {0: 1, 1: 2, 2: 3, 3: 16, ...}
        """
        if not self.circuit_optimizer:
            # Tenter de charger depuis le backend
            self.load_calibration_from_backend()
        
        if not self.circuit_optimizer:
            self._log("Warning: Pas de donnÃ©es de calibration, utilisation du layout par dÃ©faut", 
                     LogLevel.WARN)
            return {i: i for i in range(n_qubits)}
        
        return self.circuit_optimizer.find_optimal_layout(n_qubits, strategy=strategy)
    
    def transpile_optimized(self, circuits, optimization_level: int = 3,
                           strategy: str = 'none',  # Qiskit/Sabre par dÃ©faut
                           vf2_max_trials: int = 100000) -> list:  # VF2 activÃ© par dÃ©faut
        """
        Transpile avec Qiskit SabreLayout + VF2PostLayout (optimal).
        
        [v2.5.5] Pipeline optimal:
        ==========================
        1. Qiskit O3 avec SabreLayout (minimise SWAPs)
        2. VF2PostLayout (amÃ©liore de -1.9% les gates 2Q)
        
        Args:
            circuits: Circuit(s) Ã  transpiler
            optimization_level: Niveau d'optimisation Qiskit (0-3)
            strategy: 'none' (dÃ©faut=Sabre), 'topology_aware' (DÃ‰CONSEILLÃ‰), 'best_qubits'
            vf2_max_trials: Trials pour VF2PostLayout (dÃ©faut: 100000)
        
        Returns:
            Circuit(s) transpilÃ©(s)
        """
        # GÃ©rer liste ou circuit unique
        is_single = not isinstance(circuits, list)
        circuit_list = [circuits] if is_single else circuits
        
        # Utiliser transpile_circuits avec les nouveaux defaults
        result = self.transpile_circuits(
            circuit_list,
            optimization_level=optimization_level,
            use_optimal_layout=(strategy != 'none'),
            layout_strategy=strategy,
            use_vf2_post_layout=(vf2_max_trials > 0),
            vf2_max_trials=vf2_max_trials
        )
        
        return result[0] if is_single else result
    
    def display_calibration_summary(self) -> str:
        """
        Affiche un rÃ©sumÃ© de l'analyse de calibration.
        
        Returns:
            RÃ©sumÃ© formatÃ©
        """
        if not self.circuit_optimizer:
            self.load_calibration_from_backend()
        
        if self.circuit_optimizer:
            summary = self.circuit_optimizer.display_summary()
            print(summary)
            return summary
        else:
            msg = "Pas de donnÃ©es de calibration disponibles"
            print(msg)
            return msg
    
    def get_faulty_qubits(self) -> Set[int]:
        """
        Retourne la liste des qubits Ã  Ã©viter basÃ©e sur l'analyse complÃ¨te.
        
        Utilise toutes les mÃ©triques: readout error, T1, T2, asymÃ©trie, etc.
        """
        if not self.circuit_optimizer:
            self.load_calibration_from_backend()
        
        if self.circuit_optimizer:
            return self.circuit_optimizer.get_faulty_qubits()
        
        return set()
    
    # =========================================================================
    # BACKEND RECOMMENDER
    # =========================================================================
    
    def recommend_backend(self, circuit=None, criteria: List[str] = None,
                         display: bool = True) -> Dict:
        """
        Recommande le meilleur backend pour un circuit.
        
        Args:
            circuit: Circuit Ã  analyser (optionnel)
            criteria: CritÃ¨res de sÃ©lection
            display: Afficher la recommandation
        
        Returns:
            Dict avec 'recommended', 'score', 'reasons', 'alternatives'
        """
        result = self.recommender.recommend(circuit, criteria)
        
        if display:
            self.recommender.display_recommendation(result)
        
        return result
    
    def compare_backends(self, backends: List[str], circuit=None) -> Dict:
        """Compare plusieurs backends."""
        return self.recommender.compare_backends(backends, circuit)
    
    # =========================================================================
    # RESULT CACHE
    # =========================================================================
    
    def run_on_qpu_cached(self, circuits, shots: int = 4096,
                          use_cache: bool = True, **kwargs) -> List[Dict]:
        """
        ExÃ©cute sur QPU avec cache automatique.
        
        Args:
            circuits: Circuits Ã  exÃ©cuter
            shots: Nombre de shots
            use_cache: Utiliser le cache (dÃ©faut: True)
            **kwargs: Arguments supplÃ©mentaires pour run_on_qpu
        
        Returns:
            Liste des rÃ©sultats (depuis cache ou QPU)
        """
        if not self._enable_cache or not use_cache:
            return self.run_on_qpu(circuits, shots, **kwargs)
        
        # VÃ©rifier le cache
        backend_name = self.backend.name if self.backend else None
        cached = self.cache.get(circuits, shots, backend_name)
        
        if cached:
            self.logger.info(f"[CACHE] HIT - QPU saved: {cached['qpu_time_saved']:.1f}s")
            return cached['results']
        
        # ExÃ©cuter sur QPU
        results = self.run_on_qpu(circuits, shots, **kwargs)
        
        # RÃ©cupÃ©rer le temps QPU RÃ‰EL depuis le rapport
        qpu_time = self.report.get('qpu_time_s', section='execution') or 0
        
        # Sauvegarder dans le cache
        if results:
            job_id = self.report.get('job_id', section='execution')
            self.cache.save(
                circuits, shots, results,
                backend=backend_name,
                job_id=job_id,
                qpu_time_s=qpu_time
            )
        
        return results
    
    def cache_stats(self, display: bool = True) -> Dict:
        """Retourne les statistiques du cache."""
        if not self.cache:
            return {'error': 'Cache non active'}
        
        stats = self.cache.stats()
        
        if display:
            self.cache.display_stats()
        
        return stats
    
    def cache_clear(self, older_than_days: int = None, all_cache: bool = False):
        """Nettoie le cache."""
        if self.cache:
            self.cache.clear(older_than_days, all_cache)
    
    # =========================================================================
    # JOB QUEUE
    # =========================================================================
    
    def queue_add(self, circuits, shots: int = 4096, name: str = None,
                  priority: int = 1) -> str:
        """Ajoute des circuits Ã  la queue."""
        return self.job_queue.add(circuits, shots, name, priority)
    
    def queue_submit_all(self, max_concurrent: int = 3, 
                         wait: bool = False) -> List[str]:
        """Soumet tous les items de la queue."""
        return self.job_queue.submit_all(max_concurrent, wait)
    
    def queue_status(self, display: bool = True) -> Dict:
        """Retourne le statut de la queue."""
        status = self.job_queue.status()
        
        if display:
            self.job_queue.display_status()
        
        return status
    
    def queue_results(self, wait: bool = False) -> Dict:
        """RÃ©cupÃ¨re les rÃ©sultats de la queue."""
        return self.job_queue.get_results(wait=wait)
    
    # =========================================================================
    # NOTIFICATIONS
    # =========================================================================
    
    def setup_notifications(self, email: str = None, 
                           slack_webhook: str = None,
                           discord_webhook: str = None,
                           notify_on: List[str] = None):
        """
        Configure les notifications.
        
        Args:
            email: Adresse email
            slack_webhook: URL webhook Slack
            discord_webhook: URL webhook Discord
            notify_on: Ã‰vÃ©nements Ã  notifier
        """
        self.notifications.configure(
            email=email,
            slack_webhook=slack_webhook,
            discord_webhook=discord_webhook,
            notify_on=notify_on or ['job_complete', 'job_failed']
        )
    
    def test_notification(self) -> bool:
        """Envoie une notification de test."""
        return self.notifications.test()
    
    # =========================================================================
    # COST ESTIMATOR
    # =========================================================================
    
    def estimate_cost(self, circuits, shots: int = 4096,
                      display: bool = True) -> Dict:
        """
        Estime le coÃ»t d'exÃ©cution avant soumission.
        
        [v2.5.14] Accepte circuit unique OU liste.
        
        Args:
            circuits: Circuit unique OU liste de circuits Ã  estimer
            shots: Nombre de shots
            display: Afficher l'estimation
        
        Returns:
            Dict avec estimations dÃ©taillÃ©es
        """
        # [v2.5.14] Auto-wrapping
        from qiskit import QuantumCircuit
        if isinstance(circuits, QuantumCircuit):
            circuits = [circuits]
        
        estimate = self.cost_estimator.estimate(circuits, shots)
        
        if display:
            self.cost_estimator.display_estimate(estimate)
        
        return estimate
    
    def run_on_qpu_with_confirm(self, circuits, shots: int = 4096,
                                **kwargs) -> Optional[List[Dict]]:
        """
        ExÃ©cute sur QPU avec confirmation du coÃ»t.
        
        Affiche l'estimation et demande confirmation avant d'exÃ©cuter.
        [v2.5.14] Accepte circuit unique OU liste.
        """
        # [v2.5.14] Auto-wrapping
        from qiskit import QuantumCircuit
        if isinstance(circuits, QuantumCircuit):
            circuits = [circuits]
        
        estimate = self.cost_estimator.estimate(circuits, shots)
        
        confirmed = self.cost_estimator.display_estimate(estimate, confirm=True)
        
        if confirmed:
            return self.run_on_qpu(circuits, shots, **kwargs)
        else:
            self.logger.info("Execution annulee par l'utilisateur")
            return None
    
    # =========================================================================
    # MÃ‰THODES EXISTANTES
    # =========================================================================
    
    def get_new_circuit_builder(self, builder_type: str) -> CircuitBuilder:
        """
        Retourne un des nouveaux circuit builders.
        
        Args:
            builder_type: 'quantum_signature', 'zkp', 'timelock', 'oblivious_transfer'
        """
        builders = {
            'quantum_signature': QuantumSignatureBuilder,
            'zkp': ZKPBuilder,
            'timelock': TimeLockBuilder,
            'oblivious_transfer': ObliviousTransferBuilder,
        }
        
        builder_cls = builders.get(builder_type)
        if builder_cls:
            return builder_cls(self.topology, self.logger)
        
        raise ValueError(f"Unknown builder type: {builder_type}")
    
    def analyze_quantum_advantage(self, counts: Dict, n_qubits: int) -> Dict:
        """Analyse pour preuve d'avantage quantique."""
        return self.quantum_advantage.analyze(counts, n_qubits)
    
    def export_results_enhanced(self, data: Dict, name: str) -> Dict[str, Path]:
        """Exporte les rÃ©sultats dans tous les formats."""
        return self.enhanced_exporter.export_all(data, name)
    
    def get_ml_recommendations(self, task: str) -> Dict:
        """Obtient les recommandations ML pour une tÃ¢che."""
        return self.ml_optimizer.get_recommendations(task)


# =============================================================================
# QMC FRAMEWORK v2.5.22 - NOUVELLES FONCTIONNALITÃ‰S (BLOC 1)
# =============================================================================
# 
# Ce bloc contient:
# 1. SimulatorComparator - Comparaison automatique Simulateur â†” QPU
# 2. XEBCalculator - Cross-Entropy Benchmarking intÃ©grÃ©
# 3. BudgetAlertManager - Alertes budget QPU
# 4. DryRunManager - Mode simulation sans envoi QPU
# =============================================================================


# =============================================================================
# 1. SIMULATOR COMPARATOR - Comparaison Sim â†” QPU
# =============================================================================

class SimulatorComparator:
    """
    Comparateur automatique des rÃ©sultats Simulateur vs QPU.
    
    Permet de valider que le bruit QPU n'altÃ¨re pas significativement
    les rÃ©sultats attendus, essentiel pour les brevets QMC.
    
    Usage:
        comparator = SimulatorComparator(framework)
        comparison = comparator.compare(
            circuits,
            qpu_results,
            metrics=['fidelity', 'tvd', 'kl_divergence', 'xeb']
        )
        comparator.generate_report(comparison, "comparison_report.html")
    """
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.logger = getattr(framework, 'logger', None)
    
    def compare(self, 
                circuits: List,
                qpu_results: List[Dict] = None,
                shots: int = 4096,
                metrics: List[str] = None,
                run_simulator: bool = True,
                run_qpu: bool = False) -> Dict[str, Any]:
        """
        Compare les rÃ©sultats simulateur vs QPU.
        
        Args:
            circuits: Liste de circuits Ã  comparer
            qpu_results: RÃ©sultats QPU existants (optionnel)
            shots: Nombre de shots
            metrics: MÃ©triques Ã  calculer ['fidelity', 'tvd', 'kl_divergence', 'xeb', 'hellinger']
            run_simulator: ExÃ©cuter le simulateur (dÃ©faut: True)
            run_qpu: ExÃ©cuter sur QPU (dÃ©faut: False, utilise qpu_results)
            
        Returns:
            Dict avec comparaisons dÃ©taillÃ©es par circuit et mÃ©triques agrÃ©gÃ©es
        """
        import numpy as np
        from datetime import datetime
        
        if metrics is None:
            metrics = ['fidelity', 'tvd', 'hellinger']
        
        if not isinstance(circuits, list):
            circuits = [circuits]
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'n_circuits': len(circuits),
            'shots': shots,
            'metrics_requested': metrics,
            'circuits': [],
            'summary': {}
        }
        
        # ExÃ©cuter simulateur si demandÃ©
        sim_results = None
        if run_simulator:
            if self.logger:
                self.logger.info("ğŸ–¥ï¸ ExÃ©cution simulateur...")
            sim_results = self._run_simulator(circuits, shots)
        
        # ExÃ©cuter QPU si demandÃ©
        if run_qpu and qpu_results is None:
            if self.logger:
                self.logger.info("âš›ï¸ ExÃ©cution QPU...")
            qpu_results = self.framework.run_on_qpu(circuits, shots=shots)
        
        if qpu_results is None:
            raise ValueError("qpu_results requis ou run_qpu=True")
        
        if sim_results is None:
            if self.logger:
                self.logger.info("ğŸ–¥ï¸ ExÃ©cution simulateur pour comparaison...")
            sim_results = self._run_simulator(circuits, shots)
        
        # Comparer chaque circuit
        all_metrics = {m: [] for m in metrics}
        
        for i, circuit in enumerate(circuits):
            sim_counts = sim_results[i]['counts'] if i < len(sim_results) else {}
            qpu_counts = qpu_results[i]['counts'] if i < len(qpu_results) else {}
            
            circuit_comparison = {
                'index': i,
                'sim_unique_states': len(sim_counts),
                'qpu_unique_states': len(qpu_counts),
                'metrics': {}
            }
            
            # Calculer chaque mÃ©trique
            for metric in metrics:
                value = self._compute_metric(metric, sim_counts, qpu_counts, shots)
                circuit_comparison['metrics'][metric] = value
                all_metrics[metric].append(value)
            
            results['circuits'].append(circuit_comparison)
        
        # RÃ©sumÃ© statistique
        for metric in metrics:
            values = all_metrics[metric]
            results['summary'][metric] = {
                'mean': float(np.mean(values)),
                'std': float(np.std(values)),
                'min': float(np.min(values)),
                'max': float(np.max(values)),
                'median': float(np.median(values))
            }
        
        # Verdict global
        fidelity_mean = results['summary'].get('fidelity', {}).get('mean', 0)
        if fidelity_mean >= 0.95:
            results['verdict'] = 'EXCELLENT'
            results['verdict_emoji'] = 'ğŸŸ¢'
        elif fidelity_mean >= 0.85:
            results['verdict'] = 'GOOD'
            results['verdict_emoji'] = 'ğŸŸ¡'
        elif fidelity_mean >= 0.70:
            results['verdict'] = 'ACCEPTABLE'
            results['verdict_emoji'] = 'ğŸŸ '
        else:
            results['verdict'] = 'POOR'
            results['verdict_emoji'] = 'ğŸ”´'
        
        return results
    
    def _run_simulator(self, circuits: List, shots: int) -> List[Dict]:
        """ExÃ©cute les circuits sur simulateur Aer."""
        try:
            from qiskit_aer import AerSimulator
            from qiskit.primitives import StatevectorSampler
        except ImportError:
            from qiskit_aer import AerSimulator
            from qiskit.primitives import Sampler as StatevectorSampler
        
        results = []
        
        # Utiliser StatevectorSampler pour rÃ©sultats idÃ©aux
        try:
            sampler = StatevectorSampler()
            job = sampler.run(circuits, shots=shots)
            pub_results = job.result()
            
            for i, pub_result in enumerate(pub_results):
                counts = {}
                # Extraire les counts
                if hasattr(pub_result, 'data'):
                    for name in ['meas', 'c', 'c_data']:
                        try:
                            cr_data = getattr(pub_result.data, name, None)
                            if cr_data is not None:
                                counts = cr_data.get_counts()
                                break
                        except:
                            pass
                
                results.append({
                    'circuit_index': i,
                    'counts': counts,
                    'shots': sum(counts.values()) if counts else shots
                })
        except Exception as e:
            # Fallback vers AerSimulator
            backend = AerSimulator()
            from qiskit import transpile
            transpiled = transpile(circuits, backend)
            job = backend.run(transpiled, shots=shots)
            result = job.result()
            
            for i in range(len(circuits)):
                counts = result.get_counts(i)
                results.append({
                    'circuit_index': i,
                    'counts': counts,
                    'shots': sum(counts.values()) if counts else shots
                })
        
        return results
    
    def _compute_metric(self, metric: str, sim_counts: Dict, qpu_counts: Dict, shots: int) -> float:
        """Calcule une mÃ©trique de comparaison."""
        import numpy as np
        
        # Obtenir tous les Ã©tats possibles
        all_states = set(sim_counts.keys()) | set(qpu_counts.keys())
        
        if not all_states:
            return 0.0
        
        # Convertir en distributions de probabilitÃ©
        sim_total = sum(sim_counts.values()) or 1
        qpu_total = sum(qpu_counts.values()) or 1
        
        sim_probs = {s: sim_counts.get(s, 0) / sim_total for s in all_states}
        qpu_probs = {s: qpu_counts.get(s, 0) / qpu_total for s in all_states}
        
        p = np.array([sim_probs[s] for s in sorted(all_states)])
        q = np.array([qpu_probs[s] for s in sorted(all_states)])
        
        # Ã‰viter division par zÃ©ro
        p = np.clip(p, 1e-10, 1.0)
        q = np.clip(q, 1e-10, 1.0)
        
        if metric == 'fidelity':
            # FidelitÃ© classique (Bhattacharyya)
            return float(np.sum(np.sqrt(p * q)) ** 2)
        
        elif metric == 'tvd':
            # Total Variation Distance
            return float(0.5 * np.sum(np.abs(p - q)))
        
        elif metric == 'kl_divergence':
            # Kullback-Leibler Divergence
            return float(np.sum(p * np.log(p / q)))
        
        elif metric == 'hellinger':
            # Distance de Hellinger
            return float(np.sqrt(0.5 * np.sum((np.sqrt(p) - np.sqrt(q)) ** 2)))
        
        elif metric == 'xeb':
            # Cross-Entropy Benchmarking (simplifiÃ©)
            # XEB = 2^n * <p_ideal(x)> - 1 oÃ¹ x sont les rÃ©sultats mesurÃ©s
            n_qubits = len(next(iter(all_states))) if all_states else 1
            xeb_sum = sum(sim_probs.get(state, 0) * count for state, count in qpu_counts.items())
            xeb_sum /= qpu_total
            return float((2 ** n_qubits) * xeb_sum - 1)
        
        else:
            raise ValueError(f"MÃ©trique inconnue: {metric}")
    
    def generate_report(self, comparison: Dict, output_path: str = None) -> str:
        """GÃ©nÃ¨re un rapport HTML de comparaison."""
        import json
        from datetime import datetime
        
        html = f'''<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Comparaison Simulateur vs QPU</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 40px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        h1 {{ color: #1a1a2e; border-bottom: 3px solid #4361ee; padding-bottom: 10px; }}
        h2 {{ color: #16213e; margin-top: 30px; }}
        .verdict {{ font-size: 24px; padding: 20px; border-radius: 10px; text-align: center; margin: 20px 0; }}
        .verdict.EXCELLENT {{ background: #d4edda; color: #155724; }}
        .verdict.GOOD {{ background: #fff3cd; color: #856404; }}
        .verdict.ACCEPTABLE {{ background: #ffe5d0; color: #8a4000; }}
        .verdict.POOR {{ background: #f8d7da; color: #721c24; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background: #4361ee; color: white; }}
        tr:hover {{ background: #f5f5f5; }}
        .metric-good {{ color: #28a745; font-weight: bold; }}
        .metric-ok {{ color: #ffc107; font-weight: bold; }}
        .metric-bad {{ color: #dc3545; font-weight: bold; }}
        .summary-box {{ background: #e8f4f8; padding: 20px; border-radius: 10px; margin: 20px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š Comparaison Simulateur vs QPU</h1>
        <p>GÃ©nÃ©rÃ© le {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
        
        <div class="verdict {comparison.get('verdict', 'UNKNOWN')}">
            {comparison.get('verdict_emoji', 'â“')} Verdict: {comparison.get('verdict', 'UNKNOWN')}
        </div>
        
        <div class="summary-box">
            <h2>ğŸ“ˆ RÃ©sumÃ©</h2>
            <ul>
                <li><strong>Circuits analysÃ©s:</strong> {comparison.get('n_circuits', 0)}</li>
                <li><strong>Shots:</strong> {comparison.get('shots', 0)}</li>
                <li><strong>MÃ©triques:</strong> {', '.join(comparison.get('metrics_requested', []))}</li>
            </ul>
        </div>
        
        <h2>ğŸ“Š MÃ©triques AgrÃ©gÃ©es</h2>
        <table>
            <tr>
                <th>MÃ©trique</th>
                <th>Moyenne</th>
                <th>Ã‰cart-type</th>
                <th>Min</th>
                <th>Max</th>
            </tr>
'''
        
        for metric, stats in comparison.get('summary', {}).items():
            mean_val = stats.get('mean', 0)
            if metric in ['fidelity', 'xeb']:
                css_class = 'metric-good' if mean_val >= 0.9 else ('metric-ok' if mean_val >= 0.7 else 'metric-bad')
            else:  # tvd, kl, hellinger (lower is better)
                css_class = 'metric-good' if mean_val <= 0.1 else ('metric-ok' if mean_val <= 0.3 else 'metric-bad')
            
            html += f'''            <tr>
                <td>{metric}</td>
                <td class="{css_class}">{mean_val:.4f}</td>
                <td>{stats.get('std', 0):.4f}</td>
                <td>{stats.get('min', 0):.4f}</td>
                <td>{stats.get('max', 0):.4f}</td>
            </tr>
'''
        
        html += '''        </table>
        
        <h2>ğŸ“‹ DÃ©tails par Circuit</h2>
        <table>
            <tr>
                <th>Circuit</th>
                <th>Ã‰tats Sim</th>
                <th>Ã‰tats QPU</th>
'''
        
        for metric in comparison.get('metrics_requested', []):
            html += f'                <th>{metric}</th>\n'
        
        html += '            </tr>\n'
        
        for circuit in comparison.get('circuits', []):
            html += f'''            <tr>
                <td>#{circuit.get('index', 0)}</td>
                <td>{circuit.get('sim_unique_states', 0)}</td>
                <td>{circuit.get('qpu_unique_states', 0)}</td>
'''
            for metric in comparison.get('metrics_requested', []):
                val = circuit.get('metrics', {}).get(metric, 0)
                html += f'                <td>{val:.4f}</td>\n'
            html += '            </tr>\n'
        
        html += '''        </table>
    </div>
</body>
</html>'''
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html)
        
        return html


# =============================================================================
# 2. XEB CALCULATOR - Cross-Entropy Benchmarking
# =============================================================================

class XEBCalculator:
    """
    Calculateur de Cross-Entropy Benchmarking (XEB).
    
    Le XEB est la mÃ©trique standard pour prouver l'avantage quantique,
    utilisÃ©e par Google pour la suprÃ©matie quantique.
    
    XEB = 2^n * E[p_ideal(x)] - 1
    
    oÃ¹:
    - n = nombre de qubits
    - x = bitstrings mesurÃ©s sur QPU
    - p_ideal(x) = probabilitÃ© idÃ©ale (simulateur)
    
    Score:
    - XEB = 1: Processeur quantique parfait
    - XEB = 0: Ã‰quivalent Ã  bruit uniforme (classique)
    - XEB < 0: Pire que le bruit (erreur systÃ©matique)
    
    Usage:
        xeb = XEBCalculator()
        score = xeb.compute(qpu_counts, ideal_probs, n_qubits=50)
    """
    
    def __init__(self, method: str = 'linear'):
        """
        Args:
            method: 'linear' (standard) ou 'log' (pour grands circuits)
        """
        self.method = method
    
    def compute(self,
                qpu_counts: Dict[str, int],
                ideal_probs: Dict[str, float],
                n_qubits: int = None) -> Dict[str, Any]:
        """
        Calcule le score XEB.
        
        Args:
            qpu_counts: Counts mesurÃ©s sur QPU {'00': 500, '11': 500}
            ideal_probs: ProbabilitÃ©s idÃ©ales {'00': 0.5, '11': 0.5}
            n_qubits: Nombre de qubits (dÃ©duit si non fourni)
            
        Returns:
            Dict avec score XEB et statistiques dÃ©taillÃ©es
        """
        import numpy as np
        
        if not qpu_counts:
            return {'xeb_score': 0.0, 'error': 'No QPU counts'}
        
        # DÃ©duire n_qubits
        if n_qubits is None:
            first_key = next(iter(qpu_counts.keys()))
            n_qubits = len(first_key)
        
        total_shots = sum(qpu_counts.values())
        dim = 2 ** n_qubits
        
        # Calculer XEB
        if self.method == 'linear':
            # XEB linÃ©aire standard
            xeb_sum = 0.0
            for bitstring, count in qpu_counts.items():
                p_ideal = ideal_probs.get(bitstring, 0.0)
                xeb_sum += p_ideal * count
            
            xeb_score = (dim * xeb_sum / total_shots) - 1
        
        elif self.method == 'log':
            # XEB logarithmique (plus stable pour grands circuits)
            log_sum = 0.0
            for bitstring, count in qpu_counts.items():
                p_ideal = ideal_probs.get(bitstring, 1e-10)
                log_sum += count * np.log(dim * p_ideal)
            
            xeb_score = np.exp(log_sum / total_shots) - 1
        
        else:
            raise ValueError(f"MÃ©thode inconnue: {self.method}")
        
        # Statistiques additionnelles
        porter_thomas_mean = 1.0  # Distribution attendue pour circuits alÃ©atoires
        
        # Calcul de la variance du XEB (pour intervalle de confiance)
        # Var(XEB) â‰ˆ 2/M pour M shots
        xeb_variance = 2.0 / total_shots
        xeb_std = np.sqrt(xeb_variance)
        
        # InterprÃ©tation
        if xeb_score >= 0.9:
            interpretation = "EXCELLENT - Near-ideal quantum processor"
            emoji = "ğŸŸ¢"
        elif xeb_score >= 0.5:
            interpretation = "GOOD - Significant quantum advantage"
            emoji = "ğŸŸ¡"
        elif xeb_score >= 0.1:
            interpretation = "MODERATE - Noisy but quantum"
            emoji = "ğŸŸ "
        elif xeb_score >= 0:
            interpretation = "MARGINAL - Barely above classical"
            emoji = "ğŸŸ "
        else:
            interpretation = "POOR - Systematic errors detected"
            emoji = "ğŸ”´"
        
        return {
            'xeb_score': float(xeb_score),
            'xeb_std': float(xeb_std),
            'confidence_interval_95': (float(xeb_score - 1.96 * xeb_std), 
                                        float(xeb_score + 1.96 * xeb_std)),
            'n_qubits': n_qubits,
            'total_shots': total_shots,
            'unique_states_measured': len(qpu_counts),
            'unique_states_ideal': len(ideal_probs),
            'method': self.method,
            'interpretation': interpretation,
            'emoji': emoji
        }
    
    def compute_from_circuits(self,
                              circuits: List,
                              qpu_results: List[Dict],
                              shots: int = 4096) -> Dict[str, Any]:
        """
        Calcule XEB directement depuis circuits et rÃ©sultats QPU.
        Simule automatiquement les probabilitÃ©s idÃ©ales.
        
        Args:
            circuits: Liste de circuits
            qpu_results: RÃ©sultats QPU du framework
            shots: Nombre de shots
            
        Returns:
            Dict avec XEB moyen et par circuit
        """
        import numpy as np
        
        # Simuler les probabilitÃ©s idÃ©ales
        try:
            from qiskit.quantum_info import Statevector
        except ImportError:
            raise ImportError("qiskit.quantum_info requis pour compute_from_circuits")
        
        if not isinstance(circuits, list):
            circuits = [circuits]
        
        xeb_scores = []
        circuit_results = []
        
        for i, circuit in enumerate(circuits):
            # Obtenir statevector idÃ©al
            try:
                # Supprimer les mesures pour obtenir le statevector
                circuit_no_meas = circuit.remove_final_measurements(inplace=False)
                sv = Statevector.from_instruction(circuit_no_meas)
                ideal_probs = sv.probabilities_dict()
            except Exception:
                # Fallback: distribution uniforme
                n_qubits = circuit.num_qubits
                ideal_probs = {format(i, f'0{n_qubits}b'): 1/(2**n_qubits) for i in range(2**n_qubits)}
            
            # Obtenir counts QPU
            qpu_counts = qpu_results[i].get('counts', {}) if i < len(qpu_results) else {}
            
            # Calculer XEB
            result = self.compute(qpu_counts, ideal_probs)
            xeb_scores.append(result['xeb_score'])
            circuit_results.append({
                'index': i,
                **result
            })
        
        return {
            'xeb_mean': float(np.mean(xeb_scores)),
            'xeb_std': float(np.std(xeb_scores)),
            'xeb_min': float(np.min(xeb_scores)),
            'xeb_max': float(np.max(xeb_scores)),
            'n_circuits': len(circuits),
            'circuits': circuit_results
        }


# =============================================================================
# 3. BUDGET ALERT MANAGER - Alertes Budget QPU
# =============================================================================

class BudgetAlertManager:
    """
    Gestionnaire d'alertes pour le budget QPU.
    
    Surveille l'utilisation du temps QPU et dÃ©clenche des alertes
    quand des seuils sont atteints.
    
    Usage:
        alert_mgr = BudgetAlertManager(
            monthly_limit_minutes=50,
            alert_thresholds=[0.5, 0.8, 0.95],
            callback=lambda level, usage: send_notification(...)
        )
        alert_mgr.check(current_usage_minutes=35)
    """
    
    def __init__(self,
                 monthly_limit_minutes: float = 50.0,
                 alert_thresholds: List[float] = None,
                 callback: Callable = None,
                 auto_block_at: float = 1.0):
        """
        Args:
            monthly_limit_minutes: Limite mensuelle en minutes
            alert_thresholds: Seuils d'alerte (ex: [0.5, 0.8, 0.95])
            callback: Fonction appelÃ©e lors d'une alerte (level, usage_info)
            auto_block_at: Bloque les runs Ã  ce seuil (1.0 = 100%)
        """
        self.monthly_limit = monthly_limit_minutes
        self.thresholds = alert_thresholds or [0.5, 0.8, 0.95]
        self.callback = callback
        self.auto_block = auto_block_at
        self.alerts_sent = set()  # Pour Ã©viter les alertes rÃ©pÃ©tÃ©es
        self._blocked = False
    
    def check(self, current_usage_minutes: float) -> Dict[str, Any]:
        """
        VÃ©rifie l'utilisation et dÃ©clenche les alertes si nÃ©cessaire.
        
        Args:
            current_usage_minutes: Utilisation actuelle en minutes
            
        Returns:
            Dict avec statut et alertes dÃ©clenchÃ©es
        """
        usage_ratio = current_usage_minutes / self.monthly_limit
        remaining = self.monthly_limit - current_usage_minutes
        
        result = {
            'usage_minutes': current_usage_minutes,
            'limit_minutes': self.monthly_limit,
            'usage_ratio': usage_ratio,
            'usage_percent': usage_ratio * 100,
            'remaining_minutes': max(0, remaining),
            'alerts_triggered': [],
            'blocked': False
        }
        
        # VÃ©rifier chaque seuil
        for threshold in sorted(self.thresholds):
            if usage_ratio >= threshold and threshold not in self.alerts_sent:
                self.alerts_sent.add(threshold)
                alert_info = {
                    'threshold': threshold,
                    'threshold_percent': threshold * 100,
                    'level': self._get_alert_level(threshold)
                }
                result['alerts_triggered'].append(alert_info)
                
                if self.callback:
                    try:
                        self.callback(alert_info['level'], result)
                    except Exception as e:
                        pass
        
        # Bloquer si limite atteinte
        if usage_ratio >= self.auto_block:
            self._blocked = True
            result['blocked'] = True
            result['block_reason'] = f"Budget limit reached ({usage_ratio*100:.1f}%)"
        
        return result
    
    def _get_alert_level(self, threshold: float) -> str:
        """Retourne le niveau d'alerte."""
        if threshold >= 0.95:
            return 'CRITICAL'
        elif threshold >= 0.8:
            return 'WARNING'
        elif threshold >= 0.5:
            return 'INFO'
        return 'DEBUG'
    
    def is_blocked(self) -> bool:
        """Retourne True si le budget est bloquÃ©."""
        return self._blocked
    
    def reset_alerts(self):
        """RÃ©initialise les alertes (dÃ©but de mois)."""
        self.alerts_sent.clear()
        self._blocked = False
    
    def get_status_display(self, current_usage_minutes: float) -> str:
        """Retourne un affichage ASCII du statut budget."""
        usage_ratio = current_usage_minutes / self.monthly_limit
        remaining = max(0, self.monthly_limit - current_usage_minutes)
        
        # Barre de progression
        bar_width = 30
        filled = int(usage_ratio * bar_width)
        bar = 'â–ˆ' * min(filled, bar_width) + 'â–‘' * max(0, bar_width - filled)
        
        # Couleur (emoji)
        if usage_ratio >= 0.95:
            emoji = 'ğŸ”´'
            status = 'CRITICAL'
        elif usage_ratio >= 0.8:
            emoji = 'ğŸŸ '
            status = 'WARNING'
        elif usage_ratio >= 0.5:
            emoji = 'ğŸŸ¡'
            status = 'ATTENTION'
        else:
            emoji = 'ğŸŸ¢'
            status = 'OK'
        
        return f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ’° BUDGET QPU STATUS                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  {emoji} Status: {status:<12}                                â•‘
â•‘  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®             â•‘
â•‘  â”‚ [{bar}] {usage_ratio*100:5.1f}%             â”‚             â•‘
â•‘  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯             â•‘
â•‘  Used:      {current_usage_minutes:6.1f} min                               â•‘
â•‘  Limit:     {self.monthly_limit:6.1f} min                               â•‘
â•‘  Remaining: {remaining:6.1f} min                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""


# =============================================================================
# 4. DRY RUN MANAGER - Mode Simulation Sans Envoi QPU
# =============================================================================

class DryRunManager:
    """
    Gestionnaire de "Dry Run" - simule l'exÃ©cution complÃ¨te sans envoyer au QPU.
    
    Permet de:
    - Valider les circuits avant soumission
    - Estimer le temps et le coÃ»t
    - Voir le layout de transpilation prÃ©vu
    - DÃ©tecter les erreurs potentielles
    
    Usage:
        dry_run = DryRunManager(framework)
        result = dry_run.run(
            circuits,
            shots=4096,
            include_transpilation=True,
            include_simulation=True
        )
    """
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.logger = getattr(framework, 'logger', None)
    
    def run(self,
            circuits: List,
            shots: int = 4096,
            include_transpilation: bool = True,
            include_simulation: bool = False,
            include_cost: bool = True,
            optimization_level: int = 3) -> Dict[str, Any]:
        """
        ExÃ©cute un dry run complet.
        
        Args:
            circuits: Circuit(s) Ã  analyser
            shots: Nombre de shots prÃ©vu
            include_transpilation: Transpiler les circuits
            include_simulation: ExÃ©cuter sur simulateur
            include_cost: Estimer le coÃ»t
            optimization_level: Niveau d'optimisation Qiskit
            
        Returns:
            Dict avec toutes les informations de prÃ©-exÃ©cution
        """
        from datetime import datetime
        import time
        
        if not isinstance(circuits, list):
            circuits = [circuits]
        
        start_time = time.time()
        
        result = {
            'timestamp': datetime.now().isoformat(),
            'mode': 'DRY_RUN',
            'n_circuits': len(circuits),
            'shots': shots,
            'backend_target': getattr(self.framework, 'backend_name', 'unknown'),
            'validation': {'passed': True, 'errors': [], 'warnings': []},
            'circuits_info': [],
            'transpilation': None,
            'cost_estimate': None,
            'simulation_results': None
        }
        
        # 1. Validation des circuits
        if self.logger:
            self.logger.info("ğŸ” Validation des circuits...")
        
        for i, circuit in enumerate(circuits):
            circuit_info = {
                'index': i,
                'name': getattr(circuit, 'name', f'circuit_{i}'),
                'num_qubits': circuit.num_qubits,
                'num_clbits': circuit.num_clbits,
                'depth': circuit.depth(),
                'size': circuit.size(),
                'gates': dict(circuit.count_ops()),
                'valid': True,
                'issues': []
            }
            
            # VÃ©rifications
            if circuit.num_qubits > 156:
                circuit_info['issues'].append(f"Trop de qubits: {circuit.num_qubits} > 156 (max Heron)")
                circuit_info['valid'] = False
                result['validation']['errors'].append(f"Circuit {i}: trop de qubits")
            
            if circuit.depth() > 1000:
                circuit_info['issues'].append(f"Profondeur Ã©levÃ©e: {circuit.depth()} - risque de dÃ©cohÃ©rence")
                result['validation']['warnings'].append(f"Circuit {i}: profondeur Ã©levÃ©e")
            
            if circuit.num_clbits == 0:
                circuit_info['issues'].append("Pas de registre classique - pas de mesure?")
                result['validation']['warnings'].append(f"Circuit {i}: pas de mesure")
            
            result['circuits_info'].append(circuit_info)
        
        result['validation']['passed'] = len(result['validation']['errors']) == 0
        
        # 2. Transpilation
        if include_transpilation and result['validation']['passed']:
            if self.logger:
                self.logger.info("âš™ï¸ Transpilation...")
            
            try:
                backend = getattr(self.framework, 'backend', None)
                if backend is None:
                    result['transpilation'] = {'error': 'Backend non connectÃ©'}
                else:
                    from qiskit import transpile
                    transpile_start = time.time()
                    
                    transpiled = transpile(
                        circuits,
                        backend=backend,
                        optimization_level=optimization_level
                    )
                    
                    transpile_time = time.time() - transpile_start
                    
                    if not isinstance(transpiled, list):
                        transpiled = [transpiled]
                    
                    result['transpilation'] = {
                        'success': True,
                        'optimization_level': optimization_level,
                        'transpile_time_s': transpile_time,
                        'circuits': []
                    }
                    
                    for i, tc in enumerate(transpiled):
                        result['transpilation']['circuits'].append({
                            'index': i,
                            'transpiled_depth': tc.depth(),
                            'transpiled_size': tc.size(),
                            'gates_2q': sum(1 for inst in tc.data if len(inst.qubits) == 2),
                            'layout': str(tc.layout.final_index_layout()) if tc.layout else None
                        })
                        
                        # Mettre Ã  jour circuits_info
                        result['circuits_info'][i]['transpiled_depth'] = tc.depth()
                        result['circuits_info'][i]['gates_2q'] = sum(1 for inst in tc.data if len(inst.qubits) == 2)
                        
            except Exception as e:
                result['transpilation'] = {'error': str(e)}
        
        # 3. Estimation du coÃ»t
        if include_cost:
            if self.logger:
                self.logger.info("ğŸ’° Estimation du coÃ»t...")
            
            try:
                if hasattr(self.framework, 'estimate_cost'):
                    cost = self.framework.estimate_cost(circuits, shots=shots)
                    result['cost_estimate'] = cost
                else:
                    # Estimation basique
                    total_gates_2q = sum(
                        c.get('gates_2q', 0) 
                        for c in result.get('transpilation', {}).get('circuits', [])
                    )
                    estimated_time_s = len(circuits) * shots * 0.001 + total_gates_2q * 0.0001
                    result['cost_estimate'] = {
                        'estimated_time_s': estimated_time_s,
                        'estimated_time_min': estimated_time_s / 60,
                        'n_circuits': len(circuits),
                        'total_shots': len(circuits) * shots
                    }
            except Exception as e:
                result['cost_estimate'] = {'error': str(e)}
        
        # 4. Simulation (optionnel)
        if include_simulation and result['validation']['passed']:
            if self.logger:
                self.logger.info("ğŸ–¥ï¸ Simulation...")
            
            try:
                from qiskit_aer import AerSimulator
                from qiskit import transpile
                
                sim_backend = AerSimulator()
                sim_circuits = transpile(circuits, sim_backend)
                job = sim_backend.run(sim_circuits, shots=shots)
                sim_result = job.result()
                
                result['simulation_results'] = []
                for i in range(len(circuits)):
                    counts = sim_result.get_counts(i)
                    result['simulation_results'].append({
                        'index': i,
                        'counts': counts,
                        'unique_states': len(counts),
                        'top_5': sorted(counts.items(), key=lambda x: -x[1])[:5]
                    })
                    
            except Exception as e:
                result['simulation_results'] = {'error': str(e)}
        
        # Temps total
        result['total_time_s'] = time.time() - start_time
        
        # RÃ©sumÃ©
        result['summary'] = self._generate_summary(result)
        
        return result
    
    def _generate_summary(self, result: Dict) -> Dict:
        """GÃ©nÃ¨re un rÃ©sumÃ© du dry run."""
        summary = {
            'ready_for_qpu': result['validation']['passed'],
            'total_circuits': result['n_circuits'],
            'total_qubits_max': max(c['num_qubits'] for c in result['circuits_info']),
            'total_depth_max': max(c['depth'] for c in result['circuits_info']),
            'errors': len(result['validation']['errors']),
            'warnings': len(result['validation']['warnings'])
        }
        
        if result.get('transpilation') and not result['transpilation'].get('error'):
            summary['transpiled_depth_max'] = max(
                c['transpiled_depth'] 
                for c in result['transpilation']['circuits']
            )
            summary['total_gates_2q'] = sum(
                c['gates_2q'] 
                for c in result['transpilation']['circuits']
            )
        
        if result.get('cost_estimate') and not result['cost_estimate'].get('error'):
            summary['estimated_time_min'] = result['cost_estimate'].get('estimated_time_min', 0)
        
        return summary
    
    def display(self, result: Dict) -> str:
        """Affiche le rÃ©sultat du dry run de maniÃ¨re visuelle."""
        summary = result.get('summary', {})
        validation = result.get('validation', {})
        
        status_emoji = 'âœ…' if summary.get('ready_for_qpu') else 'âŒ'
        status_text = 'READY' if summary.get('ready_for_qpu') else 'NOT READY'
        
        output = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        ğŸ”¬ DRY RUN RESULTS                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  {status_emoji} Status: {status_text:<15}                                          â•‘
â•‘                                                                              â•‘
â•‘  ğŸ“Š CIRCUITS                                                                 â•‘
â•‘     Total: {summary.get('total_circuits', 0):<5}  Max Qubits: {summary.get('total_qubits_max', 0):<5}  Max Depth: {summary.get('total_depth_max', 0):<5}       â•‘
"""
        
        if summary.get('transpiled_depth_max'):
            output += f"""â•‘                                                                              â•‘
â•‘  âš™ï¸ TRANSPILATION                                                            â•‘
â•‘     Transpiled Depth: {summary.get('transpiled_depth_max', 0):<5}  2Q Gates: {summary.get('total_gates_2q', 0):<5}                      â•‘
"""
        
        if summary.get('estimated_time_min') is not None:
            output += f"""â•‘                                                                              â•‘
â•‘  ğŸ’° COST ESTIMATE                                                            â•‘
â•‘     Estimated Time: {summary.get('estimated_time_min', 0):.2f} min                                          â•‘
"""
        
        if validation.get('errors'):
            output += f"""â•‘                                                                              â•‘
â•‘  âŒ ERRORS ({len(validation['errors'])})                                                          â•‘
"""
            for err in validation['errors'][:3]:
                output += f"â•‘     â€¢ {err[:60]:<60} â•‘\n"
        
        if validation.get('warnings'):
            output += f"""â•‘                                                                              â•‘
â•‘  âš ï¸ WARNINGS ({len(validation['warnings'])})                                                        â•‘
"""
            for warn in validation['warnings'][:3]:
                output += f"â•‘     â€¢ {warn[:60]:<60} â•‘\n"
        
        output += """â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        return output
# =============================================================================
# QMC FRAMEWORK v2.5.22 - NOUVELLES FONCTIONNALITÃ‰S (BLOC 2)
# =============================================================================
# 
# Ce bloc contient:
# 5. CampaignManager - Gestionnaire de campagnes d'expÃ©riences
# 6. ArchiveReplayer - Replay d'expÃ©riences depuis archive
# 7. AnomalyDetector - DÃ©tection automatique d'anomalies
# 8. GitTracker - IntÃ©gration Git/Versioning
# =============================================================================


# =============================================================================
# 5. CAMPAIGN MANAGER - Gestionnaire de Campagnes d'ExpÃ©riences
# =============================================================================

class CampaignManager:
    """
    Gestionnaire de campagnes d'expÃ©riences avec variations de paramÃ¨tres.
    
    Permet d'exÃ©cuter des Ã©tudes paramÃ©triques automatisÃ©es avec
    gÃ©nÃ©ration de rapports comparatifs.
    
    Usage:
        campaign.add_variation("n_qubits", [50, 75, 100])
        campaign.add_variation("depth", [5, 10, 15])
        campaign.set_circuit_builder(my_circuit_builder)
        
        results = campaign.run(shots=4096)
        campaign.generate_report("campaign_report.html")
    """
    
    def __init__(self, framework: 'QMCFramework', name: str):
        self.framework = framework
        self.name = name
        self.variations = {}
        self.circuit_builder = None
        self.results = []
        self.metadata = {
            'created': None,
            'completed': None,
            'status': 'pending'
        }
        self.logger = getattr(framework, 'logger', None)
    
    def add_variation(self, parameter: str, values: List[Any]) -> 'CampaignManager':
        """
        Ajoute une variation de paramÃ¨tre.
        
        Args:
            parameter: Nom du paramÃ¨tre (ex: 'n_qubits', 'depth')
            values: Liste de valeurs Ã  tester
            
        Returns:
            self pour chaÃ®nage
        """
        self.variations[parameter] = values
        return self
    
    def set_circuit_builder(self, builder: Callable) -> 'CampaignManager':
        """
        DÃ©finit la fonction de construction de circuits.
        
        Args:
            builder: Callable(**params) -> QuantumCircuit ou List[QuantumCircuit]
            
        Returns:
            self pour chaÃ®nage
        """
        self.circuit_builder = builder
        return self
    
    def get_combinations(self) -> List[Dict[str, Any]]:
        """GÃ©nÃ¨re toutes les combinaisons de paramÃ¨tres."""
        import itertools
        
        if not self.variations:
            return [{}]
        
        keys = list(self.variations.keys())
        values = [self.variations[k] for k in keys]
        
        combinations = []
        for combo in itertools.product(*values):
            combinations.append(dict(zip(keys, combo)))
        
        return combinations
    
    def run(self,
            shots: int = 4096,
            mode: str = 'qpu',
            parallel: bool = False,
            continue_on_error: bool = True,
            delay_between_runs: float = 5.0) -> List[Dict[str, Any]]:
        """
        ExÃ©cute la campagne complÃ¨te.
        
        Args:
            shots: Nombre de shots par run
            mode: 'qpu', 'simulator', ou 'both'
            parallel: ExÃ©cuter en parallÃ¨le (non implÃ©mentÃ©)
            continue_on_error: Continuer malgrÃ© les erreurs
            delay_between_runs: Pause entre runs (secondes)
            
        Returns:
            Liste des rÃ©sultats pour chaque combinaison
        """
        from datetime import datetime
        import time
        
        if self.circuit_builder is None:
            raise ValueError("circuit_builder non dÃ©fini! Utilisez set_circuit_builder()")
        
        combinations = self.get_combinations()
        self.metadata['created'] = datetime.now().isoformat()
        self.metadata['status'] = 'running'
        self.metadata['total_runs'] = len(combinations)
        
        if self.logger:
            self.logger.info(f"ğŸš€ DÃ©marrage campagne '{self.name}' avec {len(combinations)} combinaisons")
        
        self.results = []
        
        for i, params in enumerate(combinations):
            run_result = {
                'index': i,
                'parameters': params.copy(),
                'status': 'pending',
                'qpu_results': None,
                'sim_results': None,
                'metrics': {},
                'error': None,
                'timestamp': datetime.now().isoformat()
            }
            
            if self.logger:
                self.logger.info(f"  [{i+1}/{len(combinations)}] Params: {params}")
            
            try:
                # Construire le(s) circuit(s)
                circuits = self.circuit_builder(**params)
                if not isinstance(circuits, list):
                    circuits = [circuits]
                
                run_result['n_circuits'] = len(circuits)
                run_result['circuit_info'] = {
                    'num_qubits': circuits[0].num_qubits,
                    'depth': circuits[0].depth()
                }
                
                # ExÃ©cuter selon le mode
                if mode in ('qpu', 'both'):
                    try:
                        qpu_results = self.framework.run_on_qpu(circuits, shots=shots)
                        run_result['qpu_results'] = qpu_results
                    except Exception as e:
                        run_result['error'] = f"QPU error: {str(e)}"
                        if not continue_on_error:
                            raise
                
                if mode in ('simulator', 'both'):
                    try:
                        from qiskit_aer import AerSimulator
                        from qiskit import transpile
                        
                        backend = AerSimulator()
                        transpiled = transpile(circuits, backend)
                        job = backend.run(transpiled, shots=shots)
                        result = job.result()
                        
                        sim_results = []
                        for j in range(len(circuits)):
                            sim_results.append({
                                'circuit_index': j,
                                'counts': result.get_counts(j),
                                'shots': shots
                            })
                        run_result['sim_results'] = sim_results
                    except Exception as e:
                        run_result['error'] = f"Simulator error: {str(e)}"
                        if not continue_on_error:
                            raise
                
                # Calculer mÃ©triques de base
                if run_result['qpu_results']:
                    qpu_counts = run_result['qpu_results'][0].get('counts', {})
                    run_result['metrics']['qpu_unique_states'] = len(qpu_counts)
                    run_result['metrics']['qpu_entropy'] = self._compute_entropy(qpu_counts)
                
                if run_result['sim_results']:
                    sim_counts = run_result['sim_results'][0].get('counts', {})
                    run_result['metrics']['sim_unique_states'] = len(sim_counts)
                
                run_result['status'] = 'completed'
                
            except Exception as e:
                run_result['status'] = 'error'
                run_result['error'] = str(e)
                if not continue_on_error:
                    self.metadata['status'] = 'error'
                    raise
            
            self.results.append(run_result)
            
            # Pause entre runs
            if i < len(combinations) - 1 and delay_between_runs > 0:
                time.sleep(delay_between_runs)
        
        self.metadata['completed'] = datetime.now().isoformat()
        self.metadata['status'] = 'completed'
        self.metadata['successful_runs'] = sum(1 for r in self.results if r['status'] == 'completed')
        
        if self.logger:
            self.logger.info(f"âœ… Campagne terminÃ©e: {self.metadata['successful_runs']}/{len(combinations)} rÃ©ussis")
        
        return self.results
    
    def _compute_entropy(self, counts: Dict[str, int]) -> float:
        """Calcule l'entropie de Shannon."""
        import numpy as np
        
        total = sum(counts.values())
        if total == 0:
            return 0.0
        
        probs = [c / total for c in counts.values()]
        return float(-sum(p * np.log2(p) for p in probs if p > 0))
    
    def generate_report(self, output_path: str = None) -> str:
        """GÃ©nÃ¨re un rapport HTML de la campagne."""
        from datetime import datetime
        
        html = f'''<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Campagne: {self.name}</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 40px; background: #f0f2f5; }}
        .container {{ max-width: 1400px; margin: 0 auto; }}
        h1 {{ color: #1a1a2e; text-align: center; }}
        .summary-cards {{ display: flex; gap: 20px; margin: 20px 0; flex-wrap: wrap; }}
        .card {{ background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); flex: 1; min-width: 200px; }}
        .card h3 {{ margin-top: 0; color: #4361ee; }}
        .card .value {{ font-size: 32px; font-weight: bold; color: #1a1a2e; }}
        table {{ width: 100%; border-collapse: collapse; background: white; border-radius: 10px; overflow: hidden; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        th {{ background: #4361ee; color: white; padding: 15px; text-align: left; }}
        td {{ padding: 12px 15px; border-bottom: 1px solid #eee; }}
        tr:hover {{ background: #f8f9fa; }}
        .status-completed {{ color: #28a745; font-weight: bold; }}
        .status-error {{ color: #dc3545; font-weight: bold; }}
        .param-table {{ margin: 30px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š Campagne: {self.name}</h1>
        
        <div class="summary-cards">
            <div class="card">
                <h3>Total Runs</h3>
                <div class="value">{len(self.results)}</div>
            </div>
            <div class="card">
                <h3>RÃ©ussis</h3>
                <div class="value" style="color: #28a745;">{sum(1 for r in self.results if r['status'] == 'completed')}</div>
            </div>
            <div class="card">
                <h3>Erreurs</h3>
                <div class="value" style="color: #dc3545;">{sum(1 for r in self.results if r['status'] == 'error')}</div>
            </div>
            <div class="card">
                <h3>Variations</h3>
                <div class="value">{len(self.variations)}</div>
            </div>
        </div>
        
        <h2>ğŸ“‹ ParamÃ¨tres VariÃ©s</h2>
        <table class="param-table">
            <tr><th>ParamÃ¨tre</th><th>Valeurs</th></tr>
'''
        
        for param, values in self.variations.items():
            html += f'            <tr><td><strong>{param}</strong></td><td>{values}</td></tr>\n'
        
        html += '''        </table>
        
        <h2>ğŸ“Š RÃ©sultats DÃ©taillÃ©s</h2>
        <table>
            <tr>
                <th>#</th>
                <th>ParamÃ¨tres</th>
                <th>Qubits</th>
                <th>Depth</th>
                <th>Ã‰tats QPU</th>
                <th>Entropie</th>
                <th>Status</th>
            </tr>
'''
        
        for r in self.results:
            status_class = f"status-{r['status']}"
            params_str = ', '.join(f"{k}={v}" for k, v in r['parameters'].items())
            
            html += f'''            <tr>
                <td>{r['index']}</td>
                <td>{params_str}</td>
                <td>{r.get('circuit_info', {}).get('num_qubits', '-')}</td>
                <td>{r.get('circuit_info', {}).get('depth', '-')}</td>
                <td>{r.get('metrics', {}).get('qpu_unique_states', '-')}</td>
                <td>{r.get('metrics', {}).get('qpu_entropy', 0):.2f}</td>
                <td class="{status_class}">{r['status'].upper()}</td>
            </tr>
'''
        
        html += f'''        </table>
        
        <p style="text-align: center; color: #666; margin-top: 30px;">
            GÃ©nÃ©rÃ© le {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
        </p>
    </div>
</body>
</html>'''
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html)
        
        return html
    
    def to_dataframe(self):
        """Convertit les rÃ©sultats en DataFrame pandas."""
        try:
            import pandas as pd
        except ImportError:
            raise ImportError("pandas requis pour to_dataframe()")
        
        rows = []
        for r in self.results:
            row = {**r['parameters']}
            row['status'] = r['status']
            row['qubits'] = r.get('circuit_info', {}).get('num_qubits')
            row['depth'] = r.get('circuit_info', {}).get('depth')
            row.update(r.get('metrics', {}))
            rows.append(row)
        
        return pd.DataFrame(rows)


# =============================================================================
# 6. ARCHIVE REPLAYER - Replay d'ExpÃ©riences depuis Archive
# =============================================================================

class ArchiveReplayer:
    """
    Permet de rejouer une expÃ©rience passÃ©e depuis son archive JSON.
    
    Utile pour:
    - ReproductibilitÃ© des expÃ©riences
    - Comparaison avec diffÃ©rents backends
    - Re-test avec plus de shots
    
    Usage:
        replayer = ArchiveReplayer(framework)
        original = replayer.load("archive_20260102.json")
        
        # Rejouer sur un autre backend
        new_results = replayer.replay(
            backend="ibm_torino",
            shots=8192  # Plus de shots
        )
    """
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.archive_data = None
        self.archive_path = None
        self.logger = getattr(framework, 'logger', None)
    
    def load(self, archive_path: str) -> Dict[str, Any]:
        """
        Charge une archive JSON.
        
        Args:
            archive_path: Chemin vers l'archive
            
        Returns:
            DonnÃ©es de l'archive
        """
        import json
        
        with open(archive_path, 'r', encoding='utf-8') as f:
            self.archive_data = json.load(f)
        
        self.archive_path = archive_path
        
        if self.logger:
            self.logger.info(f"ğŸ“¦ Archive chargÃ©e: {archive_path}")
            self.logger.info(f"   Project: {self.archive_data.get('project', 'unknown')}")
            self.logger.info(f"   Backend original: {self.archive_data.get('backend', {}).get('name', 'unknown')}")
            self.logger.info(f"   Circuits: {len(self.archive_data.get('results', []))}")
        
        return self.archive_data
    
    def get_summary(self) -> Dict[str, Any]:
        """Retourne un rÃ©sumÃ© de l'archive chargÃ©e."""
        if self.archive_data is None:
            raise ValueError("Aucune archive chargÃ©e! Utilisez load() d'abord.")
        
        results = self.archive_data.get('results', [])
        
        return {
            'project': self.archive_data.get('project'),
            'timestamp': self.archive_data.get('timestamp'),
            'backend_original': self.archive_data.get('backend', {}).get('name'),
            'n_circuits': len(results),
            'total_shots': sum(r.get('shots', 0) for r in results),
            'n_qubits': results[0].get('n_qubits') if results else None,
            'job_id': self.archive_data.get('job', {}).get('job_id'),
            'execution_time': self.archive_data.get('timing', {}).get('total_time_s')
        }
    
    def get_circuits_info(self) -> List[Dict]:
        """Retourne les informations sur les circuits."""
        if self.archive_data is None:
            raise ValueError("Aucune archive chargÃ©e!")
        
        circuits_info = []
        transpilation = self.archive_data.get('transpilation', {})
        circuits_transpiled = transpilation.get('circuits_transpiled', [])
        
        for i, result in enumerate(self.archive_data.get('results', [])):
            info = {
                'index': i,
                'shots': result.get('shots'),
                'unique_states': result.get('unique_states'),
                'n_qubits': result.get('n_qubits')
            }
            
            if i < len(circuits_transpiled):
                info['transpiled_depth'] = circuits_transpiled[i].get('transpiled_depth')
                info['gates_2q'] = circuits_transpiled[i].get('gates_2q')
            
            circuits_info.append(info)
        
        return circuits_info
    
    def reconstruct_circuits(self) -> List:
        """
        Tente de reconstruire les circuits depuis l'archive.
        
        Note: NÃ©cessite que l'archive contienne les circuits sÃ©rialisÃ©s
        (QASM ou QPY), ce qui n'est pas toujours le cas.
        """
        if self.archive_data is None:
            raise ValueError("Aucune archive chargÃ©e!")
        
        circuits_data = self.archive_data.get('circuits', [])
        
        if not circuits_data:
            raise ValueError("L'archive ne contient pas de circuits sÃ©rialisÃ©s. "
                           "Utilisez replay_with_builder() avec un circuit_builder.")
        
        from qiskit import QuantumCircuit
        
        circuits = []
        for cd in circuits_data:
            if 'qasm' in cd:
                qc = QuantumCircuit.from_qasm_str(cd['qasm'])
                circuits.append(qc)
            else:
                raise ValueError("Format de circuit non supportÃ©")
        
        return circuits
    
    def replay(self,
               circuits: List = None,
               backend: str = None,
               shots: int = None,
               **kwargs) -> Dict[str, Any]:
        """
        Rejoue l'expÃ©rience avec les mÃªmes circuits ou de nouveaux paramÃ¨tres.
        
        Args:
            circuits: Circuits Ã  utiliser (si None, tente de reconstruire)
            backend: Backend cible (si None, utilise l'original)
            shots: Nombre de shots (si None, utilise l'original)
            **kwargs: Arguments additionnels pour run_on_qpu()
            
        Returns:
            Dict avec rÃ©sultats originaux et nouveaux
        """
        if self.archive_data is None:
            raise ValueError("Aucune archive chargÃ©e!")
        
        original_results = self.archive_data.get('results', [])
        original_backend = self.archive_data.get('backend', {}).get('name')
        original_shots = original_results[0].get('shots') if original_results else 4096
        
        # DÃ©terminer les paramÃ¨tres
        target_backend = backend or original_backend
        target_shots = shots or original_shots
        
        # Obtenir les circuits
        if circuits is None:
            circuits = self.reconstruct_circuits()
        
        if self.logger:
            self.logger.info(f"ğŸ”„ Replay de {len(circuits)} circuits")
            self.logger.info(f"   Backend: {original_backend} â†’ {target_backend}")
            self.logger.info(f"   Shots: {original_shots} â†’ {target_shots}")
        
        # Changer de backend si nÃ©cessaire
        if target_backend != self.framework.backend_name:
            self.framework.backend_name = target_backend
            if self.framework._connected:
                self.framework.connect()
        
        # ExÃ©cuter
        new_results = self.framework.run_on_qpu(circuits, shots=target_shots, **kwargs)
        
        return {
            'original': {
                'backend': original_backend,
                'shots': original_shots,
                'results': original_results
            },
            'replay': {
                'backend': target_backend,
                'shots': target_shots,
                'results': new_results
            },
            'archive_path': self.archive_path
        }
    
    def replay_with_builder(self,
                            circuit_builder: Callable,
                            params: Dict[str, Any] = None,
                            **kwargs) -> Dict[str, Any]:
        """
        Rejoue avec un circuit_builder et les paramÃ¨tres de l'archive.
        
        Args:
            circuit_builder: Fonction qui construit les circuits
            params: ParamÃ¨tres Ã  passer au builder (sinon extraits de l'archive)
            **kwargs: Arguments pour run_on_qpu()
        """
        if self.archive_data is None:
            raise ValueError("Aucune archive chargÃ©e!")
        
        # Extraire les paramÃ¨tres de l'archive si non fournis
        if params is None:
            params = self.archive_data.get('parameters', {})
        
        circuits = circuit_builder(**params)
        if not isinstance(circuits, list):
            circuits = [circuits]
        
        return self.replay(circuits=circuits, **kwargs)


# =============================================================================
# 7. ANOMALY DETECTOR - DÃ©tection Automatique d'Anomalies
# =============================================================================

class AnomalyDetector:
    """
    DÃ©tecte automatiquement les anomalies dans les rÃ©sultats quantiques.
    
    Types d'anomalies dÃ©tectÃ©es:
    - Qubits dÃ©faillants (biais excessif)
    - Bruit anormalement Ã©levÃ©
    - Patterns de dÃ©cohÃ©rence
    - Ã‰tats inattendus
    
    Usage:
        detector = AnomalyDetector()
        anomalies = detector.analyze(results, expected_states=['00', '11'])
    """
    
    def __init__(self,
                 bias_threshold: float = 0.7,
                 noise_threshold: float = 0.3,
                 entropy_threshold: float = 0.5):
        """
        Args:
            bias_threshold: Seuil de biais qubit (dÃ©faut: 0.7)
            noise_threshold: Seuil de bruit (dÃ©faut: 0.3)
            entropy_threshold: Seuil d'entropie relative (dÃ©faut: 0.5)
        """
        self.bias_threshold = bias_threshold
        self.noise_threshold = noise_threshold
        self.entropy_threshold = entropy_threshold
    
    def analyze(self,
                results: List[Dict],
                expected_states: List[str] = None,
                n_qubits: int = None) -> Dict[str, Any]:
        """
        Analyse complÃ¨te des rÃ©sultats pour dÃ©tecter les anomalies.
        
        Args:
            results: RÃ©sultats du framework (list de dicts avec 'counts')
            expected_states: Ã‰tats attendus (pour dÃ©tection d'Ã©tats inattendus)
            n_qubits: Nombre de qubits (dÃ©duit si non fourni)
            
        Returns:
            Dict avec anomalies dÃ©tectÃ©es et recommandations
        """
        import numpy as np
        
        analysis = {
            'status': 'OK',
            'anomalies': [],
            'warnings': [],
            'suspicious_qubits': set(),
            'recommendations': [],
            'metrics': {}
        }
        
        all_counts = []
        for r in results:
            counts = r.get('counts', {})
            if counts:
                all_counts.append(counts)
                if n_qubits is None:
                    n_qubits = len(next(iter(counts.keys())))
        
        if not all_counts:
            analysis['status'] = 'ERROR'
            analysis['anomalies'].append("Pas de counts disponibles")
            return analysis
        
        # 1. Analyse de biais par qubit
        qubit_bias = self._analyze_qubit_bias(all_counts, n_qubits)
        analysis['metrics']['qubit_bias'] = qubit_bias
        
        for q, bias in qubit_bias.items():
            if bias > self.bias_threshold:
                analysis['suspicious_qubits'].add(q)
                analysis['warnings'].append(f"Qubit {q}: biais Ã©levÃ© ({bias:.2f})")
        
        # 2. Analyse de bruit
        noise_level = self._analyze_noise(all_counts, expected_states)
        analysis['metrics']['noise_level'] = noise_level
        
        if noise_level > self.noise_threshold:
            analysis['anomalies'].append(f"Bruit Ã©levÃ©: {noise_level:.2%}")
            analysis['status'] = 'WARNING'
        
        # 3. Analyse d'entropie
        entropy_analysis = self._analyze_entropy(all_counts, n_qubits)
        analysis['metrics']['entropy'] = entropy_analysis
        
        if entropy_analysis['relative_entropy'] < self.entropy_threshold:
            analysis['warnings'].append(
                f"Entropie faible: {entropy_analysis['entropy']:.2f} bits "
                f"(attendu: ~{entropy_analysis['max_entropy']:.2f})"
            )
        
        # 4. DÃ©tection d'Ã©tats inattendus
        if expected_states:
            unexpected = self._detect_unexpected_states(all_counts, expected_states)
            if unexpected['significant_unexpected']:
                analysis['anomalies'].append(
                    f"Ã‰tats inattendus significatifs: {unexpected['significant_unexpected']}"
                )
                analysis['status'] = 'WARNING'
            analysis['metrics']['unexpected_states'] = unexpected
        
        # 5. DÃ©tection de patterns de dÃ©cohÃ©rence
        decoherence = self._detect_decoherence_patterns(all_counts)
        if decoherence['detected']:
            analysis['warnings'].append(f"Pattern de dÃ©cohÃ©rence dÃ©tectÃ©: {decoherence['type']}")
        analysis['metrics']['decoherence'] = decoherence
        
        # GÃ©nÃ©rer recommandations
        analysis['recommendations'] = self._generate_recommendations(analysis)
        analysis['suspicious_qubits'] = list(analysis['suspicious_qubits'])
        
        # Status final
        if analysis['anomalies']:
            analysis['status'] = 'ANOMALY_DETECTED'
        elif analysis['warnings']:
            analysis['status'] = 'WARNING'
        
        return analysis
    
    def _analyze_qubit_bias(self, all_counts: List[Dict], n_qubits: int) -> Dict[int, float]:
        """Analyse le biais de chaque qubit."""
        qubit_ones = {q: 0 for q in range(n_qubits)}
        total_shots = 0
        
        for counts in all_counts:
            for bitstring, count in counts.items():
                total_shots += count
                for q, bit in enumerate(reversed(bitstring)):
                    if bit == '1':
                        qubit_ones[q] += count
        
        # Calculer le biais (distance Ã  0.5)
        bias = {}
        for q in range(n_qubits):
            p_one = qubit_ones[q] / total_shots if total_shots > 0 else 0.5
            bias[q] = abs(p_one - 0.5) * 2  # Normaliser Ã  [0, 1]
        
        return bias
    
    def _analyze_noise(self, all_counts: List[Dict], expected_states: List[str] = None) -> float:
        """Estime le niveau de bruit."""
        if not expected_states:
            return 0.0
        
        expected_set = set(expected_states)
        total = 0
        unexpected = 0
        
        for counts in all_counts:
            for state, count in counts.items():
                total += count
                if state not in expected_set:
                    unexpected += count
        
        return unexpected / total if total > 0 else 0.0
    
    def _analyze_entropy(self, all_counts: List[Dict], n_qubits: int) -> Dict:
        """Analyse l'entropie des rÃ©sultats."""
        import numpy as np
        
        # AgrÃ©ger tous les counts
        total_counts = {}
        for counts in all_counts:
            for state, count in counts.items():
                total_counts[state] = total_counts.get(state, 0) + count
        
        total = sum(total_counts.values())
        if total == 0:
            return {'entropy': 0, 'max_entropy': n_qubits, 'relative_entropy': 0}
        
        probs = [c / total for c in total_counts.values()]
        entropy = -sum(p * np.log2(p) for p in probs if p > 0)
        max_entropy = n_qubits  # Maximum = log2(2^n) = n
        
        return {
            'entropy': float(entropy),
            'max_entropy': float(max_entropy),
            'relative_entropy': float(entropy / max_entropy) if max_entropy > 0 else 0
        }
    
    def _detect_unexpected_states(self, all_counts: List[Dict], 
                                   expected_states: List[str]) -> Dict:
        """DÃ©tecte les Ã©tats inattendus significatifs."""
        expected_set = set(expected_states)
        unexpected_counts = {}
        total = 0
        
        for counts in all_counts:
            for state, count in counts.items():
                total += count
                if state not in expected_set:
                    unexpected_counts[state] = unexpected_counts.get(state, 0) + count
        
        # Ã‰tats inattendus significatifs (>1% du total)
        threshold = total * 0.01
        significant = {s: c for s, c in unexpected_counts.items() if c > threshold}
        
        return {
            'total_unexpected': sum(unexpected_counts.values()),
            'total_unexpected_ratio': sum(unexpected_counts.values()) / total if total > 0 else 0,
            'unique_unexpected': len(unexpected_counts),
            'significant_unexpected': significant
        }
    
    def _detect_decoherence_patterns(self, all_counts: List[Dict]) -> Dict:
        """DÃ©tecte les patterns typiques de dÃ©cohÃ©rence."""
        # Pattern 1: Drift vers |0...0âŸ©
        zero_state_ratio = []
        for counts in all_counts:
            total = sum(counts.values())
            zero_state = '0' * len(next(iter(counts.keys())))
            ratio = counts.get(zero_state, 0) / total if total > 0 else 0
            zero_state_ratio.append(ratio)
        
        if len(zero_state_ratio) > 1:
            import numpy as np
            # VÃ©rifier si tendance croissante vers |0âŸ©
            trend = np.polyfit(range(len(zero_state_ratio)), zero_state_ratio, 1)[0]
            if trend > 0.05:
                return {'detected': True, 'type': 'T1_decay', 'trend': float(trend)}
        
        return {'detected': False, 'type': None}
    
    def _generate_recommendations(self, analysis: Dict) -> List[str]:
        """GÃ©nÃ¨re des recommandations basÃ©es sur l'analyse."""
        recommendations = []
        
        if analysis['suspicious_qubits']:
            qubits_str = ', '.join(map(str, list(analysis['suspicious_qubits'])[:5]))
            recommendations.append(f"Ã‰viter les qubits: {qubits_str}")
        
        if analysis['metrics'].get('noise_level', 0) > 0.2:
            recommendations.append("RÃ©duire la profondeur du circuit ou augmenter les shots")
        
        if analysis['metrics'].get('entropy', {}).get('relative_entropy', 1) < 0.3:
            recommendations.append("VÃ©rifier que le circuit gÃ©nÃ¨re bien de la superposition")
        
        if analysis['metrics'].get('decoherence', {}).get('detected'):
            recommendations.append("RÃ©duire le temps d'exÃ©cution du circuit (dÃ©cohÃ©rence dÃ©tectÃ©e)")
        
        if not recommendations:
            recommendations.append("Aucun problÃ¨me majeur dÃ©tectÃ©")
        
        return recommendations


# =============================================================================
# 8. GIT TRACKER - IntÃ©gration Git/Versioning
# =============================================================================

class GitTracker:
    """
    IntÃ¨gre le suivi Git aux expÃ©riences quantiques.
    
    Permet de:
    - Associer chaque run Ã  un commit Git
    - Tracker les modifications de code
    - Assurer la reproductibilitÃ©
    
    Usage:
        tracker = GitTracker()
        git_info = tracker.get_current_state()
        
        # AprÃ¨s run
        tracker.tag_experiment("exp_001", results)
    """
    
    def __init__(self, repo_path: str = "."):
        self.repo_path = repo_path
        self._git_available = self._check_git()
    
    def _check_git(self) -> bool:
        """VÃ©rifie si Git est disponible."""
        import subprocess
        try:
            subprocess.run(['git', '--version'], capture_output=True, check=True)
            return True
        except (subprocess.CalledProcessError, FileNotFoundError):
            return False
    
    def get_current_state(self) -> Dict[str, Any]:
        """
        RÃ©cupÃ¨re l'Ã©tat Git actuel.
        
        Returns:
            Dict avec commit, branch, dirty status, etc.
        """
        import subprocess
        
        if not self._git_available:
            return {'error': 'Git non disponible', 'available': False}
        
        state = {'available': True}
        
        try:
            # Commit actuel
            result = subprocess.run(
                ['git', 'rev-parse', 'HEAD'],
                capture_output=True, text=True, cwd=self.repo_path
            )
            state['commit_hash'] = result.stdout.strip()
            
            # Commit court
            result = subprocess.run(
                ['git', 'rev-parse', '--short', 'HEAD'],
                capture_output=True, text=True, cwd=self.repo_path
            )
            state['commit_short'] = result.stdout.strip()
            
            # Branch actuelle
            result = subprocess.run(
                ['git', 'rev-parse', '--abbrev-ref', 'HEAD'],
                capture_output=True, text=True, cwd=self.repo_path
            )
            state['branch'] = result.stdout.strip()
            
            # Status (dirty?)
            result = subprocess.run(
                ['git', 'status', '--porcelain'],
                capture_output=True, text=True, cwd=self.repo_path
            )
            state['dirty'] = len(result.stdout.strip()) > 0
            state['uncommitted_changes'] = result.stdout.strip().split('\n') if state['dirty'] else []
            
            # Message du dernier commit
            result = subprocess.run(
                ['git', 'log', '-1', '--format=%s'],
                capture_output=True, text=True, cwd=self.repo_path
            )
            state['last_commit_message'] = result.stdout.strip()
            
            # Date du dernier commit
            result = subprocess.run(
                ['git', 'log', '-1', '--format=%ci'],
                capture_output=True, text=True, cwd=self.repo_path
            )
            state['last_commit_date'] = result.stdout.strip()
            
            # Remote
            result = subprocess.run(
                ['git', 'remote', 'get-url', 'origin'],
                capture_output=True, text=True, cwd=self.repo_path
            )
            state['remote_url'] = result.stdout.strip() if result.returncode == 0 else None
            
        except Exception as e:
            state['error'] = str(e)
        
        return state
    
    def get_diff(self, cached: bool = False) -> str:
        """RÃ©cupÃ¨re le diff actuel."""
        import subprocess
        
        if not self._git_available:
            return ""
        
        cmd = ['git', 'diff']
        if cached:
            cmd.append('--cached')
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.repo_path)
            return result.stdout
        except Exception:
            return ""
    
    def create_experiment_tag(self, tag_name: str, message: str = None) -> bool:
        """
        CrÃ©e un tag Git pour marquer une expÃ©rience.
        
        Args:
            tag_name: Nom du tag (ex: 'exp_001')
            message: Message du tag
            
        Returns:
            True si succÃ¨s
        """
        import subprocess
        
        if not self._git_available:
            return False
        
        cmd = ['git', 'tag']
        if message:
            cmd.extend(['-a', tag_name, '-m', message])
        else:
            cmd.append(tag_name)
        
        try:
            subprocess.run(cmd, capture_output=True, check=True, cwd=self.repo_path)
            return True
        except subprocess.CalledProcessError:
            return False
    
    def embed_in_archive(self, archive_data: Dict) -> Dict:
        """
        Ajoute les informations Git Ã  une archive.
        
        Args:
            archive_data: DonnÃ©es d'archive Ã  enrichir
            
        Returns:
            Archive enrichie avec infos Git
        """
        git_state = self.get_current_state()
        archive_data['git'] = git_state
        
        # Ajouter un warning si dirty
        if git_state.get('dirty'):
            if 'warnings' not in archive_data:
                archive_data['warnings'] = []
            archive_data['warnings'].append(
                f"Code modifiÃ© depuis le dernier commit ({git_state.get('commit_short')})"
            )
        
        return archive_data
    
    def verify_reproducibility(self, archive_path: str) -> Dict[str, Any]:
        """
        VÃ©rifie si l'Ã©tat actuel permet de reproduire une expÃ©rience archivÃ©e.
        
        Args:
            archive_path: Chemin vers l'archive
            
        Returns:
            Dict avec statut de reproductibilitÃ©
        """
        import json
        
        with open(archive_path, 'r') as f:
            archive = json.load(f)
        
        archived_git = archive.get('git', {})
        current_git = self.get_current_state()
        
        result = {
            'reproducible': True,
            'issues': [],
            'archived_commit': archived_git.get('commit_short'),
            'current_commit': current_git.get('commit_short')
        }
        
        # VÃ©rifier le commit
        if archived_git.get('commit_hash') != current_git.get('commit_hash'):
            result['reproducible'] = False
            result['issues'].append(
                f"Commit diffÃ©rent: {archived_git.get('commit_short')} â†’ {current_git.get('commit_short')}"
            )
        
        # VÃ©rifier si dirty
        if current_git.get('dirty'):
            result['reproducible'] = False
            result['issues'].append("Code modifiÃ© localement")
        
        # VÃ©rifier la branche
        if archived_git.get('branch') != current_git.get('branch'):
            result['issues'].append(
                f"Branche diffÃ©rente: {archived_git.get('branch')} â†’ {current_git.get('branch')}"
            )
        
        return result
# =============================================================================
# QMC FRAMEWORK v2.5.22 - NOUVELLES FONCTIONNALITÃ‰S (BLOC 3)
# =============================================================================
# 
# Ce bloc contient:
# 9. MultiBackendRunner - ExÃ©cution multi-backend simultanÃ©e
# 10. StandardBenchmarks - Benchmarks standards intÃ©grÃ©s
# 11. PublicationExporter - Export LaTeX/PDF pour publications
# 12. CorrelationAnalyzer - Analyse de corrÃ©lations inter-qubits
# 13. TranspilationCache - Cache intelligent de transpilation
# =============================================================================


# =============================================================================
# 9. MULTI-BACKEND RUNNER - ExÃ©cution Multi-Backend SimultanÃ©e
# =============================================================================

class MultiBackendRunner:
    """
    ExÃ©cute les mÃªmes circuits sur plusieurs backends en parallÃ¨le.
    
    Permet de:
    - Comparer les performances entre backends
    - Identifier le meilleur backend pour un circuit donnÃ©
    - Valider la reproductibilitÃ© cross-platform
    
    Usage:
        runner = MultiBackendRunner(framework)
        results = runner.run(
            circuits,
            backends=["ibm_fez", "ibm_torino", "ibm_brisbane"],
            shots=4096
        )
        comparison = runner.compare_results(results)
    """
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.logger = getattr(framework, 'logger', None)
        self.original_backend = framework.backend_name
    
    def run(self,
            circuits: List,
            backends: List[str],
            shots: int = 4096,
            parallel: bool = False,
            continue_on_error: bool = True) -> Dict[str, Any]:
        """
        ExÃ©cute les circuits sur plusieurs backends.
        
        Args:
            circuits: Circuits Ã  exÃ©cuter
            backends: Liste des backends cibles
            shots: Nombre de shots
            parallel: ExÃ©cution parallÃ¨le (non implÃ©mentÃ© - nÃ©cessite multi-compte)
            continue_on_error: Continuer si un backend Ã©choue
            
        Returns:
            Dict avec rÃ©sultats par backend
        """
        from datetime import datetime
        
        if not isinstance(circuits, list):
            circuits = [circuits]
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'n_circuits': len(circuits),
            'shots': shots,
            'backends': {},
            'comparison': None
        }
        
        for backend_name in backends:
            if self.logger:
                self.logger.info(f"ğŸ”„ ExÃ©cution sur {backend_name}...")
            
            backend_result = {
                'backend': backend_name,
                'status': 'pending',
                'results': None,
                'error': None,
                'execution_time_s': None
            }
            
            try:
                import time
                start = time.time()
                
                # Changer de backend
                self.framework.backend_name = backend_name
                if hasattr(self.framework, '_connected') and self.framework._connected:
                    self.framework.connect()
                
                # ExÃ©cuter
                qpu_results = self.framework.run_on_qpu(circuits, shots=shots)
                
                backend_result['results'] = qpu_results
                backend_result['status'] = 'completed'
                backend_result['execution_time_s'] = time.time() - start
                
            except Exception as e:
                backend_result['status'] = 'error'
                backend_result['error'] = str(e)
                if not continue_on_error:
                    raise
            
            results['backends'][backend_name] = backend_result
        
        # Restaurer le backend original
        self.framework.backend_name = self.original_backend
        
        # Comparer les rÃ©sultats
        results['comparison'] = self._compare_backends(results['backends'])
        
        return results
    
    def _compare_backends(self, backends_results: Dict) -> Dict:
        """Compare les rÃ©sultats entre backends."""
        import numpy as np
        
        comparison = {
            'metrics': {},
            'ranking': [],
            'consistency': {}
        }
        
        # Extraire les mÃ©triques par backend
        for backend, data in backends_results.items():
            if data['status'] != 'completed' or not data['results']:
                continue
            
            results = data['results']
            
            # Calculer mÃ©triques
            total_unique_states = sum(r.get('unique_states', 0) for r in results)
            avg_entropy = np.mean([
                self._compute_entropy(r.get('counts', {})) 
                for r in results
            ])
            
            comparison['metrics'][backend] = {
                'total_unique_states': total_unique_states,
                'avg_entropy': float(avg_entropy),
                'execution_time': data.get('execution_time_s', 0)
            }
        
        # Ranking par entropie (plus Ã©levÃ©e = meilleur pour circuits alÃ©atoires)
        if comparison['metrics']:
            ranked = sorted(
                comparison['metrics'].items(),
                key=lambda x: x[1]['avg_entropy'],
                reverse=True
            )
            comparison['ranking'] = [b[0] for b in ranked]
            comparison['best_backend'] = comparison['ranking'][0] if comparison['ranking'] else None
        
        # Calculer la consistance entre backends
        comparison['consistency'] = self._compute_consistency(backends_results)
        
        return comparison
    
    def _compute_entropy(self, counts: Dict) -> float:
        """Calcule l'entropie de Shannon."""
        import numpy as np
        
        total = sum(counts.values())
        if total == 0:
            return 0.0
        
        probs = [c / total for c in counts.values()]
        return float(-sum(p * np.log2(p) for p in probs if p > 0))
    
    def _compute_consistency(self, backends_results: Dict) -> Dict:
        """Calcule la consistance des rÃ©sultats entre backends."""
        import numpy as np
        
        # Extraire les distributions de probabilitÃ©
        distributions = {}
        for backend, data in backends_results.items():
            if data['status'] != 'completed' or not data['results']:
                continue
            
            # AgrÃ©ger les counts du premier circuit
            counts = data['results'][0].get('counts', {})
            total = sum(counts.values())
            if total > 0:
                distributions[backend] = {k: v/total for k, v in counts.items()}
        
        if len(distributions) < 2:
            return {'pairwise_fidelity': {}, 'avg_fidelity': None}
        
        # Calculer la fidÃ©litÃ© entre chaque paire
        backends = list(distributions.keys())
        pairwise = {}
        fidelities = []
        
        for i, b1 in enumerate(backends):
            for b2 in backends[i+1:]:
                d1, d2 = distributions[b1], distributions[b2]
                all_states = set(d1.keys()) | set(d2.keys())
                
                # FidÃ©litÃ© classique
                fidelity = sum(
                    np.sqrt(d1.get(s, 0) * d2.get(s, 0))
                    for s in all_states
                ) ** 2
                
                pairwise[f"{b1}_vs_{b2}"] = float(fidelity)
                fidelities.append(fidelity)
        
        return {
            'pairwise_fidelity': pairwise,
            'avg_fidelity': float(np.mean(fidelities)) if fidelities else None
        }
    
    def generate_report(self, results: Dict, output_path: str = None) -> str:
        """GÃ©nÃ¨re un rapport HTML de comparaison multi-backend."""
        from datetime import datetime
        
        comparison = results.get('comparison', {})
        
        html = f'''<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Comparaison Multi-Backend</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 40px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; }}
        h1 {{ color: #1a1a2e; text-align: center; }}
        .ranking {{ display: flex; justify-content: center; gap: 30px; margin: 30px 0; }}
        .rank-card {{ padding: 20px 40px; border-radius: 10px; text-align: center; }}
        .rank-1 {{ background: linear-gradient(135deg, #ffd700, #ffed4a); }}
        .rank-2 {{ background: linear-gradient(135deg, #c0c0c0, #e8e8e8); }}
        .rank-3 {{ background: linear-gradient(135deg, #cd7f32, #daa06d); }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th {{ background: #4361ee; color: white; padding: 12px; }}
        td {{ padding: 12px; border-bottom: 1px solid #ddd; text-align: center; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ”„ Comparaison Multi-Backend</h1>
        <p style="text-align: center;">GÃ©nÃ©rÃ© le {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
        
        <h2>ğŸ† Classement</h2>
        <div class="ranking">
'''
        
        ranking = comparison.get('ranking', [])
        medals = ['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰']
        
        for i, backend in enumerate(ranking[:3]):
            rank_class = f"rank-{i+1}"
            medal = medals[i] if i < 3 else f"#{i+1}"
            html += f'''            <div class="rank-card {rank_class}">
                <div style="font-size: 48px;">{medal}</div>
                <div style="font-size: 24px; font-weight: bold;">{backend}</div>
            </div>
'''
        
        html += '''        </div>
        
        <h2>ğŸ“Š MÃ©triques DÃ©taillÃ©es</h2>
        <table>
            <tr>
                <th>Backend</th>
                <th>Ã‰tats Uniques</th>
                <th>Entropie Moy.</th>
                <th>Temps (s)</th>
                <th>Status</th>
            </tr>
'''
        
        for backend, data in results.get('backends', {}).items():
            metrics = comparison.get('metrics', {}).get(backend, {})
            status = data.get('status', 'unknown')
            status_color = '#28a745' if status == 'completed' else '#dc3545'
            
            html += f'''            <tr>
                <td><strong>{backend}</strong></td>
                <td>{metrics.get('total_unique_states', '-')}</td>
                <td>{metrics.get('avg_entropy', 0):.3f}</td>
                <td>{metrics.get('execution_time', 0):.1f}</td>
                <td style="color: {status_color};">{status.upper()}</td>
            </tr>
'''
        
        html += '''        </table>
        
        <h2>ğŸ”— Consistance Inter-Backend</h2>
'''
        
        consistency = comparison.get('consistency', {})
        if consistency.get('avg_fidelity'):
            html += f'''        <p><strong>FidÃ©litÃ© moyenne:</strong> {consistency['avg_fidelity']:.4f}</p>
        <table>
            <tr><th>Paire</th><th>FidÃ©litÃ©</th></tr>
'''
            for pair, fid in consistency.get('pairwise_fidelity', {}).items():
                html += f'            <tr><td>{pair}</td><td>{fid:.4f}</td></tr>\n'
            html += '        </table>\n'
        
        html += '''    </div>
</body>
</html>'''
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html)
        
        return html


# =============================================================================
# 10. STANDARD BENCHMARKS - Benchmarks Standards IntÃ©grÃ©s
# =============================================================================

class StandardBenchmarks:
    """
    Suite de benchmarks standards pour Ã©valuer les performances QPU.
    
    Benchmarks disponibles:
    - Mirror circuits (fidÃ©litÃ©)
    - Quantum Volume (QV)
    - Layer Fidelity
    - Randomized Benchmarking (RB)
    
    Usage:
        bench = StandardBenchmarks(framework)
        results = bench.run_all(n_qubits=50)
        # Ou individuellement:
        qv = bench.quantum_volume(n_qubits=5)
    """
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.logger = getattr(framework, 'logger', None)
    
    def run_all(self, n_qubits: int = 10, shots: int = 4096) -> Dict[str, Any]:
        """
        ExÃ©cute tous les benchmarks disponibles.
        
        Args:
            n_qubits: Nombre de qubits Ã  tester
            shots: Nombre de shots par benchmark
            
        Returns:
            Dict avec tous les rÃ©sultats de benchmark
        """
        from datetime import datetime
        
        results = {
            'timestamp': datetime.now().isoformat(),
            'n_qubits': n_qubits,
            'shots': shots,
            'benchmarks': {}
        }
        
        # Mirror circuits
        if self.logger:
            self.logger.info("ğŸ”¬ Running Mirror Circuits benchmark...")
        try:
            results['benchmarks']['mirror'] = self.mirror_circuits(n_qubits, shots)
        except Exception as e:
            results['benchmarks']['mirror'] = {'error': str(e)}
        
        # Layer fidelity
        if self.logger:
            self.logger.info("ğŸ”¬ Running Layer Fidelity benchmark...")
        try:
            results['benchmarks']['layer_fidelity'] = self.layer_fidelity(n_qubits, shots)
        except Exception as e:
            results['benchmarks']['layer_fidelity'] = {'error': str(e)}
        
        # Quantum Volume (limitÃ© Ã  5 qubits pour temps raisonnable)
        qv_qubits = min(n_qubits, 5)
        if self.logger:
            self.logger.info(f"ğŸ”¬ Running Quantum Volume benchmark (n={qv_qubits})...")
        try:
            results['benchmarks']['quantum_volume'] = self.quantum_volume(qv_qubits, shots)
        except Exception as e:
            results['benchmarks']['quantum_volume'] = {'error': str(e)}
        
        # Score global
        results['overall_score'] = self._compute_overall_score(results['benchmarks'])
        
        return results
    
    def mirror_circuits(self, n_qubits: int, shots: int = 4096, depth: int = 10) -> Dict:
        """
        Benchmark Mirror Circuits.
        
        Un circuit miroir applique des portes puis leur inverse.
        Un QPU parfait retourne toujours |0...0âŸ©.
        
        La fidÃ©litÃ© mesure la probabilitÃ© de retourner Ã  l'Ã©tat initial.
        """
        from qiskit import QuantumCircuit
        from qiskit.circuit.library import EfficientSU2
        import numpy as np
        
        # CrÃ©er un circuit avec couches alÃ©atoires
        qc = QuantumCircuit(n_qubits, n_qubits)
        
        # Ajouter des couches de portes alÃ©atoires
        np.random.seed(42)  # ReproductibilitÃ©
        for _ in range(depth):
            for q in range(n_qubits):
                # Rotation alÃ©atoire
                theta = np.random.uniform(0, 2*np.pi)
                phi = np.random.uniform(0, 2*np.pi)
                qc.u(theta, phi, 0, q)
            
            # CNOTs
            for q in range(0, n_qubits - 1, 2):
                qc.cx(q, q + 1)
        
        qc.barrier()
        
        # Miroir: inverse des portes
        qc = qc.compose(qc.inverse())
        
        qc.measure_all()
        
        # ExÃ©cuter
        results = self.framework.run_on_qpu([qc], shots=shots)
        
        if not results:
            return {'error': 'No results'}
        
        counts = results[0].get('counts', {})
        ground_state = '0' * n_qubits
        ground_count = counts.get(ground_state, 0)
        total = sum(counts.values())
        
        fidelity = ground_count / total if total > 0 else 0
        
        return {
            'type': 'mirror_circuits',
            'n_qubits': n_qubits,
            'depth': depth * 2,  # Aller + retour
            'fidelity': float(fidelity),
            'ground_state_count': ground_count,
            'total_shots': total,
            'interpretation': self._interpret_fidelity(fidelity)
        }
    
    def layer_fidelity(self, n_qubits: int, shots: int = 4096, max_layers: int = 10) -> Dict:
        """
        Benchmark Layer Fidelity.
        
        Mesure comment la fidÃ©litÃ© dÃ©croÃ®t avec le nombre de couches.
        Permet d'estimer le taux d'erreur par couche.
        """
        from qiskit import QuantumCircuit
        import numpy as np
        
        fidelities = []
        layers_tested = list(range(1, max_layers + 1, 2))
        
        for n_layers in layers_tested:
            # Circuit avec n_layers couches puis miroir
            qc = QuantumCircuit(n_qubits, n_qubits)
            
            np.random.seed(42)
            for _ in range(n_layers):
                for q in range(n_qubits):
                    qc.h(q)
                for q in range(0, n_qubits - 1, 2):
                    qc.cx(q, q + 1)
            
            qc.barrier()
            qc = qc.compose(qc.inverse())
            qc.measure_all()
            
            # ExÃ©cuter
            results = self.framework.run_on_qpu([qc], shots=shots)
            
            if results:
                counts = results[0].get('counts', {})
                ground_state = '0' * n_qubits
                fidelity = counts.get(ground_state, 0) / sum(counts.values())
                fidelities.append(float(fidelity))
            else:
                fidelities.append(0.0)
        
        # Estimer le taux d'erreur par couche (fit exponentiel)
        if len(fidelities) > 1:
            # F = F0 * exp(-r * layers) => log(F) = log(F0) - r * layers
            log_fid = [np.log(max(f, 1e-10)) for f in fidelities]
            try:
                coeffs = np.polyfit(layers_tested, log_fid, 1)
                error_rate_per_layer = -coeffs[0]
            except:
                error_rate_per_layer = None
        else:
            error_rate_per_layer = None
        
        return {
            'type': 'layer_fidelity',
            'n_qubits': n_qubits,
            'layers_tested': layers_tested,
            'fidelities': fidelities,
            'error_rate_per_layer': float(error_rate_per_layer) if error_rate_per_layer else None,
            'interpretation': 'Lower error rate = better hardware'
        }
    
    def quantum_volume(self, n_qubits: int = 5, shots: int = 4096, n_trials: int = 10) -> Dict:
        """
        Benchmark Quantum Volume (simplifiÃ©).
        
        Le QV mesure la profondeur maximale de circuit "carrÃ©" (depth = width)
        qu'un QPU peut exÃ©cuter de maniÃ¨re fiable.
        """
        from qiskit import QuantumCircuit
        from qiskit.circuit.library import QuantumVolume as QVCircuit
        import numpy as np
        
        # GÃ©nÃ©rer plusieurs circuits QV
        heavy_output_counts = []
        
        for trial in range(n_trials):
            # CrÃ©er un circuit QV
            qc = QVCircuit(n_qubits, seed=trial)
            qc.measure_all()
            
            # Calculer les heavy outputs (simulation idÃ©ale)
            try:
                from qiskit.quantum_info import Statevector
                qc_no_meas = QVCircuit(n_qubits, seed=trial)
                sv = Statevector.from_instruction(qc_no_meas)
                probs = sv.probabilities_dict()
                median_prob = np.median(list(probs.values()))
                heavy_outputs = {k for k, v in probs.items() if v > median_prob}
            except:
                heavy_outputs = set()
            
            # ExÃ©cuter sur QPU
            results = self.framework.run_on_qpu([qc], shots=shots)
            
            if results:
                counts = results[0].get('counts', {})
                total = sum(counts.values())
                heavy_count = sum(counts.get(h, 0) for h in heavy_outputs)
                heavy_prob = heavy_count / total if total > 0 else 0
                heavy_output_counts.append(heavy_prob)
        
        # QV est atteint si >2/3 des heavy outputs sont mesurÃ©s
        avg_heavy = np.mean(heavy_output_counts) if heavy_output_counts else 0
        qv_passed = avg_heavy > 2/3
        
        return {
            'type': 'quantum_volume',
            'n_qubits': n_qubits,
            'n_trials': n_trials,
            'avg_heavy_output_probability': float(avg_heavy),
            'threshold': 2/3,
            'qv_passed': qv_passed,
            'estimated_qv': 2 ** n_qubits if qv_passed else None,
            'interpretation': f"QV â‰¥ {2**n_qubits}" if qv_passed else f"QV < {2**n_qubits}"
        }
    
    def _interpret_fidelity(self, fidelity: float) -> str:
        """InterprÃ¨te une valeur de fidÃ©litÃ©."""
        if fidelity >= 0.99:
            return "EXCELLENT"
        elif fidelity >= 0.95:
            return "VERY_GOOD"
        elif fidelity >= 0.90:
            return "GOOD"
        elif fidelity >= 0.80:
            return "MODERATE"
        else:
            return "POOR"
    
    def _compute_overall_score(self, benchmarks: Dict) -> Dict:
        """Calcule un score global basÃ© sur tous les benchmarks."""
        scores = []
        
        if 'mirror' in benchmarks and 'fidelity' in benchmarks['mirror']:
            scores.append(benchmarks['mirror']['fidelity'])
        
        if 'layer_fidelity' in benchmarks and 'fidelities' in benchmarks['layer_fidelity']:
            scores.append(np.mean(benchmarks['layer_fidelity']['fidelities']))
        
        if 'quantum_volume' in benchmarks and 'avg_heavy_output_probability' in benchmarks['quantum_volume']:
            scores.append(benchmarks['quantum_volume']['avg_heavy_output_probability'])
        
        if scores:
            overall = float(np.mean(scores))
            return {
                'score': overall,
                'grade': self._interpret_fidelity(overall),
                'components': len(scores)
            }
        
        return {'score': None, 'grade': 'N/A', 'components': 0}


# =============================================================================
# 11. PUBLICATION EXPORTER - Export LaTeX/PDF pour Publications
# =============================================================================

class PublicationExporter:
    """
    Exporte les rÃ©sultats dans des formats adaptÃ©s aux publications scientifiques.
    
    Formats supportÃ©s:
    - LaTeX (figures, tableaux)
    - PDF (via LaTeX)
    - Markdown
    - INPI (format brevet franÃ§ais)
    
    Usage:
        exporter = PublicationExporter()
        exporter.export_latex(results, "results.tex", language='en')
        exporter.export_inpi(results, "brevet.docx")
    """
    
    def __init__(self, output_dir: str = "."):
        self.output_dir = output_dir
    
    def export_latex(self,
                     results: Dict,
                     output_path: str,
                     language: str = 'en',
                     include_figures: bool = True) -> str:
        """
        Exporte les rÃ©sultats en LaTeX.
        
        Args:
            results: RÃ©sultats Ã  exporter
            output_path: Fichier de sortie (.tex)
            language: 'en' ou 'fr'
            include_figures: Inclure les commandes figure
        """
        from datetime import datetime
        
        # Labels selon la langue
        labels = {
            'en': {
                'title': 'Quantum Experiment Results',
                'backend': 'Backend',
                'qubits': 'Qubits',
                'depth': 'Circuit Depth',
                'shots': 'Shots',
                'fidelity': 'Fidelity',
                'entropy': 'Entropy',
                'table_caption': 'Summary of experimental results',
                'figure_caption': 'Probability distribution of measured states'
            },
            'fr': {
                'title': 'RÃ©sultats d\'ExpÃ©rience Quantique',
                'backend': 'Backend',
                'qubits': 'Qubits',
                'depth': 'Profondeur',
                'shots': 'Tirs',
                'fidelity': 'FidÃ©litÃ©',
                'entropy': 'Entropie',
                'table_caption': 'RÃ©sumÃ© des rÃ©sultats expÃ©rimentaux',
                'figure_caption': 'Distribution de probabilitÃ© des Ã©tats mesurÃ©s'
            }
        }
        
        L = labels.get(language, labels['en'])
        
        latex = f'''% Generated by QMC Framework - {datetime.now().strftime("%Y-%m-%d")}
\\documentclass{{article}}
\\usepackage{{booktabs}}
\\usepackage{{graphicx}}
\\usepackage[utf8]{{inputenc}}

\\title{{{L['title']}}}
\\author{{QMC Research Lab}}
\\date{{\\today}}

\\begin{{document}}

\\maketitle

\\section{{Experimental Setup}}

\\begin{{table}}[h]
\\centering
\\caption{{{L['table_caption']}}}
\\begin{{tabular}}{{lc}}
\\toprule
\\textbf{{Parameter}} & \\textbf{{Value}} \\\\
\\midrule
{L['backend']} & {results.get('backend', {}).get('name', 'N/A')} \\\\
{L['qubits']} & {results.get('results', [{}])[0].get('n_qubits', 'N/A')} \\\\
{L['shots']} & {results.get('results', [{}])[0].get('shots', 'N/A')} \\\\
\\bottomrule
\\end{{tabular}}
\\end{{table}}

\\section{{Results}}

'''
        
        # Tableau des rÃ©sultats
        if results.get('results'):
            latex += '''\\begin{table}[h]
\\centering
\\begin{tabular}{cccc}
\\toprule
\\textbf{Circuit} & \\textbf{Unique States} & \\textbf{Max Prob} & \\textbf{Entropy} \\\\
\\midrule
'''
            for r in results.get('results', []):
                counts = r.get('counts', {})
                if counts:
                    total = sum(counts.values())
                    max_prob = max(counts.values()) / total if total > 0 else 0
                    entropy = self._compute_entropy(counts)
                    latex += f"{r.get('circuit_index', 0)} & {len(counts)} & {max_prob:.4f} & {entropy:.2f} \\\\\n"
            
            latex += '''\\bottomrule
\\end{tabular}
\\end{table}

'''
        
        latex += '''\\end{document}
'''
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(latex)
        
        return latex
    
    def export_markdown(self, results: Dict, output_path: str) -> str:
        """Exporte les rÃ©sultats en Markdown."""
        from datetime import datetime
        
        md = f'''# Quantum Experiment Results

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## Experimental Setup

| Parameter | Value |
|-----------|-------|
| Backend | {results.get('backend', {}).get('name', 'N/A')} |
| Qubits | {results.get('results', [{}])[0].get('n_qubits', 'N/A')} |
| Shots | {results.get('results', [{}])[0].get('shots', 'N/A')} |

## Results Summary

| Circuit | Unique States | Entropy |
|---------|---------------|---------|
'''
        
        for r in results.get('results', []):
            counts = r.get('counts', {})
            entropy = self._compute_entropy(counts) if counts else 0
            md += f"| {r.get('circuit_index', 0)} | {len(counts)} | {entropy:.2f} |\n"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(md)
        
        return md
    
    def export_inpi_figures_prompts(self, 
                                     results: Dict,
                                     output_path: str,
                                     n_figures: int = 5) -> str:
        """
        GÃ©nÃ¨re un fichier JSON de prompts pour figures INPI (N&B).
        
        Conforme aux rÃ¨gles INPI: noir et blanc uniquement.
        """
        import json
        
        prompts = []
        
        # Figure 1: Architecture systÃ¨me
        prompts.append({
            "id": "fig_1",
            "figure": "Figure 1 - Architecture du systÃ¨me",
            "prompt": f"Create a technical system architecture diagram in BLACK AND WHITE ONLY for patent documentation. Style: Clean technical schematic with precise lines, white background, no colors, no gradients. Show a flow from 'EntrÃ©e' through 'Circuit Quantique' ({results.get('results', [{}])[0].get('n_qubits', 'N')} qubits) to 'Mesure' and 'RÃ©sultat'. Use boxes with sharp corners, arrows for data flow. Labels in FRENCH. Format: Landscape, 300 DPI, publication-ready."
        })
        
        # Figure 2: Distribution des Ã©tats
        prompts.append({
            "id": "fig_2",
            "figure": "Figure 2 - Distribution des Ã©tats mesurÃ©s",
            "prompt": "Create a BAR CHART in BLACK AND WHITE ONLY showing probability distribution. X-axis: quantum states (bitstrings like '00', '01', '10', '11'). Y-axis: probability (0 to 1). Use solid black bars with white background. Include axis labels in FRENCH: 'Ã‰tat quantique', 'ProbabilitÃ©'. No colors, gradients, or 3D effects. -ready quality."
        })
        
        # Figure 3: Circuit quantique
        prompts.append({
            "id": "fig_3",
            "figure": "Figure 3 - SchÃ©ma du circuit quantique",
            "prompt": f"Create a quantum circuit diagram in BLACK AND WHITE for {results.get('results', [{}])[0].get('n_qubits', 5)} qubits. Show horizontal qubit lines, gate boxes (H, X, CNOT), and measurement symbols at the end. Use standard quantum computing notation. Clean technical drawing style, no colors. Labels: 'q0', 'q1', etc. for qubits. Format: Landscape, 300 DPI."
        })
        
        # Figure 4: MÃ©triques de performance
        prompts.append({
            "id": "fig_4",
            "figure": "Figure 4 - MÃ©triques de fidÃ©litÃ©",
            "prompt": "Create a LINE GRAPH in BLACK AND WHITE showing fidelity metrics. X-axis: 'Nombre de couches' (1 to 10). Y-axis: 'FidÃ©litÃ©' (0 to 1). Use solid black line with data point markers (circles). Include dotted reference line at fidelity=0.9. Grid lines in light gray. Labels in FRENCH. -ready quality."
        })
        
        # Figure 5: Comparaison
        prompts.append({
            "id": "fig_5",
            "figure": "Figure 5 - Tableau comparatif",
            "prompt": "Create a technical COMPARISON TABLE in BLACK AND WHITE. Headers: 'ParamÃ¨tre', 'Valeur MesurÃ©e', 'Valeur ThÃ©orique'. Rows for: Qubits, Profondeur, FidÃ©litÃ©, Entropie. Use clean lines, professional typography. All text in FRENCH. No shading or colors.  documentation style."
        })
        
        # Sauvegarder
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(prompts[:n_figures], f, indent=2, ensure_ascii=False)
        
        return json.dumps(prompts[:n_figures], indent=2, ensure_ascii=False)
    
    def _compute_entropy(self, counts: Dict) -> float:
        """Calcule l'entropie de Shannon."""
        import numpy as np
        
        total = sum(counts.values())
        if total == 0:
            return 0.0
        
        probs = [c / total for c in counts.values()]
        return float(-sum(p * np.log2(p) for p in probs if p > 0))


# =============================================================================
# 12. INTER-QUBIT CORRELATION ANALYZER - Analyse de CorrÃ©lations Inter-Qubits
# =============================================================================

class InterQubitCorrelationAnalyzer:
    """
    Analyse les corrÃ©lations quantiques entre qubits.
    
    Permet de:
    - DÃ©tecter les qubits fortement corrÃ©lÃ©s
    - Identifier les problÃ¨mes de crosstalk
    - Optimiser le mapping des circuits
    
    Usage:
        analyzer = InterQubitCorrelationAnalyzer()
        correlations = analyzer.analyze(results)
        matrix = analyzer.get_correlation_matrix(results)
    """
    
    def analyze(self, results: List[Dict]) -> Dict[str, Any]:
        """
        Analyse complÃ¨te des corrÃ©lations.
        
        Args:
            results: RÃ©sultats du framework
            
        Returns:
            Dict avec matrice de corrÃ©lation et statistiques
        """
        import numpy as np
        
        # AgrÃ©ger tous les counts
        all_counts = {}
        n_qubits = None
        
        for r in results:
            counts = r.get('counts', {})
            for state, count in counts.items():
                if n_qubits is None:
                    n_qubits = len(state)
                all_counts[state] = all_counts.get(state, 0) + count
        
        if not all_counts or n_qubits is None:
            return {'error': 'No counts available'}
        
        # Calculer la matrice de corrÃ©lation
        correlation_matrix = self._compute_correlation_matrix(all_counts, n_qubits)
        
        # Identifier les paires fortement corrÃ©lÃ©es
        strong_correlations = []
        for i in range(n_qubits):
            for j in range(i + 1, n_qubits):
                corr = correlation_matrix[i, j]
                if abs(corr) > 0.5:
                    strong_correlations.append({
                        'qubits': (i, j),
                        'correlation': float(corr),
                        'type': 'positive' if corr > 0 else 'negative'
                    })
        
        # Identifier les qubits problÃ©matiques (corrÃ©lation avec tous)
        avg_correlations = np.mean(np.abs(correlation_matrix), axis=1)
        problematic_qubits = [
            int(q) for q in range(n_qubits) 
            if avg_correlations[q] > 0.3
        ]
        
        return {
            'n_qubits': n_qubits,
            'correlation_matrix': correlation_matrix.tolist(),
            'strong_correlations': sorted(
                strong_correlations, 
                key=lambda x: abs(x['correlation']), 
                reverse=True
            ),
            'problematic_qubits': problematic_qubits,
            'avg_correlation': float(np.mean(np.abs(correlation_matrix))),
            'max_correlation': float(np.max(np.abs(correlation_matrix - np.eye(n_qubits))))
        }
    
    def _compute_correlation_matrix(self, counts: Dict[str, int], n_qubits: int):
        """Calcule la matrice de corrÃ©lation entre qubits."""
        import numpy as np
        
        total = sum(counts.values())
        
        # Calculer les probabilitÃ©s marginales et jointes
        p_single = np.zeros(n_qubits)  # P(q_i = 1)
        p_joint = np.zeros((n_qubits, n_qubits))  # P(q_i = 1, q_j = 1)
        
        for state, count in counts.items():
            prob = count / total
            bits = [int(b) for b in reversed(state)]
            
            for i, b in enumerate(bits):
                if b == 1:
                    p_single[i] += prob
                    for j, b2 in enumerate(bits):
                        if b2 == 1:
                            p_joint[i, j] += prob
        
        # Calculer la corrÃ©lation: Corr(i,j) = (P(i,j) - P(i)P(j)) / sqrt(Var(i)Var(j))
        correlation = np.zeros((n_qubits, n_qubits))
        
        for i in range(n_qubits):
            for j in range(n_qubits):
                if i == j:
                    correlation[i, j] = 1.0
                else:
                    cov = p_joint[i, j] - p_single[i] * p_single[j]
                    var_i = p_single[i] * (1 - p_single[i])
                    var_j = p_single[j] * (1 - p_single[j])
                    
                    if var_i > 0 and var_j > 0:
                        correlation[i, j] = cov / np.sqrt(var_i * var_j)
        
        return correlation
    
    def visualize_matrix(self, correlation_matrix: List[List[float]], output_path: str = None) -> str:
        """GÃ©nÃ¨re une visualisation ASCII de la matrice."""
        import numpy as np
        
        matrix = np.array(correlation_matrix)
        n = len(matrix)
        
        # CaractÃ¨res pour les niveaux de corrÃ©lation
        chars = [' ', 'â–‘', 'â–’', 'â–“', 'â–ˆ']
        
        output = "Correlation Matrix:\n"
        output += "    " + "".join(f"{i:3}" for i in range(n)) + "\n"
        output += "   +" + "-" * (3 * n) + "+\n"
        
        for i in range(n):
            output += f"{i:2} |"
            for j in range(n):
                val = abs(matrix[i, j])
                idx = min(int(val * 4), 4)
                output += f" {chars[idx]} "
            output += "|\n"
        
        output += "   +" + "-" * (3 * n) + "+\n"
        output += "Legend: ' '=0  'â–‘'=0.25  'â–’'=0.5  'â–“'=0.75  'â–ˆ'=1.0\n"
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(output)
        
        return output


# =============================================================================
# 13. TRANSPILATION CACHE - Cache Intelligent de Transpilation
# =============================================================================

class TranspilationCache:
    """
    Cache intelligent pour les circuits transpilÃ©s.
    
    Ã‰vite de re-transpiler des circuits identiques pour le mÃªme backend,
    Ã©conomisant du temps CPU significatif.
    
    Usage:
        cache = TranspilationCache(max_age_hours=24)
        
        # La transpilation utilise le cache automatiquement
        transpiled = cache.get_or_transpile(circuit, backend)
    """
    
    def __init__(self, max_age_hours: float = 24, max_entries: int = 1000):
        """
        Args:
            max_age_hours: DurÃ©e de vie max des entrÃ©es en heures
            max_entries: Nombre max d'entrÃ©es dans le cache
        """
        self.max_age_seconds = max_age_hours * 3600
        self.max_entries = max_entries
        self._cache = {}  # key -> (transpiled_circuit, timestamp, backend_info)
        self._hits = 0
        self._misses = 0
    
    def _circuit_hash(self, circuit, optimization_level: int = 3) -> str:
        """GÃ©nÃ¨re un hash unique pour un circuit."""
        import hashlib
        
        # Utiliser le QASM comme reprÃ©sentation canonique
        try:
            qasm = circuit.qasm()
        except:
            # Fallback: utiliser le nombre de portes et la profondeur
            qasm = f"{circuit.num_qubits}_{circuit.depth()}_{circuit.size()}_{dict(circuit.count_ops())}"
        
        key_str = f"{qasm}_{optimization_level}"
        return hashlib.sha256(key_str.encode()).hexdigest()[:16]
    
    def _backend_hash(self, backend) -> str:
        """GÃ©nÃ¨re un hash pour l'Ã©tat du backend."""
        import hashlib
        
        # Inclure le nom et la date de calibration
        try:
            name = backend.name
            # Essayer d'obtenir la date de derniÃ¨re calibration
            props = backend.properties() if hasattr(backend, 'properties') else None
            calib_date = props.last_update_date.isoformat() if props else "unknown"
        except:
            name = str(backend)
            calib_date = "unknown"
        
        key_str = f"{name}_{calib_date}"
        return hashlib.sha256(key_str.encode()).hexdigest()[:8]
    
    def get(self, circuit, backend, optimization_level: int = 3):
        """
        RÃ©cupÃ¨re un circuit transpilÃ© depuis le cache.
        
        Returns:
            Circuit transpilÃ© ou None si non trouvÃ©/expirÃ©
        """
        import time
        
        circuit_hash = self._circuit_hash(circuit, optimization_level)
        backend_hash = self._backend_hash(backend)
        key = f"{circuit_hash}_{backend_hash}"
        
        if key in self._cache:
            transpiled, timestamp, _ = self._cache[key]
            
            # VÃ©rifier l'expiration
            if time.time() - timestamp < self.max_age_seconds:
                self._hits += 1
                return transpiled
            else:
                # ExpirÃ©, supprimer
                del self._cache[key]
        
        self._misses += 1
        return None
    
    def put(self, circuit, backend, transpiled, optimization_level: int = 3):
        """Ajoute un circuit transpilÃ© au cache."""
        import time
        
        circuit_hash = self._circuit_hash(circuit, optimization_level)
        backend_hash = self._backend_hash(backend)
        key = f"{circuit_hash}_{backend_hash}"
        
        # Nettoyer si cache plein
        if len(self._cache) >= self.max_entries:
            self._evict_oldest()
        
        self._cache[key] = (
            transpiled,
            time.time(),
            {'backend': backend_hash, 'opt_level': optimization_level}
        )
    
    def get_or_transpile(self, circuit, backend, optimization_level: int = 3):
        """
        RÃ©cupÃ¨re depuis le cache ou transpile.
        
        Args:
            circuit: Circuit Ã  transpiler
            backend: Backend cible
            optimization_level: Niveau d'optimisation
            
        Returns:
            Circuit transpilÃ©
        """
        # Essayer le cache
        cached = self.get(circuit, backend, optimization_level)
        if cached is not None:
            return cached
        
        # Transpiler
        from qiskit import transpile
        transpiled = transpile(circuit, backend, optimization_level=optimization_level)
        
        # Mettre en cache
        self.put(circuit, backend, transpiled, optimization_level)
        
        return transpiled
    
    def _evict_oldest(self):
        """Supprime les entrÃ©es les plus anciennes."""
        if not self._cache:
            return
        
        # Trier par timestamp et supprimer les 10% plus anciens
        sorted_keys = sorted(
            self._cache.keys(),
            key=lambda k: self._cache[k][1]
        )
        
        n_to_remove = max(1, len(sorted_keys) // 10)
        for key in sorted_keys[:n_to_remove]:
            del self._cache[key]
    
    def clear(self):
        """Vide le cache."""
        self._cache.clear()
        self._hits = 0
        self._misses = 0
    
    def stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du cache."""
        total = self._hits + self._misses
        hit_rate = self._hits / total if total > 0 else 0
        
        return {
            'entries': len(self._cache),
            'max_entries': self.max_entries,
            'hits': self._hits,
            'misses': self._misses,
            'hit_rate': hit_rate,
            'hit_rate_percent': f"{hit_rate*100:.1f}%"
        }
# =============================================================================
# QMC FRAMEWORK v2.5.22 - NOUVELLES FONCTIONNALITÃ‰S (BLOC 4)
# =============================================================================
# 
# Ce bloc contient:
# 14. WebDashboard - Dashboard Web temps rÃ©el
# 15. NotificationHub - Notifications multi-canal
# 16. JobScheduler - Planification de jobs
# 17. DatabaseExporter - Export vers bases de donnÃ©es
# 18. AdversarialCircuitGenerator - GÃ©nÃ©rateur de circuits adversariaux
# =============================================================================


# =============================================================================
# 14. WEB DASHBOARD - Dashboard Web Temps RÃ©el
# =============================================================================

class WebDashboard:
    """
    Dashboard web local pour visualiser les expÃ©riences en temps rÃ©el.
    
    FonctionnalitÃ©s:
    - Visualisation des jobs en cours
    - Historique des expÃ©riences
    - Statistiques d'utilisation
    - Graphiques interactifs
    
    Usage:
        dashboard = WebDashboard(framework)
        dashboard.start(port=8080)
        # AccÃ©der Ã  http://localhost:8080
    """
    
    def __init__(self, framework: 'QMCFramework', data_dir: str = "qmc_runs"):
        self.framework = framework
        self.data_dir = data_dir
        self._server = None
        self._running = False
    
    def start(self, port: int = 8080, open_browser: bool = True):
        """
        DÃ©marre le dashboard web.
        
        Args:
            port: Port HTTP
            open_browser: Ouvrir automatiquement le navigateur
        """
        import threading
        from http.server import HTTPServer, SimpleHTTPRequestHandler
        import json
        import os
        
        dashboard_html = self._generate_dashboard_html()
        
        class DashboardHandler(SimpleHTTPRequestHandler):
            def __init__(self, *args, framework=None, data_dir=None, **kwargs):
                self.framework = framework
                self.data_dir = data_dir
                super().__init__(*args, **kwargs)
            
            def do_GET(self):
                if self.path == '/':
                    self.send_response(200)
                    self.send_header('Content-type', 'text/html')
                    self.end_headers()
                    self.wfile.write(dashboard_html.encode())
                elif self.path == '/api/status':
                    self.send_response(200)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    status = self._get_status()
                    self.wfile.write(json.dumps(status).encode())
                elif self.path == '/api/archives':
                    self.send_response(200)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    archives = self._get_archives()
                    self.wfile.write(json.dumps(archives).encode())
                else:
                    super().do_GET()
            
            def _get_status(self):
                return {
                    'connected': getattr(self.framework, '_connected', False) if self.framework else False,
                    'backend': getattr(self.framework, 'backend_name', 'N/A') if self.framework else 'N/A',
                    'project': getattr(self.framework, 'project', 'N/A') if self.framework else 'N/A'
                }
            
            def _get_archives(self):
                archives = []
                if self.data_dir and os.path.exists(self.data_dir):
                    for root, dirs, files in os.walk(self.data_dir):
                        for f in files:
                            if f.startswith('archive_') and f.endswith('.json'):
                                archives.append({
                                    'name': f,
                                    'path': os.path.join(root, f)
                                })
                return archives[:20]  # Limiter Ã  20
            
            def log_message(self, format, *args):
                pass  # Supprimer les logs
        
        # CrÃ©er le handler avec les rÃ©fÃ©rences
        def handler_factory(*args, **kwargs):
            return DashboardHandler(*args, framework=self.framework, data_dir=self.data_dir, **kwargs)
        
        try:
            self._server = HTTPServer(('localhost', port), handler_factory)
            self._running = True
            
            print(f"ğŸŒ Dashboard dÃ©marrÃ© sur http://localhost:{port}")
            
            if open_browser:
                import webbrowser
                webbrowser.open(f'http://localhost:{port}')
            
            # DÃ©marrer dans un thread sÃ©parÃ©
            thread = threading.Thread(target=self._server.serve_forever)
            thread.daemon = True
            thread.start()
            
        except Exception as e:
            print(f"âŒ Erreur dÃ©marrage dashboard: {e}")
    
    def stop(self):
        """ArrÃªte le dashboard."""
        if self._server:
            self._server.shutdown()
            self._running = False
            print("Dashboard arrÃªtÃ©")
    
    def _generate_dashboard_html(self) -> str:
        """GÃ©nÃ¨re le HTML du dashboard."""
        return '''<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>QMC Framework Dashboard</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { 
            font-family: 'Segoe UI', Arial, sans-serif; 
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: white;
            min-height: 100vh;
        }
        .header {
            background: rgba(255,255,255,0.1);
            padding: 20px;
            text-align: center;
            border-bottom: 1px solid rgba(255,255,255,0.1);
        }
        .header h1 { font-size: 28px; }
        .header .subtitle { opacity: 0.7; }
        .container { max-width: 1400px; margin: 0 auto; padding: 20px; }
        .cards { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 20px 0; }
        .card {
            background: rgba(255,255,255,0.1);
            border-radius: 15px;
            padding: 25px;
            backdrop-filter: blur(10px);
        }
        .card h3 { margin-bottom: 15px; font-size: 14px; opacity: 0.7; text-transform: uppercase; }
        .card .value { font-size: 36px; font-weight: bold; }
        .card.status-ok .value { color: #4ade80; }
        .card.status-error .value { color: #f87171; }
        .section { margin: 30px 0; }
        .section h2 { margin-bottom: 20px; padding-bottom: 10px; border-bottom: 1px solid rgba(255,255,255,0.2); }
        table { width: 100%; border-collapse: collapse; }
        th, td { padding: 12px; text-align: left; border-bottom: 1px solid rgba(255,255,255,0.1); }
        th { background: rgba(255,255,255,0.1); }
        .refresh-btn {
            background: #4361ee;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 8px;
            cursor: pointer;
            float: right;
        }
        .refresh-btn:hover { background: #3651d4; }
    </style>
</head>
<body>
    <div class="header">
        <h1>âš›ï¸ QMC Framework Dashboard</h1>
        <p class="subtitle">Quantum Computing Research Lab</p>
    </div>
    
    <div class="container">
        <button class="refresh-btn" onclick="refresh()">ğŸ”„ Refresh</button>
        
        <div class="cards">
            <div class="card" id="status-card">
                <h3>Connection Status</h3>
                <div class="value" id="status">Loading...</div>
            </div>
            <div class="card">
                <h3>Backend</h3>
                <div class="value" id="backend">-</div>
            </div>
            <div class="card">
                <h3>Project</h3>
                <div class="value" id="project">-</div>
            </div>
            <div class="card">
                <h3>Archives</h3>
                <div class="value" id="archive-count">-</div>
            </div>
        </div>
        
        <div class="section">
            <h2>ğŸ“¦ Recent Archives</h2>
            <table id="archives-table">
                <thead>
                    <tr><th>Name</th><th>Path</th></tr>
                </thead>
                <tbody id="archives-body">
                </tbody>
            </table>
        </div>
    </div>
    
    <script>
        async function refresh() {
            try {
                // Status
                const statusRes = await fetch('/api/status');
                const status = await statusRes.json();
                
                document.getElementById('status').textContent = status.connected ? 'ğŸŸ¢ Connected' : 'ğŸ”´ Disconnected';
                document.getElementById('status-card').className = 'card ' + (status.connected ? 'status-ok' : 'status-error');
                document.getElementById('backend').textContent = status.backend;
                document.getElementById('project').textContent = status.project;
                
                // Archives
                const archivesRes = await fetch('/api/archives');
                const archives = await archivesRes.json();
                
                document.getElementById('archive-count').textContent = archives.length;
                
                const tbody = document.getElementById('archives-body');
                tbody.innerHTML = '';
                archives.forEach(a => {
                    const tr = document.createElement('tr');
                    tr.innerHTML = `<td>${a.name}</td><td style="font-size: 12px; opacity: 0.7;">${a.path}</td>`;
                    tbody.appendChild(tr);
                });
                
            } catch (e) {
                console.error('Refresh error:', e);
            }
        }
        
        // Auto-refresh every 10 seconds
        refresh();
        setInterval(refresh, 10000);
    </script>
</body>
</html>'''


# =============================================================================
# 15. NOTIFICATION HUB - Notifications Multi-Canal
# =============================================================================

class NotificationHub:
    """
    Hub de notifications multi-canal.
    
    Canaux supportÃ©s:
    - Console (print)
    - Fichier log
    - Email (SMTP)
    - Webhook (Slack, Discord, etc.)
    - Sound (bip systÃ¨me)
    
    Usage:
        notif = NotificationHub()
        notif.add_channel('console')
        notif.add_channel('webhook', url='https://hooks.slack.com/...')
        notif.add_channel('email', smtp_server='smtp.gmail.com', ...)
        
        notif.notify('job_complete', {'job_id': 'xxx', 'status': 'OK'})
    """
    
    def __init__(self):
        self.channels = {}
        self.events = {
            'job_complete': 'âœ… Job terminÃ©',
            'job_error': 'âŒ Erreur job',
            'budget_alert': 'ğŸ’° Alerte budget',
            'queue_update': 'ğŸ“Š Mise Ã  jour file',
            'experiment_done': 'ğŸ”¬ ExpÃ©rience terminÃ©e'
        }
    
    def add_channel(self, channel_type: str, **config):
        """
        Ajoute un canal de notification.
        
        Args:
            channel_type: 'console', 'file', 'email', 'webhook', 'sound'
            **config: Configuration spÃ©cifique au canal
        """
        self.channels[channel_type] = {
            'type': channel_type,
            'config': config,
            'enabled': True
        }
        return self
    
    def remove_channel(self, channel_type: str):
        """Supprime un canal."""
        if channel_type in self.channels:
            del self.channels[channel_type]
    
    def enable_channel(self, channel_type: str, enabled: bool = True):
        """Active/dÃ©sactive un canal."""
        if channel_type in self.channels:
            self.channels[channel_type]['enabled'] = enabled
    
    def notify(self, event: str, data: Dict = None, message: str = None):
        """
        Envoie une notification sur tous les canaux actifs.
        
        Args:
            event: Type d'Ã©vÃ©nement ('job_complete', 'job_error', etc.)
            data: DonnÃ©es associÃ©es
            message: Message personnalisÃ© (sinon gÃ©nÃ©rÃ© automatiquement)
        """
        from datetime import datetime
        
        # Construire le message
        if message is None:
            event_label = self.events.get(event, event)
            message = f"[{datetime.now().strftime('%H:%M:%S')}] {event_label}"
            if data:
                details = ', '.join(f"{k}={v}" for k, v in data.items())
                message += f" - {details}"
        
        # Envoyer sur chaque canal
        for channel_type, channel in self.channels.items():
            if not channel['enabled']:
                continue
            
            try:
                if channel_type == 'console':
                    self._notify_console(message)
                elif channel_type == 'file':
                    self._notify_file(message, channel['config'])
                elif channel_type == 'email':
                    self._notify_email(event, message, data, channel['config'])
                elif channel_type == 'webhook':
                    self._notify_webhook(event, message, data, channel['config'])
                elif channel_type == 'sound':
                    self._notify_sound(event)
            except Exception as e:
                print(f"âš ï¸ Erreur notification {channel_type}: {e}")
    
    def _notify_console(self, message: str):
        """Notification console."""
        print(message)
    
    def _notify_file(self, message: str, config: Dict):
        """Notification fichier."""
        filepath = config.get('path', 'notifications.log')
        with open(filepath, 'a', encoding='utf-8') as f:
            f.write(message + '\n')
    
    def _notify_email(self, event: str, message: str, data: Dict, config: Dict):
        """Notification email via SMTP."""
        import smtplib
        from email.mime.text import MIMEText
        
        smtp_server = config.get('smtp_server')
        smtp_port = config.get('smtp_port', 587)
        username = config.get('username')
        password = config.get('password')
        to_email = config.get('to_email')
        from_email = config.get('from_email', username)
        
        if not all([smtp_server, username, password, to_email]):
            return
        
        msg = MIMEText(message)
        msg['Subject'] = f"QMC Framework: {event}"
        msg['From'] = from_email
        msg['To'] = to_email
        
        try:
            with smtplib.SMTP(smtp_server, smtp_port) as server:
                server.starttls()
                server.login(username, password)
                server.send_message(msg)
        except Exception as e:
            print(f"âŒ Email error: {e}")
    
    def _notify_webhook(self, event: str, message: str, data: Dict, config: Dict):
        """Notification webhook (Slack, Discord, etc.)."""
        import urllib.request
        import json
        
        url = config.get('url')
        if not url:
            return
        
        # Format Slack-compatible
        payload = {
            'text': message,
            'attachments': [{
                'color': '#36a64f' if 'complete' in event else '#ff0000',
                'fields': [
                    {'title': k, 'value': str(v), 'short': True}
                    for k, v in (data or {}).items()
                ]
            }]
        }
        
        req = urllib.request.Request(
            url,
            data=json.dumps(payload).encode(),
            headers={'Content-Type': 'application/json'}
        )
        
        try:
            urllib.request.urlopen(req, timeout=5)
        except Exception as e:
            print(f"âŒ Webhook error: {e}")
    
    def _notify_sound(self, event: str):
        """Notification sonore."""
        try:
            # Bip systÃ¨me
            print('\a', end='', flush=True)
        except:
            pass
    
    def test(self):
        """Teste tous les canaux configurÃ©s."""
        self.notify('test', {'message': 'Test notification'}, 
                   message="ğŸ§ª Test notification from QMC Framework")


# =============================================================================
# 16. JOB SCHEDULER - Planification de Jobs
# =============================================================================

class JobScheduler:
    """
    Planificateur de jobs pour exÃ©cution diffÃ©rÃ©e.
    
    Permet de:
    - Programmer des jobs Ã  une heure prÃ©cise
    - Planifier des jobs rÃ©currents
    - Attendre que la file d'attente se vide
    
    Usage:
        scheduler = JobScheduler(framework)
        
        # Planifier pour 2h du matin (heure creuse)
        scheduler.schedule(
            circuits,
            shots=4096,
            run_at="2026-01-06 02:00"
        )
        
        # Attendre que la file soit < 5 jobs
        scheduler.schedule_when_queue_low(
            circuits,
            shots=4096,
            max_queue=5
        )
    """
    
    def __init__(self, framework: 'QMCFramework'):
        self.framework = framework
        self.scheduled_jobs = []
        self._scheduler_thread = None
        self._running = False
    
    def schedule(self,
                 circuits: List,
                 shots: int = 4096,
                 run_at: str = None,
                 delay_seconds: int = None,
                 callback: Callable = None,
                 **kwargs) -> str:
        """
        Planifie un job pour exÃ©cution diffÃ©rÃ©e.
        
        Args:
            circuits: Circuits Ã  exÃ©cuter
            shots: Nombre de shots
            run_at: Datetime d'exÃ©cution (format: "YYYY-MM-DD HH:MM")
            delay_seconds: DÃ©lai en secondes (alternatif Ã  run_at)
            callback: Fonction appelÃ©e avec les rÃ©sultats
            **kwargs: Arguments additionnels pour run_on_qpu()
            
        Returns:
            ID du job planifiÃ©
        """
        from datetime import datetime, timedelta
        import uuid
        
        job_id = str(uuid.uuid4())[:8]
        
        # DÃ©terminer le moment d'exÃ©cution
        if run_at:
            run_datetime = datetime.strptime(run_at, "%Y-%m-%d %H:%M")
        elif delay_seconds:
            run_datetime = datetime.now() + timedelta(seconds=delay_seconds)
        else:
            run_datetime = datetime.now()
        
        job = {
            'id': job_id,
            'circuits': circuits,
            'shots': shots,
            'run_at': run_datetime,
            'callback': callback,
            'kwargs': kwargs,
            'status': 'scheduled',
            'created_at': datetime.now()
        }
        
        self.scheduled_jobs.append(job)
        
        print(f"ğŸ“… Job {job_id} planifiÃ© pour {run_datetime.strftime('%Y-%m-%d %H:%M')}")
        
        # DÃ©marrer le scheduler si pas dÃ©jÃ  actif
        if not self._running:
            self._start_scheduler()
        
        return job_id
    
    def schedule_when_queue_low(self,
                                 circuits: List,
                                 shots: int = 4096,
                                 max_queue: int = 5,
                                 check_interval: int = 60,
                                 timeout_hours: int = 24,
                                 **kwargs) -> str:
        """
        Planifie un job quand la file d'attente IBM est basse.
        
        Args:
            circuits: Circuits Ã  exÃ©cuter
            shots: Nombre de shots
            max_queue: Nombre max de jobs en file avant exÃ©cution
            check_interval: Intervalle de vÃ©rification en secondes
            timeout_hours: Timeout max en heures
            **kwargs: Arguments additionnels
        """
        import uuid
        from datetime import datetime
        
        job_id = str(uuid.uuid4())[:8]
        
        job = {
            'id': job_id,
            'circuits': circuits,
            'shots': shots,
            'type': 'queue_triggered',
            'max_queue': max_queue,
            'check_interval': check_interval,
            'timeout_hours': timeout_hours,
            'kwargs': kwargs,
            'status': 'waiting_for_queue',
            'created_at': datetime.now()
        }
        
        self.scheduled_jobs.append(job)
        
        print(f"ğŸ“… Job {job_id} en attente (file < {max_queue} jobs)")
        
        if not self._running:
            self._start_scheduler()
        
        return job_id
    
    def cancel(self, job_id: str) -> bool:
        """Annule un job planifiÃ©."""
        for job in self.scheduled_jobs:
            if job['id'] == job_id and job['status'] == 'scheduled':
                job['status'] = 'cancelled'
                print(f"âŒ Job {job_id} annulÃ©")
                return True
        return False
    
    def list_scheduled(self) -> List[Dict]:
        """Liste les jobs planifiÃ©s."""
        return [
            {
                'id': j['id'],
                'status': j['status'],
                'run_at': j.get('run_at', 'queue-triggered'),
                'created_at': j['created_at']
            }
            for j in self.scheduled_jobs
        ]
    
    def _start_scheduler(self):
        """DÃ©marre le thread du scheduler."""
        import threading
        
        self._running = True
        self._scheduler_thread = threading.Thread(target=self._scheduler_loop, daemon=True)
        self._scheduler_thread.start()
    
    def _scheduler_loop(self):
        """Boucle principale du scheduler."""
        from datetime import datetime
        import time
        
        while self._running:
            now = datetime.now()
            
            for job in self.scheduled_jobs:
                if job['status'] not in ('scheduled', 'waiting_for_queue'):
                    continue
                
                should_run = False
                
                # Jobs avec datetime fixe
                if job.get('run_at') and job['status'] == 'scheduled':
                    if now >= job['run_at']:
                        should_run = True
                
                # Jobs dÃ©clenchÃ©s par file basse
                elif job.get('type') == 'queue_triggered':
                    # VÃ©rifier la file (simplifiÃ© - idÃ©alement appeler l'API IBM)
                    # Pour l'instant, on simule
                    should_run = True  # TODO: ImplÃ©menter vraie vÃ©rification
                
                if should_run:
                    self._execute_job(job)
            
            # Pause
            time.sleep(10)
    
    def _execute_job(self, job: Dict):
        """ExÃ©cute un job planifiÃ©."""
        from datetime import datetime
        
        job['status'] = 'running'
        job['started_at'] = datetime.now()
        
        print(f"ğŸš€ ExÃ©cution job {job['id']}...")
        
        try:
            results = self.framework.run_on_qpu(
                job['circuits'],
                shots=job['shots'],
                **job.get('kwargs', {})
            )
            
            job['status'] = 'completed'
            job['results'] = results
            job['completed_at'] = datetime.now()
            
            if job.get('callback'):
                job['callback'](results)
            
            print(f"âœ… Job {job['id']} terminÃ©")
            
        except Exception as e:
            job['status'] = 'error'
            job['error'] = str(e)
            print(f"âŒ Job {job['id']} erreur: {e}")
    
    def stop(self):
        """ArrÃªte le scheduler."""
        self._running = False


# =============================================================================
# 17. DATABASE EXPORTER - Export vers Bases de DonnÃ©es
# =============================================================================

class DatabaseExporter:
    """
    Exporte les rÃ©sultats vers diffÃ©rentes bases de donnÃ©es.
    
    Bases supportÃ©es:
    - SQLite (local)
    - PostgreSQL
    - MongoDB
    
    Usage:
        exporter = DatabaseExporter()
        exporter.connect_sqlite("qmc_results.db")
        exporter.save(results)
        
        # Ou PostgreSQL
        exporter.connect_postgres("postgresql://user:pass@host/db")
    """
    
    def __init__(self):
        self.connection = None
        self.db_type = None
    
    def connect_sqlite(self, db_path: str = "qmc_results.db"):
        """Connecte Ã  une base SQLite."""
        import sqlite3
        
        self.connection = sqlite3.connect(db_path)
        self.db_type = 'sqlite'
        
        # CrÃ©er les tables si nÃ©cessaire
        self._create_tables_sqlite()
        
        print(f"âœ… ConnectÃ© Ã  SQLite: {db_path}")
    
    def connect_postgres(self, connection_string: str):
        """Connecte Ã  PostgreSQL."""
        try:
            import psycopg2
            self.connection = psycopg2.connect(connection_string)
            self.db_type = 'postgres'
            self._create_tables_postgres()
            print("âœ… ConnectÃ© Ã  PostgreSQL")
        except ImportError:
            raise ImportError("psycopg2 requis pour PostgreSQL: pip install psycopg2-binary")
    
    def _create_tables_sqlite(self):
        """CrÃ©e les tables SQLite."""
        cursor = self.connection.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS experiments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                project TEXT,
                backend TEXT,
                n_circuits INTEGER,
                total_shots INTEGER,
                execution_time_s REAL,
                metadata TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                experiment_id INTEGER,
                circuit_index INTEGER,
                shots INTEGER,
                unique_states INTEGER,
                n_qubits INTEGER,
                counts TEXT,
                FOREIGN KEY (experiment_id) REFERENCES experiments(id)
            )
        ''')
        
        self.connection.commit()
    
    def _create_tables_postgres(self):
        """CrÃ©e les tables PostgreSQL."""
        cursor = self.connection.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS experiments (
                id SERIAL PRIMARY KEY,
                timestamp TIMESTAMP,
                project VARCHAR(255),
                backend VARCHAR(255),
                n_circuits INTEGER,
                total_shots INTEGER,
                execution_time_s REAL,
                metadata JSONB
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS results (
                id SERIAL PRIMARY KEY,
                experiment_id INTEGER REFERENCES experiments(id),
                circuit_index INTEGER,
                shots INTEGER,
                unique_states INTEGER,
                n_qubits INTEGER,
                counts JSONB
            )
        ''')
        
        self.connection.commit()
    
    def save(self, archive_data: Dict) -> int:
        """
        Sauvegarde les rÃ©sultats dans la base.
        
        Args:
            archive_data: DonnÃ©es d'archive du framework
            
        Returns:
            ID de l'expÃ©rience crÃ©Ã©e
        """
        import json
        
        if self.connection is None:
            raise RuntimeError("Non connectÃ©! Utilisez connect_sqlite() ou connect_postgres()")
        
        cursor = self.connection.cursor()
        
        # InsÃ©rer l'expÃ©rience
        results = archive_data.get('results', [])
        
        if self.db_type == 'sqlite':
            cursor.execute('''
                INSERT INTO experiments (timestamp, project, backend, n_circuits, total_shots, execution_time_s, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                archive_data.get('timestamp'),
                archive_data.get('project'),
                archive_data.get('backend', {}).get('name'),
                len(results),
                sum(r.get('shots', 0) for r in results),
                archive_data.get('timing', {}).get('total_time_s'),
                json.dumps(archive_data.get('metadata', {}))
            ))
            experiment_id = cursor.lastrowid
            
            # InsÃ©rer les rÃ©sultats
            for r in results:
                cursor.execute('''
                    INSERT INTO results (experiment_id, circuit_index, shots, unique_states, n_qubits, counts)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    experiment_id,
                    r.get('circuit_index', 0),
                    r.get('shots', 0),
                    r.get('unique_states', 0),
                    r.get('n_qubits'),
                    json.dumps(r.get('counts', {}))
                ))
        
        elif self.db_type == 'postgres':
            cursor.execute('''
                INSERT INTO experiments (timestamp, project, backend, n_circuits, total_shots, execution_time_s, metadata)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            ''', (
                archive_data.get('timestamp'),
                archive_data.get('project'),
                archive_data.get('backend', {}).get('name'),
                len(results),
                sum(r.get('shots', 0) for r in results),
                archive_data.get('timing', {}).get('total_time_s'),
                json.dumps(archive_data.get('metadata', {}))
            ))
            experiment_id = cursor.fetchone()[0]
            
            for r in results:
                cursor.execute('''
                    INSERT INTO results (experiment_id, circuit_index, shots, unique_states, n_qubits, counts)
                    VALUES (%s, %s, %s, %s, %s, %s)
                ''', (
                    experiment_id,
                    r.get('circuit_index', 0),
                    r.get('shots', 0),
                    r.get('unique_states', 0),
                    r.get('n_qubits'),
                    json.dumps(r.get('counts', {}))
                ))
        
        self.connection.commit()
        return experiment_id
    
    def query(self, sql: str, params: tuple = None) -> List[Dict]:
        """ExÃ©cute une requÃªte SQL."""
        cursor = self.connection.cursor()
        cursor.execute(sql, params or ())
        
        columns = [desc[0] for desc in cursor.description]
        return [dict(zip(columns, row)) for row in cursor.fetchall()]
    
    def get_experiments(self, limit: int = 100) -> List[Dict]:
        """RÃ©cupÃ¨re les derniÃ¨res expÃ©riences."""
        return self.query(
            "SELECT * FROM experiments ORDER BY timestamp DESC LIMIT ?",
            (limit)
        )
    
    def close(self):
        """Ferme la connexion."""
        if self.connection:
            self.connection.close()
            self.connection = None


# =============================================================================
# 18. ADVERSARIAL CIRCUIT GENERATOR - Circuits Adversariaux
# =============================================================================

class AdversarialCircuitGenerator:
    """
    GÃ©nÃ¨re des circuits conÃ§us pour tester les limites du QPU.
    
    Types de circuits adversariaux:
    - noise_sensitivity: Circuits sensibles au bruit
    - depth_stress: Circuits trÃ¨s profonds
    - connectivity_stress: Circuits qui stressent la connectivitÃ©
    - crosstalk_probe: Circuits pour dÃ©tecter le crosstalk
    
    Usage:
        gen = AdversarialCircuitGenerator()
        circuits = gen.generate('noise_sensitivity', n_qubits=50)
        # ExÃ©cuter et analyser pour identifier les faiblesses du QPU
    """
    
    def __init__(self, seed: int = None):
        self.seed = seed
        if seed is not None:
            import numpy as np
            np.random.seed(seed)
    
    def generate(self,
                 adversarial_type: str,
                 n_qubits: int,
                 **kwargs) -> List:
        """
        GÃ©nÃ¨re des circuits adversariaux.
        
        Args:
            adversarial_type: Type de circuit adversarial
            n_qubits: Nombre de qubits
            **kwargs: Arguments spÃ©cifiques au type
            
        Returns:
            Liste de circuits
        """
        generators = {
            'noise_sensitivity': self._generate_noise_sensitive,
            'depth_stress': self._generate_depth_stress,
            'connectivity_stress': self._generate_connectivity_stress,
            'crosstalk_probe': self._generate_crosstalk_probe,
            'decoherence_test': self._generate_decoherence_test
        }
        
        if adversarial_type not in generators:
            raise ValueError(f"Type inconnu: {adversarial_type}. "
                           f"Disponibles: {list(generators.keys())}")
        
        return generators[adversarial_type](n_qubits, **kwargs)
    
    def _generate_noise_sensitive(self, n_qubits: int, n_circuits: int = 5) -> List:
        """
        GÃ©nÃ¨re des circuits trÃ¨s sensibles au bruit.
        
        Ces circuits utilisent beaucoup de portes T qui sont particuliÃ¨rement
        sensibles aux erreurs de phase.
        """
        from qiskit import QuantumCircuit
        import numpy as np
        
        circuits = []
        
        for i in range(n_circuits):
            qc = QuantumCircuit(n_qubits, n_qubits)
            
            # CrÃ©er une superposition
            for q in range(n_qubits):
                qc.h(q)
            
            # Appliquer beaucoup de portes T (sensibles au bruit de phase)
            for _ in range(20):
                for q in range(n_qubits):
                    qc.t(q)
                    qc.s(q)
                    qc.t(q)
                
                # CNOTs pour propager les erreurs
                for q in range(0, n_qubits - 1, 2):
                    qc.cx(q, q + 1)
            
            qc.measure_all()
            circuits.append(qc)
        
        return circuits
    
    def _generate_depth_stress(self, n_qubits: int, 
                                target_depth: int = 500,
                                n_circuits: int = 3) -> List:
        """
        GÃ©nÃ¨re des circuits trÃ¨s profonds pour tester la dÃ©cohÃ©rence.
        """
        from qiskit import QuantumCircuit
        import numpy as np
        
        circuits = []
        
        for i in range(n_circuits):
            qc = QuantumCircuit(n_qubits, n_qubits)
            
            layers_needed = target_depth // 2
            
            for _ in range(layers_needed):
                # Couche de rotations
                for q in range(n_qubits):
                    theta = np.random.uniform(0, np.pi)
                    qc.ry(theta, q)
                
                # Couche de CNOTs
                for q in range(0, n_qubits - 1, 2):
                    qc.cx(q, q + 1)
            
            qc.measure_all()
            circuits.append(qc)
        
        return circuits
    
    def _generate_connectivity_stress(self, n_qubits: int, n_circuits: int = 3) -> List:
        """
        GÃ©nÃ¨re des circuits qui nÃ©cessitent beaucoup de SWAPs.
        
        Ces circuits appliquent des CNOTs entre qubits distants,
        forÃ§ant le transpiler Ã  insÃ©rer des SWAPs.
        """
        from qiskit import QuantumCircuit
        import numpy as np
        
        circuits = []
        
        for i in range(n_circuits):
            qc = QuantumCircuit(n_qubits, n_qubits)
            
            # Superposition initiale
            for q in range(n_qubits):
                qc.h(q)
            
            # CNOTs entre qubits trÃ¨s distants
            for _ in range(10):
                for q in range(n_qubits // 2):
                    # CNOT entre qubit q et qubit (n-1-q)
                    target = n_qubits - 1 - q
                    if q != target:
                        qc.cx(q, target)
                
                # CNOTs en diagonale
                for q in range(n_qubits - 1):
                    qc.cx(q, (q + n_qubits // 3) % n_qubits)
            
            qc.measure_all()
            circuits.append(qc)
        
        return circuits
    
    def _generate_crosstalk_probe(self, n_qubits: int, n_circuits: int = 5) -> List:
        """
        GÃ©nÃ¨re des circuits pour dÃ©tecter le crosstalk entre qubits.
        
        Ces circuits appliquent des portes sur des qubits adjacents
        simultanÃ©ment pour dÃ©tecter les interfÃ©rences.
        """
        from qiskit import QuantumCircuit
        
        circuits = []
        
        for i in range(n_circuits):
            qc = QuantumCircuit(n_qubits, n_qubits)
            
            # Pattern 1: Tous les qubits pairs en X, impairs inactifs
            for q in range(0, n_qubits, 2):
                qc.x(q)
            
            qc.barrier()
            
            # Pattern 2: OpÃ©rations simultanÃ©es sur voisins
            for _ in range(10):
                # CNOTs simultanÃ©s sur paires adjacentes
                for q in range(0, n_qubits - 1, 2):
                    qc.cx(q, q + 1)
                
                qc.barrier()
                
                for q in range(1, n_qubits - 1, 2):
                    qc.cx(q, q + 1)
                
                qc.barrier()
            
            qc.measure_all()
            circuits.append(qc)
        
        return circuits
    
    def _generate_decoherence_test(self, n_qubits: int, 
                                    wait_layers: int = 50,
                                    n_circuits: int = 5) -> List:
        """
        GÃ©nÃ¨re des circuits avec des "pauses" pour tester la dÃ©cohÃ©rence T1/T2.
        
        Utilise des portes identitÃ© pour crÃ©er du temps d'attente.
        """
        from qiskit import QuantumCircuit
        
        circuits = []
        
        for i in range(n_circuits):
            qc = QuantumCircuit(n_qubits, n_qubits)
            
            # CrÃ©er un Ã©tat de Bell / GHZ
            qc.h(0)
            for q in range(n_qubits - 1):
                qc.cx(q, q + 1)
            
            # "Attendre" avec des barriÃ¨res
            for _ in range(wait_layers):
                qc.barrier()
                for q in range(n_qubits):
                    qc.id(q)  # Porte identitÃ©
            
            qc.measure_all()
            circuits.append(qc)
        
        return circuits
    
    def analyze_vulnerability(self, 
                              results: List[Dict],
                              adversarial_type: str) -> Dict[str, Any]:
        """
        Analyse les rÃ©sultats des circuits adversariaux.
        
        Args:
            results: RÃ©sultats d'exÃ©cution
            adversarial_type: Type de circuit utilisÃ©
            
        Returns:
            Dict avec analyse des vulnÃ©rabilitÃ©s dÃ©tectÃ©es
        """
        import numpy as np
        
        analysis = {
            'type': adversarial_type,
            'vulnerabilities': [],
            'metrics': {}
        }
        
        # Calculer des mÃ©triques de base
        entropies = []
        for r in results:
            counts = r.get('counts', {})
            if counts:
                total = sum(counts.values())
                probs = [c / total for c in counts.values()]
                entropy = -sum(p * np.log2(p) for p in probs if p > 0)
                entropies.append(entropy)
        
        if entropies:
            analysis['metrics']['avg_entropy'] = float(np.mean(entropies))
            analysis['metrics']['min_entropy'] = float(np.min(entropies))
        
        # Analyse spÃ©cifique au type
        if adversarial_type == 'noise_sensitivity':
            if analysis['metrics'].get('avg_entropy', 0) < 2:
                analysis['vulnerabilities'].append(
                    "SensibilitÃ© au bruit: entropie faible indique perte de cohÃ©rence"
                )
        
        elif adversarial_type == 'depth_stress':
            if analysis['metrics'].get('avg_entropy', 0) < 1:
                analysis['vulnerabilities'].append(
                    "DÃ©cohÃ©rence critique: circuits profonds perdent l'information"
                )
        
        elif adversarial_type == 'connectivity_stress':
            # Compter les Ã©tats uniques
            unique_states = [len(r.get('counts', {})) for r in results]
            if np.mean(unique_states) < 10:
                analysis['vulnerabilities'].append(
                    "ProblÃ¨me de connectivitÃ©: trop de SWAPs dÃ©gradent le rÃ©sultat"
                )
        
        return analysis

# =============================================================================
# PRINT VERSION INFO
# =============================================================================

def print_version_info():
    """Affiche les informations de version."""
    print(FRAMEWORK_BANNER_V2_4)
    print("  === v2.4 Features ===")
    print("  Circuit Builders: quantum_signature, zkp, timelock, oblivious_transfer")
    print("  Analyzers: xeb_advanced, honeypot, quantum_advantage")
    print("  Modules: threshold_crypto, quantum_signature, zkp")
    print()
    print("  === v2.5 Features ===")
    print("  BackendRecommender:   recommend_backend(), compare_backends()")
    print("  ResultCache:          run_on_qpu_cached(), cache_stats(), cache_clear()")
    print("  JobQueueManager:      queue_add(), queue_submit_all(), queue_results()")
    print("  NotificationManager:  setup_notifications(), test_notification()")
    print("  CircuitCostEstimator: estimate_cost(), run_on_qpu_with_confirm()")
    print()
    print("  6 Circuit Types: GHZ, IQP, Bell, Random, QFT, Cluster")
    print()


if __name__ == "__main__":
    print_version_info()
    print("Use QMCFramework class for all features.")
    print()
    print("  fw = QMCFrameworkV2_4(project='test', backend_name='ibm_torino')")
    print("  fw.initialize(mode=RunMode.QPU)")
    print("  fw.connect()")
